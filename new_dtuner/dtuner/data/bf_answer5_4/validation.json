[
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "The audio was Audiosignal was detected by ?",
      "The audio was Audiosignal was detected by spoof?",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio was Audiosignal was detected by CNN? The audio was Audiosignal was detected by CNN?",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio was Audiosignal was detected by CNN?",
      "The audio was Audiosignal was detected by ?",
      "The audio was Audiosignal was detected by spoof?",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio was Audiosignal was detected by CNN? The audio was Audiosignal was detected by CNN?",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio was Audiosignal was detected by CNN?",
      "The audio was Audiosignal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-4], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes AudioFeature which a  value of 0 was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a GTCC-4 value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-4], shap_value[0.8105])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "MFCC-4 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-4 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <shap_value> shap value: [ 0.8105 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... There are different CaptureDevice signatures ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... There are different CaptureDevice signatures ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... There are different CaptureDevice signatures ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-18], shap_value[0.6155])",
    "ref": [
      "0.6155 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.61 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-18 ......",
      "0.6155 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-18 ], <shap_value> shap value: [ 0.6155 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-8], classification[bonafide], shap_value[-0.2601])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.2601 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.2601 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2601 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-12], classification[bonafide], shap_value[0.2183])",
    "ref": [
      "Yes AudioFeature which a Yes value of 0.2183 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "0.2183 AudioFeature which a shap value of 0.2183 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.2183 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.2183 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.2183 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2183 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-48], classification[bonafide])",
    "ref": [
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-48 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-5], interpreter[shap], shap_value[-0.961])",
    "ref": [
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes a professional mixer was used ......",
      "Yes a professional mixer was used ...... Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.961 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a -0.961 value of -0.961 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.961 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-32], shap_value[0.2725])",
    "ref": [
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.272 ......",
      "0.2725 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-32 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2725 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-32 ], <shap_value> shap value: [ 0.2725 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-6], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "GTCC-6 AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "GTCC-6 AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-6 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-5], shap_value[0.3475])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "0.3475 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.347 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "0.3475 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3475 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-5 ], <shap_value> shap value: [ 0.3475 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-0], interpreter[shap], shap_value[0.4636])",
    "ref": [
      "Yes person shap was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.463 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 2 was detected by AudioFeature with a 0.4636 value of 0.4636 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of 0.4636 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4636 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of LFCC-0 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4636 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4636 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "1 was found to be the id of the speaker in the sample ......",
      "1 was found to be the id of the speaker in the sample ...... The entire recording was made using multiple microphones .....",
      "The entire recording was made using multiple microphones ..... The entire recording was made using multiple microphones .....",
      "1 was found to be the id of the speaker in the sample ......",
      "1 was found to be the id of the speaker in the sample ...... The entire recording was made using multiple microphones .....",
      "The entire recording was made using multiple microphones ..... The entire recording was made using multiple microphones .....",
      "1 was found to be the id of the speaker in the sample ......",
      "1 was found to be the id of the speaker in the sample ...... The entire recording was made using multiple microphones .....",
      "The entire recording was made using multiple microphones ..... The entire recording was made using multiple microphones .....",
      "1 was found to be the id of the speaker in the sample ......",
      "The entire recording was made using multiple microphones ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_length[5])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The CaptureDevice signature indicates a digital microphone was used ..... The CaptureDevice signature indicates a digital microphone was used .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The CaptureDevice signature indicates a digital microphone was used .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The CaptureDevice signature indicates a digital microphone was used ..... The CaptureDevice signature indicates a digital microphone was used .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The CaptureDevice signature indicates a digital microphone was used .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The CaptureDevice signature indicates a digital microphone was used ..... The CaptureDevice signature indicates a digital microphone was used .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The CaptureDevice signature indicates a digital microphone was used .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The CaptureDevice signature indicates a digital microphone was used ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_length> change length: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-10], classification[bonafide], shap_value[0.4123])",
    "ref": [
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "There were two speakers on the audio ..... Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.4123 was used to detect the sample as Audiosignal ......",
      "There were two speakers on the audio .....",
      " AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "LFCC-10 AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4123 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-13], interpreter[shap], shap_value[-0.7617])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...... Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ......",
      "Yes person 3 was detected by AudioFeature with a sha value of -0.7617 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.7617 ......",
      "Yes person -0.7617 was detected by AudioFeature with a shap value of -0.7617 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person 3 was detected by AudioFeature with a -0.7617 value of -0.7617 ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7617 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-1], interpreter[shap], shap_value[-0.8245])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of - ......",
      "Yes person MSRCC-1 was detected by AudioFeature with a shap value of -0.824MSRCC-1 ......",
      "Yes person 5 was detected by AudioFeature with a s value of -0.8245 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.824 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of MSRCC-1 ......",
      "Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of -0.8245 ......",
      "Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ...... Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of - ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8245 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-7], classification[replayed], shap_value[0.2689], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a CNN value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a  value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2689 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-11], classification[replayed], shap_value[0.6015], detected_by[CNN])",
    "ref": [
      "replayed AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There was more than one CaptureDevice ...... Yes AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.6015 value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by LFCC-11 ......",
      "Yes AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.60 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.6015 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-0], shap_value[-0.9366])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-0 ......",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN .....",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......",
      "PSRCC-0 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.936 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-0 ......",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN .....",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-0 ], <shap_value> shap value: [ -0.9366 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-35], shap_value[0.0417])",
    "ref": [
      "0.0417 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "Voice cloning was used too ......",
      "Voice cloning was used too ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "0.0417 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-35 ], <shap_value> shap value: [ 0.0417 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-58], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-58 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-32], classification[replayed], shap_value[-0.7018], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.70 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7018 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-5], shap_value[0])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-5 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "GTCC-5 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "yes AudioFeature was used to determine speaker id ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-5 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-5 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "4 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "4 was found to be the id of the speaker in the sample ......",
      "4 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "4 was found to be the id of the speaker in the sample ......",
      "4 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "4 was found to be the id of the speaker in the sample ......",
      "4 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-56], classification[bonafide], shap_value[-0.9298])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.9298 was used to detect the sample as Audiosignal ......",
      "-0.9298 AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.9298 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9298 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-56 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9298 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "The added noise is the same throughout ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The added noise is the same throughout ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The added noise is the same throughout ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The added noise is the same throughout ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The added noise is the same throughout ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The added noise is the same throughout ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The added noise is the same throughout ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-38], shap_value[-0.813])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-38 ......",
      "Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "Yes AudioFeature which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ......",
      "LFCC-38 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-38 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.813 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <shap_value> shap value: [ -0.813 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The CaptureDevice signature indicates a digital microphone was used ..... The audio sample is not a Audio_signal sample ......",
      "The CaptureDevice signature indicates a digital microphone was used .....",
      "The audio sample is not a Audio_signal sample ...... The audio sample is not a Audio_signal sample ......",
      "The audio sample is a Audio_signal sample ......",
      "The CaptureDevice signature indicates a digital microphone was used ..... The audio sample is not a Audio_signal sample ......",
      "The CaptureDevice signature indicates a digital microphone was used .....",
      "The audio sample is not a Audio_signal sample ...... The audio sample is not a Audio_signal sample ......",
      "The audio sample is a Audio_signal sample ......",
      "The CaptureDevice signature indicates a digital microphone was used ..... The audio sample is not a Audio_signal sample ......",
      "The CaptureDevice signature indicates a digital microphone was used .....",
      "The audio sample is not a Audio_signal sample ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-26], interpreter[shap], shap_value[0.6407])",
    "ref": [
      "Yes AudioFeature which a shap value of LFCC-26 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker  for the audio sample ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 2 value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 0.6407 for the audio sample ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-26 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6407 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-19], classification[bonafide], shap_value[0.2365])",
    "ref": [
      "0.2365 AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......",
      "No . Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-19 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.23 was used to detect the sample as Audiosignal ......",
      "No .",
      "Yes AudioFeature which a Yes value of 0.2365 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.2365 was used to detect the sample as Audiosignal ......",
      "0.2365 AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-19 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2365 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-43], interpreter[shap], shap_value[-0.9911])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ......",
      "Yes person 6 was detected by AudioFeature with a -0.9911 value of -0.9911 ......",
      "Yes person 6 was detected by AudioFeature with a  value of -0.9911 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of LFCC-43 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.9911 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9911 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0. ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-43 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9911 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-16], classification[replayed], detected_by[CNN])",
    "ref": [
      "The alterations are consistent with known programs ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-16 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-3], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Ye AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by  ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being Audiosignal by a MixtureModel Abstract ...... The audio file was classified as being Audiosignal by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... The audio file was classified as being Audiosignal by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being Audiosignal by a MixtureModel Abstract ...... The audio file was classified as being Audiosignal by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... The audio file was classified as being Audiosignal by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being Audiosignal by a MixtureModel Abstract ...... The audio file was classified as being Audiosignal by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... The audio file was classified as being Audiosignal by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being Audiosignal by a MixtureModel Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-27], shap_value[0.1778])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-27 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "MFCC-27 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-27 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <shap_value> shap value: [ 0.1778 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "The audio sample was found to be sed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio sample was found to be spoofed......",
      "The audio sample was found to be spoofed...... The audio sample was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample was found to be sed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio sample was found to be spoofed......",
      "The audio sample was found to be spoofed...... The audio sample was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample was found to be sed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio sample was found to be spoofed......",
      "The audio sample was found to be spoofed......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-49], classification[replayed], shap_value[0.0739], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.0739 AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by LFCC-49 ......",
      "Ye AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-49 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0739 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[1])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... 1 was found to be the id of the speaker in the sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      " was found to be the id of the speaker in the sample ......",
      "1 was found to be the id of the speaker in the sample ...... 1 was found to be the id of the speaker in the sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... 1 was found to be the id of the speaker in the sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      " was found to be the id of the speaker in the sample ......",
      "1 was found to be the id of the speaker in the sample ...... 1 was found to be the id of the speaker in the sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... 1 was found to be the id of the speaker in the sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "1 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-39], classification[replayed], shap_value[0.8099], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a s value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Yes AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "MFCC-39 AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-39 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8099 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-8], interpreter[shap], shap_value[0.585])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a  value of 0.585 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.58 ......",
      "Yes person 1 was detected by AudioFeature with a yes value of 0.585 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.585 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.585 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.585 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.585 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.585 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 1 was detected by AudioFeature with a  value of 0.585 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.585 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.585 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-7], shap_value[0.0101])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "This is a Audiosignal was detected by CNN audio shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "PSRCC-7 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.01 ......",
      "This is a Audiosignal was detected by CNN audio",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "This is a Audiosignal was detected by CNN audio shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-7 ], <shap_value> shap value: [ 0.0101 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by Yes recording was converted ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "CNN the Audiosignal was detected by CNN recording was converted ......",
      "Yes the Audiosignal was detected by C recording was converted ......",
      "Yes the Audiosignal was detected by CNN recording was converted ...... Yes the Audiosignal was detected by CNN recording was converted ......",
      "Yes the Audiosignal was detected by CNN recording was c ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes the Audiosignal was detected by CNN recording was converted ......",
      "Yes the Audiosignal was detected by CNN recording was Yes ......",
      " the Audiosignal was detected by CNN recording was converted ......",
      "Yes the Audiosignal was detected by Yes recording was converted ......",
      "Yes the Audiosignal was detected by CNN recording was converted ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... There are signs that the recording was altered .....",
      "There are signs that the recording was altered ..... There are signs that the recording was altered .....",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... There are signs that the recording was altered .....",
      "There are signs that the recording was altered ..... There are signs that the recording was altered .....",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... There are signs that the recording was altered .....",
      "There are signs that the recording was altered ..... There are signs that the recording was altered .....",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... There are signs that the recording was altered .....",
      "There are signs that the recording was altered ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-19], classification[replayed], detected_by[CNN])",
    "ref": [
      "There are anomalies ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are anomalies .....",
      "There are anomalies ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are anomalies .....",
      "There are anomalies ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are anomalies .....",
      "There are anomalies ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-19 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[6])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ...... The Midwestern word ope was used .....",
      "The Midwestern word ope was used ..... The Midwestern word ope was used .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ...... The Midwestern word ope was used .....",
      "The Midwestern word ope was used ..... The Midwestern word ope was used .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ...... The Midwestern word ope was used .....",
      "The Midwestern word ope was used ..... The Midwestern word ope was used .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8105 ...... The Midwestern word ope was used .....",
      "The Midwestern word ope was used ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-11], classification[replayed], shap_value[0.4596], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a s value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The alterations are consistent with known programs .....",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MSRCC-11 value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of 0.45 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "The alterations are consistent with known programs ..... Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4596 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-30], interpreter[shap], shap_value[0.8519])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8MFCC-3019 was used to detect the id of speaker MFCC-30 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.819 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a 0.8519 value of 0.8519 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.8519 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8519 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-37], classification[bonafide], shap_value[-0.6044])",
    "ref": [
      "Yes AudioFeature which a shap value of LFCC-37 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.6044 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-37 value of -0.6044 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-37 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-37 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6044 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The regional accent is consistent .....",
      "The regional accent is consistent ..... The regional accent is consistent .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The regional accent is consistent .....",
      "The regional accent is consistent ..... The regional accent is consistent .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The regional accent is consistent .....",
      "The regional accent is consistent ..... The regional accent is consistent .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The regional accent is consistent .....",
      "The regional accent is consistent ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-54], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-54 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... The speed is consistent throughout the recording .....",
      "The speed is consistent throughout the recording ..... The speed is consistent throughout the recording .....",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... The speed is consistent throughout the recording .....",
      "The speed is consistent throughout the recording ..... The speed is consistent throughout the recording .....",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... The speed is consistent throughout the recording .....",
      "The speed is consistent throughout the recording ..... The speed is consistent throughout the recording .....",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... The speed is consistent throughout the recording .....",
      "The speed is consistent throughout the recording ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-1], shap_value[-0.7544])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-1 ......",
      "Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.75 ......",
      "Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ......",
      "-0.7544 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-1 ......",
      "Yes AudioFeature which a shap value of 0.2365 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7544 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <shap_value> shap value: [ -0.7544 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-52], classification[replayed], shap_value[0.9951], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a replayed value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.995 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ...... Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9951 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-42], classification[replayed], shap_value[0.3363], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.33 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by LFCC-42 ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3363 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-6], classification[replayed], shap_value[-0.8714], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Ye AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...... Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by LFCC-6 ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-6 AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8714 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-7], interpreter[shap], shap_value[0.041])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a PSRCC-7 value of 0.041 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 6 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 6 was detected by AudioFeature with a sha value of 0.041 ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes person PSRCC-7 was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes person 6 was detected by AudioFeature with a PSRCC-7 value of 0.041 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.041 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-5], shap_value[0.2522])",
    "ref": [
      "LFCC-5 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.252 ......",
      "The person speaks for 6 seconds ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......",
      "The person speaks for 6 seconds .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......",
      "LFCC-5 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.252 ......",
      "The person speaks for 6 seconds ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2522 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <shap_value> shap value: [ 0.2522 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... No other spoof types are there ......",
      "No other spoof types are there ...... No other spoof types are there ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... No other spoof types are there ......",
      "No other spoof types are there ...... No other spoof types are there ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... No other spoof types are there ......",
      "No other spoof types are there ...... No other spoof types are there ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... No other spoof types are there ......",
      "No other spoof types are there ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "The audio file was classified as being converted by a MixtureModel Abstract ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "The audio file was classified as being converted by a MixtureModel Abstract ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "The audio file was classified as being converted by a MixtureModel Abstract ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio file was classified as being converted by a MixtureModel Abstract ......",
      "The audio file was classified as being converted by a MixtureModel Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...... Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ..... Interpreters is used for identifying the important features in classifying the recording .....",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...... Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ..... Interpreters is used for identifying the important features in classifying the recording .....",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...... Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ..... Interpreters is used for identifying the important features in classifying the recording .....",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...... Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ....."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-12], shap_value[0.0583])",
    "ref": [
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "The Audiosignal was detected by CNN audio was converted ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......",
      "0.0583 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "The Audiosignal was detected by CNN audio was converted ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0583 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-12 ], <shap_value> shap value: [ 0.0583 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the recording ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the recording ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...... There appears to be a cloned voice on the recording ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There appears to be a cloned voice on the recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "There was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... The entire recording was made using multiple microphones .....",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "The entire recording was made using multiple microphones ..... The entire recording was made using multiple microphones .....",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... The entire recording was made using multiple microphones .....",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "The entire recording was made using multiple microphones ..... The entire recording was made using multiple microphones .....",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... The entire recording was made using multiple microphones .....",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "The entire recording was made using multiple microphones ..... The entire recording was made using multiple microphones .....",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... The entire recording was made using multiple microphones .....",
      "The entire recording was made using multiple microphones ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-26], interpreter[shap], shap_value[-0.9625])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker -0.9625 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4469 ......",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker  for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4469 ...... Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a 7 value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-26 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker -0.9625 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9625 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-15], shap_value[0.3891])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-15 ......",
      "The audio sample is not a Audio_signal sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......",
      "MFCC-15 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "The audio sample is not a Audio_signal sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-15 ......",
      "The audio sample is not a Audio_signal sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3891 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-15 ], <shap_value> shap value: [ 0.3891 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-28], classification[replayed], shap_value[0.6383], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by 0.6383 ......",
      "LFCC-28 AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-28 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ...... Yes AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.6383 value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-28 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.6383 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-37], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-37 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio was made live ......",
      "The audio was made live ...... The audio was made live ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio was made live ......",
      "The audio was made live ...... The audio was made live ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio was made live ......",
      "The audio was made live ...... The audio was made live ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio was made live ......",
      "The audio was made live ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-33], classification[bonafide], shap_value[-0.0396])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.0396 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a -0.0396 value of -0.0396 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0396 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-33 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0396 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-59], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-59 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... The Audiosignal was detected by CNN audio was converted ......",
      "The Audiosignal was detected by spoof audio was converted ......",
      "The Audiosignal was detected by CNN audio was converted ...... The Audiosignal was detected by CNN audio was converted ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "The Audiosignal was detected by C audio was converted ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... The Audiosignal was detected by CNN audio was converted ......",
      "The Audiosignal was detected by spoof audio was converted ......",
      "The Audiosignal was detected by CNN audio was converted ...... The Audiosignal was detected by CNN audio was converted ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "The Audiosignal was detected by C audio was converted ......",
      "The Audiosignal was detected by CNN audio was converted ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... The added noise is the same throughout ......",
      "The added noise is the same throughout ...... The added noise is the same throughout ......",
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... The added noise is the same throughout ......",
      "The added noise is the same throughout ...... The added noise is the same throughout ......",
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... The added noise is the same throughout ......",
      "The added noise is the same throughout ...... The added noise is the same throughout ......",
      "No the recording uses multiple microphones ......",
      "The added noise is the same throughout ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-2], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-55], classification[replayed], detected_by[CNN])",
    "ref": [
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-55 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-31], classification[bonafide])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-31 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-4], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-26], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-26 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-9], classification[bonafide], shap_value[-0.6748])",
    "ref": [
      "Yes AudioFeature which a bonafide value of -0.6748 was used to detect the sample as Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Yes AudioFeature which a shap value of -0.6748 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.67 was used to detect the sample as Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.6748 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.6748 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6748 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6748 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.6748 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.6748 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6748 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6748 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[professional_mixer])",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ......",
      "spoof a professional mixer was used ......",
      " a professional mixer was used ......",
      "The next CaptureDevice starts at 10 seconds ...... Yes a professional mixer was used ......",
      "Yes a professional mixer was used ...... Yes a professional mixer was used ......",
      "The next CaptureDevice starts at 10 seconds ......",
      "spoof a professional mixer was used ......",
      " a professional mixer was used ......",
      "The next CaptureDevice starts at 10 seconds ...... Yes a professional mixer was used ......",
      "Yes a professional mixer was used ...... Yes a professional mixer was used ......",
      "Yes a professional mixer was used ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ professional_mixer ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-20], shap_value[-0.7234])",
    "ref": [
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-20 ......",
      "LFCC-20 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.723 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-20 ......",
      "LFCC-20 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <shap_value> shap value: [ -0.7234 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-0], interpreter[shap], shap_value[0.3962])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3 ......",
      "Yes person 5 was detected by AudioFeature with a PSRCC-0 value of 0.3962 ......",
      "Yes person 5 was detected by AudioFeature with a sh value of 0.3962 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.3962 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.3962 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3962 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "No other features were used ...... No other features were used ......",
      "A CaptureDevice signature was detected ......",
      "A CaptureDevice signature was detected ...... No other features were used ......",
      "No other features were used ...... No other features were used ......",
      "A CaptureDevice signature was detected ......",
      "A CaptureDevice signature was detected ...... No other features were used ......",
      "No other features were used ...... No other features were used ......",
      "A CaptureDevice signature was detected ......",
      "A CaptureDevice signature was detected ...... No other features were used ......",
      "No other features were used ...... No other features were used ......",
      "No other features were used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-5], classification[bonafide])",
    "ref": [
      "2 was found to be the id of the speaker in the sample ......",
      "2 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "2 was found to be the id of the speaker in the sample ......",
      "2 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "2 was found to be the id of the speaker in the sample ......",
      "2 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "2 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-16], classification[replayed], shap_value[-0.1883], detected_by[CNN])",
    "ref": [
      "shap AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The entire recording was made using multiple microphones ..... Yes AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Y AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a replayed value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1883 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There are multiple CaptureDevice signatures as well ...... There are multiple CaptureDevice signatures as well ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There are multiple CaptureDevice signatures as well ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are multiple CaptureDevice signatures as well ...... There are multiple CaptureDevice signatures as well ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There are multiple CaptureDevice signatures as well ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are multiple CaptureDevice signatures as well ...... There are multiple CaptureDevice signatures as well ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There are multiple CaptureDevice signatures as well ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are multiple CaptureDevice signatures as well ...... There are multiple CaptureDevice signatures as well ......",
      "There are multiple CaptureDevice signatures as well ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[PSRCC-5], interpreter[shap], shap_value[-0.0051])",
    "ref": [
      "Yes AudioFeature which a yes value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "There appears to be a cloned voice on the audio ...... Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker -0.0051 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "There appears to be a cloned voice on the audio ...... Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ PSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0051 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[text_to_speech], classified_by[feature])",
    "ref": [
      "Other spoofs also show the audio same was Audio_signal ......",
      "Other features also show the audio same was Audio_signal ...... Other features also show the audio same was Audio_signal ......",
      "person 8 spoke the audio sample ......",
      "person 8 spoke the audio sample ...... Other features also show the audio same was Audio_signal ......",
      "Other featus also show the audio same was Audio_signal ......",
      "Other spoofs also show the audio same was Audio_signal ......",
      "Other features also show the audio same was Audio_signal ...... Other features also show the audio same was Audio_signal ......",
      "person 8 spoke the audio sample ......",
      "person 8 spoke the audio sample ...... Other features also show the audio same was Audio_signal ......",
      "Other featus also show the audio same was Audio_signal ......",
      "Other features also show the audio same was Audio_signal ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ text_to_speech ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-0], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-0 AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "The audio sample was found to be spoofed......",
      "The audio sample was found to be spoofed...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-0 AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "The audio sample was found to be spoofed......",
      "The audio sample was found to be spoofed...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-0 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-15], classification[bonafide], shap_value[0.8066])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "0.8066 AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "The person speaks for 6 seconds ..... Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "The person speaks for 6 seconds .....",
      "Yes AudioFeature which a sh value of 0.8066 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-15 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8066 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-1], shap_value[0.3386])",
    "ref": [
      "0.3386 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "There appears to be a cloned voice on the audio ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-1 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.33 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "There appears to be a cloned voice on the audio ......",
      "0.3386 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "There appears to be a cloned voice on the audio ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <shap_value> shap value: [ 0.3386 ]> )"
  },
  {
    "mr": "inform(classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... The recording was made live ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "The recording was made live ...... The recording was made live ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... The recording was made live ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "The recording was made live ...... The recording was made live ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... The recording was made live ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "The recording was made live ...... The recording was made live ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... The recording was made live ......",
      "The recording was made live ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-3], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a yes value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "There are anomalies .....",
      "There are anomalies ..... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of GTCC-3 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a  value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-10], determined[speaker_id])",
    "ref": [
      " AudioFeature was used to determine speaker id ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "GTCC-10 AudioFeature was used to determine speaker id ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      " AudioFeature was used to determine speaker id ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "GTCC-10 AudioFeature was used to determine speaker id ......",
      "Interpreters gave ConstantQFeature a value of 0.667 AudioFeature a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .....",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-10 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-49], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-49 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes the recording is fake .....",
      "Yes the recording is fake ..... Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Y the recording is fake .....",
      "spoofed the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes the recording is fake .....",
      "Yes the recording is fake ..... Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Y the recording is fake .....",
      "spoofed the recording is fake .....",
      "Yes the recording is fake ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-42], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-42 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-8], classification[bonafide])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-41], classification[bonafide], shap_value[-0.7678])",
    "ref": [
      "shap AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-41 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.7678 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.7678 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6155 ...... Yes AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7678 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-41 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7678 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[2])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "There were two speakers on the audio ..... There were two speakers on the audio .....",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... There were two speakers on the audio .....",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "There were two speakers on the audio ..... There were two speakers on the audio .....",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... There were two speakers on the audio .....",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "There were two speakers on the audio ..... There were two speakers on the audio .....",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... There were two speakers on the audio .....",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "There were two speakers on the audio ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-42], interpreter[shap], shap_value[0.3174])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a sh value of 0.3174 ......",
      "The regional accent is consistent .....",
      "Yes person shap was detected by AudioFeature with a shap value of 0.3174 ......",
      "The regional accent is consistent ..... Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a 6 value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 6 was detected by AudioFeature with a sh value of 0.3174 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.3174 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-42 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3174 ]> )"
  },
  {
    "mr": "inform(speaker_id[8])",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ...... person 8 spoke the audio sample ......",
      "person 8 spoke the audio sample ...... person 8 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... person 8 spoke the audio sample ......",
      "person 8 spoke the audio sample ...... person 8 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... person 8 spoke the audio sample ......",
      "person 8 spoke the audio sample ...... person 8 spoke the audio sample ......",
      "person 8 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-38], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-38 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-27], classification[replayed], shap_value[-0.0037], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a Yes value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ...... Yes AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.3962 ......",
      "Yes AudioFeature which a  value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-27 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0037 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[digital])",
    "ref": [
      "The signal is consistent with a spoof CaptureDevice .....",
      "The signal is consistent with a dig CaptureDevice .....",
      "The signal is consistent with a digital CaptureDevice ..... The signal is consistent with a digital CaptureDevice .....",
      "No other spoof types are there ...... The signal is consistent with a digital CaptureDevice .....",
      "No other spoof types are there ......",
      "The signal is consistent with a spoof CaptureDevice .....",
      "The signal is consistent with a dig CaptureDevice .....",
      "The signal is consistent with a digital CaptureDevice ..... The signal is consistent with a digital CaptureDevice .....",
      "No other spoof types are there ...... The signal is consistent with a digital CaptureDevice .....",
      "No other spoof types are there ......",
      "The signal is consistent with a digital CaptureDevice ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ digital ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-0], classification[replayed], shap_value[-0.5188], detected_by[CNN])",
    "ref": [
      "The audio sample was found to be spoofed...... Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "PSRCC-0 AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio sample was found to be spoofed......",
      "Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by  ......",
      " AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5188 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The alterations are consistent with known programs .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The alterations are consistent with known programs ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-28], classification[replayed], shap_value[0.4742], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by  ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by 0.4742 ......",
      "Yes AudioFeature which a sh value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MFCC-28 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-28 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4742 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-43], interpreter[shap], shap_value[-0.5918])",
    "ref": [
      "Yes AudioFeature which a 7 value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a s value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a 7 value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-43 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5918 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-15], shap_value[0.604])",
    "ref": [
      "This is a Audiosignal was detected by CNN audio shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......",
      "LFCC-15 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......",
      "This is a Audiosignal was detected by CNN audio",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......",
      "This is a Audiosignal was detected by CNN audio shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......",
      "LFCC-15 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......",
      "This is a Audiosignal was detected by CNN audio",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.604 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-15 ], <shap_value> shap value: [ 0.604 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-22], shap_value[0.8259])",
    "ref": [
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.585 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.585 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-22 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "MFCC-22 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.585 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8259 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-22 ], <shap_value> shap value: [ 0.8259 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-36], interpreter[shap], shap_value[-0.493])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.493 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 7 was detected by AudioFeature with a yes value of -0.493 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "Yes person 7 was detected by AudioFeature with a s value of -0.493 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.493 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.493 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-40], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording was made live ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording was made live ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording was made live ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording was made live ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording was made live ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording was made live ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-40 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-19], classification[replayed], shap_value[0.5165], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.5165 value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-19 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5165 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-12], determined[speaker_id])",
    "ref": [
      "y AudioFeature was used to determine speaker id ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... yes AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-12 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-38], shap_value[-0.8306])",
    "ref": [
      "MFCC-38 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "MFCC-38 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "Yes AudioFeature which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-38 ], <shap_value> shap value: [ -0.8306 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[no_microphone])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ...... No I do not recognize any of the CaptureDevice signatures ......",
      "No I do not recognize any of the CaptureDevice signatures ...... No I do not recognize any of the CaptureDevice signatures ......",
      " I do not recognize any of the CaptureDevice signatures ......",
      "No I do recognize any of the CaptureDevice signatures ......",
      "no_microphone I do not recognize any of the CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ...... No I do not recognize any of the CaptureDevice signatures ......",
      "No I do not recognize any of the CaptureDevice signatures ...... No I do not recognize any of the CaptureDevice signatures ......",
      " I do not recognize any of the CaptureDevice signatures ......",
      "No I do not recognize any of the CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ no_microphone ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-10], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8066 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made with a mobile device and some with a computer ..... Some of the recording was made with a mobile device and some with a computer .....",
      "Some of the recording was made with a mobile device and some with a spoof .....",
      "Some of the recording was made with a mobile device and some with a comp .....",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...... Some of the recording was made with a mobile device and some with a computer .....",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "Some of the recording was made with a mobile device and some with a computer ..... Some of the recording was made with a mobile device and some with a computer .....",
      "Some of the recording was made with a mobile device and some with a spoof .....",
      "Some of the recording was made with a mobile device and some with a comp .....",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...... Some of the recording was made with a mobile device and some with a computer .....",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "Some of the recording was made with a mobile device and some with a computer ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-56], shap_value[-0.1399])",
    "ref": [
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-56 ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "-0.1399 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......",
      "Yes AudioFeature which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1399 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-56 ], <shap_value> shap value: [ -0.1399 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-18], interpreter[shap], shap_value[-0.6226])",
    "ref": [
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6226 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6226 was used to detect the id of speaker -0.6226 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.6226 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a -0.6226 value of -0.6226 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6226 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-15], classification[replayed], shap_value[-0.3564], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a  value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.3564 AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Voice cloning was used too ...... Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Voice cloning was used too ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by LFCC-15 ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-15 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3564 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4123 was used to detect the sample as Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-39], classification[replayed], shap_value[-0.6783], detected_by[CNN])",
    "ref": [
      "Constant-Q Cepstral Coefficients ......",
      "Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Constant-Q Cepstral Coefficients ...... Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.6783 value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by shap ......",
      " AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6783 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-5], interpreter[shap], shap_value[0.4106])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a 3 value of 0.4106 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.4106 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.4106 ......",
      "This is a Audiosignal was detected by CNN audio Yes person 3 was detected by AudioFeature with a shap value of 0.4106 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.4106 ......",
      "Yes person 3 was detected by AudioFeature with a sh value of 0.4106 ......",
      "This is a Audiosignal was detected by CNN audio",
      "Yes person 3 was detected by AudioFeature with a shap value of MFCC-5 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4106 ......",
      "Yes person 3 was detected by AudioFeature with a 3 value of 0.4106 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.4106 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4106 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-0], feature[MFCC-0], feature[LFCC-2], feature[MFCC-4])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Voice cloning was used ......",
      "Voice cloning was used ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC- had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Voice cloning was used ......",
      "Voice cloning was used ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC- had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-0 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-6], classification[bonafide], shap_value[-0.5029])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-6 value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "LFCC-6 AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5029 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5029 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-7], shap_value[-0.3273])",
    "ref": [
      "LFCC-7 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-7 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ......",
      "LFCC-7 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-7 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3273 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-7 ], <shap_value> shap value: [ -0.3273 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-59], interpreter[shap], shap_value[-0.9055])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9055 ......",
      "Yes person 3 was detected by AudioFeature with a LFCC-59 value of -0.9055 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.9055 ......",
      "Yes person 3 was detected by AudioFeature with a  value of -0.9055 ......",
      "It appears that part of the recording was sped up ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "It appears that part of the recording was sped up ...... Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-59 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9055 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-27], interpreter[shap], shap_value[0.147])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.147 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-27 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a 0.147 value of 0.147 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ...... Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker yes for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.8245 ......",
      "Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.147 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-0], interpreter[shap], shap_value[-0.5486])",
    "ref": [
      "The recording file was classified as being synthetic by a MixtureModel Abstract ...... Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.486 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 5 for the audio sample ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a LFCC-0 value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.-0.5486486 was used to detect the id of speaker -0.5486 for the audio sample ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ...... Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5486 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-36], classification[replayed], shap_value[0.0482], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by LFCC-36 ......",
      "Yes AudioFeature which a sha value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-36 AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.0482 value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-36 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0482 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... Constant-Q Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... Constant-Q Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ...... Constant-Q Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7234 ......",
      "Constant-Q Cepstral Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-21], classification[bonafide])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-21 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "A single Audiosignal signature was detected ......",
      "A single Audiosignal signature was detected ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "A single Audiosignal signature was detected ......",
      "A single Audiosignal signature was detected ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "A single Audiosignal signature was detected ......",
      "A single Audiosignal signature was detected ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There appears to be a cloned voice on the audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... This is a Audiosignal was detected by CNN audio",
      "This is a Audiosignal was detected by spoof audio",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "This is a Audiosignal was detected by CNN audio This is a Audiosignal was detected by CNN audio",
      "This is a Audiosignal was detected by C audio",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... This is a Audiosignal was detected by CNN audio",
      "This is a Audiosignal was detected by spoof audio",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "This is a Audiosignal was detected by CNN audio This is a Audiosignal was detected by CNN audio",
      "This is a Audiosignal was detected by C audio",
      "This is a Audiosignal was detected by CNN audio"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-12], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-12], interpreter[shap], shap_value[0.2519])",
    "ref": [
      "Yes person PSRCC-12 was detected by AudioFeature with a shap value of 0.2519 ......",
      "Yes person 6 was detected by AudioFeature with a 6 value of 0.2519 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.2519 ......",
      "Yes person 6 was detected by AudioFeature with a sha value of 0.2519 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.251 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9055 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.2519 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.2519 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.2519 ......",
      "Yes person PSRCC-12 was detected by AudioFeature with a shap value of 0.2519 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.2519 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2519 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-20], feature[MFCC-10], feature[LFCC-5], feature[MFCC-3])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC M had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-20 had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC M had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-20 had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-20 ], <feature> feature: [ MFCC-10 ], <feature> feature: [ LFCC-5 ], <feature> feature: [ MFCC-3 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-27], interpreter[shap], shap_value[0.0828])",
    "ref": [
      "Yes AudioFeature which a 4 value of 0.0828 was used to detect the id of speaker 4 for the audio sample ......",
      "The alterations are consistent with known programs .....",
      "Yes AudioFeature which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.082 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.0828 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0828 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0828 was used to detect the id of speaker LFCC-27 for the audio sample ......",
      "The alterations are consistent with known programs ..... Yes AudioFeature which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-27 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a 4 value of 0.0828 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0828 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-2], classification[bonafide], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "GTCC-2 AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Other samples show the person speaks at a different speed ......",
      "Yes AudioFeature which a GTCC-2 value of 1 was used to detect the sample as Audiosignal ......",
      "Other samples show the person speaks at a different speed ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 1 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-41], interpreter[shap], shap_value[-0.599])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.599 was used to detect the id of speaker LFCC-41 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.599 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-41 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.599 was used to detect the id of speaker  for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.599 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.599 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-25], interpreter[shap], shap_value[-0.5195])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of yes ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.595 ......",
      "Yes person 1 was detected by AudioFeature with a -0.5195 value of -0.5195 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Yes person 1 was detected by AudioFeature with a shap value of -0.5195 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5195 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.5195 ......",
      "Yes person 1 was detected by AudioFeature with a sh value of -0.5195 ......",
      "Yes person -0.5195 was detected by AudioFeature with a shap value of -0.5-0.519595 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person 1 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5195 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5195 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ...... There was no CaptureDevice signature on the recording ......",
      "There was no CaptureDevice signature on the recording ...... There was no CaptureDevice signature on the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ...... There was no CaptureDevice signature on the recording ......",
      "There was no CaptureDevice signature on the recording ...... There was no CaptureDevice signature on the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ...... There was no CaptureDevice signature on the recording ......",
      "There was no CaptureDevice signature on the recording ...... There was no CaptureDevice signature on the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ...... There was no CaptureDevice signature on the recording ......",
      "There was no CaptureDevice signature on the recording ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-20], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-20 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-2], shap_value[0.463])",
    "ref": [
      "MFCC-2 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4 ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......",
      "MFCC-2 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.463 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-2 ], <shap_value> shap value: [ 0.463 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Linear physicalattribute Cepstral Coefficients ......",
      "Linear physicalattribute Cepstral Coefficients ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Linear physicalattribute Cepstral Coefficients ......",
      "Linear physicalattribute Cepstral Coefficients ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Linear physicalattribute Cepstral Coefficients ......",
      "Linear physicalattribute Cepstral Coefficients ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Linear physicalattribute Cepstral Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3386 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-4], interpreter[shap], shap_value[-0.174])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.17 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a 4 value of -0.174 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Yes AudioFeature which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.17-0.174 was used to detect the id of speaker -0.174 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.174 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.17 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.174 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-8], classification[bonafide], shap_value[0.9013])",
    "ref": [
      "Y AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Voice cloning was used ......",
      "LFCC-8 AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Voice cloning was used ...... Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9013 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-32], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-32 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-21], interpreter[shap], shap_value[-0.7655])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker LFCC-21 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-21 value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-21 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7655 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-12], shap_value[-0.5508])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ......",
      "PSRCC-12 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "Yes AudioFeature which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5508 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <shap_value> shap value: [ -0.5508 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      ">1 the recording uses multiple microphones ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "No the recording uses multiple microphones ...... No the recording uses multiple microphones ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...... No the recording uses multiple microphones ......",
      " the recording uses multiple microphones ......",
      ">1 the recording uses multiple microphones ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "No the recording uses multiple microphones ...... No the recording uses multiple microphones ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...... No the recording uses multiple microphones ......",
      " the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ...... A single Audiosignal signature was detected ......",
      "A single Audiosignal signature was detected ...... A single Audiosignal signature was detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ...... A single Audiosignal signature was detected ......",
      "A single Audiosignal signature was detected ...... A single Audiosignal signature was detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ...... A single Audiosignal signature was detected ......",
      "A single Audiosignal signature was detected ...... A single Audiosignal signature was detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0417 ......",
      "A single Audiosignal signature was detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[2], speaker_length[6])",
    "ref": [
      "The person speaks for  seconds .....",
      "The person speaks for 6 seconds ..... The person speaks for 6 seconds .....",
      "The person speaks for multi_speaker seconds .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ...... The person speaks for 6 seconds .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "The person speaks for  seconds .....",
      "The person speaks for 6 seconds ..... The person speaks for 6 seconds .....",
      "The person speaks for multi_speaker seconds .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ...... The person speaks for 6 seconds .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "The person speaks for 6 seconds ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ 2 ], <speaker_length> speaker length: [ 6 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Yes AudioFeature which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ......",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..... Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .....",
      "Interpreters gave ConstantQFeature a value of 0.324 AudioFeature a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-41], interpreter[shap], shap_value[0.4469])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4469 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4469 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4469 ......",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Yes person 2 was detected by AudioFeature with a shap value of 0.4469 ......",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person MFCC-41 was detected by AudioFeature with a shap value of 0.4469 ......",
      "Yes person 2 was detected by AudioFeature with a  value of 0.4469 ......",
      "Yes person 2 was detected by AudioFeature with a MFCC-41 value of 0.4469 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4469 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4469 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-9], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 1 value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "GTCC-9 AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Ye AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-42], interpreter[shap], shap_value[-0.4738])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a LFCC-42 value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-42 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4738 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "A CaptureDevice signature was detected ...... A CaptureDevice signature was detected ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ...... A CaptureDevice signature was detected ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "A CaptureDevice signature was detected ...... A CaptureDevice signature was detected ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ...... A CaptureDevice signature was detected ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "A CaptureDevice signature was detected ...... A CaptureDevice signature was detected ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ...... A CaptureDevice signature was detected ......",
      "Yes AudioFeature which a shap value of -0.2601 was used to detect the sample as Audiosignal ......",
      "A CaptureDevice signature was detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(model[GMM], spoof_type[synthetic], classification[spoof])",
    "ref": [
      "The recording file was classified as being GMM by a MixtureModel Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... The recording file was classified as being synthetic by a MixtureModel Abstract ......",
      "The recording file was classified as being synthet by a MixtureModel Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ...... The recording file was classified as being synthetic by a MixtureModel Abstract ......",
      "The recording file was classified as being GMM by a MixtureModel Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ...... The recording file was classified as being synthetic by a MixtureModel Abstract ......",
      "The recording file was classified as being synthet by a MixtureModel Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0101 ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ...... The recording file was classified as being synthetic by a MixtureModel Abstract ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ......"
    ],
    "new_mr": "<inform> inform ( <model> model: [ GMM ], <spoof_type> spoof type: [ synthetic ], <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ...... The alterations are consistent with known programs .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ...... The alterations are consistent with known programs .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ...... The alterations are consistent with known programs .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "The alterations are consistent with known programs ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The speaker is from the midwestern United States ...... The speaker is from the midwestern United States ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... The speaker is from the midwestern United States ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "The speaker is from the midwestern United States ...... The speaker is from the midwestern United States ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... The speaker is from the midwestern United States ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "The speaker is from the midwestern United States ...... The speaker is from the midwestern United States ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... The speaker is from the midwestern United States ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "The speaker is from the midwestern United States ...... The speaker is from the midwestern United States ......",
      "The speaker is from the midwestern United States ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "N . There was more than one CaptureDevice ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "No . No . There was more than one CaptureDevice ......",
      "No . No . No . There was more than one CaptureDevice ......",
      "No .",
      "No . There are different CaptureDevice signatures ...... There was more than one CaptureDevice ......",
      "No . There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... No . There are different CaptureDevice signatures ...... There was more than one CaptureDevice ......",
      "spoof . There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ......",
      "No . There was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-32], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-32 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-6], classification[bonafide], shap_value[-0.9786])",
    "ref": [
      "Yes AudioFeature which a -0.9786 value of -0.9786 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ...... Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.9786 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ......",
      "Yes AudioFeature which a -0.9786 value of -0.9786 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9786 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9786 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], num_samples[3])",
    "ref": [
      "There were three cuts ...... There were three cuts ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... There were three cuts ......",
      "There were three cuts ...... There were three cuts ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... There were three cuts ......",
      "There were three cuts ...... There were three cuts ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... There were three cuts ......",
      "There were three cuts ...... There were three cuts ......",
      "There were three cuts ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <num_samples> num samples: [ 3 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[mixer])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ...... A professional mixer was used ......",
      "A professional mixer was used ...... A professional mixer was used ......",
      "A professional mi was used ......",
      "A professional spoof was used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ...... A professional mixer was used ......",
      "A professional mixer was used ...... A professional mixer was used ......",
      "A professional mi was used ......",
      "A professional spoof was used ......",
      "A professional mixer was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ mixer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-23], classification[bonafide], shap_value[0.2316])",
    "ref": [
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "0.2316 AudioFeature which a shap value of 0.2316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.2316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.2316 was used to detect the sample as Audiosignal ......",
      "Interpreters gave AudioFeature a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Yes AudioFeature which a shap value of 0.2316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2316 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2316 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.2316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2316 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2316 ]> )"
  },
  {
    "mr": "inform(speaker_id[2])",
    "ref": [
      "2 was found to be the id of the speaker in the sample ...... 2 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... 2 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "2 was found to be the id of the speaker in the sample ...... 2 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... 2 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "2 was found to be the id of the speaker in the sample ...... 2 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...... 2 was found to be the id of the speaker in the sample ......",
      "2 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made using a  ......",
      "Some of the recording was made using a spoof ......",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess .....",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess ..... Some of the recording was made using a computer ......",
      "Some of the recording was made using a  ......",
      "Some of the recording was made using a spoof ......",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess .....",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess ..... Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-38], interpreter[shap], shap_value[-0.9714])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a -0.9714 value of -0.9714 ......",
      "Yes person 3 was detected by AudioFeature with a s value of -0.9714 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "Yes person LFCC-38 was detected by AudioFeature with a shap value of -0.9714 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9714 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes person 3 was detected by AudioFeature with a -0.9714 value of -0.9714 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.9714 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9714 ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "The Audiosignal was detected by CNN audio was converted ......",
      "person 6 spoke the audio sample ...... person 6 spoke the audio sample ......",
      "The Audiosignal was detected by CNN audio was converted ...... person 6 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "The Audiosignal was detected by CNN audio was converted ......",
      "person 6 spoke the audio sample ...... person 6 spoke the audio sample ......",
      "The Audiosignal was detected by CNN audio was converted ...... person 6 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "The Audiosignal was detected by CNN audio was converted ......",
      "person 6 spoke the audio sample ...... person 6 spoke the audio sample ......",
      "person 6 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the recording uses multiple microphones ...... No the recording uses multiple microphones ......",
      "N the recording uses multiple microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      ">1 the recording uses multiple microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ...... No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... No the recording uses multiple microphones ......",
      "N the recording uses multiple microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      ">1 the recording uses multiple microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ...... No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-4], interpreter[shap], shap_value[-0.0612])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.061 ......",
      "Yes person 2 was detected by AudioFeature with a 2 value of -0.0612 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.061shap ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 2 was detected by AudioFeature with a shap value of -0.0612 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.0612 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.0612 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes person 2 was detected by AudioFeature with a shap value of MFCC-4 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of -0.0612 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.061 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.0612 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0612 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-0], interpreter[shap], shap_value[-0.7532])",
    "ref": [
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7532 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a  value of -0.7532 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 1 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... Yes AudioFeature which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.7532 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "Yes AudioFeature which a shap value of -0.7532 was used to detect the id of speaker -0.7532 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7532 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-0], classification[replayed], shap_value[-0.4974], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "LFCC-0 AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.497 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4974 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-8], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a sha value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Y AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0 was used to detect the sample as Audiosignal ......",
      "GTCC-8 AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-10], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "person 8 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of GTCC-10 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a s value of 1 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 2 value of 1 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker  for the audio sample ......",
      "person 8 spoke the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-53], interpreter[shap], shap_value[-0.6426])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.6426 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.6426 value of -0.6426 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.42 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.-0.642642-0.6426 was used to detect the id of speaker -0.6426 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-53 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6426 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-6], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "CNN AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by  ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-4], classification[replayed], shap_value[0.9456], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a MFCC-4 value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a  value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The speed is consistent throughout the recording .....",
      "Yes AudioFeature which a shap value of 0.94 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MFCC-4 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9456 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are anomalies .....",
      "There are anomalies ..... There are anomalies .....",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are anomalies .....",
      "There are anomalies ..... There are anomalies .....",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are anomalies .....",
      "There are anomalies ..... There are anomalies .....",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are anomalies .....",
      "There are anomalies ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-39], shap_value[0.185])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......",
      "0.185 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......",
      "Yes AudioFeature which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.185 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-39 ], <shap_value> shap value: [ 0.185 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-12], classification[replayed], shap_value[0.9509], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... Yes AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "Yes AudioFeature which a  value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by 0.9509 ......",
      " AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9509 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-7], shap_value[1])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "1 determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "1 determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-7 ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "There was more than one CaptureDevice ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one CaptureDevice ......",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one CaptureDevice ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one CaptureDevice ......",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one CaptureDevice ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one CaptureDevice ......",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one CaptureDevice ...... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-8], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-4], classification[bonafide])",
    "ref": [
      "The added noise is the same throughout ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The added noise is the same throughout ......",
      "The added noise is the same throughout ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The added noise is the same throughout ......",
      "The added noise is the same throughout ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The added noise is the same throughout ......",
      "The added noise is the same throughout ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-2], interpreter[shap], shap_value[-0.5958])",
    "ref": [
      "Yes AudioFeature which a LFCC-2 value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-2 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a  value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "The signal is consistent with a digital CaptureDevice .....",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "The signal is consistent with a digital CaptureDevice ..... Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a LFCC-2 value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5958 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-18], interpreter[shap], shap_value[0.8507])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker 0.8507 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.85 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a MFCC-18 value of 0.8507 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.8507 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ...... Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker 0.8507 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8507 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-13], shap_value[-0.9535])",
    "ref": [
      "-0.9535 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "Yes the Audiosignal was detected by CNN recording was converted ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9 ......",
      "Yes the Audiosignal was detected by CNN recording was converted ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "-0.9535 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "Yes the Audiosignal was detected by CNN recording was converted ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-13 ], <shap_value> shap value: [ -0.9535 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-29], interpreter[shap], shap_value[0.0397])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0.0397 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person 2 was detected by AudioFeature with a yes value of 0.0397 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 2 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.0397 ......",
      "Yes person 0.0397 was detected by AudioFeature with a shap value of 0.0397 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0397 ]> )"
  },
  {
    "mr": "inform(response[yes], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "yes the audio sample was detected as PhysicalAccess was detected by replayed .....",
      "y the audio sample was detected as PhysicalAccess was detected by CNN .....",
      "CNN the audio sample was detected as PhysicalAccess was detected by CNN .....",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ...... yes the audio sample was detected as PhysicalAccess was detected by CNN .....",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.9911 ......",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN ..... yes the audio sample was detected as PhysicalAccess was detected by CNN .....",
      "yes the audio sample was detected as PhysicalAccess was detected by  .....",
      "yes the audio sample was detected as PhysicalAccess was detected by replayed .....",
      "y the audio sample was detected as PhysicalAccess was detected by CNN .....",
      "CNN the audio sample was detected as PhysicalAccess was detected by CNN .....",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by  audio sample was PhysicalAccess .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ...... The Audiosignal was detected by CNN audio sample was PhysicalAccess .....",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess ..... The Audiosignal was detected by CNN audio sample was PhysicalAccess .....",
      "The Audiosignal was detected by spoof audio sample was PhysicalAccess .....",
      "The Audiosignal was detected by  audio sample was PhysicalAccess .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8306 ...... The Audiosignal was detected by CNN audio sample was PhysicalAccess .....",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess ..... The Audiosignal was detected by CNN audio sample was PhysicalAccess .....",
      "The Audiosignal was detected by spoof audio sample was PhysicalAccess .....",
      "The Audiosignal was detected by CNN audio sample was PhysicalAccess ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-28], classification[bonafide], shap_value[-0.4318])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a Yes value of -0.4318 was used to detect the sample as Audiosignal ......",
      "-0.4318 AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.4318 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4318 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-28 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4318 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-31], shap_value[0.3977])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0.3977 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3977 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <shap_value> shap value: [ 0.3977 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-39], interpreter[shap], shap_value[0.2731])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0.2731731 was used to detect the id of speaker 0.2731 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.2731 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.273 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.731 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6044 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-39 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.2731 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0.2731731 was used to detect the id of speaker 0.2731 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2731 ]> )"
  },
  {
    "mr": "inform(classification[spoofed], model[GMM], detected_by[CNN])",
    "ref": [
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The recording file was classified as being Audiosignal was detected by spoofed by a MixtureModel Abstract .....",
      "The recording file was classified as being Audiosignal was detected by  by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The recording file was classified as being Audiosignal was detected by spoofed by a MixtureModel Abstract .....",
      "The recording file was classified as being Audiosignal was detected by  by a MixtureModel Abstract .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <model> model: [ GMM ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-24], shap_value[-0.0217])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......",
      "-0.0217 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0217 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <shap_value> shap value: [ -0.0217 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ..... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ..... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Interpreters is used for identifying the important features in classifying the recording .....",
      "Interpreters is used for identifying the important features in classifying the recording ..... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Interpreters is used for identifying the important features in classifying the recording .....",
      "Spectral Centroid physicalattribute Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-18], interpreter[shap], shap_value[0.2652])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a 0.2652 value of 0.2652 ......",
      "The signal is consistent with a digital CaptureDevice .....",
      "Yes person  was detected by AudioFeature with a shap value of 0.65 ......",
      "The signal is consistent with a digital CaptureDevice ..... Yes person 2 was detected by AudioFeature with a shap value of 0.2652 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0.2652 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.2 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.2652 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.2652 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 2 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.yes65yes ......",
      "Yes person 2 was detected by AudioFeature with a 0.2652 value of 0.2652 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.2652 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2652 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-14], classification[bonafide])",
    "ref": [
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-14 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-3], interpreter[shap], shap_value[0.0106])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes person 4 was detected by AudioFeature with a sha value of 0.0106 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.0106 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.0106 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.0106 ......",
      "Yes person 4 was detected by AudioFeature with a 4 value of 0.0106 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person MSRCC-3 was detected by AudioFeature with a shap value of 0.0106 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.0106 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.0106 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0106 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-1], shap_value[-0.8258])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.825 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "-0.8258 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-1 ......",
      "This is a Audiosignal was detected by CNN audio",
      "This is a Audiosignal was detected by CNN audio shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.825 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "-0.8258 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8258 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-1 ], <shap_value> shap value: [ -0.8258 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-34], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-34 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-0], interpreter[shap], shap_value[0.3488])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ...... Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 0.3488 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ......",
      "Yes AudioFeature which a MFCC-0 value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker  for the audio sample ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ...... Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3488 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-6], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "The audio sample was found to be spoofed......",
      " AudioFeature was used to determine speaker id ......",
      "The audio sample was found to be spoofed...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "The audio sample was found to be spoofed......",
      " AudioFeature was used to determine speaker id ......",
      "The audio sample was found to be spoofed...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-6 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "The recording was made live ...... yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "CNN the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ...... yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "yes the Audiosignal was detected by  audio was a PhysicalAccess audio sample ......",
      "yes the Audiosignal was detected by replayed audio was a PhysicalAccess audio sample ......",
      " the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "The recording was made live ......",
      "The recording was made live ...... yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "CNN the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ...... yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......",
      "yes the Audiosignal was detected by CNN audio was a PhysicalAccess audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-47], classification[replayed], shap_value[-0.7487], detected_by[CNN])",
    "ref": [
      "-0.7487 AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.74 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ......",
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...... Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-47 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7487 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-0], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9013 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-29], interpreter[shap], shap_value[0.903])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes person MFCC-29 was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.903 ......",
      "Yes person 6 was detected by AudioFeature with a 0.903 value of 0.903 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 6 was detected by AudioFeature with a sh value of 0.903 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7617 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.903 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.903 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-24], classification[replayed], shap_value[-0.7938], detected_by[CNN])",
    "ref": [
      "Y AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by C ......",
      "The speaker is from the midwestern United States ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.7938 AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The speaker is from the midwestern United States ...... Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-24 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7938 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "No the Audiosignal was detected by spoofed recording was not a PhysicalAccess recording ......",
      " the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ...... No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "spoofed the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "No the Audiosignal was detected by  recording was not a PhysicalAccess recording ......",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ...... No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by spoofed recording was not a PhysicalAccess recording ......",
      " the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-8], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Voice cloning was used ......",
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Voice cloning was used ......",
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Voice cloning was used ......",
      "Voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-31], interpreter[shap], shap_value[0.3664])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0.366 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.366yes ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.3 ......",
      "Yes person 4 was detected by AudioFeature with a s value of 0.3664 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of LFCC-31 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes person 4 was detected by AudioFeature with a yes value of 0.3664 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.366 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.3664 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3664 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-34], interpreter[shap], shap_value[-0.1938])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a s value of -0.1938 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.1938 ......",
      "Yes AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.1938 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of - ......",
      "Yes AudioFeature which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of -0.1938 ......",
      "Yes person 5 was detected by AudioFeature with a s value of -0.1938 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.1938 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1938 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "No the recording uses multiple microphones ...... Voice cloning was used ......",
      "Voice clon was used ......",
      "Voice spoof was used ......",
      "Voice cloning was used ...... Voice cloning was used ......",
      "No the recording uses multiple microphones ......",
      "No the recording uses multiple microphones ...... Voice cloning was used ......",
      "Voice clon was used ......",
      "Voice spoof was used ......",
      "Voice cloning was used ...... Voice cloning was used ......",
      "No the recording uses multiple microphones ......",
      "Voice cloning was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-30], classification[bonafide], shap_value[-0.3982])",
    "ref": [
      "bonafide AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ...... Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.041 ......",
      "Yes AudioFeature which a shap value of -0.398 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.3982 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3982 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3982 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-41], classification[replayed], shap_value[0.2867], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN ..... Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "shap AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2867 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different sp ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different spoof ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different sp ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different spoof ......",
      "Other samples show the person speaks at a different speed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-8], classification[replayed], shap_value[-0.5069], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MFCC-8 value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by -0.5069 ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5069 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-24], classification[bonafide], shap_value[-0.9239])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-24 was used to detect the sample as Audiosignal ......",
      "LFCC-24 AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ......",
      "Y AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9239 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-24 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9239 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[recording_sped_up])",
    "ref": [
      "It appears that part of the recording was sped up ...... It appears that part of the recording was sped up ......",
      "No the recording uses multiple microphones ...... It appears that part of the recording was sped up ......",
      "No the recording uses multiple microphones ......",
      "It appears that part of the recording was sped up ...... It appears that part of the recording was sped up ......",
      "No the recording uses multiple microphones ...... It appears that part of the recording was sped up ......",
      "No the recording uses multiple microphones ......",
      "It appears that part of the recording was sped up ...... It appears that part of the recording was sped up ......",
      "No the recording uses multiple microphones ...... It appears that part of the recording was sped up ......",
      "No the recording uses multiple microphones ......",
      "It appears that part of the recording was sped up ...... It appears that part of the recording was sped up ......",
      "It appears that part of the recording was sped up ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ recording_sped_up ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Voice cloning was used too ...... Voice cloning was used too ......",
      "Voice spoof was used too ......",
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ...... Voice cloning was used too ......",
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Voice cloni was used too ......",
      "Voice cloning was used too ...... Voice cloning was used too ......",
      "Voice spoof was used too ......",
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ...... Voice cloning was used too ......",
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Voice cloni was used too ......",
      "Voice cloning was used too ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-27], classification[replayed], detected_by[CNN])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-27 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-36], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-36 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[4])",
    "ref": [
      "4 was found to be the id of the speaker in the sample ...... 4 was found to be the id of the speaker in the sample ......",
      "No I do not recognize any of the CaptureDevice signatures ...... 4 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "No I do not recognize any of the CaptureDevice signatures ......",
      "4 was found to be the id of the speaker in the sample ...... 4 was found to be the id of the speaker in the sample ......",
      "No I do not recognize any of the CaptureDevice signatures ...... 4 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "No I do not recognize any of the CaptureDevice signatures ......",
      "4 was found to be the id of the speaker in the sample ...... 4 was found to be the id of the speaker in the sample ......",
      "No I do not recognize any of the CaptureDevice signatures ...... 4 was found to be the id of the speaker in the sample ......",
      "4 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-20], interpreter[shap], shap_value[-0.0025])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.002 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......",
      "Yes person 5 was detected by AudioFeature with a yes value of -0.0025 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.002yes ......",
      "person 6 spoke the audio sample ...... Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......",
      "Yes person 5 was detected by AudioFeature with a  value of -0.0025 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of MFCC-20 ......",
      "person 6 spoke the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.002 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.0025 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0025 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-11], shap_value[0])",
    "ref": [
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-7], classification[bonafide], shap_value[0.9144])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ......",
      "Yes AudioFeature which a 0.9144 value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9366 ...... Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.914 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9144 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9144 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-4], interpreter[shap], shap_value[-0.4847])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of  ......",
      "Yes person 1 was detected by AudioFeature with a -0.4847 value of -0.4847 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.4847 ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ......",
      "Yes person 1 was detected by AudioFeature with a  value of -0.4847 ......",
      "Yes person -0.4847 was detected by AudioFeature with a shap value of -0.4847 ......",
      "Yes AudioFeature which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 1 was detected by AudioFeature with a shap value of MSRCC-4 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of  ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4847 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4847 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-3], interpreter[shap], shap_value[0.5227])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a 4 value of 0.5227 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a sha value of 0.5227 was used to detect the id of speaker 4 for the audio sample ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5227 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-41], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-41 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof])",
    "ref": [
      "No the recording is not Audiosignal ...... No the recording is not Audiosignal ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... No the recording is not Audiosignal ......",
      "spoof the recording is not Audiosignal ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "N the recording is not Audiosignal ......",
      "No the recording is Audiosignal ......",
      "No the recording is not Audiosignal ...... No the recording is not Audiosignal ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... No the recording is not Audiosignal ......",
      "spoof the recording is not Audiosignal ......",
      "The recording file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "No the recording is not Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_at[10])",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The next CaptureDevice starts at  seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at spoof seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The next CaptureDevice starts at  seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at spoof seconds ......",
      "The next CaptureDevice starts at 10 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_at> change at: [ 10 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-0], interpreter[shap], shap_value[0.4138])",
    "ref": [
      "Yes person 0.4138 was detected by AudioFeature with a shap value of 0.4138 ......",
      "Yes person 6 was detected by AudioFeature with a MFCC-0 value of 0.4138 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4138 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4636 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.4138 ......",
      "Yes person 6 was detected by AudioFeature with a sha value of 0.4138 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.4138 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.4138 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.4 ......",
      "Yes person 0.4138 was detected by AudioFeature with a shap value of 0.4138 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.4138 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4138 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-37], classification[bonafide])",
    "ref": [
      "There are signs that the recording was altered ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are signs that the recording was altered .....",
      "There are signs that the recording was altered ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are signs that the recording was altered .....",
      "There are signs that the recording was altered ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are signs that the recording was altered .....",
      "There are signs that the recording was altered ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-37 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... No other features were used ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "No other featurs were used ......",
      "No other features were used ...... No other features were used ......",
      "No other bonafides were used ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ...... No other features were used ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.493 ......",
      "No other featurs were used ......",
      "No other features were used ...... No other features were used ......",
      "No other bonafides were used ......",
      "No other features were used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-41], shap_value[-0.3481])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      "MFCC-41 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-41 ......",
      "The audio sample is not a Audio_signal sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0 ......",
      "The audio sample is not a Audio_signal sample ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      "MFCC-41 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-41 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3481 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <shap_value> shap value: [ -0.3481 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-43], classification[bonafide], shap_value[-0.5496])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "Yes AudioFeature which a sha value of -0.5496 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.5496 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5496 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5496 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ...... Yes AudioFeature which a shap value of -0.5496 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.5496 value of -0.5496 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "-0.5496 AudioFeature which a shap value of -0.5496 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9535 ......",
      "Yes AudioFeature which a shap value of -0.5496 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5496 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-4], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-4 AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "y AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-4 AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1778 ......",
      "y AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-4 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-3], interpreter[shap], shap_value[0.0437])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.0437 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.04 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.0437 value of 0.0437 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker PSRCC-3 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0437 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes this is a Audiosignal was detected by CN recording",
      "CNN this is a Audiosignal was detected by CNN recording",
      "Yes this is a Audiosignal was detected by CNN recording Yes this is a Audiosignal was detected by CNN recording",
      "Yes this is a Audiosignal was detected by Yes recording",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes this is a Audiosignal was detected by CNN recording",
      "Ye this is a Audiosignal was detected by CNN recording",
      "Yes AudioFeature which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes this is a Audiosignal was detected by CN recording",
      "CNN this is a Audiosignal was detected by CNN recording",
      "Yes this is a Audiosignal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-10], interpreter[shap], shap_value[-0.2339])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.2shapshap9 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.29 ......",
      "Yes person 3 was detected by AudioFeature with a -0.2339 value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Voice cloning was used too ......",
      "Voice cloning was used too ...... Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a s value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2339 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2339 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "No other spoof types were detected ..... No other spoof types were detected .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... No other spoof types were detected .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "No other spoof types were detected ..... No other spoof types were detected .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... No other spoof types were detected .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "No other spoof types were detected ..... No other spoof types were detected .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ...... No other spoof types were detected .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.0397 ......",
      "No other spoof types were detected ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  }
]