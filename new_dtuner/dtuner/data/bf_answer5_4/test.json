[
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-22], classification[bonafide])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-22 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-53], classification[bonafide], shap_value[0.1457])",
    "ref": [
      "0.1457 AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ......",
      "Yes the recording is synthetic ......",
      "Yes AudioFeature which a LFCC-53 value of 0.1457 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ......",
      "Yes the recording is synthetic ...... Yes AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.1457 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ......",
      "0.1457 AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1457 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1457 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "Yes there were multi_microphone microphones ......",
      "Yes there were 2 microphones ...... Yes there were 2 microphones ......",
      "The recording is artificially slowed ...... Yes there were 2 microphones ......",
      "The recording is artificially slowed ......",
      "Yes there were  microphones ......",
      "Yes there were multi_microphone microphones ......",
      "Yes there were 2 microphones ...... Yes there were 2 microphones ......",
      "The recording is artificially slowed ...... Yes there were 2 microphones ......",
      "The recording is artificially slowed ......",
      "Yes there were  microphones ......",
      "Yes there were 2 microphones ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-17], interpreter[shap], shap_value[-0.164])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.14 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a -0.164 value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1shap4 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.164 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was converted .....",
      "No the Audiosignal was detected by spoofed recording was not converted .....",
      "No the Audiosignal was detected by  recording was not converted .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ......",
      " the Audiosignal was detected by CNN recording was not converted .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ...... No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not convert .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... No the Audiosignal was detected by CNN recording was not converted .....",
      "CNN the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not spoofed .....",
      "No the Audiosignal was detected by CNN recording was not converted ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... There are inconsistencies ......",
      "There are inconsistencies ...... There are inconsistencies ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... There are inconsistencies ......",
      "There are inconsistencies ...... There are inconsistencies ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... There are inconsistencies ......",
      "There are inconsistencies ...... There are inconsistencies ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "There are inconsistencies ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-35], interpreter[shap], shap_value[0.4155])",
    "ref": [
      "Yes AudioFeature which a 0.4155 value of 0.4155 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4155 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4155 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.4155 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 0.4155 value of 0.4155 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4155 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-31], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-31 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There is an echo ..... There is an echo .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is an echo .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There is an echo ..... There is an echo .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is an echo .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There is an echo ..... There is an echo .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is an echo .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There is an echo ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[sampling])",
    "ref": [
      "Yes . Yes . There is evidence of sampling ......",
      "Yes . Yes . Yes . There is evidence of sampling ......",
      "There is evidence of sampling ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... Yes . There is evidence of sampling ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... There is evidence of sampling ......",
      " . There is evidence of sampling ......",
      "Yes .",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... Yes . There is evidence of sampling ......",
      "sampling . There is evidence of sampling ......",
      "Yes . There is evidence of spoof ......",
      "Yes . There is evidence of sampling ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Interpreters is used for identifying the important features in classifing the audio ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Interpreters is used for identifying the important features in classifing the audio ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Interpreters is used for identifying the important features in classifing the audio ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Interpreters is used for identifying the important features in classifing the audio ...... Interpreters is used for identifying the important features in classifing the audio ......",
      "Interpreters is used for identifying the important features in classifing the audio ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio has several CaptureDevice signatures ...... The audio has several CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio has several CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio has several CaptureDevice signatures ...... The audio has several CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio has several CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio has several CaptureDevice signatures ...... The audio has several CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio has several CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio has several CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-4], feature[MFCC-0], feature[LFCC-2], feature[MFCC-5])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-0 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC  had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-0 had the highest impact on classification ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC  had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-4 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-20], interpreter[shap], shap_value[-0.9142])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a 2 value of -0.9142 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9142 ......",
      "Yes person 2 was detected by AudioFeature with a s value of -0.9142 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 2 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9142 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9142 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.914 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.91 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.914yes ......",
      "Yes person 2 was detected by AudioFeature with a 2 value of -0.9142 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9142 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9142 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-23], interpreter[shap], shap_value[-0.2913])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a LFCC-23 value of -0.2913 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.2913 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.2913 ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... Yes person 2 was detected by AudioFeature with a shap value of -0.2913 ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "Yes person  was detected by AudioFeature with a shap value of -0.913 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of -0.2913 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.yes913 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.2 ......",
      "Yes person 2 was detected by AudioFeature with a LFCC-23 value of -0.2913 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.2913 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2913 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Everything points to this audio sample being Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Everything points to this audio sample being Audiosignal ...... Everything points to this audio sample being Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Everything points to this audio sample being Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Everything points to this audio sample being Audiosignal ...... Everything points to this audio sample being Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Everything points to this audio sample being Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Everything points to this audio sample being Audiosignal ...... Everything points to this audio sample being Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Everything points to this audio sample being Audiosignal ......",
      "Everything points to this audio sample being Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1], signal_length(10))",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-34], classification[replayed], shap_value[-0.2293], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a replayed value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-34 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "LFCC-34 AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a s value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2293 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[4], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-34], interpreter[shap], shap_value[-0.8814])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker -0.8814 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8814 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-38], classification[replayed], shap_value[-0.643], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6995 ...... Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6995 ......",
      "Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a sh value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.643 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It seems like a computer was used ...... It seems like a computer was used ......",
      "It seems like a compute was used ......",
      "It seems like a spoof was used ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... It seems like a computer was used ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "It seems like a computer was used ...... It seems like a computer was used ......",
      "It seems like a compute was used ......",
      "It seems like a spoof was used ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... It seems like a computer was used ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "It seems like a computer was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-31], classification[replayed], shap_value[0.8955], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a replayed value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.8955 AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8955 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-39], classification[bonafide], shap_value[0.4439])",
    "ref": [
      "shap AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.4439 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.443 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.4439 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4439 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4439 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-57], interpreter[shap], shap_value[0.6978])",
    "ref": [
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker shap for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a 1 value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-57 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6978 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-21], interpreter[shap], shap_value[0.3949])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-21 was used to detect the id of speaker 5 for the audio sample ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "Yes AudioFeature which a s value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a 5 value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker yes for the audio sample ......",
      "No the Audiosignal was detected by CNN recording was not converted ..... Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3949 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-11], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a shap value of GTCC-11 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 0 for the audio sample ......",
      "Yes AudioFeature which a 0 value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of GTCC-11 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio is syn ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio is synthetic ......",
      "The audio is synthetic ...... The audio is synthetic ......",
      "The audio is spoof ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio is syn ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The audio is synthetic ......",
      "The audio is synthetic ...... The audio is synthetic ......",
      "The audio is spoof ......",
      "The audio is synthetic ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-45], interpreter[shap], shap_value[-0.3826])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.38 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a yes value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker -0.3826 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-45 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3826 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[copy])",
    "ref": [
      "No other spoof types were detected ...... The audio appears to be a copy .....",
      "No other spoof types were detected ......",
      "The audio appears to be a copy ..... The audio appears to be a copy .....",
      "The audio appears to be a spoof .....",
      "The audio appears to be a  .....",
      "No other spoof types were detected ...... The audio appears to be a copy .....",
      "No other spoof types were detected ......",
      "The audio appears to be a copy ..... The audio appears to be a copy .....",
      "The audio appears to be a spoof .....",
      "The audio appears to be a  .....",
      "The audio appears to be a copy ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ copy ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "No this audio is fake ...... No this audio is fake ......",
      "The next synthesized area begins at 16 seconds ...... No this audio is fake ......",
      "The next synthesized area begins at 16 seconds ......",
      "No this audio is fake ...... No this audio is fake ......",
      "The next synthesized area begins at 16 seconds ...... No this audio is fake ......",
      "The next synthesized area begins at 16 seconds ......",
      "No this audio is fake ...... No this audio is fake ......",
      "The next synthesized area begins at 16 seconds ...... No this audio is fake ......",
      "The next synthesized area begins at 16 seconds ......",
      "No this audio is fake ...... No this audio is fake ......",
      "No this audio is fake ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-6], interpreter[shap], shap_value[-0.8167])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a MFCC-6 value of -0.8167 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 3 was detected by AudioFeature with a sha value of -0.8167 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.8167 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 3 was detected by AudioFeature with a shap value of -0.8167 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8167 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.8167 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.8167 ......",
      "Yes person 3 was detected by AudioFeature with a MFCC-6 value of -0.8167 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8167 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8167 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-13], shap_value[0])",
    "ref": [
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-13 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-4], classification[replayed], shap_value[-0.7388], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a CNN value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7825 ...... Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Y AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7825 ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.73 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7388 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "spoofed voice cloning was used ......",
      "Yes voice cloning was used ...... Yes voice cloning was used ......",
      "Yes voice Yes was used ......",
      "Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes voice cloning was used ......",
      "Yes voice cloni was used ......",
      "Yes AudioFeature which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye voice cloning was used ......",
      "spoofed voice cloning was used ......",
      "Yes voice cloning was used ...... Yes voice cloning was used ......",
      "Yes voice Yes was used ......",
      "Yes voice cloning was used ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ...... Features in the recording show there were two microphones used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ...... Features in the recording show there were two microphones used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ...... Features in the recording show there were two microphones used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-40], interpreter[shap], shap_value[-0.9913])",
    "ref": [
      "Yes person LFCC-40 was detected by AudioFeature with a shap value of -0.9913 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9913 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ......",
      "Yes person 5 was detected by AudioFeature with a yes value of -0.9913 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of -0.9913 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.99 ......",
      "Yes person LFCC-40 was detected by AudioFeature with a shap value of -0.9913 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9913 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-53], interpreter[shap], shap_value[-0.2638])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 1 was detected by AudioFeature with a  value of -0.2638 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.2638 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0 ......",
      "It is not a bona fide recording ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.2638 ......",
      "It is not a bona fide recording ...... Yes person 1 was detected by AudioFeature with a shap value of -0.2638 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.2638 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.2638 ......",
      "Yes person 1 was detected by AudioFeature with a -0.2638 value of -0.2638 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.2638 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-53 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2638 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-19], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-19 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-12], classification[replayed], shap_value[-0.6521], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a replayed value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by PSRCC-12 ......",
      "Yes AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "PSRCC-12 AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.652 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... Yes AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6521 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-57], classification[bonafide])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-57 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-2], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of GTCC-2 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a 4 value of 1 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ......",
      "The alterations are consistent with known programs .....",
      "The alterations are consistent with known programs ..... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker GTCC-2 for the audio sample ......",
      "Yes AudioFeature which a sha value of 1 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], detected_by[CNN])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ...... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ..... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way .....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by spoof in this way .....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CN in this way .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ...... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way .....",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ..... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way .....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by spoof in this way .....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CN in this way .....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-39], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-39 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-14], shap_value[0.6262])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.62 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "0.6262 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.62 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <shap_value> shap value: [ 0.6262 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-24], classification[replayed], shap_value[-0.0073], detected_by[CNN])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by -0.0073 ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0073 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-7], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-10], classification[bonafide], shap_value[0.0536])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0536 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.0536 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0536 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0536 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Some of the recording was made using a computer ......",
      "The audio sample was found to be spoofed...... The audio sample was found to be spoofed......",
      "The audio sample was found to be sed......",
      "Some of the recording was made using a computer ...... The audio sample was found to be spoofed......",
      "Some of the recording was made using a computer ......",
      "The audio sample was found to be spoofed...... The audio sample was found to be spoofed......",
      "The audio sample was found to be sed......",
      "Some of the recording was made using a computer ...... The audio sample was found to be spoofed......",
      "Some of the recording was made using a computer ......",
      "The audio sample was found to be spoofed...... The audio sample was found to be spoofed......",
      "The audio sample was found to be spoofed......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-33], interpreter[shap], shap_value[0.4724])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of 0.4724 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.47 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of LFCC-33 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of 0.4724 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.4724 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4724 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-3], classification[bonafide], shap_value[0.9178])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9178 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.9178 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.9178 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.9178 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " AudioFeature which a shap value of 0.9178 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.9178 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.9178 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9178 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9178 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-52], classification[bonafide], shap_value[0.3733])",
    "ref": [
      "Yes AudioFeature which a shap value of LFCC-52 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-52 value of 0.3733 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.3733 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-52 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3733 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-32], interpreter[shap], shap_value[-0.9992])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.999 ......",
      "Yes person MFCC-32 was detected by AudioFeature with a shap value of -0.9992 ......",
      "Yes person 1 was detected by AudioFeature with a sha value of -0.9992 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......",
      "Yes person 1 was detected by AudioFeature with a -0.9992 value of -0.9992 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9992 ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9992 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It looks like the recording was edited using software ...... It looks like the recording was edited using software ......",
      "Everything points to this audio sample being Audiosignal ...... It looks like the recording was edited using software ......",
      "Everything points to this audio sample being Audiosignal ......",
      "It looks like the recording was edited using spoof ......",
      "It looks like the recording was edited using softwar ......",
      "It looks like the recording was edited using software ...... It looks like the recording was edited using software ......",
      "Everything points to this audio sample being Audiosignal ...... It looks like the recording was edited using software ......",
      "Everything points to this audio sample being Audiosignal ......",
      "It looks like the recording was edited using spoof ......",
      "It looks like the recording was edited using softwar ......",
      "It looks like the recording was edited using software ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-11], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "CNN AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a GTCC-11 value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by -1 ......",
      "Yes AudioFeature which a  value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-33], interpreter[shap], shap_value[0.2648])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0.2648 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.2648 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.26 ......",
      "Yes person 3 was detected by AudioFeature with a MFCC-33 value of 0.2648 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.2648 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 3 ......",
      "Yes person 3 was detected by AudioFeature with a sh value of 0.2648 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.2648 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.2648 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.2648 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.2648 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2648 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ...... There is more than one area of synthesized AcousticWave ......",
      "There is more than one area of synthesized AcousticWave ...... There is more than one area of synthesized AcousticWave ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ...... There is more than one area of synthesized AcousticWave ......",
      "There is more than one area of synthesized AcousticWave ...... There is more than one area of synthesized AcousticWave ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ...... There is more than one area of synthesized AcousticWave ......",
      "There is more than one area of synthesized AcousticWave ...... There is more than one area of synthesized AcousticWave ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ...... There is more than one area of synthesized AcousticWave ......",
      "There is more than one area of synthesized AcousticWave ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-2], interpreter[shap], shap_value[0.6718])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a LFCC-2 value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.618 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "No most of the recording was not made with a mobile phone ......",
      "Yes person LFCC-2 was detected by AudioFeature with a shap value of 0.6LFCC-218 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of LFCC-2 ......",
      "Yes person 7 was detected by AudioFeature with a sha value of 0.6718 ......",
      "No most of the recording was not made with a mobile phone ...... Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a LFCC-2 value of 0.6718 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6718 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-14], interpreter[shap], shap_value[-0.8355])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a LFCC-14 value of -0.8355 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "The audio is not Audiosignal ......",
      "The audio is not Audiosignal ...... Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.8355 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8355 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-6], classification[bonafide], shap_value[0.5258])",
    "ref": [
      "MSRCC-6 AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MSRCC-6 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.5258 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.5258 value of 0.5258 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "MSRCC-6 AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5258 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "There were spoof microphones used ......",
      "yes AudioFeature was used to determine speaker id ...... There were 2 microphones used ......",
      "There were  microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "yes AudioFeature was used to determine speaker id ......",
      "There were spoof microphones used ......",
      "yes AudioFeature was used to determine speaker id ...... There were 2 microphones used ......",
      "There were  microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "There were 2 microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-21], classification[bonafide], shap_value[0.6636])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.66 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ...... Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "Yes AudioFeature which a LFCC-21 value of 0.6636 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.6636 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.66 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6636 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-20], classification[bonafide], shap_value[0.6675])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ...... Yes AudioFeature which a shap value of 0.6675 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6675 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6675 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.6675 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.6675 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.6675 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "0.6675 AudioFeature which a shap value of 0.6675 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "Yes AudioFeature which a shap value of 0.6675 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6675 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-7], interpreter[shap], shap_value[-0.9296])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.929 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.92 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a 6 value of -0.9296 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.929yes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.9296 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9296 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-7], interpreter[shap], shap_value[-0.4878])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a yes value of -0.4878 ......",
      "Yes person 3 was detected by AudioFeature with a  value of -0.4878 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.4878 ......",
      "Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...... Yes person 3 was detected by AudioFeature with a shap value of -0.4878 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.4878 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.4878 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.4878 ......",
      "Yes person 3 was detected by AudioFeature with a yes value of -0.4878 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.4878 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4878 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-51], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-51 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(model[CNN], task[spoof_detecting], detected_by[CNN])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ...... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......",
      "No the Audiosignal was detected by CNN recording was not converted ..... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ...... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......",
      "No the Audiosignal was detected by CNN recording was not converted ..... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ...... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......",
      "No the Audiosignal was detected by CNN recording was not converted ..... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <model> model: [ CNN ], <task> task: [ spoof_detecting ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The audio sample was found to be bonafide...... The audio sample was found to be bonafide......",
      "The audio sample was found to be none......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample was found to be bonafide......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample was found to be bonafid......",
      "The audio sample was found to be bonafide...... The audio sample was found to be bonafide......",
      "The audio sample was found to be none......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample was found to be bonafide......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample was found to be bonafid......",
      "The audio sample was found to be bonafide......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-12], classification[replayed], shap_value[-0.642], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.642 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "There were 2 microphones used ......",
      "There were 2 microphones used ...... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "There were 2 microphones used ......",
      "There were 2 microphones used ...... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "There were 2 microphones used ......",
      "There were 2 microphones used ...... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-1], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Y AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-55], classification[bonafide], shap_value[-0.1297])",
    "ref": [
      "Yes AudioFeature which a bonafide value of -0.1297 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.1297 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.1297 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1297 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.1297 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.1297 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.12 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.1297 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.1297 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1297 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1297 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-32], shap_value[-0.7306])",
    "ref": [
      "It seems like a computer was used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-32 ......",
      "It seems like a computer was used ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......",
      "MFCC-32 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.73 ......",
      "It seems like a computer was used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-32 ......",
      "It seems like a computer was used ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <shap_value> shap value: [ -0.7306 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "It appears there was voice spoof .....",
      "It appears there was voice cloning ..... It appears there was voice cloning .....",
      "No this audio is fake ...... It appears there was voice cloning .....",
      "No this audio is fake ......",
      "It appears there was voice clo .....",
      "It appears there was voice spoof .....",
      "It appears there was voice cloning ..... It appears there was voice cloning .....",
      "No this audio is fake ...... It appears there was voice cloning .....",
      "No this audio is fake ......",
      "It appears there was voice clo .....",
      "It appears there was voice cloning ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "A Audiosignal signature was not detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "A Audiosignal signature was not detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "A Audiosignal signature was not detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "A Audiosignal signature was not detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "A Audiosignal signature was not detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "A Audiosignal signature was not detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "A Audiosignal signature was not detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide])",
    "ref": [
      "bonafide it is not a bona fide recording ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "No it is not a bona fide recording ...... No it is not a bona fide recording ......",
      "N it is not a bona fide recording ......",
      "No it is a bona fide recording ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ...... No it is not a bona fide recording ......",
      "bonafide it is not a bona fide recording ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "No it is not a bona fide recording ...... No it is not a bona fide recording ......",
      "N it is not a bona fide recording ......",
      "No it is not a bona fide recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "The audio was Audiosignal was detected by CNN? The audio was Audiosignal was detected by CNN?",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...... The audio was Audiosignal was detected by CNN?",
      "The audio was Audiosignal was detected by CN?",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio was Audiosignal was detected by spoof?",
      "The audio was Audiosignal was detected by CNN? The audio was Audiosignal was detected by CNN?",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...... The audio was Audiosignal was detected by CNN?",
      "The audio was Audiosignal was detected by CN?",
      "Yes AudioFeature which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio was Audiosignal was detected by spoof?",
      "The audio was Audiosignal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-8], interpreter[shap], shap_value[0.3074])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.30 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.3074 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.3074 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.30 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3074 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by  by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by computer by a MixtureModel Abstract .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by  by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by computer by a MixtureModel Abstract .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-27], classification[replayed], shap_value[-0.5562], detected_by[CNN])",
    "ref": [
      "person 3 was detected as the primary speaker of the audio sample ...... Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "person 3 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5562 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-12], interpreter[shap], shap_value[-0.6016])",
    "ref": [
      "Yes AudioFeature which a -0.6016 value of -0.6016 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.60 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8167 ......",
      "Yes AudioFeature which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.6016 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6016 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-12 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6016 was used to detect the id of speaker -0.6016 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8167 ...... Yes AudioFeature which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a -0.6016 value of -0.6016 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6016 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-50], classification[bonafide])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-50 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-51], classification[replayed], shap_value[-0.8842], detected_by[CNN])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "Yes AudioFeature which a sha value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-51 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "shap AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8842 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-25], classification[bonafide], shap_value[0.983])",
    "ref": [
      "Yes AudioFeature which a sha value of 0.983 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a 0.983 value of 0.983 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "0.983 AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.983 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-11], interpreter[shap], shap_value[-0.9056])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of MFCC-11 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of -0.9056 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9056 ......",
      "Yes person 2 was detected by AudioFeature with a 2 value of -0.9056 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.9056 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9056 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... The audio uses multiple microphones ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "The audio uses multiple microphones ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Because the background noise changes too quickly to be natural ...... Because the background noise changes too quickly to be natural ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...... Because the background noise changes too quickly to be natural ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Because the background noise changes too quickly to be natural ...... Because the background noise changes too quickly to be natural ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...... Because the background noise changes too quickly to be natural ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Because the background noise changes too quickly to be natural ...... Because the background noise changes too quickly to be natural ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...... Because the background noise changes too quickly to be natural ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Because the background noise changes too quickly to be natural ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-12], shap_value[-0.5786])",
    "ref": [
      "LFCC-12 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-12 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <shap_value> shap value: [ -0.5786 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-42], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes the recording is synthetic ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording is synthetic ......",
      "Yes the recording is synthetic ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording is synthetic ......",
      "Yes the recording is synthetic ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording is synthetic ......",
      "Yes the recording is synthetic ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-42 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-1], classification[bonafide], shap_value[-0.5419])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.5419 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "Yes AudioFeature which a s value of -0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ...... Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5419 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-14], classification[replayed], shap_value[0.5317], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MFCC-14 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.5317 AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5317 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-8], classification[replayed], shap_value[0.7072], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a sha value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "PSRCC-8 AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Ye AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of PSRCC-8 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7072 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-0], classification[replayed], shap_value[0.3558], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of MSRCC-0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a CNN value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.3558 AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.355 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... Yes AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3558 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-22], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-22 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-46], shap_value[-0.2953])",
    "ref": [
      "The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-46 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......",
      "The alterations are consistent with known programs ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......",
      "-0.2953 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.29 ......",
      "The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-46 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <shap_value> shap value: [ -0.2953 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-8], shap_value[-0.373])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3 ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ......",
      "LFCC-8 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.373 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <shap_value> shap value: [ -0.373 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-13], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of GTCC-13 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a GTCC-13 value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "The audio uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio uses multiple microphones ......",
      "The audio uses multiple microphones ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 6 was detected as the primary speaker of the audio sample ...... person 6 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ...... person 6 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 6 was detected as the primary speaker of the audio sample ...... person 6 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ...... person 6 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5419 was used to detect the sample as Audiosignal ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 6 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-36], shap_value[-0.0131])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.0131 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.01 ......",
      "Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......",
      "Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.0131 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0131 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <shap_value> shap value: [ -0.0131 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[5])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio is a little faster between the five and ten second mark ...... The audio is a little faster between the five and ten second mark ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... The audio is a little faster between the five and ten second mark ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio is a little faster between the five and ten second mark ...... The audio is a little faster between the five and ten second mark ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... The audio is a little faster between the five and ten second mark ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio is a little faster between the five and ten second mark ...... The audio is a little faster between the five and ten second mark ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... The audio is a little faster between the five and ten second mark ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio is a little faster between the five and ten second mark ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-9], classification[replayed], shap_value[0.5114], detected_by[CNN])",
    "ref": [
      "Y AudioFeature which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-9 value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way .....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ..... Yes AudioFeature which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by  ......",
      "replayed AudioFeature which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a sha value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5114 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], mic_type[mobile_phone], mic_type[computer])",
    "ref": [
      "Yes some of the recording was made with a mobile device and some with a compute .....",
      "Yes some of the recording was made with a mobile device and some with a spoof .....",
      "Y some of the recording was made with a mobile device and some with a computer .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "spoof some of the recording was made with a mobile device and some with a computer .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a computer ..... Yes some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a compute .....",
      "Yes some of the recording was made with a mobile device and some with a spoof .....",
      "Y some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a computer ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ], <mic_type> mic type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-16], interpreter[shap], shap_value[0.8851])",
    "ref": [
      "person 6 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 0.8851 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a 0.8851 value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ......",
      "person 6 was detected as the primary speaker of the audio sample ...... Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "person 6 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8851 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-11], classification[replayed], shap_value[-0.5246], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.52 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      " AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5246 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-17], classification[bonafide], shap_value[0.0961])",
    "ref": [
      "Y AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ...... Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.0961 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......",
      "MFCC-17 AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-17 value of 0.0961 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0961 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0961 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-10], classification[bonafide])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-8], determined[speaker_id])",
    "ref": [
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-8 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[spoof], mic_type[mobile_phone])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[syntheic])",
    "ref": [
      "syntheic the recording is synthetic ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Ye the recording is synthetic ......",
      "Yes the recording is synthetic ...... Yes the recording is synthetic ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ...... Yes the recording is synthetic ......",
      "syntheic the recording is synthetic ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Ye the recording is synthetic ......",
      "Yes the recording is synthetic ...... Yes the recording is synthetic ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ...... Yes the recording is synthetic ......",
      "Yes the recording is synthetic ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ syntheic ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-13], shap_value[-0.8209])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "-0.8209 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <shap_value> shap value: [ -0.8209 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-8], classification[replayed], shap_value[-0.9437], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... Yes AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by -0.9437 ......",
      "Yes AudioFeature which a sha value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.9437 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-23], shap_value[-0.0117])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.01 ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......",
      "-0.0117 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-23 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.01 ......",
      "Yes AudioFeature which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......",
      "-0.0117 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0117 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <shap_value> shap value: [ -0.0117 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-25], interpreter[shap], shap_value[0.7825])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person 1 was detected by AudioFeature with a sh value of 0.7825 ......",
      "Yes person LFCC-25 was detected by AudioFeature with a shap value of 0.7825 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.7825 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7825 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.7825 ......",
      "Yes person 1 was detected by AudioFeature with a 1 value of 0.7825 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes person 1 was detected by AudioFeature with a shap value of 0.7825 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7825 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7825 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-27], interpreter[shap], shap_value[-0.3514])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of -0.35 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 3 was detected by AudioFeature with a  value of -0.3514 ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3514 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.3514 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.514 ......",
      "Yes person -0.3514 was detected by AudioFeature with a shap value of -0.-0.3514514 ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...... Yes person 3 was detected by AudioFeature with a shap value of -0.3514 ......",
      "Yes person 3 was detected by AudioFeature with a -0.3514 value of -0.3514 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.35 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3514 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3514 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-47], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-47 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[20])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "The spoof increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ...... The speed increases at the 20 second mark ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ...... The speed increases at the 20 second mark ......",
      "The s increases at the 20 second mark ......",
      "The speed increases at the spoof second mark ......",
      "The speed increases at the 2 second mark ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "The spoof increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ...... The speed increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-56], interpreter[shap], shap_value[0.8985])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a 0.8985 value of 0.8985 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.8985 was used to detect the id of speaker 5 for the audio sample ......",
      "Constant-Q Cepstral Coefficients ...... Yes AudioFeature which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ......",
      "Constant-Q Cepstral Coefficients ......",
      "Yes AudioFeature which a shap value of LFCC-56 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.898 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8980.8985 was used to detect the id of speaker 0.8985 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-56 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8985 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-57], shap_value[-0.5116])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.5116 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "Yes the recording is synthetic ......",
      "Yes the recording is synthetic ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <shap_value> shap value: [ -0.5116 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-33], interpreter[shap], shap_value[-0.2863])",
    "ref": [
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "No other spoof types were detected ...... Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a MFCC-33 value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker  for the audio sample ......",
      "No other spoof types were detected ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2863 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes there was more than one CaptureDevice ...... Yes there was more than one CaptureDevice ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "spoof there was more than one CaptureDevice ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes there was more than one CaptureDevice ......",
      "Ye there was more than one CaptureDevice ......",
      "Yes there was more than one CaptureDevice ...... Yes there was more than one CaptureDevice ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "spoof there was more than one CaptureDevice ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes there was more than one CaptureDevice ......",
      "Ye there was more than one CaptureDevice ......",
      "Yes there was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-50], interpreter[shap], shap_value[-0.1122])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.11 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.11 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a -0.1122 value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.11yesyes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.11 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-50 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1122 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-10], interpreter[shap], shap_value[0.289])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 5 was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a 0.289 value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a  value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.289 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.289 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.289 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ...... The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ...... The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "The alterations are consistent with known programs ..... The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ...... The alterations are consistent with known programs .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "The alterations are consistent with known programs ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-12], interpreter[shap], shap_value[0.4129])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.412 ......",
      "Yes person 2 was detected by AudioFeature with a s value of 0.4129 ......",
      "Yes person 2 was detected by AudioFeature with a 2 value of 0.4129 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 2 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.419 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ......",
      "Yes person 0.4129 was detected by AudioFeature with a shap value of 0.410.41299 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.412 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4129 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4129 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[synthetic], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ...... Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a syntheti recording ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      " the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by C recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by spoofed recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a spoofed recording ......",
      "synthetic the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ...... Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-11], interpreter[shap], shap_value[-0.3846])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of - ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of -0.3846 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.3846 ......",
      "The audio sample was PhysicalAccess was detected by CNN as well ......",
      "Yes person 5 was detected by AudioFeature with a  value of -0.3846 ......",
      "The audio sample was PhysicalAccess was detected by CNN as well ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.3846 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3846 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "It appears there was voice cloning .....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It appears there was voice cloning ..... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It appears there was voice cloning .....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It appears there was voice cloning ..... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It appears there was voice cloning .....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It appears there was voice cloning ..... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It appears there was voice cloning .....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-2], shap_value[0.0476])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0 ......",
      "It was altered using software ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "PSRCC-2 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0476 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0476 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0476 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0476 ......",
      "It was altered using software ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0476 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0 ......",
      "It was altered using software ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0476 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <shap_value> shap value: [ 0.0476 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-3], classification[replayed], shap_value[-0.7698], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a -0.7698 value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.769 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-3 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7698 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-6], classification[bonafide], shap_value[-0.8808])",
    "ref": [
      "Yes AudioFeature which a s value of -0.8808 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.8808 was used to detect the sample as Audiosignal ......",
      "It is not a bona fide recording ......",
      "Yes AudioFeature which a shap value of -0.8808 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8808 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.8808 was used to detect the sample as Audiosignal ......",
      "It is not a bona fide recording ...... Yes AudioFeature which a shap value of -0.8808 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "MFCC-6 AudioFeature which a shap value of -0.8808 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.8808 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8808 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8808 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-13], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker  for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 3 value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a s value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of GTCC-13 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-16], classification[bonafide], shap_value[0.4647])",
    "ref": [
      " AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-16 was used to detect the sample as Audiosignal ......",
      "0.4647 AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.4647 value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4647 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-19], shap_value[0.6196])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.619 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ......",
      "0.6196 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.619 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6196 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <shap_value> shap value: [ 0.6196 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-1], classification[replayed], shap_value[-0.2422], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.242 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.2422 value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MSRCC-1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2422 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-6], classification[bonafide], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "GTCC-6 AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 1 value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Y AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It shows signs of having been digitally manipulated ...... It shows signs of having been digitally manipulated ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ...... It shows signs of having been digitally manipulated ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "It shows signs of having been digitally manipulated ...... It shows signs of having been digitally manipulated ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ...... It shows signs of having been digitally manipulated ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "It shows signs of having been digitally manipulated ...... It shows signs of having been digitally manipulated ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ...... It shows signs of having been digitally manipulated ......",
      "Yes AudioFeature which a shap value of 0.3733 was used to detect the sample as Audiosignal ......",
      "It shows signs of having been digitally manipulated ...... It shows signs of having been digitally manipulated ......",
      "It shows signs of having been digitally manipulated ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[2])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-30], classification[replayed], shap_value[-0.662], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by LFCC-30 ......",
      "shap AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-30 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.662 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ...... It appears that part of the audio was sped up ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "It appears that part of the audio was sped up ...... It appears that part of the audio was sped up ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ...... It appears that part of the audio was sped up ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "It appears that part of the audio was sped up ...... It appears that part of the audio was sped up ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ...... It appears that part of the audio was sped up ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ......",
      "It appears that part of the audio was sped up ...... It appears that part of the audio was sped up ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5116 ...... It appears that part of the audio was sped up ......",
      "It appears that part of the audio was sped up ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.983 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-5], classification[replayed], shap_value[-0.7587], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a  value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by LFCC-5 ......",
      "Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "Yes AudioFeature which a shap value of -0.758 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7587 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-46], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-46 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      " was found to be the id of the speaker in the sample ......",
      "6 was found to be the id of the speaker in the sample ...... 6 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...... 6 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " was found to be the id of the speaker in the sample ......",
      "6 was found to be the id of the speaker in the sample ...... 6 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...... 6 was found to be the id of the speaker in the sample ......",
      "Yes AudioFeature which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " was found to be the id of the speaker in the sample ......",
      "6 was found to be the id of the speaker in the sample ...... 6 was found to be the id of the speaker in the sample ......",
      "6 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-17], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-17 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-3], interpreter[shap], shap_value[-0.5773])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.5773 ......",
      "Yes person 6 was detected by AudioFeature with a 6 value of -0.5773 ......",
      "Yes person 6 was detected by AudioFeature with a sha value of -0.5773 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.5773 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.5773 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......",
      "Yes person PSRCC-3 was detected by AudioFeature with a shap value of -0.5773 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.5773 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.5 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 6 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.5773 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.5773 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5773 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-7], interpreter[shap], shap_value[-0.2138])",
    "ref": [
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2138 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.213 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a MSRCC-7 value of -0.2138 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.2138 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2138 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2138 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-27], interpreter[shap], shap_value[0.8535])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...... Yes person 1 was detected by AudioFeature with a shap value of 0.8535 ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.8535 ......",
      "Yes person 1 was detected by AudioFeature with a 1 value of 0.8535 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8535 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.8535 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.853 ......",
      "Yes person 1 was detected by AudioFeature with a sha value of 0.8535 ......",
      "Yes person 0.8535 was detected by AudioFeature with a shap value of 0.8535 ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...... Yes person 1 was detected by AudioFeature with a shap value of 0.8535 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8535 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8535 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The recording is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording is artificially slowed ...... The recording is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The recording is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording is artificially slowed ...... The recording is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The recording is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording is artificially slowed ...... The recording is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The recording is artificially slowed ......",
      "The recording is artificially slowed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-5], interpreter[shap], shap_value[-0.3996])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.399-0.3996 was used to detect the id of speaker -0.3996 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.399 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.3996 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a -0.3996 value of -0.3996 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.399-0.3996 was used to detect the id of speaker -0.3996 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3996 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-24], interpreter[shap], shap_value[0.8609])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker LFCC-24 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a LFCC-24 value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8609 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "It was altered using software ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "It was altered using software ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "It was altered using software ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ...... It was altered using software ......",
      "It was altered using software ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... No other spoof types were detected ......",
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... No other spoof types were detected ......",
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... No other spoof types were detected ......",
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "No other spoof types were detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-6], interpreter[shap], shap_value[-0.9158])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.9158 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-6 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.958 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9yes58 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.91 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.9158 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9158 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-16], classification[replayed], shap_value[-0.4135], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by LFCC-16 ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.2648 ...... Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4135 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], replay_order[3], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by Yes and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ......",
      "It has been PhysicalAccess was detected by CN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded replayed times ......",
      "Yes AudioFeature which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by Yes and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <replay_order> replay order: [ 3 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-27], classification[bonafide], shap_value[-0.3069])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.30 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.3069 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-27 value of -0.3069 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.30 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3069 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-36], interpreter[shap], shap_value[0.9205])",
    "ref": [
      "Yes AudioFeature which a sha value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker yes for the audio sample ......",
      "yes AudioFeature was used to determine speaker id ...... Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a 4 value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9205 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-57], classification[bonafide], shap_value[-0.9499])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.9499 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.9499 was used to detect the sample as Audiosignal ......",
      "There were 2 microphones used ...... Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.949 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "There were 2 microphones used ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9499 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9499 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "The audio sample was PhysicalAccess was detected by C as well ......",
      "The audio sample was PhysicalAccess was detected by replay as well ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ...... The audio sample was PhysicalAccess was detected by CNN as well ......",
      "The audio sample was PhysicalAccess was detected by CNN as well ...... The audio sample was PhysicalAccess was detected by CNN as well ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      "The audio sample was PhysicalAccess was detected by C as well ......",
      "The audio sample was PhysicalAccess was detected by replay as well ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ...... The audio sample was PhysicalAccess was detected by CNN as well ......",
      "The audio sample was PhysicalAccess was detected by CNN as well ...... The audio sample was PhysicalAccess was detected by CNN as well ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      "The audio sample was PhysicalAccess was detected by CNN as well ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... The recording was faked using playback ......",
      "yes AudioFeature was used to determine speaker id ......",
      "The recording was faked using playback ...... The recording was faked using playback ......",
      "yes AudioFeature was used to determine speaker id ...... The recording was faked using playback ......",
      "yes AudioFeature was used to determine speaker id ......",
      "The recording was faked using playback ...... The recording was faked using playback ......",
      "yes AudioFeature was used to determine speaker id ...... The recording was faked using playback ......",
      "yes AudioFeature was used to determine speaker id ......",
      "The recording was faked using playback ...... The recording was faked using playback ......",
      "yes AudioFeature was used to determine speaker id ...... The recording was faked using playback ......",
      "The recording was faked using playback ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Y the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ...... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "spoofed the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by Yes recording was a PhysicalAccess recording ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes the Audiosignal was detected by CN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Y the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ...... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "spoofed the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-33], classification[replayed], shap_value[0.812], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ......",
      "Yes AudioFeature which a sha value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2953 ...... Yes AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by 0.812 ......",
      "0.812 AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.812 value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.812 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[PSRCC-4], interpreter[shap], shap_value[0.4174])",
    "ref": [
      "Constant-Q Cepstral Coefficients ......",
      "Yes AudioFeature which a sh value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Constant-Q Cepstral Coefficients ...... Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of PSRCC-4 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.417 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a 3 value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Constant-Q Cepstral Coefficients ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ PSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4174 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-43], shap_value[0.9284])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "LFCC-43 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-43 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7306 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "LFCC-43 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <shap_value> shap value: [ 0.9284 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-20], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 6 was detected as the primary speaker of the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 6 was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 6 was detected as the primary speaker of the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 6 was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 6 was detected as the primary speaker of the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 6 was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-20 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-9], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person yes was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes person 4 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 4 was detected by AudioFeature with a 4 value of 0 ......",
      "Yes person 4 was detected by AudioFeature with a sh value of 0 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ...... Yes person 4 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of  ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-28], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-28 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-40], classification[replayed], shap_value[0.4012], detected_by[CNN])",
    "ref": [
      "replayed AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Ye AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4012 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-54], classification[bonafide], shap_value[0.6103])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "The audio is synthetic ......",
      "Ye AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "The audio is synthetic ...... Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.6103 was used to detect the sample as Audiosignal ......",
      "0.6103 AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6103 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6103 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], detected_by[CNN])",
    "ref": [
      "Yes the recording was Audiosignal was detected by CNN ...... Yes the recording was Audiosignal was detected by CNN ......",
      "spoof the recording was Audiosignal was detected by CNN ......",
      "Yes the recording was Audiosignal was detected by CN ......",
      "Yes the recording was Audiosignal was detected by spoof ......",
      " the recording was Audiosignal was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ...... Yes the recording was Audiosignal was detected by CNN ......",
      "Yes the recording was Audiosignal was detected by CNN ...... Yes the recording was Audiosignal was detected by CNN ......",
      "spoof the recording was Audiosignal was detected by CNN ......",
      "Yes the recording was Audiosignal was detected by CN ......",
      "Yes the recording was Audiosignal was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-12], determined[speaker_id])",
    "ref": [
      " AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-12 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Constant-Q Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Constant-Q Cepstral Coefficients ...... Constant-Q Cepstral Coefficients ......",
      "Constant-Q Cepstral Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-49], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3846 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-49 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-48], interpreter[shap], shap_value[-0.5])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person 4 was detected by AudioFeature with a 4 value of -0.5 ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 4 was detected by AudioFeature with a sha value of -0.5 ......",
      "Yes AudioFeature which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 4 was detected by AudioFeature with a shap value of -0.5 ......",
      "Yes person LFCC-48 was detected by AudioFeature with a shap value of -0.5 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.5 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.5 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.5 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.5 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-48 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], mic_type[mobile_phone])",
    "ref": [
      "No most of the recording was made with a mobile phone ......",
      "person 6 was detected as the primary speaker of the audio sample ...... No most of the recording was not made with a mobile phone ......",
      "spoof most of the recording was not made with a mobile phone ......",
      "N most of the recording was not made with a mobile phone ......",
      "No most of the recording was not made with a mobile phone ...... No most of the recording was not made with a mobile phone ......",
      "person 6 was detected as the primary speaker of the audio sample ......",
      "No most of the recording was made with a mobile phone ......",
      "person 6 was detected as the primary speaker of the audio sample ...... No most of the recording was not made with a mobile phone ......",
      "spoof most of the recording was not made with a mobile phone ......",
      "N most of the recording was not made with a mobile phone ......",
      "No most of the recording was not made with a mobile phone ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-30], classification[replayed], detected_by[CNN])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-30 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-5], classification[bonafide], shap_value[-0.158])",
    "ref": [
      "Yes AudioFeature which a sha value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.158 value of -0.158 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8209 ...... Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.158 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-44], shap_value[0.4408])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.44 ......",
      "LFCC-44 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......",
      "Yes there was more than one CaptureDevice ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......",
      "Yes there was more than one CaptureDevice ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.44 ......",
      "LFCC-44 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......",
      "Yes there was more than one CaptureDevice ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4408 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <shap_value> shap value: [ 0.4408 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-16], interpreter[shap], shap_value[0.7676])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a 0.7676 value of 0.7676 ......",
      "6 was found to be the id of the speaker in the sample ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.66 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.yes6yes6 ......",
      "Yes person 7 was detected by AudioFeature with a sh value of 0.7676 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......",
      "6 was found to be the id of the speaker in the sample ...... Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......",
      "Yes person 7 was detected by AudioFeature with a 0.7676 value of 0.7676 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7676 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-9], interpreter[shap], shap_value[0])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a  value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a 4 value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker GTCC-9 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-37], classification[bonafide], shap_value[-0.3635])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes there were 2 microphones ......",
      "Yes AudioFeature which a s value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes there were 2 microphones ...... Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.3635 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3635 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3635 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Part of the AcousticWave is synthesized ...... Part of the AcousticWave is synthesized ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Part of the AcousticWave is synthesized ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Part of the AcousticWave is synthesized ...... Part of the AcousticWave is synthesized ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Part of the AcousticWave is synthesized ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Part of the AcousticWave is synthesized ...... Part of the AcousticWave is synthesized ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Part of the AcousticWave is synthesized ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Part of the AcousticWave is synthesized ...... Part of the AcousticWave is synthesized ......",
      "Part of the AcousticWave is synthesized ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      "No the Audiosignal was detected by converted recording was not converted .....",
      "Yes the recording was Audiosignal was detected by CNN ...... No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by  recording was not converted .....",
      "N the Audiosignal was detected by CNN recording was not converted .....",
      "converted the Audiosignal was detected by CNN recording was not converted .....",
      "Yes the recording was Audiosignal was detected by CNN ......",
      "No the Audiosignal was detected by CNN recording was not converted ..... No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not conver .....",
      "No the Audiosignal was detected by CNN recording was converted .....",
      "No the Audiosignal was detected by CNN recording was not CNN .....",
      "No the Audiosignal was detected by CNN recording was not converted ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "A Audiosignal signature was detected ......",
      "A Audiosignal signature was not detected ...... A Audiosignal signature was not detected ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ...... A Audiosignal signature was not detected ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ......",
      "A Audiosignal signature was detected ......",
      "A Audiosignal signature was not detected ...... A Audiosignal signature was not detected ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ...... A Audiosignal signature was not detected ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ......",
      "A Audiosignal signature was detected ......",
      "A Audiosignal signature was not detected ...... A Audiosignal signature was not detected ......",
      "A Audiosignal signature was not detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-0], shap_value[0.4598])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.45 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "0.4598 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.45 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4598 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <shap_value> shap value: [ 0.4598 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-8], classification[bonafide], shap_value[-0.7408])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-8 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.7408 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "-0.7408 AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.7408 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7408 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7408 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-9], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.158 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by spoof audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Audiosignal was detected by  audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by spoof audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Audiosignal was detected by  audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[7])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ......",
      "Yes AudioFeature which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-16], shap_value[0.2676])",
    "ref": [
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "MFCC-16 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-16 ......",
      "Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.267 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "MFCC-16 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-16 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2676 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <shap_value> shap value: [ 0.2676 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-1], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ...... Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a 0 value of 0 ......",
      "Yes AudioFeature which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...... Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-12], interpreter[shap], shap_value[-0.7561])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.561 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.7561 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.7561 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.7561 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 7 ......",
      "Yes person MSRCC-12 was detected by AudioFeature with a shap value of -0.MSRCC-12561 ......",
      "Yes person 7 was detected by AudioFeature with a s value of -0.7561 ......",
      "Yes person 7 was detected by AudioFeature with a yes value of -0.7561 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.756 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.561 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.7561 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7561 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-2], classification[bonafide], shap_value[0.7845])",
    "ref": [
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.784 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.7845 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ...... Yes AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ......",
      "0.7845 AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.7845 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5786 ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7845 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[no])",
    "ref": [
      "I do recognize any of the CaptureDevice signatures ......",
      "I do spooft recognize any of the CaptureDevice signatures ......",
      "It shows signs of having been digitally manipulated ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do not recognize any of the CaptureDevice signatures ...... I do not recognize any of the CaptureDevice signatures ......",
      "It shows signs of having been digitally manipulated ......",
      "I do t recognize any of the CaptureDevice signatures ......",
      "I do recognize any of the CaptureDevice signatures ......",
      "I do spooft recognize any of the CaptureDevice signatures ......",
      "It shows signs of having been digitally manipulated ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do not recognize any of the CaptureDevice signatures ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do not recognize any of the CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ no ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ...... The voice changes during the conversation ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......",
      "The voice changes during the conversation ...... The voice changes during the conversation ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ...... The voice changes during the conversation ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......",
      "The voice changes during the conversation ...... The voice changes during the conversation ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ...... The voice changes during the conversation ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ......",
      "The voice changes during the conversation ...... The voice changes during the conversation ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.9992 ...... The voice changes during the conversation ......",
      "The voice changes during the conversation ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-12], interpreter[shap], shap_value[0.364])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.30.3644 was used to detect the id of speaker 0.364 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.34 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.364 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a 6 value of 0.364 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3069 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.30.3644 was used to detect the id of speaker 0.364 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.364 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by conversion audio was converted ......",
      "The Audiosignal was detected by CN audio was converted ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "The Audiosignal was detected by CNN audio was converted ...... The Audiosignal was detected by CNN audio was converted ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... The Audiosignal was detected by CNN audio was converted ......",
      "The Audiosignal was detected by conversion audio was converted ......",
      "The Audiosignal was detected by CN audio was converted ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "The Audiosignal was detected by CNN audio was converted ...... The Audiosignal was detected by CNN audio was converted ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... The Audiosignal was detected by CNN audio was converted ......",
      "The Audiosignal was detected by CNN audio was converted ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not converted ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "No the Audiosignal was detected by CNN recording was not converted .....",
      "No the Audiosignal was detected by CNN recording was not converted ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-11], shap_value[-0.761])",
    "ref": [
      "-0.761 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.76 ......",
      "-0.761 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.761 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <shap_value> shap value: [ -0.761 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-57], interpreter[shap], shap_value[0.1692])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.169 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.1692 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.1692 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 2 ......",
      "Yes person 2 was detected by AudioFeature with a 0.1692 value of 0.1692 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.1692 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.169 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.169shap ......",
      "Yes person 2 was detected by AudioFeature with a s value of 0.1692 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.169 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.1692 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-57 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1692 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-2], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-51], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-51 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-10], interpreter[shap], shap_value[0.4852])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a LFCC-10 value of 0.4852 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker 0.4852 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.4852 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4852 ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "This is a Audiosignal was detected by CNN recording This is a Audiosignal was detected by CNN recording",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... This is a Audiosignal was detected by CNN recording",
      "This is a Audiosignal was detected by spoof recording",
      "This is a Audiosignal was detected by CN recording",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "This is a Audiosignal was detected by CNN recording This is a Audiosignal was detected by CNN recording",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... This is a Audiosignal was detected by CNN recording",
      "This is a Audiosignal was detected by spoof recording",
      "This is a Audiosignal was detected by CN recording",
      "This is a Audiosignal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-1], shap_value[0.5149])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "0.5149 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-1 ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.51 ......",
      "Yes AudioFeature which a shap value of 0.4647 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "0.5149 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <shap_value> shap value: [ 0.5149 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-10], interpreter[shap], shap_value[-0.3591])",
    "ref": [
      "Yes AudioFeature which a s value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a MFCC-10 value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-10 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker MFCC-10 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3591 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-4], shap_value[0.6758])",
    "ref": [
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......",
      "PSRCC-4 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-4 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......",
      "PSRCC-4 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6758 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <shap_value> shap value: [ 0.6758 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-22], interpreter[shap], shap_value[-0.9592])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a yes value of -0.9592 ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.9592 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.9592 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.9592 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.9 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 4 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9592 ......",
      "Yes person 4 was detected by AudioFeature with a sha value of -0.9592 ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...... Yes person 4 was detected by AudioFeature with a shap value of -0.9592 ......",
      "Yes person 4 was detected by AudioFeature with a yes value of -0.9592 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.9592 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9592 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-13], interpreter[shap], shap_value[0.7152])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0.715 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of MFCC-13 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person 2 was detected by AudioFeature with a 2 value of 0.7152 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7676 ......",
      "Yes person 2 was detected by AudioFeature with a s value of 0.7152 ......",
      "Yes person 0.7152 was detected by AudioFeature with a shap value of 0.7150.7152 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.715 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7152 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-1], interpreter[shap], shap_value[0.2695])",
    "ref": [
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.695 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 2 for the audio sample ......",
      "It was altered using software ......",
      "It was altered using software ...... Yes AudioFeature which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 0.2695 value of 0.2695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.2695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.shap695 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2695 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-14], classification[bonafide], shap_value[0.3406])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "0.3406 AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.3406 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.3406 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3406 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3406 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-56], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-56 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a compute ......",
      "Some of the recording was made using a spoof ......",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-5 had the highest impact on classification ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a compute ......",
      "Some of the recording was made using a spoof ......",
      "Some of the recording was made using a computer ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[no_microphone])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... Dynamic microphones were used the most ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... Dynamic microphones were used the most ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... Dynamic microphones were used the most ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6718 ...... Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ no_microphone ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The audio has several CaptureDevice signatures ......",
      "The audio has several CaptureDevice signatures ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The audio has several CaptureDevice signatures ......",
      "The audio has several CaptureDevice signatures ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The audio has several CaptureDevice signatures ......",
      "The audio has several CaptureDevice signatures ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The audio has several CaptureDevice signatures ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-34], interpreter[shap], shap_value[0.6721])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a sh value of 0.6721 ......",
      "Yes person 5 was detected by AudioFeature with a yes value of 0.6721 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of shap ......",
      "Yes AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ...... Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.6721 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.6721 ......",
      "Yes person 5 was detected by AudioFeature with a sh value of 0.6721 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6721 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6721 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-42], shap_value[-0.4086])",
    "ref": [
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "LFCC-42 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4086 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <shap_value> shap value: [ -0.4086 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-2], interpreter[shap], shap_value[-0.4862])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a yes value of -0.4862 ......",
      "Yes AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a s value of -0.4862 ......",
      "Yes person -0.4862 was detected by AudioFeature with a shap value of -0.486-0.4862 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes AudioFeature which a shap value of 0.7845 was used to detect the sample as Audiosignal ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.486 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ......",
      "Yes person 2 was detected by AudioFeature with a yes value of -0.4862 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4862 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-44], interpreter[shap], shap_value[-0.643])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a 5 value of -0.643 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.643 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.643 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.643 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of -0.643 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.64 ......",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract .....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..... Yes person 5 was detected by AudioFeature with a shap value of -0.643 ......",
      "Yes person LFCC-44 was detected by AudioFeature with a shap value of -0.643 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of LFCC-44 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of -0.643 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.643 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-44 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.643 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-49], interpreter[shap], shap_value[0.6995])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6 ......",
      "Yes person 5 was detected by AudioFeature with a  value of 0.6995 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.699 ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 5 was detected by AudioFeature with a shap value of 0.6995 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6995 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.6995 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.699shap ......",
      "Yes person 5 was detected by AudioFeature with a yes value of 0.6995 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6995 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-49 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6995 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-9], classification[replayed], shap_value[0.1518], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...... Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.15 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by C ......",
      "shap AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by MFCC-9 ......",
      "Ye AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1518 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-0], interpreter[shap], shap_value[0.4844])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person MSRCC-0 was detected by AudioFeature with a shap value of 0.4844 ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 3 was detected by AudioFeature with a shap value of 0.4844 ......",
      "Yes person 3 was detected by AudioFeature with a  value of 0.4844 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4844 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.4844 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.4844 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person 3 was detected by AudioFeature with a 3 value of 0.4844 ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.4844 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4844 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-3], shap_value[-0.2957])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.29 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MSRCC-3 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.29 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2957 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <shap_value> shap value: [ -0.2957 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-17], classification[replayed], shap_value[-0.524], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a replayed value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.524 AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by -0.524 ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.524 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... The audio is not Audiosignal ......",
      "The audio is Audiosignal ......",
      "The audio is not Audiosignal ...... The audio is not Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... The audio is not Audiosignal ......",
      "The audio is Audiosignal ......",
      "The audio is not Audiosignal ...... The audio is not Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...... The audio is not Audiosignal ......",
      "The audio is Audiosignal ......",
      "The audio is not Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-23], interpreter[shap], shap_value[-0.4514])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a sh value of -0.4514 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4514 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.4514 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.45yes4 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.4514 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.454 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ......",
      "Yes person 1 was detected by AudioFeature with a -0.4514 value of -0.4514 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 1 was detected by AudioFeature with a sh value of -0.4514 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4514 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4514 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-1], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-11], classification[bonafide], shap_value[-0.6353])",
    "ref": [
      "Yes AudioFeature which a sha value of -0.6353 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-11 value of -0.6353 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      "LFCC-11 AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.2913 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.2913 ...... Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.6353 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6353 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6353 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-33], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-33 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-4], classification[bonafide])",
    "ref": [
      "Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Some of the recording was made using a computer ......",
      "Some of the recording was made using a computer ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Some of the recording was made using a computer ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-54], interpreter[shap], shap_value[0.6141])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.6141 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a 7 value of 0.6141 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-54 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6141 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-41], classification[bonafide], shap_value[0.5419])",
    "ref": [
      "Yes AudioFeature which a s value of 0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.5419 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.5419 was used to detect the sample as Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...... Yes AudioFeature which a shap value of 0.5419 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.54 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5419 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.5419 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5419 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5419 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1], change_at[16])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ...... The next synthesized area begins at 16 seconds ......",
      "The next synthesized area begins at 1 seconds ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "The next synthesized area begins at 16 seconds ...... The next synthesized area begins at 16 seconds ......",
      "The next synthesized area begins at spoof seconds ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ...... The next synthesized area begins at 16 seconds ......",
      "The next synthesized area begins at 1 seconds ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6262 ......",
      "The next synthesized area begins at 16 seconds ...... The next synthesized area begins at 16 seconds ......",
      "The next synthesized area begins at spoof seconds ......",
      "The next synthesized area begins at 16 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ], <change_at> change at: [ 16 ]> )"
  },
  {
    "mr": "inform(speaker_id[3], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4724 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-16], shap_value[-0.27])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "LFCC-16 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "LFCC-16 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.27 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <shap_value> shap value: [ -0.27 ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "No other spoof types were detected ...... person 3 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "No other spoof types were detected ......",
      "person 3 was detected as the primary speaker of the audio sample ...... person 3 was detected as the primary speaker of the audio sample ......",
      "No other spoof types were detected ...... person 3 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "No other spoof types were detected ......",
      "person 3 was detected as the primary speaker of the audio sample ...... person 3 was detected as the primary speaker of the audio sample ......",
      "No other spoof types were detected ...... person 3 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 3 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-5], determined[speaker_id])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-5 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... Yes there was more than one CaptureDevice ......",
      " there was more than one CaptureDevice ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "Yes there was more than one CaptureDevice ...... Yes there was more than one CaptureDevice ......",
      ">1 there was more than one CaptureDevice ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... Yes there was more than one CaptureDevice ......",
      " there was more than one CaptureDevice ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "Yes there was more than one CaptureDevice ...... Yes there was more than one CaptureDevice ......",
      ">1 there was more than one CaptureDevice ......",
      "Yes there was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-19], interpreter[shap], shap_value[-0.2333])",
    "ref": [
      "Yes AudioFeature which a  value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker  for the audio sample ......",
      "The audio is not Audiosignal ...... Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a -0.2333 value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "The audio is not Audiosignal ......",
      "Yes AudioFeature which a  value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2333 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-4], classification[bonafide], shap_value[-0.4076])",
    "ref": [
      "The recording was faked using playback ......",
      "Ye AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.4076 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.4076 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "The recording was faked using playback ...... Yes AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "The recording was faked using playback ......",
      "Yes AudioFeature which a shap value of -0.4076 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4076 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-29], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-29 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-0], shap_value[0.2452])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-0 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.245 ......",
      "0.2452 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "Yes AudioFeature which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-0 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2452 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <shap_value> shap value: [ 0.2452 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "Constant-Q Cepstral Coefficients ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Constant-Q Cepstral Coefficients ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Constant-Q Cepstral Coefficients ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Constant-Q Cepstral Coefficients ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Constant-Q Cepstral Coefficients ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Constant-Q Cepstral Coefficients ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Constant-Q Cepstral Coefficients ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.7152 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-23], interpreter[shap], shap_value[-0.664])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ...... Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.664 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 2 value of -0.664 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9056 ......",
      "Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.664 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-21], shap_value[0.8713])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "0.8713 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "0.8713 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8713 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <shap_value> shap value: [ 0.8713 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-4], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "GTCC-4 AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by 1 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a GTCC-4 value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5258 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "It is a bona fide recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It is not a bona fide recording ...... It is not a bona fide recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... It is not a bona fide recording ......",
      "It is a bona fide recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It is not a bona fide recording ...... It is not a bona fide recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... It is not a bona fide recording ......",
      "It is a bona fide recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It is not a bona fide recording ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-37], interpreter[shap], shap_value[-0.6485])",
    "ref": [
      "Yes AudioFeature which a yes value of -0.6485 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes voice cloning was used ......",
      "Yes AudioFeature which a shap value of LFCC-37 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes voice cloning was used ...... Yes AudioFeature which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.6485 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6485 was used to detect the id of speaker -0.6485 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6485 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.6485 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6485 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-49], interpreter[shap], shap_value[-0.1791])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker -0.1791 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.1791 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.1791 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-49 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1791 ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ...... person 7 was detected as the primary speaker of the audio sample ......",
      "person 7 was detected as the primary speaker of the audio sample ...... person 7 was detected as the primary speaker of the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ...... person 7 was detected as the primary speaker of the audio sample ......",
      "person 7 was detected as the primary speaker of the audio sample ...... person 7 was detected as the primary speaker of the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.9913 ...... person 7 was detected as the primary speaker of the audio sample ......",
      "person 7 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-3], determined[speaker_id])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......",
      " AudioFeature was used to determine speaker id ......",
      "GTCC-3 AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6636 was used to detect the sample as Audiosignal ......",
      " AudioFeature was used to determine speaker id ......",
      "GTCC-3 AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-3 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-9], interpreter[shap], shap_value[-0.562])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-9 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.562 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ...... Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.562 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.562 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-15], interpreter[shap], shap_value[-0.6354])",
    "ref": [
      "Other samples show the person speaks at a different speed ...... Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a -0.6354 value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.635 was used to detect the id of speaker  for the audio sample ......",
      "Other samples show the person speaks at a different speed ......",
      "Yes AudioFeature which a shap value of -0.635yes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......",
      "Other samples show the person speaks at a different speed ...... Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6354 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "There were  microphones used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... There were 2 microphones used ......",
      "There were multi_microphone microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ......",
      "There were  microphones used ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9284 ...... There were 2 microphones used ......",
      "There were multi_microphone microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "There were 2 microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-40], classification[bonafide], shap_value[-0.8852])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ......",
      "bonafide AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4862 ...... Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-40 value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.88 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8852 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8852 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "It is not a bona fide recording ......",
      "It is not a bona fide recording ...... There were 2 microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "It is not a bona fide recording ......",
      "It is not a bona fide recording ...... There were 2 microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "It is not a bona fide recording ......",
      "It is not a bona fide recording ...... There were 2 microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "There were 2 microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-4], interpreter[shap], shap_value[0])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a sh value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a GTCC-4 value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speech_speed])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different speed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speech_speed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-10], interpreter[shap], shap_value[0.114])",
    "ref": [
      "Yes AudioFeature which a 4 value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ...... Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.11 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.11shap was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5149 ......",
      "Yes AudioFeature which a 4 value of 0.114 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.114 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-32], interpreter[shap], shap_value[0.0732])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Constant-Q Cepstral Coefficients ...... Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.073yes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-32 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 0.0732 value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.073 was used to detect the id of speaker  for the audio sample ......",
      "Constant-Q Cepstral Coefficients ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0732 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-7], interpreter[shap], shap_value[0.0685])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of MSRCC-7 ......",
      "Yes there was more than one CaptureDevice ...... Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ......",
      "Yes person 5 was detected by AudioFeature with a 0.0685 value of 0.0685 ......",
      "Yes person 5 was detected by AudioFeature with a  value of 0.0685 ......",
      "Yes there was more than one CaptureDevice ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.068yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.068 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of MSRCC-7 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.0685 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0685 ]> )"
  }
]