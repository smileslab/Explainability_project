[
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The audio is not Audiosignal was detected by none?",
      "Two different speeds were detected ...... The audio is not Audiosignal was detected by CNN?",
      "The audio is not Audiosignal was detected by CNN? The audio is not Audiosignal was detected by CNN?",
      "Two different speeds were detected ......",
      "The audio is not Audiosignal was detected by C?",
      "The audio is Audiosignal was detected by CNN?",
      "The audio is not Audiosignal was detected by none?",
      "Two different speeds were detected ...... The audio is not Audiosignal was detected by CNN?",
      "The audio is not Audiosignal was detected by CNN? The audio is not Audiosignal was detected by CNN?",
      "Two different speeds were detected ......",
      "The audio is not Audiosignal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-39], shap_value[0.6906])",
    "ref": [
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "LFCC-39 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-39 ......",
      "There is evidence of sampling ......",
      "There is evidence of sampling ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "LFCC-39 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <shap_value> shap value: [ 0.6906 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[PSRCC-1], interpreter[shap], shap_value[0.6359])",
    "ref": [
      "Yes .",
      "Yes person 7 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.6359 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 7 ......",
      "Yes person 7 was detected by AudioFeature with a PSRCC-1 value of 0.6359 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6359 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.6359 ......",
      "Yes person PSRCC-1 was detected by AudioFeature with a shap value of 0.6359 ......",
      "Yes . Yes person 7 was detected by AudioFeature with a shap value of 0.6359 ......",
      "Yes person 7 was detected by AudioFeature with a sha value of 0.6359 ......",
      "Yes .",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.6359 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ PSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6359 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-18], classification[replayed], shap_value[-0.607], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-18 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-18 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.607 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[1])",
    "ref": [
      "person  spoke the audio sample ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... person 1 spoke the audio sample ......",
      "person 1 spoke the audio sample ...... person 1 spoke the audio sample ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "person  spoke the audio sample ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... person 1 spoke the audio sample ......",
      "person 1 spoke the audio sample ...... person 1 spoke the audio sample ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "person  spoke the audio sample ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... person 1 spoke the audio sample ......",
      "person 1 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-56], classification[replayed], shap_value[0.256], detected_by[CNN])",
    "ref": [
      "LFCC-56 AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of 0.25 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-56 value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-56 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.256 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-8], classification[bonafide])",
    "ref": [
      "There was more than one CaptureDevice ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-53], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-53 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-0], classification[bonafide], shap_value[0.2774])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Several features were used ...... Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-0 value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "LFCC-0 AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Several features were used ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2774 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...... It seems like a computer was used ......",
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It seems like a compu was used ......",
      "It seems like a spoof was used ......",
      "It seems like a computer was used ...... It seems like a computer was used ......",
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...... It seems like a computer was used ......",
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It seems like a compu was used ......",
      "It seems like a spoof was used ......",
      "It seems like a computer was used ...... It seems like a computer was used ......",
      "It seems like a computer was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-29], classification[replayed], shap_value[0.9762], detected_by[CNN])",
    "ref": [
      "replayed AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by LFCC-29 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a CNN value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-29 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9762 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-7], classification[replayed], shap_value[-0.1884], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by -0.1884 ......",
      "shap AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by C ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      " AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.1884 value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1884 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-2], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "There were 2 microphones used ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "There were 2 microphones used ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "There were 2 microphones used ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "There were 2 microphones used ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-2 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-54], interpreter[shap], shap_value[0.7811])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of 0.781 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ......",
      "Yes person 6 was detected by AudioFeature with a 6 value of 0.7811 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.7811 ......",
      "Yes person 6 was detected by AudioFeature with a sha value of 0.7811 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of LFCC-54 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.7811 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.781 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-54 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7811 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[digital])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording device was digital ..... The recording device was digital .....",
      "The recording device was dig .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The recording device was digital .....",
      "The recording device was spoof .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording device was digital ..... The recording device was digital .....",
      "The recording device was dig .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The recording device was digital .....",
      "The recording device was spoof .....",
      "The recording device was digital ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ digital ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-8], shap_value[0])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-8 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-8 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[PSRCC-12], interpreter[shap], shap_value[0.9752])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.90.975252 was used to detect the id of speaker 0.9752 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.952 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a s value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a PSRCC-12 value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ PSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9752 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-12], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-3], shap_value[-0.0079])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "-0.0079 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-3 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0079 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-3 ], <shap_value> shap value: [ -0.0079 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-39], interpreter[shap], shap_value[0.7222])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a yes value of 0.7222 ......",
      "Yes person 1 was detected by AudioFeature with a s value of 0.7222 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.7222 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7222 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.7222 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of 0.7222 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.7222 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7222 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7222 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-35], interpreter[shap], shap_value[0.3982])",
    "ref": [
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 0.3982 value of 0.3982 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.398 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.398shap was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.3982 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3982 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "The audio file was classified as being spoof by a MixtureModel Abstract ......",
      "The audio file was classified as being syn by a MixtureModel Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio file was classified as being synthetic by a MixtureModel Abstract ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...... The audio file was classified as being synthetic by a MixtureModel Abstract ......",
      "The audio file was classified as being spoof by a MixtureModel Abstract ......",
      "The audio file was classified as being syn by a MixtureModel Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio file was classified as being synthetic by a MixtureModel Abstract ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...... The audio file was classified as being synthetic by a MixtureModel Abstract ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[additive_noise])",
    "ref": [
      "Yes. Yes. Artificial background noise was added to the recording ......",
      "Artificial background noise was added to the recording ......",
      "Yes. Yes. Yes. Artificial background noise was added to the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ...... Yes. Artificial background noise was added to the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ...... Artificial background noise was added to the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ...... Yes. Artificial background noise was added to the recording ......",
      "Yes.",
      "additive_noise. Artificial background noise was added to the recording ......",
      "Y. Artificial background noise was added to the recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "Yes. Artificial background noise was added to the recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ additive_noise ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes this is a PhysicalAccess was detected by CN and re-recorded sample ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "spoofed this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "Y this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "Yes this is a PhysicalAccess was detected by Yes and re-recorded sample ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...... Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "Yes this is a PhysicalAccess was detected by CN and re-recorded sample ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "spoofed this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[mixer])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...... A professional mixer was used ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "A professional spoof was used ......",
      "A professional mixer was used ...... A professional mixer was used ......",
      "A professional  was used ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...... A professional mixer was used ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "A professional spoof was used ......",
      "A professional mixer was used ...... A professional mixer was used ......",
      "A professional  was used ......",
      "A professional mixer was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ mixer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-10], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ...... Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes person 3 was detected by AudioFeature with a sh value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of  ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a 0 value of 0 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 3 ......",
      "Yes person GTCC-10 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ...... Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-25], shap_value[-0.7432])",
    "ref": [
      "Two different speeds were detected ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "-0.7432 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-25 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "Two different speeds were detected ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "Two different speeds were detected ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "-0.7432 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <shap_value> shap value: [ -0.7432 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-18], classification[replayed], shap_value[0.2232], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a s value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.2232 AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-18 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2232 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-15], interpreter[shap], shap_value[0.3767])",
    "ref": [
      "Yes person LFCC-15 was detected by AudioFeature with a shap value of 0.3767 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.376 ......",
      "Yes person 1 was detected by AudioFeature with a sha value of 0.3767 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes person 1 was detected by AudioFeature with a shap value of yes ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.3767 ......",
      "Yes person 1 was detected by AudioFeature with a LFCC-15 value of 0.3767 ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ......",
      "Yes person LFCC-15 was detected by AudioFeature with a shap value of 0.3767 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3767 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-48], classification[replayed], detected_by[CNN])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-48 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[replayed])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Yes part of the recording was played back ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes part of the recording was played back ...... Yes part of the recording was played back ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Yes part of the recording was played back ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes part of the recording was played back ...... Yes part of the recording was played back ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Yes part of the recording was played back ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes part of the recording was played back ...... Yes part of the recording was played back ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Yes part of the recording was played back ......",
      "Yes part of the recording was played back ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ...... The signal is consistent with a cloned voice ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ...... The signal is consistent with a cloned voice ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ...... The signal is consistent with a cloned voice ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the entire recording was made using multiple microphones ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "No the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "No the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "No the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ..... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-5], shap_value[-0.6687])",
    "ref": [
      "Two different speeds were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-5 ......",
      "Two different speeds were detected ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6687 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6687 ......",
      "PSRCC-5 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6687 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6687 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6687 ......",
      "Two different speeds were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-5 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6687 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-5 ], <shap_value> shap value: [ -0.6687 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-24], classification[bonafide], shap_value[-0.9231])",
    "ref": [
      "person 8 was detected as the primary speaker of the audio sample ...... Yes AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.9231 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.9231 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ......",
      "person 8 was detected as the primary speaker of the audio sample ......",
      " AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "person 8 was detected as the primary speaker of the audio sample ...... Yes AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9231 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9231 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-20], shap_value[0.3878])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.387 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "0.3878 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.387 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-20 ], <shap_value> shap value: [ 0.3878 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes the recording is PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-50], classification[replayed], detected_by[CNN])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-50 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-45], interpreter[shap], shap_value[0.8788])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.8788 ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 2 was detected by AudioFeature with a shap value of 0.8788 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.8788 ......",
      "Yes person 2 was detected by AudioFeature with a yes value of 0.8788 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.8788 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.8788 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0.8788 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of LFCC-45 ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.8788 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-45 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8788 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...... The audio is fake .....",
      "The audio is fake ..... The audio is fake .....",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...... The audio is fake .....",
      "The audio is fake ..... The audio is fake .....",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...... The audio is fake .....",
      "The audio is fake ..... The audio is fake .....",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "The audio is fake ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording was found to be bonafide...... Yes the recording was found to be bonafide......",
      "Yes the recording was found to be bonafid......",
      "Yes the recording was found to be Yes......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording was found to be bonafide......",
      "Y the recording was found to be bonafide......",
      "bonafide the recording was found to be bonafide......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording was found to be bonafide...... Yes the recording was found to be bonafide......",
      "Yes the recording was found to be bonafid......",
      "Yes the recording was found to be bonafide......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[phone])",
    "ref": [
      "Most of the recording was not made with a mobile  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ...... Most of the recording was not made with a mobile phone ......",
      "Most of the recording was made with a mobile phone ......",
      "Most of the recording was not made with a mobile phone ...... Most of the recording was not made with a mobile phone ......",
      "Most of the recording was not made with a mobile spoof ......",
      "Most of the recording was not made with a mobile  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ...... Most of the recording was not made with a mobile phone ......",
      "Most of the recording was made with a mobile phone ......",
      "Most of the recording was not made with a mobile phone ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ phone ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-3], determined[speaker_id])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ......",
      "MFCC-3 AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ...... yes AudioFeature was used to determine speaker id ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ......",
      "MFCC-3 AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-3 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-57], classification[replayed], shap_value[-0.3017], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.30 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a sha value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3017 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-1], interpreter[shap], shap_value[0.4636])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes the recording shows signs of being edited ......",
      "Yes person 5 was detected by AudioFeature with a s value of 0.4636 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 5 was detected by AudioFeature with a 0.4636 value of 0.4636 ......",
      "Yes person 0.4636 was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes the recording shows signs of being edited ...... Yes person 5 was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4636 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.4636 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.4636 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4636 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-36], shap_value[0.3678])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ......",
      "MFCC-36 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3678 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-36 ], <shap_value> shap value: [ 0.3678 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-11], shap_value[0.8242])",
    "ref": [
      "PSRCC-11 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.82 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "PSRCC-11 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <shap_value> shap value: [ 0.8242 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-5], interpreter[shap], shap_value[-0.3035])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of - ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.3035 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of PSRCC-5 ......",
      "That CaptureDevice was used for 5 seconds ...... Yes person 6 was detected by AudioFeature with a shap value of -0.3035 ......",
      "Yes person 6 was detected by AudioFeature with a yes value of -0.3035 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.3035 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.3035 ......",
      "Yes person -0.3035 was detected by AudioFeature with a shap value of -0.3035 ......",
      "That CaptureDevice was used for 5 seconds ......",
      "Yes person 6 was detected by AudioFeature with a sh value of -0.3035 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of - ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.3035 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3035 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[4])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...... person 4 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "person  spoke the audio sample ......",
      "person 4 spoke the audio sample ...... person 4 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...... person 4 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "person  spoke the audio sample ......",
      "person 4 spoke the audio sample ...... person 4 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...... person 4 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "person 4 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[1])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(speaker_id[5])",
    "ref": [
      " was found to be the id of the speaker in the sample ......",
      "yes AudioFeature was used to determine speaker id ...... 5 was found to be the id of the speaker in the sample ......",
      "yes AudioFeature was used to determine speaker id ......",
      "5 was found to be the id of the speaker in the sample ...... 5 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "yes AudioFeature was used to determine speaker id ...... 5 was found to be the id of the speaker in the sample ......",
      "yes AudioFeature was used to determine speaker id ......",
      "5 was found to be the id of the speaker in the sample ...... 5 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "yes AudioFeature was used to determine speaker id ...... 5 was found to be the id of the speaker in the sample ......",
      "5 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-7], interpreter[shap], shap_value[-0.6095])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-7 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6095 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-8], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Ye AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -1 value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of GTCC-8 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... There are inconsistencies in the background noise which indicate the room changed ......",
      "There are inconsistencies in the background noise which indicate the room changed ...... There are inconsistencies in the background noise which indicate the room changed ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... There are inconsistencies in the background noise which indicate the room changed ......",
      "There are inconsistencies in the background noise which indicate the room changed ...... There are inconsistencies in the background noise which indicate the room changed ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... There are inconsistencies in the background noise which indicate the room changed ......",
      "There are inconsistencies in the background noise which indicate the room changed ...... There are inconsistencies in the background noise which indicate the room changed ......",
      "yes AudioFeature was used to determine speaker id ......",
      "There are inconsistencies in the background noise which indicate the room changed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-3], classification[replayed], shap_value[-0.2809], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by MFCC-3 ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.28 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2809 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-15], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-15 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-23], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-23 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-28], interpreter[shap], shap_value[0.3137])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......",
      "Yes person 0.3137 was detected by AudioFeature with a shap value of 0.30.313737 ......",
      "Yes person 1 was detected by AudioFeature with a  value of 0.3137 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of LFCC-28 ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.337 ......",
      "Yes person 1 was detected by AudioFeature with a 1 value of 0.3137 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3 ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...... Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3137 ]> )"
  },
  {
    "mr": "inform(classification[spoof] , edit_type[multi_microphone], signal_start[10])",
    "ref": [
      "The next CaptureDevice starts at 1 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at spoof seconds ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...... The next CaptureDevice starts at 10 seconds ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The next CaptureDevice starts at 1 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at spoof seconds ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...... The next CaptureDevice starts at 10 seconds ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The next CaptureDevice starts at 10 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <, edit_type> , edit type: [ multi_microphone ], <signal_start> signal start: [ 10 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-3], shap_value[0.8689])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "MFCC-3 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "The audio shows signs of 3 different editors ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.86 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-3 ......",
      "The audio shows signs of 3 different editors ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "MFCC-3 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-3 ], <shap_value> shap value: [ 0.8689 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "No other bonafides were used ......",
      "No other features were used ...... No other features were used ......",
      "No other featus were used ......",
      "The noise changes significantly at the 20 second mark ..... No other features were used ......",
      "The noise changes significantly at the 20 second mark .....",
      "No other bonafides were used ......",
      "No other features were used ...... No other features were used ......",
      "No other featus were used ......",
      "The noise changes significantly at the 20 second mark ..... No other features were used ......",
      "The noise changes significantly at the 20 second mark .....",
      "No other features were used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-37], shap_value[0.9166])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "0.9166 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-37 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <shap_value> shap value: [ 0.9166 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-20], interpreter[shap], shap_value[-0.133])",
    "ref": [
      "Yes AudioFeature which a s value of -0.133 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.133 was used to detect the id of speaker -0.133 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a -0.133 value of -0.133 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.133 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a s value of -0.133 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.133 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-7], interpreter[shap], shap_value[0.6918])",
    "ref": [
      "Yes person shap was detected by AudioFeature with a shap value of 0.6918 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6918 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.6918 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.6918 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes person 5 was detected by AudioFeature with a LFCC-7 value of 0.6918 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 5 was detected by AudioFeature with a shap value of 0.6918 ......",
      "Yes person 5 was detected by AudioFeature with a  value of 0.6918 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.6918 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.6918 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6918 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-17], classification[replayed], shap_value[-0.0283], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MFCC-17 value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of MFCC-17 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Subband Spectral Flux Coefficients ...... Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by -0.0283 ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0283 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being synthe by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being spoof by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being synthe by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being spoof by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-1], interpreter[shap], shap_value[0.7525])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a sha value of 0.7525 ......",
      "Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 4 was detected by AudioFeature with a shap value of LFCC-1 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.7525 ......",
      "Yes person 4 was detected by AudioFeature with a LFCC-1 value of 0.7525 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.752 ......",
      "Yes person LFCC-1 was detected by AudioFeature with a shap value of 0.7525 ......",
      "Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ......",
      "Yes person 4 was detected by AudioFeature with a sha value of 0.7525 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7525 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by  audio was not a PhysicalAccess audio ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by none audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by  audio was not a PhysicalAccess audio ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by  audio was a synthetic audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a synth audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Audiosignal was detected by CNN audio was a spoof audio ......",
      "The Audiosignal was detected by spoof audio was a synthetic audio ......",
      "The Audiosignal was detected by  audio was a synthetic audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a synth audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-46], classification[bonafide], shap_value[-0.8192])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.8192 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8192 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-2], feature[MFCC-6], feature[LFCC-0], feature[MFCC-1])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFC had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-6 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFC had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-6 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-2 ], <feature> feature: [ MFCC-6 ], <feature> feature: [ LFCC-0 ], <feature> feature: [ MFCC-1 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "The breathing rate changes the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The breathing rate changes",
      "The breathing rate changes the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The breathing rate changes",
      "The breathing rate changes the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The breathing rate changes",
      "The breathing rate changes the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-34], classification[bonafide], shap_value[0.2379])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......",
      "Yes AudioFeature which a bonafide value of 0.2379 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-34 was used to detect the sample as Audiosignal ......",
      "MFCC-34 AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.2379 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-34 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2379 ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "7 was found to be the id of the speaker in the sample ...... 7 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... 7 was found to be the id of the speaker in the sample ......",
      "7 was found to be the id of the speaker in the sample ...... 7 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... 7 was found to be the id of the speaker in the sample ......",
      "7 was found to be the id of the speaker in the sample ...... 7 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "7 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Mel physicalattribute Cepstral Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal .",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... The Audiosignal was detected by CNN audio was a synthetic audio ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-19], interpreter[shap], shap_value[-0.1453])",
    "ref": [
      "Yes AudioFeature which a 3 value of -0.1453 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ...... Yes AudioFeature which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.1453 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.145 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.145 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.145shap was used to detect the id of speaker shap for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ......",
      "Yes AudioFeature which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 3 value of -0.1453 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1453 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "No ..... Other features also idicate the audio sample is Audiosignal ......",
      "No .....",
      "Other nones also idicate the audio sample is Audiosignal ......",
      "Other fes also idicate the audio sample is Audiosignal ......",
      "Other features also idicate the audio sample is Audiosignal ...... Other features also idicate the audio sample is Audiosignal ......",
      "No ..... Other features also idicate the audio sample is Audiosignal ......",
      "No .....",
      "Other nones also idicate the audio sample is Audiosignal ......",
      "Other fes also idicate the audio sample is Audiosignal ......",
      "Other features also idicate the audio sample is Audiosignal ...... Other features also idicate the audio sample is Audiosignal ......",
      "Other features also idicate the audio sample is Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], change_at[20])",
    "ref": [
      "The average perception gets higher in this section",
      "Artificial background noise was added to the recording ...... Artificial background noise was added to the recording ......",
      "The average perception gets higher in this section Artificial background noise was added to the recording ......",
      "The average perception gets higher in this section",
      "Artificial background noise was added to the recording ...... Artificial background noise was added to the recording ......",
      "The average perception gets higher in this section Artificial background noise was added to the recording ......",
      "The average perception gets higher in this section",
      "Artificial background noise was added to the recording ...... Artificial background noise was added to the recording ......",
      "The average perception gets higher in this section Artificial background noise was added to the recording ......",
      "The average perception gets higher in this section",
      "Artificial background noise was added to the recording ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-11], determined[speaker_id])",
    "ref": [
      "y AudioFeature was used to determine speaker id ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-11 AudioFeature was used to determine speaker id ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "y AudioFeature was used to determine speaker id ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-11 AudioFeature was used to determine speaker id ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-11 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-6], shap_value[0])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... There is a Audiosignal signature ......",
      "There is a Audiosignal signature ...... There is a Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... There is a Audiosignal signature ......",
      "There is a Audiosignal signature ...... There is a Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... There is a Audiosignal signature ......",
      "There is a Audiosignal signature ...... There is a Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... There is a Audiosignal signature ......",
      "There is a Audiosignal signature ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], sample_start[20])",
    "ref": [
      "The cut is at the sampling second mark .....",
      "The cut is at the 20 second mark ..... The cut is at the 20 second mark .....",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ...... The cut is at the 20 second mark .....",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "The cut is at the  second mark .....",
      "The cut is at the sampling second mark .....",
      "The cut is at the 20 second mark ..... The cut is at the 20 second mark .....",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ...... The cut is at the 20 second mark .....",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "The cut is at the  second mark .....",
      "The cut is at the 20 second mark ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <sample_start> sample start: [ 20 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-7], classification[replayed], shap_value[0.5117], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "PSRCC-7 AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of PSRCC-7 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5117 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-1], determined[speaker_id])",
    "ref": [
      "MFCC-1 AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ...... yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "MFCC-1 AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ...... yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-1 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-47], shap_value[0.6378])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "0.6378 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.63 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "0.6378 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-47 ], <shap_value> shap value: [ 0.6378 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-10], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      "shap AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by shap ......",
      " AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of GTCC-10 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[bonafide])",
    "ref": [
      "Y the recording was made at the same time ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ...... Yes the recording was made at the same time ......",
      "Yes the recording was made at the same time ...... Yes the recording was made at the same time ......",
      "bonafide the recording was made at the same time ......",
      "Y the recording was made at the same time ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ...... Yes the recording was made at the same time ......",
      "Yes the recording was made at the same time ...... Yes the recording was made at the same time ......",
      "bonafide the recording was made at the same time ......",
      "Yes the recording was made at the same time ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-11], classification[bonafide])",
    "ref": [
      "A professional mixer was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "A professional mixer was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "A professional mixer was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "A professional mixer was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "A professional mixer was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "A professional mixer was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "A professional mixer was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-10], classification[replayed], shap_value[-0.0292], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.029 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0292 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], change_at[20])",
    "ref": [
      "The noise changes significantly at the 2 second mark .....",
      "There was more than one CaptureDevice ......",
      "The noise changes significantly at the spoof second mark .....",
      "The noise changes significantly at the 20 second mark ..... The noise changes significantly at the 20 second mark .....",
      "There was more than one CaptureDevice ...... The noise changes significantly at the 20 second mark .....",
      "The noise changes significantly at the 2 second mark .....",
      "There was more than one CaptureDevice ......",
      "The noise changes significantly at the spoof second mark .....",
      "The noise changes significantly at the 20 second mark ..... The noise changes significantly at the 20 second mark .....",
      "There was more than one CaptureDevice ...... The noise changes significantly at the 20 second mark .....",
      "The noise changes significantly at the 20 second mark ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-5], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[5])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-5], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a  value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 0 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a  value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-15], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio shows signs of being edited ......",
      "The audio shows signs of being edited ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio shows signs of being edited ......",
      "The audio shows signs of being edited ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio shows signs of being edited ......",
      "The audio shows signs of being edited ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-15 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-8], interpreter[shap], shap_value[0.1088])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker LFCC-8 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.108 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.1088 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.1088 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker LFCC-8 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1088 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[dynamic])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Dynamic microphones were used the most ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Dynamic microphones were used the most ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Dynamic microphones were used the most ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ dynamic ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-1], classification[bonafide])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-19], classification[replayed], shap_value[-0.8568], detected_by[CNN])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... Yes AudioFeature which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-19 AudioFeature which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.8568 value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Ye AudioFeature which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MFCC-19 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "Yes AudioFeature which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by MFCC-19 ......",
      "Yes AudioFeature which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8568 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[PSRCC-8], interpreter[shap], shap_value[-0.7012])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.701-0.7012 was used to detect the id of speaker -0.7012 for the audio sample ......",
      "Yes AudioFeature which a PSRCC-8 value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.70 was used to detect the id of speaker 2 for the audio sample ......",
      "The signal indicates voice cloning .....",
      "Yes AudioFeature which a shap value of -0.701 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......",
      "The signal indicates voice cloning ..... Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.701-0.7012 was used to detect the id of speaker -0.7012 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ PSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7012 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-26], classification[bonafide], shap_value[-0.4524])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes . Yes AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "MFCC-26 AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes .",
      "Ye AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4524 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-26 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4524 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-34], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3767 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-34 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-38], classification[replayed], shap_value[-0.0316], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by -0.0316 ......",
      "Yes AudioFeature which a sha value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MFCC-38 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "Yes AudioFeature which a MFCC-38 value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ...... Yes AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-38 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0316 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_length[5])",
    "ref": [
      "That CaptureDevice was used for  seconds ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "The next CaptureDevice starts at 10 seconds ......",
      "That CaptureDevice was used for spoof seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "The next CaptureDevice starts at 10 seconds ......",
      "That CaptureDevice was used for spoof seconds ......",
      "That CaptureDevice was used for 5 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_length> change length: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-34], classification[bonafide], shap_value[-0.3612])",
    "ref": [
      "Yes AudioFeature which a bonafide value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "Yes AudioFeature which a sh value of -0.3612 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "LFCC-34 AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ...... Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3612 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-4], classification[bonafide], shap_value[0.5129])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ...... Yes AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.5129 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ......",
      "PSRCC-4 AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.51 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.5129 value of 0.5129 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ...... Yes AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5129 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5129 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[PSRCC-4], interpreter[shap], shap_value[-0.4072])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4072 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.40 ......",
      "Yes person PSRCC-4 was detected by AudioFeature with a shap value of -0.407PSRCC-4 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.407 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of -0.4072 ......",
      "Yes person 2 was detected by AudioFeature with a yes value of -0.4072 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4072 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4072 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4072 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4072 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ PSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4072 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-1], classification[bonafide], shap_value[0])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of GTCC-1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0 was used to detect the sample as Audiosignal ......",
      "GTCC-1 AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-28], classification[bonafide], shap_value[-0.7878])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.787 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.7878 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.7878 value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Yes AudioFeature which a shap value of -0.787 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-28 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7878 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed .",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-5], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      " AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      " AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-5 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-17], interpreter[shap], shap_value[-0.5241])",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ...... Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.524LFCC-17 was used to detect the id of speaker LFCC-17 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a -0.5241 value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.524 was used to detect the id of speaker 1 for the audio sample ......",
      "The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 10 seconds ...... Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5241 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-22], interpreter[shap], shap_value[0.7829])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "Yes AudioFeature which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.7829 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7829 was used to detect the id of speaker  for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ...... Yes AudioFeature which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.782 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7829 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a LFCC-22 value of 0.7829 was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "Yes AudioFeature which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7829 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-6], interpreter[shap], shap_value[0.46])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 0.46 value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker  for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.46 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-7], interpreter[shap], shap_value[0.7878])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.787 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 0.7878 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a MFCC-7 value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.787 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7878 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-4], interpreter[shap], shap_value[0.2638])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a LFCC-4 value of 0.2638 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.638 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.2638 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.shap638 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-4 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2638 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-14], interpreter[shap], shap_value[-0.4302])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of -0.4302 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.4302 ......",
      "Yes person MFCC-14 was detected by AudioFeature with a shap value of -0.MFCC-14302 ......",
      "Yes person 4 was detected by AudioFeature with a yes value of -0.4302 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.43 ......",
      "Yes person 4 was detected by AudioFeature with a sh value of -0.4302 ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 4 was detected by AudioFeature with a shap value of -0.4302 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of shap ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.302 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.4302 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.4302 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.4302 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4302 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-5], shap_value[0.2454])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.24 ......",
      "0.2454 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-5 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.24 ......",
      "0.2454 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-5 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <shap_value> shap value: [ 0.2454 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-40], interpreter[shap], shap_value[0.9729])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.9729 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of 0.9729 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of 0.9729 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.9729 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.9729 ......",
      "Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.9729 ......",
      "Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ...... Yes person 5 was detected by AudioFeature with a shap value of 0.9729 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.9729 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9729 ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[converted], model[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The recording file was classified as being c by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being spoofed by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The recording file was classified as being c by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being spoofed by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "person 7 spoke the audio sample ...... person 7 spoke the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... person 7 spoke the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "person  spoke the audio sample ......",
      "person 7 spoke the audio sample ...... person 7 spoke the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... person 7 spoke the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "person  spoke the audio sample ......",
      "person 7 spoke the audio sample ...... person 7 spoke the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... person 7 spoke the audio sample ......",
      "person 7 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-7], determined[speaker_id])",
    "ref": [
      "MFCC-7 AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... yes AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "MFCC-7 AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... yes AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-7 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], edit_start[5])",
    "ref": [
      "The recording is a little faster between the five and ten second mark ...... The recording is a little faster between the five and ten second mark ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... The recording is a little faster between the five and ten second mark ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "The recording is a little faster between the five and ten second mark ...... The recording is a little faster between the five and ten second mark ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... The recording is a little faster between the five and ten second mark ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "The recording is a little faster between the five and ten second mark ...... The recording is a little faster between the five and ten second mark ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... The recording is a little faster between the five and ten second mark ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "The recording is a little faster between the five and ten second mark ...... The recording is a little faster between the five and ten second mark ......",
      "The recording is a little faster between the five and ten second mark ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <edit_start> edit start: [ 5 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-13], determined[speaker_id])",
    "ref": [
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-13 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-26], classification[replayed], shap_value[0.6994], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-26 AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a s value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-26 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.6994 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-38], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-38 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-24], interpreter[shap], shap_value[-0.4413])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of LFCC-24 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.4413 ......",
      "Yes person 5 was detected by AudioFeature with a LFCC-24 value of -0.4413 ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.4413 ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...... Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ......",
      "Yes person 5 was detected by AudioFeature with a sh value of -0.4413 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.4413 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4413 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], sample_start[20])",
    "ref": [
      "The audio cuts abruptly at the spoof second mark ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... The audio cuts abruptly at the 20 second mark ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio cuts abruptly at the 2 second mark ......",
      "The audio cuts abruptly at the 20 second mark ...... The audio cuts abruptly at the 20 second mark ......",
      "The audio cuts abruptly at the spoof second mark ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... The audio cuts abruptly at the 20 second mark ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio cuts abruptly at the 2 second mark ......",
      "The audio cuts abruptly at the 20 second mark ...... The audio cuts abruptly at the 20 second mark ......",
      "The audio cuts abruptly at the 20 second mark ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <sample_start> sample start: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-2], determined[speaker_id])",
    "ref": [
      " AudioFeature was used to determine speaker id ......",
      "MFCC-2 AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "MFCC-2 AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-2 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-5], interpreter[shap], shap_value[0.5221])",
    "ref": [
      "Yes AudioFeature which a 3 value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a  value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker shap for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 3 value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5221 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... There is more than one CaptureDevice signature on the recording .....",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "There is more than one CaptureDevice signature on the recording ..... There is more than one CaptureDevice signature on the recording .....",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... There is more than one CaptureDevice signature on the recording .....",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "There is more than one CaptureDevice signature on the recording ..... There is more than one CaptureDevice signature on the recording .....",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... There is more than one CaptureDevice signature on the recording .....",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "There is more than one CaptureDevice signature on the recording ..... There is more than one CaptureDevice signature on the recording .....",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... There is more than one CaptureDevice signature on the recording .....",
      "There is more than one CaptureDevice signature on the recording ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoofed], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "The audio sample was Audiosignal was detected by spoofed ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... The audio sample was Audiosignal was detected by CNN ......",
      "The audio sample was Audiosignal was detected by CNN ...... The audio sample was Audiosignal was detected by CNN ......",
      "The audio sample was Audiosignal was detected by  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "The audio sample was Audiosignal was detected by spoofed ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... The audio sample was Audiosignal was detected by CNN ......",
      "The audio sample was Audiosignal was detected by CNN ...... The audio sample was Audiosignal was detected by CNN ......",
      "The audio sample was Audiosignal was detected by  ......",
      "The audio sample was Audiosignal was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-58], classification[bonafide])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-58 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The audio is not converted ...... The signal is consistent with a cloned voice ......",
      "The audio is not converted ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The audio is not converted ...... The signal is consistent with a cloned voice ......",
      "The audio is not converted ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The audio is not converted ...... The signal is consistent with a cloned voice ......",
      "The audio is not converted ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], change_at[20])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is more feedback at the 40 second mark ......",
      "There is more feedback at the 40 second mark ...... There is more feedback at the 40 second mark ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is more feedback at the 40 second mark ......",
      "There is more feedback at the 40 second mark ...... There is more feedback at the 40 second mark ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is more feedback at the 40 second mark ......",
      "There is more feedback at the 40 second mark ...... There is more feedback at the 40 second mark ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There is more feedback at the 40 second mark ......",
      "There is more feedback at the 40 second mark ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[No])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "N .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... No .....",
      "No ..... No .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "N .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... No .....",
      "No ..... No .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "N .....",
      "No ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-8], shap_value[-0.2841])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-8 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "-0.2841 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <shap_value> shap value: [ -0.2841 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature], detected_by[CNN])",
    "ref": [
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-41], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-41 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-54], shap_value[0.2979])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-54 ......",
      "No the entire recording was made using multiple microphones ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      "No the entire recording was made using multiple microphones .....",
      "LFCC-54 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.29 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-54 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <shap_value> shap value: [ 0.2979 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-2], classification[replayed], shap_value[-0.5591], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There was no Audiosignal signature ......",
      "There was no Audiosignal signature ...... Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MSRCC-2 value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5591 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-27], shap_value[0.8773])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8 ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-27 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "0.8773 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8 ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-27 ], <shap_value> shap value: [ 0.8773 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It was altered using spoof ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It was altered using software ...... It was altered using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... It was altered using software ......",
      "It was altered using  ......",
      "It was altered using spoof ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It was altered using software ...... It was altered using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... It was altered using software ......",
      "It was altered using  ......",
      "It was altered using software ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-22], classification[bonafide], shap_value[0.285])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-22 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.285 value of 0.285 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-22 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.285 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-36], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It seems like a computer was used ......",
      "It seems like a computer was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It seems like a computer was used ......",
      "It seems like a computer was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "It seems like a computer was used ......",
      "It seems like a computer was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-36 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-26], classification[replayed], shap_value[0.737], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by 0.737 ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "Yes AudioFeature which a 0.737 value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a sh value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-26 AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-26 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.737 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There were no other spoof types ......",
      "There were no other spoof types ...... There were no other spoof types ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There were no other spoof types ......",
      "There were no other spoof types ...... There were no other spoof types ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... There were no other spoof types ......",
      "There were no other spoof types ...... There were no other spoof types ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There were no other spoof types ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-17], shap_value[0.8093])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.80 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ......",
      "MFCC-17 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.80 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8093 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <shap_value> shap value: [ 0.8093 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not converted ..... The Audiosignal was detected by CNN audio was not converted .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The Audiosignal was detected by CNN audio was not converted .....",
      "The Audiosignal was detected by C audio was not converted .....",
      "The Audiosignal was detected by none audio was not converted .....",
      "The Audiosignal was detected by CNN audio was converted .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not converted ..... The Audiosignal was detected by CNN audio was not converted .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The Audiosignal was detected by CNN audio was not converted .....",
      "The Audiosignal was detected by C audio was not converted .....",
      "The Audiosignal was detected by CNN audio was not converted ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-1], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[5], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "The synthesized AcousticWave starts at 7 seconds .....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "The synthesized AcousticWave starts at 7 seconds ..... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "The synthesized AcousticWave starts at 7 seconds .....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "The synthesized AcousticWave starts at 7 seconds ..... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-12], shap_value[0])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-12 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "yes AudioFeature was used to determine speaker id ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "GTCC-12 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of GTCC-12 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-12 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Subband Spectral Flux Coefficients ...... Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Subband Spectral Flux Coefficients ...... Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Subband Spectral Flux Coefficients ...... Subband Spectral Flux Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Subband Spectral Flux Coefficients ......",
      "Subband Spectral Flux Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-31], classification[replayed], shap_value[-0.0844], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of LFCC-31 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "LFCC-31 AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a LFCC-31 value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ...... Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-31 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0844 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-21], shap_value[0.3974])",
    "ref": [
      "LFCC-21 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "yes AudioFeature was used to determine speaker id ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.39 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "LFCC-21 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "yes AudioFeature was used to determine speaker id ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <shap_value> shap value: [ 0.3974 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-30], shap_value[0.2255])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-30 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "MFCC-30 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-30 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-30 ], <shap_value> shap value: [ 0.2255 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-7], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-9], determined[speaker_id])",
    "ref": [
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-9 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-4], classification[bonafide])",
    "ref": [
      "Two different speeds were detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Two different speeds were detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Two different speeds were detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Two different speeds were detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Two different speeds were detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Two different speeds were detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Two different speeds were detected ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-7], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "person 2 spoke the audio sample ...... Voice cloning was used ......",
      "Voice spoof was used ......",
      "person 2 spoke the audio sample ......",
      "Voice cl was used ......",
      "Voice cloning was used ...... Voice cloning was used ......",
      "person 2 spoke the audio sample ...... Voice cloning was used ......",
      "Voice spoof was used ......",
      "person 2 spoke the audio sample ......",
      "Voice cl was used ......",
      "Voice cloning was used ...... Voice cloning was used ......",
      "Voice cloning was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-4], determined[speaker_id])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-4 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ...... No other spoof types were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ...... No other spoof types were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ...... No other spoof types were detected ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "No other spoof types were detected ...... No other spoof types were detected ......",
      "No other spoof types were detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-2], interpreter[shap], shap_value[1])",
    "ref": [
      "The audio sample was passed to a modeltype Abstract for classification ...... Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person  was detected by AudioFeature with a shap value of  ......",
      "The audio sample was passed to a modeltype Abstract for classification ......",
      "Yes person yes was detected by AudioFeature with a shap value of yes ......",
      "Yes person 1 was detected by AudioFeature with a 1 value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ...... Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a  value of 1 ......",
      "Yes person GTCC-2 was detected by AudioFeature with a shap value of GTCC-2 ......",
      "The audio sample was passed to a modeltype Abstract for classification ...... Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person  was detected by AudioFeature with a shap value of  ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[37])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at spoof seconds ......",
      "There is an unusually long pause at  seconds ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "There is an unusually long pause at 37 seconds ...... There is an unusually long pause at 37 seconds ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at spoof seconds ......",
      "There is an unusually long pause at  seconds ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "There is an unusually long pause at 37 seconds ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 37 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-52], interpreter[shap], shap_value[-0.7766])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a -0.7766 value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker -0.7766 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ...... Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-52 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7766 ]> )"
  },
  {
    "mr": "inform(speaker_id[8])",
    "ref": [
      "8 was found to be the id of the speaker in the sample ...... 8 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... 8 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "8 was found to be the id of the speaker in the sample ...... 8 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... 8 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "8 was found to be the id of the speaker in the sample ...... 8 was found to be the id of the speaker in the sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... 8 was found to be the id of the speaker in the sample ......",
      "8 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband .  Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband .  However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Hence the SCF feature is affected by changes in pitch and harmonic structure ...... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-37], classification[replayed], shap_value[-0.5104], detected_by[CNN])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ......",
      "Y AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ...... Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-37 AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a Yes value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5104 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-40], interpreter[shap], shap_value[-0.6692])",
    "ref": [
      "Yes AudioFeature which a 4 value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.66 was used to detect the id of speaker 4 for the audio sample ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-40 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Yes AudioFeature which a 4 value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6692 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-9], classification[bonafide], shap_value[-0.9442])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ...... Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2255 ......",
      "Yes AudioFeature which a sh value of -0.9442 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.9442 value of -0.9442 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9442 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-28], interpreter[shap], shap_value[0.9935])",
    "ref": [
      "Yes AudioFeature which a s value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 3 value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 3 for the audio sample ......",
      "No the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of 0.990.99355 was used to detect the id of speaker 0.9935 for the audio sample ......",
      "No the entire recording was made using multiple microphones ..... Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.995 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9935 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-31], interpreter[shap], shap_value[-0.7141])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker LFCC-31 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ...... Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "Yes AudioFeature which a LFCC-31 value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7141 ]> )"
  },
  {
    "mr": "inform(speaker_id[1], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... The audio shows signs of being edited ......",
      "The audio shows signs of being edited ...... The audio shows signs of being edited ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... The audio shows signs of being edited ......",
      "The audio shows signs of being edited ...... The audio shows signs of being edited ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... The audio shows signs of being edited ......",
      "The audio shows signs of being edited ...... The audio shows signs of being edited ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "The audio shows signs of being edited ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-14], classification[bonafide], shap_value[0.0192])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "0.0192 AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-14 value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0192 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-15], classification[bonafide], shap_value[-0.1785])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......",
      "-0.1785 AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.1785 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.17 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.1785 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-15 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1785 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-3], classification[bonafide], shap_value[-0.2091])",
    "ref": [
      "Yes AudioFeature which a s value of -0.2091 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.2091 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2091 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2091 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.2091 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.2091 value of -0.2091 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2091 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.2091 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2091 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2091 ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "person  spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ...... person 3 spoke the audio sample ......",
      "person 3 spoke the audio sample ...... person 3 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......",
      "person  spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ...... person 3 spoke the audio sample ......",
      "person 3 spoke the audio sample ...... person 3 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ......",
      "person  spoke the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1785 was used to detect the sample as Audiosignal ...... person 3 spoke the audio sample ......",
      "person 3 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio signal shows signs of it .....",
      "The audio signal shows signs of it ..... The audio signal shows signs of it .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio signal shows signs of it .....",
      "The audio signal shows signs of it ..... The audio signal shows signs of it .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio signal shows signs of it .....",
      "The audio signal shows signs of it ..... The audio signal shows signs of it .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio signal shows signs of it .....",
      "The audio signal shows signs of it ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-11], classification[bonafide], shap_value[-0.6615])",
    "ref": [
      " AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a bonafide value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.6615 was used to detect the sample as Audiosignal ......",
      "-0.6615 AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.66 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6615 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-22], classification[replayed], shap_value[0.752], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.7 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-22 value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes ......",
      "Yes AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by LFCC-22 ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes ...... Yes AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-22 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.752 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-31], interpreter[shap], shap_value[-0.0766])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker -0.0766 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.0766 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "Yes AudioFeature which a -0.0766 value of -0.0766 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ...... Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0766 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[sampling])",
    "ref": [
      "Yes . Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... There is evidence of sampling ......",
      "There is evidence of sampling ......",
      "Yes . Yes . There is evidence of sampling ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Yes . Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... There is evidence of sampling ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes .",
      "Yes . There is evidence of sampl ......",
      "sampling . There is evidence of sampling ......",
      "Yes . There is evidence of Yes ......",
      "Y . There is evidence of sampling ......",
      "Yes . There is evidence of sampling ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-49], classification[bonafide], shap_value[-0.9585])",
    "ref": [
      "Yes AudioFeature which a s value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ...... Yes AudioFeature which a shap value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-49 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ......",
      "Yes AudioFeature which a -0.9585 value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9585 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      "-0.9585 AudioFeature which a shap value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.9585 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9585 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-49 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9585 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-2], interpreter[shap], shap_value[0.8771])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of yes ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.877shap ......",
      "Yes person 1 was detected by AudioFeature with a yes value of 0.8771 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ......",
      "Yes person 1 was detected by AudioFeature with a s value of 0.8771 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.877 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8771 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-36], classification[replayed], shap_value[-0.7831], detected_by[CNN])",
    "ref": [
      "Y AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MFCC-36 value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a sha value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "yes AudioFeature was used to determine speaker id ...... Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-36 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7831 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "Yes the recording shows signs of 3 different editors ...... Yes the recording shows signs of 3 different editors ......",
      "This is a poor quality recording .....",
      "This is a poor quality recording ..... Yes the recording shows signs of 3 different editors ......",
      "Yes the recording shows signs of 3 different editors ...... Yes the recording shows signs of 3 different editors ......",
      "This is a poor quality recording .....",
      "This is a poor quality recording ..... Yes the recording shows signs of 3 different editors ......",
      "Yes the recording shows signs of 3 different editors ...... Yes the recording shows signs of 3 different editors ......",
      "This is a poor quality recording .....",
      "This is a poor quality recording ..... Yes the recording shows signs of 3 different editors ......",
      "Yes the recording shows signs of 3 different editors ...... Yes the recording shows signs of 3 different editors ......",
      "Yes the recording shows signs of 3 different editors ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-59], interpreter[shap], shap_value[0.9123])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 7 for the audio sample ......",
      "There are different CaptureDevice signatures ...... Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.9123 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a 7 value of 0.9123 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 7 for the audio sample ......",
      "There are different CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-59 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9123 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-11], determined[speaker_id])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "y AudioFeature was used to determine speaker id ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "y AudioFeature was used to determine speaker id ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-11 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-20], interpreter[shap], shap_value[0.8416])",
    "ref": [
      "Yes AudioFeature which a sha value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "The audio shows signs of being edited ...... Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "The audio shows signs of being edited ......",
      "Yes AudioFeature which a shap value of 0.841 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.841yes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8416 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-10], classification[bonafide])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-15], classification[replayed], shap_value[-0.8137], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-15 AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by -0.8137 ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-15 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8137 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-25], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is converted ......",
      "Yes the recording is converted ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is converted ......",
      "Yes the recording is converted ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is converted ......",
      "Yes the recording is converted ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-25 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-6], classification[replayed], shap_value[-0.2267], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of MFCC-6 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.22 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.2267 AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by -0.2267 ......",
      "Yes AudioFeature which a Yes value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2267 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-10], classification[replayed], shap_value[0.8478], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a  value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "CNN AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8478 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[37])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at spoof seconds ......",
      "There is an unusually long pause at 3 seconds ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at spoof seconds ......",
      "There is an unusually long pause at 3 seconds ......",
      "There is an unusually long pause at 37 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 37 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-0], feature[MFCC-0], feature[LFCC-2], feature[MFCC-4])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC had the highest impact on classification ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC had the highest impact on classification ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-0 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-4 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-17], shap_value[0.2636])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......",
      "LFCC-17 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......",
      "LFCC-17 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2636 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <shap_value> shap value: [ 0.2636 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone])",
    "ref": [
      "N I do not recognize any of the CaptureDevice signatures ......",
      "spoof I do not recognize any of the CaptureDevice signatures ......",
      "No I do not recognize any of the CaptureDevice signatures ...... No I do not recognize any of the CaptureDevice signatures ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ...... No I do not recognize any of the CaptureDevice signatures ......",
      "No I do recognize any of the CaptureDevice signatures ......",
      "N I do not recognize any of the CaptureDevice signatures ......",
      "spoof I do not recognize any of the CaptureDevice signatures ......",
      "No I do not recognize any of the CaptureDevice signatures ...... No I do not recognize any of the CaptureDevice signatures ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ......",
      "No I do not recognize any of the CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-9], interpreter[shap], shap_value[-0.8749])",
    "ref": [
      "It appears that part of the audio was sped up ......",
      "Yes person 3 was detected by AudioFeature with a sh value of -0.8749 ......",
      "Yes person 3 was detected by AudioFeature with a yes value of -0.8749 ......",
      "It appears that part of the audio was sped up ...... Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of MFCC-9 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.8749 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.8749 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of - ......",
      "It appears that part of the audio was sped up ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8749 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-55], classification[replayed], shap_value[0.3192], detected_by[CNN])",
    "ref": [
      "Y AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3192 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-43], classification[replayed], shap_value[0.4057], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4057 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-2], classification[replayed], shap_value[0.3903], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ......",
      " AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8689 ...... Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.3903 AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a LFCC-2 value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3903 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-17], interpreter[shap], shap_value[0.2391])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a 1 value of 0.2391 ......",
      "Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 1 was detected by AudioFeature with a sha value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of  ......",
      "Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.239 ......",
      "Yes person MFCC-17 was detected by AudioFeature with a shap value of 0.239MFCC-17 ......",
      "Yes person 1 was detected by AudioFeature with a 1 value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2391 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MSRCC-9], interpreter[shap], shap_value[-0.007])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a MSRCC-9 value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker  for the audio sample ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ...... Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.007 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-11], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a sha value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of GTCC-11 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "GTCC-11 AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0 value of 0 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-10], classification[bonafide], shap_value[0.5373])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.5373 value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.537 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5373 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-13], interpreter[shap], shap_value[0.1362])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker MFCC-13 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.13 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a 0.1362 value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......",
      "yes AudioFeature was used to determine speaker id ...... Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1362 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-26], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-26 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[2])",
    "ref": [
      "Yes part of the recording was played back ......",
      "Yes part of the recording was played back ...... person 2 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "person 2 spoke the audio sample ...... person 2 spoke the audio sample ......",
      "Yes part of the recording was played back ......",
      "Yes part of the recording was played back ...... person 2 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "person 2 spoke the audio sample ...... person 2 spoke the audio sample ......",
      "Yes part of the recording was played back ......",
      "Yes part of the recording was played back ...... person 2 spoke the audio sample ......",
      "person 2 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-9], determined[speaker_id])",
    "ref": [
      " AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      " AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......",
      "speaker_id AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-9 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-38], interpreter[shap], shap_value[0.5482])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.548shap was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a s value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "Several features were used ......",
      "Yes AudioFeature which a shap value of 0.548 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a 2 value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "Several features were used ...... Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.548shap was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5482 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-23], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-23 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[pitch])",
    "ref": [
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ...... The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ...... The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ...... The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "The average perception gets higher in this section"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ pitch ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-22], interpreter[shap], shap_value[0.1394])",
    "ref": [
      "Yes AudioFeature which a shap value of MFCC-22 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.1394 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1394 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1394 was used to detect the id of speaker MFCC-22 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.1394 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-22 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1394 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-1], classification[bonafide])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-7], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a GTCC-7 value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a  value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker GTCC-7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a GTCC-7 value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-31], classification[bonafide], shap_value[-0.5755])",
    "ref": [
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-31 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-31 value of -0.5755 was used to detect the sample as Audiosignal ......",
      "MFCC-31 AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ...... Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "Yes AudioFeature which a sh value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5755 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-12], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ......",
      "Yes person 5 was detected by AudioFeature with a  value of 0 ......",
      "Yes AudioFeature which a shap value of 0.0192 was used to detect the sample as Audiosignal ...... Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person GTCC-12 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a yes value of 0 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "informt(model[CNN], task[classification])",
    "ref": [
      "Several features were used ...... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for CNN ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for clas ......",
      "Several features were used ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ...... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ......",
      "Several features were used ...... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for CNN ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for clas ......",
      "Several features were used ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ...... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ......",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ......"
    ],
    "new_mr": "<informt> informt ( <model> model: [ CNN ], <task> task: [ classification ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MSRCC-5], interpreter[shap], shap_value[0.2787])",
    "ref": [
      "Several features show this is a Audiosignal sample ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.2787 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.2787 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.2787 ......",
      "Yes person 6 was detected by AudioFeature with a MSRCC-5 value of 0.2787 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.2787 ......",
      "Several features show this is a Audiosignal sample ...... Yes person 6 was detected by AudioFeature with a shap value of 0.2787 ......",
      "Yes person 6 was detected by AudioFeature with a  value of 0.2787 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 6 ......",
      "Several features show this is a Audiosignal sample ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.2787 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2787 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-8], interpreter[shap], shap_value[-0.7314])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.731 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 2 value of -0.7314 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ......",
      "Yes AudioFeature which a s value of -0.7314 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ...... Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7314 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-51], classification[bonafide], shap_value[0.9936])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.993 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.9936 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.9936 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.9936 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "Yes AudioFeature which a shap value of 0.9936 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.9936 was used to detect the sample as Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.9936 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.9936 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.993 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9936 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9936 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-23], classification[replayed], shap_value[-0.3555], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "No .....",
      "Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a sha value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "No ..... Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by MFCC-23 ......",
      " AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3555 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-40], classification[bonafide], shap_value[-0.5765])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ......",
      "Yes AudioFeature which a sh value of -0.5765 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6378 ...... Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-40 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5765 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-46], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Most of the recording was not made with a mobile phone ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Most of the recording was not made with a mobile phone ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Most of the recording was not made with a mobile phone ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-46 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[bonafide], multi_microphone[no], mic_quantity[1])",
    "ref": [
      "There is evidence of sampling ......",
      "There is evidence of sampling ...... The CaptureDevice signature is consistent throughout the recording .....",
      "The CaptureDevice signature is consistent throughout the recording ..... The CaptureDevice signature is consistent throughout the recording .....",
      "There is evidence of sampling ......",
      "There is evidence of sampling ...... The CaptureDevice signature is consistent throughout the recording .....",
      "The CaptureDevice signature is consistent throughout the recording ..... The CaptureDevice signature is consistent throughout the recording .....",
      "There is evidence of sampling ......",
      "There is evidence of sampling ...... The CaptureDevice signature is consistent throughout the recording .....",
      "The CaptureDevice signature is consistent throughout the recording ..... The CaptureDevice signature is consistent throughout the recording .....",
      "There is evidence of sampling ......",
      "The CaptureDevice signature is consistent throughout the recording ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <multi_microphone> multi microphone: [ no ], <mic_quantity> mic quantity: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-13], classification[bonafide], shap_value[0.3337])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-13 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... Yes AudioFeature which a shap value of 0.3337 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.3337 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.3337 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3337 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3337 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.3337 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.3337 value of 0.3337 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes AudioFeature which a shap value of 0.3337 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-13 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3337 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-5], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-1 AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[3])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are three distinct CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are three distinct CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are three distinct CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 3 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-38], classification[bonafide], shap_value[0.8451])",
    "ref": [
      "Yes AudioFeature which a sha value of 0.8451 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-38 was used to detect the sample as Audiosignal ......",
      "The average perception gets higher in this section",
      " AudioFeature which a shap value of 0.8451 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-38 value of 0.8451 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8451 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8451 was used to detect the sample as Audiosignal ......",
      "The average perception gets higher in this section Yes AudioFeature which a shap value of 0.8451 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.8451 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.8451 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8451 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8451 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-27], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-27 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-47], interpreter[shap], shap_value[0.5372])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a yes value of 0.5372 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.5372 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-47 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5372 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-24], interpreter[shap], shap_value[-0.6368])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a 4 value of -0.6368 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6368 was used to detect the id of speaker  for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.6368 was used to detect the id of speaker 4 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.6368 was used to detect the id of speaker -0.6368 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.636 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6368 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "It appears that the recording was spliced ..... It appears that the recording was spliced .....",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ...... It appears that the recording was spliced .....",
      "It appears that the recording was spliced ..... It appears that the recording was spliced .....",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ...... It appears that the recording was spliced .....",
      "It appears that the recording was spliced ..... It appears that the recording was spliced .....",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ...... It appears that the recording was spliced .....",
      "It appears that the recording was spliced ..... It appears that the recording was spliced .....",
      "It appears that the recording was spliced ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-1], shap_value[1])",
    "ref": [
      "There are different CaptureDevice signatures ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "There are different CaptureDevice signatures ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "1 determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "There are different CaptureDevice signatures ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "There are different CaptureDevice signatures ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-59], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-59 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-40], classification[replayed], shap_value[0.1447], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.0807 ...... Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.14 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.0807 ......",
      "Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by 0.1447 ......",
      "Yes AudioFeature which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-40 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1447 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-18], shap_value[-0.1509])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ......",
      "-0.1509 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1509 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-18 ], <shap_value> shap value: [ -0.1509 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-26], shap_value[-0.1124])",
    "ref": [
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "Several features show this is a Audiosignal sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "-0.1124 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-26 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "Several features show this is a Audiosignal sample ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "Several features show this is a Audiosignal sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "-0.1124 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1124 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-26 ], <shap_value> shap value: [ -0.1124 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-24], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-24 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy .  The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband .  Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values .  As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No .....",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "No ..... There are different CaptureDevice signatures ......",
      "No .....",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "No ..... There are different CaptureDevice signatures ......",
      "No .....",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "No ..... There are different CaptureDevice signatures ......",
      "No .....",
      "There are different CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-6], interpreter[shap], shap_value[0.3353])",
    "ref": [
      "Dynamic microphones were used the most ......",
      "Yes person 3 was detected by AudioFeature with a s value of 0.3353 ......",
      "Yes person LFCC-6 was detected by AudioFeature with a shap value of 0.LFCC-6LFCC-65LFCC-6 ......",
      "Yes person 3 was detected by AudioFeature with a LFCC-6 value of 0.3353 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.5 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.3353 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.3353 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Dynamic microphones were used the most ...... Yes person 3 was detected by AudioFeature with a shap value of 0.3353 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.3 ......",
      "Dynamic microphones were used the most ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.3353 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3353 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The AcousticWave patterns show where the speaker is from ...... The AcousticWave patterns show where the speaker is from ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ...... The AcousticWave patterns show where the speaker is from ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ...... The AcousticWave patterns show where the speaker is from ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ...... The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MSRCC-8], interpreter[shap], shap_value[-0.5893])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a MSRCC-8 value of -0.5893 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.589 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of MSRCC-8 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.5893 ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      "Yes person yes was detected by AudioFeature with a shap value of -0.5893 ......",
      "Yes person 2 was detected by AudioFeature with a s value of -0.5893 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ......",
      "Yes person 2 was detected by AudioFeature with a MSRCC-8 value of -0.5893 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5893 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ...... There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ...... There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ...... There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "There was more than one CaptureDevice ...... There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ...... There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by none audio was not converted .....",
      "The Audiosignal was detected by CNN audio was converted .....",
      "The Audiosignal was detected by CNN audio was not converted ..... The Audiosignal was detected by CNN audio was not converted .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ...... The Audiosignal was detected by CNN audio was not converted .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ......",
      "The Audiosignal was detected by CN audio was not converted .....",
      "The Audiosignal was detected by none audio was not converted .....",
      "The Audiosignal was detected by CNN audio was converted .....",
      "The Audiosignal was detected by CNN audio was not converted ..... The Audiosignal was detected by CNN audio was not converted .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2841 ...... The Audiosignal was detected by CNN audio was not converted .....",
      "The Audiosignal was detected by CNN audio was not converted ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[replayed], model[GMM], detected_by[CNN])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......",
      "The recording file was classified as being PhysicalAccess was detected by CN by a MixtureModel Abstract ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ...... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The recording file was classified as being PhysicalAccess was detected by replayed by a MixtureModel Abstract ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......",
      "The recording file was classified as being PhysicalAccess was detected by CN by a MixtureModel Abstract ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ...... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The recording file was classified as being PhysicalAccess was detected by replayed by a MixtureModel Abstract ......",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <model> model: [ GMM ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[GTCC-13], interpreter[shap], shap_value[-1])",
    "ref": [
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Yes person  was detected by AudioFeature with a shap value of -1 ......",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...... Yes person 7 was detected by AudioFeature with a shap value of -1 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of  ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -1 ...... Yes person 7 was detected by AudioFeature with a shap value of -1 ......",
      "Yes person 7 was detected by AudioFeature with a 7 value of -1 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 7 ......",
      "Yes person GTCC-13 was detected by AudioFeature with a shap value of -1 ......",
      "Yes person 7 was detected by AudioFeature with a sh value of -1 ......",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -1 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ GTCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-42], classification[bonafide], shap_value[0.5541])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.554 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.5541 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-42 value of 0.5541 was used to detect the sample as Audiosignal ......",
      "LFCC-42 AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-42 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.554 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5541 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-6], interpreter[shap], shap_value[-0.0215])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a s value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 6 was detected by AudioFeature with a PSRCC-6 value of -0.0215 ......",
      "Yes person PSRCC-6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0215 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-8], classification[bonafide], shap_value[0.8955])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.8955 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MSRCC-8 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.8955 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ......",
      "MSRCC-8 AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8955 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "The audio is converted ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...... The audio is not converted ......",
      "The audio is not converted ...... The audio is not converted ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "The audio is converted ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...... The audio is not converted ......",
      "The audio is not converted ...... The audio is not converted ......",
      "Yes AudioFeature which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ......",
      "The audio is converted ......",
      "The audio is not converted ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-44], interpreter[shap], shap_value[0.1772])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-44 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-44 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1772 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-3], classification[bonafide], shap_value[-0.0902])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.0902 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.0902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.0902 value of -0.0902 was used to detect the sample as Audiosignal ......",
      "-0.0902 AudioFeature which a shap value of -0.0902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.09 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.0902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0902 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.0902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0902 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0902 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-29], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-29 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "The average perception gets higher in this section"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[3])",
    "ref": [
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...... There are three distinct CaptureDevice signatures ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...... There are three distinct CaptureDevice signatures ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...... There are three distinct CaptureDevice signatures ......",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "There are three distinct CaptureDevice signatures ...... There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 3 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-5], classification[replayed], shap_value[-0.3337], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a replayed value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of PSRCC-5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.33 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3337 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-29], interpreter[shap], shap_value[-0.143])",
    "ref": [
      "Yes AudioFeature which a  value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.14 was used to detect the id of speaker 2 for the audio sample ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a LFCC-29 value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.143 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-11], shap_value[0.9009])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-11 ......",
      "MSRCC-11 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.900 ......",
      "There was no Audiosignal signature ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "There was no Audiosignal signature ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-11 ......",
      "MSRCC-11 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-11 ], <shap_value> shap value: [ 0.9009 ]> )"
  },
  {
    "mr": "inform(model[SVM], task[classification])",
    "ref": [
      "Most of the recording was not made with a mobile phone ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for class ......",
      "Most of the recording was not made with a mobile phone ...... The recording was passed to a ClassificationAlgorithm Abstract for classification ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for classification ...... The recording was passed to a ClassificationAlgorithm Abstract for classification ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for SVM ......",
      "Most of the recording was not made with a mobile phone ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for class ......",
      "Most of the recording was not made with a mobile phone ...... The recording was passed to a ClassificationAlgorithm Abstract for classification ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for classification ...... The recording was passed to a ClassificationAlgorithm Abstract for classification ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for SVM ......",
      "The recording was passed to a ClassificationAlgorithm Abstract for classification ......"
    ],
    "new_mr": "<inform> inform ( <model> model: [ SVM ], <task> task: [ classification ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-52], shap_value[-0.7935])",
    "ref": [
      "-0.7935 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.793 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-52 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "-0.7935 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.793 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7935 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <shap_value> shap value: [ -0.7935 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-10], classification[replayed], shap_value[-0.6103], detected_by[CNN])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by -0.6103 ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0 ...... Yes AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a sha value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a Yes value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.610 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6103 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "It appears the audio sample was converted ..... It appears the audio sample was converted .....",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...... It appears the audio sample was converted .....",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "It appears the audio sample was converted ..... It appears the audio sample was converted .....",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...... It appears the audio sample was converted .....",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "It appears the audio sample was converted ..... It appears the audio sample was converted .....",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...... It appears the audio sample was converted .....",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "It appears the audio sample was converted ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-53], shap_value[-0.8942])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.89 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-53 ......",
      "-0.8942 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.89 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9166 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.8942 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <shap_value> shap value: [ -0.8942 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[dynamic])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...... Dynamic microphones were used the most ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...... Dynamic microphones were used the most ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...... Dynamic microphones were used the most ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Dynamic microphones were used the most ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ dynamic ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-9], shap_value[0.0969])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-9 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "0.0969 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-9 ], <shap_value> shap value: [ 0.0969 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-8], interpreter[shap], shap_value[-0.89])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a -0.89 value of -0.89 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.89 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.89 ......",
      "Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 2 was detected by AudioFeature with a shap value of -0.89 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of -0.89 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.89 ......",
      "Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.89 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of LFCC-8 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person 2 was detected by AudioFeature with a -0.89 value of -0.89 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.89 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.89 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-22], interpreter[shap], shap_value[-0.7096])",
    "ref": [
      "Yes person -0.7096 was detected by AudioFeature with a shap value of -0.7096 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ......",
      "Yes person 3 was detected by AudioFeature with a s value of -0.7096 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.7096 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 3 was detected by AudioFeature with a MFCC-22 value of -0.7096 ......",
      "Yes person -0.7096 was detected by AudioFeature with a shap value of -0.7096 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7096 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "No the Audiosignal was detected by  recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "The signal is consistent with a cloned voice ...... No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by No recording was not a PhysicalAccess recording ......",
      "spoofed the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "The signal is consistent with a cloned voice ......",
      " the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ...... No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by  recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-11], interpreter[shap], shap_value[0.2606])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ...... Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a 0.2606 value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.26 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a s value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ...... Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2606 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-33], classification[bonafide], shap_value[-0.0018])",
    "ref": [
      "Yes AudioFeature which a bonafide value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Linear physicalattribute Cepstral Coefficients ......",
      " AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Linear physicalattribute Cepstral Coefficients ...... Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0018 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-9], shap_value[-0.6735])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-9 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <shap_value> shap value: [ -0.6735 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It looks like the audio was edited using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "It looks like the audio was edited using software ...... It looks like the audio was edited using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It looks like the audio was edited using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "It looks like the audio was edited using software ...... It looks like the audio was edited using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It looks like the audio was edited using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "It looks like the audio was edited using software ...... It looks like the audio was edited using software ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It looks like the audio was edited using software ......",
      "It looks like the audio was edited using software ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-9], shap_value[-0.1259])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "The audio is not Audiosignal was detected by CNN? shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......",
      "-0.1259 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "The audio is not Audiosignal was detected by CNN?",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "The audio is not Audiosignal was detected by CNN? shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1259 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <shap_value> shap value: [ -0.1259 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], prupose[identification])",
    "ref": [
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for SVM .....",
      "No .....",
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification ..... The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification .....",
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for  .....",
      "No ..... The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification .....",
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for SVM .....",
      "No .....",
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification ..... The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification .....",
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for  .....",
      "No ..... The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification .....",
      "The audio sample had its Entity and AudioFeature features extracted which were passed to an ClassificationAlgorithm Abstract for identification ....."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <prupose> prupose: [ identification ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-6], interpreter[shap], shap_value[-0.7884])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "It was altered using software ...... Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.788 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a 4 value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.788shap was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of PSRCC-6 was used to detect the id of speaker 4 for the audio sample ......",
      "It was altered using software ......",
      "Yes AudioFeature which a sha value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7884 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-39], classification[bonafide])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-39 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...... No the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ..... No the entire recording was made using multiple microphones .....",
      "N the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      ">1 the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...... No the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ..... No the entire recording was made using multiple microphones .....",
      "N the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      ">1 the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-2], classification[bonafide], shap_value[0.7662])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.7662 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Artificial background noise was added to the recording ...... Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Artificial background noise was added to the recording ......",
      "Ye AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7662 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-13], classification[replayed], shap_value[0.2494], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 1 ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-13 AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by 0.2494 ......",
      "Yes AudioFeature which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2494 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-26], shap_value[0.3447])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "MFCC-26 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "No I do not recognize any of the CaptureDevice signatures ......",
      "No I do not recognize any of the CaptureDevice signatures ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "MFCC-26 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-26 ], <shap_value> shap value: [ 0.3447 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-39], interpreter[shap], shap_value[-0.3915])",
    "ref": [
      "Yes person LFCC-39 was detected by AudioFeature with a shap value of -0.LFCC-39915 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.39 ......",
      "Yes person 3 was detected by AudioFeature with a -0.3915 value of -0.3915 ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......",
      "Yes person 3 was detected by AudioFeature with a sha value of -0.3915 ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 3 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.915 ......",
      "Yes person LFCC-39 was detected by AudioFeature with a shap value of -0.LFCC-39915 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3915 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-35], classification[replayed], shap_value[0.8008], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a sha value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MFCC-35 value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-35 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8008 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-55], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-55 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-11], interpreter[shap], shap_value[-0.3231])",
    "ref": [
      "The audio is not converted ...... Yes AudioFeature which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a -0.3231 value of -0.3231 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.21 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a s value of -0.3231 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.shap2shap1 was used to detect the id of speaker shap for the audio sample ......",
      "The audio is not converted ......",
      "The audio is not converted ...... Yes AudioFeature which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3231 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-9], shap_value[0])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-9 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      "There were 2 microphones ...... There were 2 microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ...... There were 2 microphones ......",
      "There were  microphones ......",
      "There were spoof microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ......",
      "There were 2 microphones ...... There were 2 microphones ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2979 ...... There were 2 microphones ......",
      "There were  microphones ......",
      "There were spoof microphones ......",
      "There were 2 microphones ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-3], interpreter[shap], shap_value[-0.0673])",
    "ref": [
      "Most of the recording was not made with a mobile phone ......",
      "Yes person 2 was detected by AudioFeature with a s value of -0.0673 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of - ......",
      "Yes person 2 was detected by AudioFeature with a MFCC-3 value of -0.0673 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.0673 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.0673 ......",
      "Yes person MFCC-3 was detected by AudioFeature with a shap value of -0.0673 ......",
      "Most of the recording was not made with a mobile phone ...... Yes person 2 was detected by AudioFeature with a shap value of -0.0673 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.0673 ......",
      "Most of the recording was not made with a mobile phone ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.0673 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0673 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-48], interpreter[shap], shap_value[0.957])",
    "ref": [
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "There were 2 microphones ...... Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a 4 value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker  for the audio sample ......",
      "There were 2 microphones ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-48 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.957 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-37], shap_value[0.4431])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.44 ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-37 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.44 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4431 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-37 ], <shap_value> shap value: [ 0.4431 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], mic_type[mobile_phone], mic_type[computer])",
    "ref": [
      "Yes some of the recording was made with a mobile device and some with a compu .....",
      "Ye some of the recording was made with a mobile device and some with a computer .....",
      "spoof some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a mobile_phone .....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...... Yes some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a computer ..... Yes some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a compu .....",
      "Ye some of the recording was made with a mobile device and some with a computer .....",
      "spoof some of the recording was made with a mobile device and some with a computer .....",
      "Yes some of the recording was made with a mobile device and some with a computer ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ], <mic_type> mic type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "The AcousticWave patterns show where the speaker is from ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The audio sample was passed to a modeltype Abstract for classification ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The audio sample was passed to a modeltype Abstract for classification ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The audio sample was passed to a modeltype Abstract for classification ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The AcousticWave patterns show where the speaker is from ......",
      "The AcousticWave patterns show where the speaker is from ...... The audio sample was passed to a modeltype Abstract for classification ......",
      "The audio sample was passed to a modeltype Abstract for classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-37], interpreter[shap], shap_value[0.1008])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Yes person 6 was detected by AudioFeature with a  value of 0.1008 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 6 was detected by AudioFeature with a 0.1008 value of 0.1008 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.1008 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.1008 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... Yes person 6 was detected by AudioFeature with a shap value of 0.1008 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.1008 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.1008 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.1008 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1008 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio shows signs of Audio_signal involvement ......",
      "The audio shows signs of Audio_signal involvement ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio shows signs of Audio_signal involvement ......",
      "The audio shows signs of Audio_signal involvement ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio shows signs of Audio_signal involvement ......",
      "The audio shows signs of Audio_signal involvement ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-1], classification[replayed], shap_value[-0.5782], detected_by[CNN])",
    "ref": [
      " AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by -0.5782 ......",
      "Yes AudioFeature which a sha value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5782 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[4])",
    "ref": [
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... person 4 was detected as the primary speaker of the audio sample ......",
      "person 4 was detected as the primary speaker of the audio sample ...... person 4 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... person 4 was detected as the primary speaker of the audio sample ......",
      "person 4 was detected as the primary speaker of the audio sample ...... person 4 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... person 4 was detected as the primary speaker of the audio sample ......",
      "person 4 was detected as the primary speaker of the audio sample ...... person 4 was detected as the primary speaker of the audio sample ......",
      "person 4 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-5], classification[replayed], shap_value[0.0597], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MSRCC-5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.0597 value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0597 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-50], interpreter[shap], shap_value[0.2635])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a s value of 0.2635 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.3035 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2635 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2635 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2635 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 0.2635 was detected by AudioFeature with a shap value of 0.2630.2635 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.3035 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.263 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of 0.2635 ......",
      "Yes person 5 was detected by AudioFeature with a s value of 0.2635 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2635 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-50 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2635 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-10], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-2], shap_value[-0.2448])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.2448 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2448 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-2 ], <shap_value> shap value: [ -0.2448 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-5], classification[replayed], shap_value[-0.2026], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of -0.2 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.2026 AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2026 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ...... There was no Audiosignal signature ......",
      "There was no Audiosignal signature ...... There was no Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ...... There was no Audiosignal signature ......",
      "There was no Audiosignal signature ...... There was no Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ...... There was no Audiosignal signature ......",
      "There was no Audiosignal signature ...... There was no Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "There was no Audiosignal signature ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(speaker_id[8], model[SVM])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "replayed the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "The recording is fake .....",
      "No the Audiosignal was detected by spoofed recording was not a PhysicalAccess recording ......",
      "The recording is fake ..... No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by  recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ...... No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "No the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "N the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "replayed the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "The recording is fake .....",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "The audio is PhysicalAccess was detected by  ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ......",
      "The audio is PhysicalAccess was detected by replay ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ...... The audio is PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ...... The audio is PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by  ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ......",
      "The audio is PhysicalAccess was detected by replay ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7525 ...... The audio is PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ...... The audio is PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-22], shap_value[0.8296])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "LFCC-22 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-22 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.82 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "LFCC-22 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8296 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-22 ], <shap_value> shap value: [ 0.8296 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-2], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a s value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a 1 value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by C ......",
      " AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-14], interpreter[shap], shap_value[0.9466])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a MFCC-14 value of 0.9466 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.9466 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9466 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "There are no inconsistencies which indicate a Audiosignal sample ..... There are no inconsistencies which indicate a Audiosignal sample .....",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... There are no inconsistencies which indicate a Audiosignal sample .....",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "There are no inconsistencies which indicate a Audiosignal sample ..... There are no inconsistencies which indicate a Audiosignal sample .....",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... There are no inconsistencies which indicate a Audiosignal sample .....",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "There are no inconsistencies which indicate a Audiosignal sample ..... There are no inconsistencies which indicate a Audiosignal sample .....",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... There are no inconsistencies which indicate a Audiosignal sample .....",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "There are no inconsistencies which indicate a Audiosignal sample ..... There are no inconsistencies which indicate a Audiosignal sample .....",
      "There are no inconsistencies which indicate a Audiosignal sample ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-2], shap_value[-1])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "-1 determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "Yes AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "-1 determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-2 ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "There are inconsistencies in the number of people speaking ...... There are inconsistencies in the number of people speaking ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ...... There are inconsistencies in the number of people speaking ......",
      "There are inconsistencies in the number of people speaking ...... There are inconsistencies in the number of people speaking ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ...... There are inconsistencies in the number of people speaking ......",
      "There are inconsistencies in the number of people speaking ...... There are inconsistencies in the number of people speaking ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5765 was used to detect the sample as Audiosignal ...... There are inconsistencies in the number of people speaking ......",
      "There are inconsistencies in the number of people speaking ...... There are inconsistencies in the number of people speaking ......",
      "There are inconsistencies in the number of people speaking ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-1], classification[replayed], shap_value[-0.5673], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a sh value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.56 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MFCC-1 value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5673 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-12], interpreter[shap], shap_value[-0.3913])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.3913 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 4 was detected by AudioFeature with a shap value of MFCC-12 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ......",
      "Yes person 4 was detected by AudioFeature with a yes value of -0.3913 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.3913 ......",
      "Yes person 4 was detected by AudioFeature with a sh value of -0.3913 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.39 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.3913 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.3913 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3913 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-58], classification[bonafide], shap_value[0.6073])",
    "ref": [
      "0.6073 AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "Yes AudioFeature which a 0.6073 value of 0.6073 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.6073 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ...... Yes AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.607 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ......",
      "0.6073 AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6073 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-58 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6073 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "The audio is artificially slowed ...... The audio is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio is artificially slowed ......",
      "The audio is artificially slowed ...... The audio is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio is artificially slowed ......",
      "The audio is artificially slowed ...... The audio is artificially slowed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio is artificially slowed ......",
      "The audio is artificially slowed ...... The audio is artificially slowed ......",
      "The audio is artificially slowed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-23], classification[replayed], shap_value[-0.561], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "shap AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ...... Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-23 value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-23 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.561 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed])",
    "ref": [
      "Ye the recording was faked using playback ......",
      "replayed the recording was faked using playback ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording was faked using playback ...... Yes the recording was faked using playback ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording was faked using playback ......",
      "Ye the recording was faked using playback ......",
      "replayed the recording was faked using playback ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording was faked using playback ...... Yes the recording was faked using playback ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording was faked using playback ......",
      "Yes the recording was faked using playback ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-29], shap_value[0.7373])",
    "ref": [
      "That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for 5 seconds ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "0.7373 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.73 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-29 ......",
      "That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for 5 seconds ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "0.7373 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-29 ], <shap_value> shap value: [ 0.7373 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-47], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-47 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-7], shap_value[-0.6482])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "-0.6482 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-7 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......",
      "There appears to be a cloned voice on the audio ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......",
      "There appears to be a cloned voice on the audio ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "-0.6482 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6482 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-7 ], <shap_value> shap value: [ -0.6482 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-8], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a GTCC-8 value of 0 ......",
      "Yes person GTCC-8 was detected by AudioFeature with a shap value of 0 ......",
      "No it is not a bona fide recording ...... Yes person 1 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 1 was detected by AudioFeature with a s value of 0 ......",
      "No it is not a bona fide recording ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0 ...... Yes person 1 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of GTCC-8 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of  ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 1 was detected by AudioFeature with a GTCC-8 value of 0 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-25], classification[replayed], shap_value[0.9811], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a s value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by 0.9811 ......",
      "Yes AudioFeature which a shap value of 0.98 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ...... Yes AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Y AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2454 ......",
      "Yes AudioFeature which a MFCC-25 value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-25 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9811 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[2], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "Yes AudioFeature which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-31], shap_value[-0.9197])",
    "ref": [
      "-0.9197 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "-0.9197 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3878 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-31 ], <shap_value> shap value: [ -0.9197 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-1], classification[replayed], shap_value[0.109], detected_by[CNN])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of -0.9806 ...... Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by LFCC-1 ......",
      "replayed AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.109 value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.9806 ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.109 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-48], classification[replayed], shap_value[0.2133], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a  value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      " AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ...... Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.21 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-48 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-48 AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-48 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2133 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-0], classification[bonafide], shap_value[0.6244])",
    "ref": [
      " AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.6244 was used to detect the sample as Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ...... Yes AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ......",
      "Yes AudioFeature which a sh value of 0.6244 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of PSRCC-0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.624 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6244 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-28], classification[bonafide])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.3137 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-28 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Linear Prediction Cepstral Coefficients ..... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear Prediction Cepstral Coefficients .....",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear Prediction Cepstral Coefficients ..... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear Prediction Cepstral Coefficients .....",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear Prediction Cepstral Coefficients ..... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear Prediction Cepstral Coefficients .....",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear Prediction Cepstral Coefficients ..... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-6], shap_value[-0.917])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-6 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ......",
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-6 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.917 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-6 ], <shap_value> shap value: [ -0.917 ]> )"
  },
  {
    "mr": "inform(response[Yes])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " ......",
      "Yes ...... Yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " ......",
      "Yes ...... Yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-4], interpreter[shap], shap_value[-0.666])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 3 for the audio sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker -0.666 for the audio sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.666 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "No . No . No . There was more than one CaptureDevice ......",
      "multi_microphone . There was more than one CaptureDevice ......",
      "There was more than one CaptureDevice ......",
      "No . Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ...... No . There was more than one CaptureDevice ......",
      "N . There was more than one CaptureDevice ......",
      "Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ...... No . There was more than one CaptureDevice ......",
      "No .",
      "No . No . There was more than one CaptureDevice ......",
      "No . There was more than one CaptureDevice ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide], detected_by[CNN])",
    "ref": [
      "No the recording is not Audiosignal was detected by bonafide ......",
      "No the recording is Audiosignal was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "No the recording is not Audiosignal was detected by CNN ...... No the recording is not Audiosignal was detected by CNN ......",
      " the recording is not Audiosignal was detected by CNN ......",
      "No the recording is not Audiosignal was detected by  ......",
      "bonafide the recording is not Audiosignal was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... No the recording is not Audiosignal was detected by CNN ......",
      "No the recording is not Audiosignal was detected by bonafide ......",
      "No the recording is Audiosignal was detected by CNN ......",
      "No the recording is not Audiosignal was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-46], interpreter[shap], shap_value[-0.3294])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of -0.3294 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.3294 ......",
      "Yes person 5 was detected by AudioFeature with a sh value of -0.3294 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.3294 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-46 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3294 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[digital])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...... The signature is consistent with a digital CaptureDevice .....",
      "The signature is consistent with a digital CaptureDevice ..... The signature is consistent with a digital CaptureDevice .....",
      "Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......",
      "The signature is consistent with a d CaptureDevice .....",
      "The signature is consistent with a spoof CaptureDevice .....",
      "Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...... The signature is consistent with a digital CaptureDevice .....",
      "The signature is consistent with a digital CaptureDevice ..... The signature is consistent with a digital CaptureDevice .....",
      "Yes AudioFeature which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ......",
      "The signature is consistent with a d CaptureDevice .....",
      "The signature is consistent with a spoof CaptureDevice .....",
      "The signature is consistent with a digital CaptureDevice ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ digital ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "spoofed the recording is fake .....",
      "Yes the recording is fake ..... Yes the recording is fake .....",
      " the recording is fake .....",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...... Yes the recording is fake .....",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "spoofed the recording is fake .....",
      "Yes the recording is fake ..... Yes the recording is fake .....",
      " the recording is fake .....",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...... Yes the recording is fake .....",
      "Yes the recording is fake ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-15], interpreter[shap], shap_value[0.1546])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.1546 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.1546 ......",
      "Yes person 2 was detected by AudioFeature with a MFCC-15 value of 0.1546 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.1546 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0.1546 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.1546 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.1546 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.1546 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.1546 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.1546 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1546 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-10], interpreter[shap], shap_value[-0.2208])",
    "ref": [
      "Yes person shap was detected by AudioFeature with a shap value of -0.2208 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 6 ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of - ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ...... Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.2208 ......",
      "Yes person 6 was detected by AudioFeature with a s value of -0.2208 ......",
      "Yes person 6 was detected by AudioFeature with a MFCC-10 value of -0.2208 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.2208 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2208 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-51], shap_value[-0.7772])",
    "ref": [
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-51 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-51 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7772 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <shap_value> shap value: [ -0.7772 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-32], classification[bonafide], shap_value[-0.9762])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "-0.9762 AudioFeature which a shap value of -0.9762 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.9762 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9762 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.9762 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9762 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9762 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.9762 value of -0.9762 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9762 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-32 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9762 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-18], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-18 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-11], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[replayed])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... The recording appears to be a copy .....",
      "The recording appears to be a copy ..... The recording appears to be a copy .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... The recording appears to be a copy .....",
      "The recording appears to be a copy ..... The recording appears to be a copy .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... The recording appears to be a copy .....",
      "The recording appears to be a copy ..... The recording appears to be a copy .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... The recording appears to be a copy .....",
      "The recording appears to be a copy ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-33], shap_value[0.101])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "LFCC-33 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-33 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-33 ], <shap_value> shap value: [ 0.101 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-2], classification[replayed], shap_value[0.1331], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a CNN value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.1331 AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It appears that part of the audio was sped up ......",
      "Yes AudioFeature which a shap value of MFCC-2 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by 0.1331 ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a  value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1331 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-41], classification[replayed], shap_value[0.5433], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a LFCC-41 value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-41 AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio is PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-41 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5433 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... They lead to a compact Abstract of the frequency spectrum. the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch.  The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . They lead to a compact Abstract of the frequency spectrum.  The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... They lead to a compact Abstract of the frequency spectrum. the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The mel in the name describes the perceived pitch. the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... They lead to a compact Abstract of the frequency spectrum. the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The mel in the name describes the perceived pitch. the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition .  The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The mel in the name describes the perceived pitch. The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The mel in the name describes the perceived pitch. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......",
      "The Mel physicalattribute Cepstral Coefficients Entity are used for automatic AcousticWave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-30], classification[bonafide], shap_value[-0.1903])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.190 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-30 was used to detect the sample as Audiosignal ......",
      "-0.1903 AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ...... Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "Yes AudioFeature which a sh value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.190 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-30 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1903 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-30], shap_value[0.7143])",
    "ref": [
      "LFCC-30 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......",
      "LFCC-30 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7143 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <shap_value> shap value: [ 0.7143 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-31], interpreter[shap], shap_value[-0.7969])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a -0.7969 value of -0.7969 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 7 was detected by AudioFeature with a s value of -0.7969 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.969 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.shap969 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.7969 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.7969 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.7969 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of - ......",
      "Yes person 7 was detected by AudioFeature with a -0.7969 value of -0.7969 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.7969 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7969 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-52], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-52 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes the recording has been tampered with ...... Yes the recording has been tampered with ......",
      "spoofed the recording has been tampered with ......",
      "Ye the recording has been tampered with ......",
      "Yes the recording was faked using playback ......",
      "Yes the recording was faked using playback ...... Yes the recording has been tampered with ......",
      "Yes the recording has been tampered with ...... Yes the recording has been tampered with ......",
      "spoofed the recording has been tampered with ......",
      "Ye the recording has been tampered with ......",
      "Yes the recording was faked using playback ......",
      "Yes the recording was faked using playback ...... Yes the recording has been tampered with ......",
      "Yes the recording has been tampered with ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-12], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "There were  microphones used ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...... There were 2 microphones used ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There were multi_microphone microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "There were  microphones used ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...... There were 2 microphones used ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There were multi_microphone microphones used ......",
      "There were 2 microphones used ...... There were 2 microphones used ......",
      "There were 2 microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-45], classification[replayed], shap_value[0.7923], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a  value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Mel physicalattribute Cepstral Coefficients ...... Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-45 AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-45 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7923 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-18], interpreter[shap], shap_value[0.7479])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.yes4yes9 ......",
      "Yes person 7 was detected by AudioFeature with a 7 value of 0.7479 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.7479 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 7 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.49 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7479 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.7479 ......",
      "Yes person 7 was detected by AudioFeature with a sh value of 0.7479 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of  ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7479 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7479 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-28], interpreter[shap], shap_value[-0.1756])",
    "ref": [
      "Yes person MFCC-28 was detected by AudioFeature with a shap value of -0.1756 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.0673 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of - ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.1756 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.1756 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.0673 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.1756 ......",
      "Yes person 4 was detected by AudioFeature with a MFCC-28 value of -0.1756 ......",
      "Yes person 4 was detected by AudioFeature with a  value of -0.1756 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.1756 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 4 ......",
      "Yes person MFCC-28 was detected by AudioFeature with a shap value of -0.1756 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.1756 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1756 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ......",
      "No other bonafides detected Audio_signal ......",
      "No other features detected Audio_signal ...... No other features detected Audio_signal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ...... No other features detected Audio_signal ......",
      "No other fs detected Audio_signal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ......",
      "No other bonafides detected Audio_signal ......",
      "No other features detected Audio_signal ...... No other features detected Audio_signal ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ...... No other features detected Audio_signal ......",
      "No other fs detected Audio_signal ......",
      "No other features detected Audio_signal ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-3], shap_value[0])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes the recording is converted ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes the recording is converted ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes the recording is converted ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-3 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-29], classification[replayed], shap_value[0.9441], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.944 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.9441 value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "CNN AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Ye AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-29 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9441 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-0], feature[MFCC-0], feature[LFCC-2], feature[MFCC-4])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC SHAP had the highest impact on the classification ......",
      "It seems like a computer was used ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFC had the highest impact on the classification ......",
      "It seems like a computer was used ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC SHAP had the highest impact on the classification ......",
      "It seems like a computer was used ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFC had the highest impact on the classification ......",
      "It seems like a computer was used ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-0 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-6], classification[replayed], shap_value[0.8902], detected_by[CNN])",
    "ref": [
      "0.8902 AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ...... Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a  value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.8902 value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8902 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-21], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-21 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-11], classification[bonafide], shap_value[0.809])",
    "ref": [
      "Yes AudioFeature which a Yes value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.809 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-34], classification[replayed], shap_value[0.4744], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by 0.4744 ......",
      " AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-34 AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-34 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4744 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-39], classification[bonafide], shap_value[0.0826])",
    "ref": [
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-39 value of 0.0826 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-39 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0826 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0826 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.0826 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0826 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.0826 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.0826 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0826 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-39 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0826 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "No ..... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "No .....",
      "No ..... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "No .....",
      "No ..... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "No .....",
      "No ..... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_type[dynamic])",
    "ref": [
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "The recording device was digital .....",
      "The recording device was digital ..... Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "The recording device was digital .....",
      "The recording device was digital ..... Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "The recording device was digital .....",
      "The recording device was digital ..... Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ...... Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_type> mic type: [ dynamic ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Two different speeds were detected ......",
      "Two different speeds were detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Two different speeds were detected ......",
      "Two different speeds were detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Two different speeds were detected ......",
      "Two different speeds were detected ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-6], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of GTCC-6 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sha value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker  for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "Yes AudioFeature which a GTCC-6 value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ...... Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-0], interpreter[shap], shap_value[-0.8051])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker  for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes AudioFeature which a -0.8051 value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8051 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-2], interpreter[shap], shap_value[0.7373])",
    "ref": [
      "Yes AudioFeature which a 0.7373 value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 0.7373 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a 0.7373 value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7373 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-2], interpreter[shap], shap_value[0.3503])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3MSRCC-203 was used to detect the id of speaker MSRCC-2 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.8559 ...... Yes AudioFeature which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.3503 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.303 was used to detect the id of speaker  for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.8559 ......",
      "Yes AudioFeature which a MSRCC-2 value of 0.3503 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of MSRCC-2 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3MSRCC-203 was used to detect the id of speaker MSRCC-2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3503 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-44], classification[bonafide])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-44 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "The Audiosignal was detected by spoof audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CN audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "The Audiosignal was detected by spoof audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CN audio was a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-35], classification[bonafide], shap_value[-0.8694])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ...... Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-35 value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-35 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ......",
      "bonafide AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-35 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8694 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-33], interpreter[shap], shap_value[-0.4495])",
    "ref": [
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4495 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.4495 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.4495 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a 1 value of -0.4495 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4495 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-34], interpreter[shap], shap_value[0.8748])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 3 value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 0.8748 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8748 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ...... The recording is fake .....",
      "The recording is fake ..... The recording is fake .....",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ...... The recording is fake .....",
      "The recording is fake ..... The recording is fake .....",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ...... The recording is fake .....",
      "The recording is fake ..... The recording is fake .....",
      "Yes AudioFeature which a shap value of 0.285 was used to detect the sample as Audiosignal ......",
      "The recording is fake ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-26], interpreter[shap], shap_value[-0.7669])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a sh value of -0.7669 ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.7669 ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.7669 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......",
      "Yes person 1 was detected by AudioFeature with a yes value of -0.7669 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person 1 was detected by AudioFeature with a shap value of MFCC-26 ......",
      "Yes person 1 was detected by AudioFeature with a sh value of -0.7669 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7669 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[8])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-1], interpreter[shap], shap_value[0.3263])",
    "ref": [
      "Yes AudioFeature which a s value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a 0.3263 value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker PSRCC-1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3263 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-8], interpreter[shap], shap_value[0.1874])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a sha value of 0.1874 ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ...... Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ......",
      "Yes person 5 was detected by AudioFeature with a 5 value of 0.1874 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.1874 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.1874 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.187 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of 0.1874 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.1874 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1874 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-36], classification[bonafide], shap_value[-0.4792])",
    "ref": [
      "Y AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-36 value of -0.4792 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.4792 was used to detect the sample as Audiosignal ......",
      "MFCC-36 AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4792 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-36 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4792 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-55], interpreter[shap], shap_value[0.8788])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a 4 value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5541 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-55 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8788 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-52], interpreter[shap], shap_value[0.556])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.556 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.556 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.556 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.556 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0.556 ......",
      "Yes the recording is converted ......",
      "Yes person 2 was detected by AudioFeature with a LFCC-52 value of 0.556 ......",
      "Yes the recording is converted ...... Yes person 2 was detected by AudioFeature with a shap value of 0.556 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.556 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-52 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.556 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-7], classification[bonafide], shap_value[-0.2973])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MSRCC-7 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2973 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2973 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-23], interpreter[shap], shap_value[-0.3711])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3711 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a  value of -0.3711 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3711 was used to detect the id of speaker LFCC-23 for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a LFCC-23 value of -0.3711 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3711 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-10], classification[bonafide], shap_value[0.8682])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.8682 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.8682 was used to detect the sample as Audiosignal ......",
      "PSRCC-10 AudioFeature which a shap value of 0.8682 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.868 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.8682 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8682 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8682 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.8682 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.8682 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8682 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8682 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-59], classification[replayed], shap_value[-0.8654], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Several features show this is a Audiosignal sample ...... Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a CNN value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Several features show this is a Audiosignal sample ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-59 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8654 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio is good ......",
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...... The audio is not good ......",
      "The audio is not good ...... The audio is not good ......",
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio is good ......",
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...... The audio is not good ......",
      "The audio is not good ...... The audio is not good ......",
      "Yes AudioFeature which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ......",
      "The audio is good ......",
      "The audio is not good ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1], signal_length[5])",
    "ref": [
      "That CaptureDevice was used for No seconds ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for No seconds ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for 5 seconds ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ], <signal_length> signal length: [ 5 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-33], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-33 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-24], interpreter[shap], shap_value[0.5756])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a  value of 0.5756 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ......",
      "Yes person MFCC-24 was detected by AudioFeature with a shap value of 0.5756 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.5756 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 3 ......",
      "Yes person 3 was detected by AudioFeature with a MFCC-24 value of 0.5756 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5756 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-9], interpreter[shap], shap_value[0.786])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ......",
      "Yes AudioFeature which a  value of 0.786 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of PSRCC-9 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.786 was used to detect the id of speaker shap for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7432 ...... Yes AudioFeature which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.786 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.786 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.786 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-12], classification[replayed], shap_value[-0.046], detected_by[CNN])",
    "ref": [
      "MSRCC-12 AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.0215 ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by MSRCC-12 ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of MSRCC-12 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.046 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "There are no unusually long or short pauses ...... There are no unusually long or short pauses ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are no unusually long or short pauses ......",
      "There are no unusually long or short pauses ...... There are no unusually long or short pauses ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are no unusually long or short pauses ......",
      "There are no unusually long or short pauses ...... There are no unusually long or short pauses ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... There are no unusually long or short pauses ......",
      "There are no unusually long or short pauses ...... There are no unusually long or short pauses ......",
      "There are no unusually long or short pauses ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-4], classification[bonafide], shap_value[-0.512])",
    "ref": [
      "shap AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.51 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "The recording is fake .....",
      "Yes AudioFeature which a bonafide value of -0.512 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.512 was used to detect the sample as Audiosignal ......",
      "The recording is fake ..... Yes AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.512 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.512 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8242 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...... The Interpreters values indicate the contribution of the features on the outcome of the classification model......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-30], classification[replayed], shap_value[-0.7633], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Y AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.7633 value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-30 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7633 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-20], classification[replayed], shap_value[0.1791], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.17 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "person 4 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.1791 AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by 0.1791 ......",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by  ......",
      "person 4 spoke the audio sample ...... Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-20 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1791 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-2], interpreter[shap], shap_value[-0.7935])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.935 was used to detect the id of speaker  for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.shap935 was used to detect the id of speaker shap for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of MFCC-2 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7935 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-16], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-16 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the entire recording was made using multiple microphones ..... No the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      " the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...... No the entire recording was made using multiple microphones .....",
      "multi_microphone the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ..... No the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      " the entire recording was made using multiple microphones .....",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...... No the entire recording was made using multiple microphones .....",
      "multi_microphone the entire recording was made using multiple microphones .....",
      "No the entire recording was made using multiple microphones ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-29], shap_value[0.8612])",
    "ref": [
      "No other features were used ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "MFCC-29 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "No other features were used ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.861 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "No other features were used ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "MFCC-29 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8612 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-29 ], <shap_value> shap value: [ 0.8612 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-9], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-2], classification[bonafide])",
    "ref": [
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "It is not a bona fide audio ...... 3 was found to be the id of the speaker in the sample ......",
      "It is not a bona fide audio ......",
      "3 was found to be the id of the speaker in the sample ...... 3 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "It is not a bona fide audio ...... 3 was found to be the id of the speaker in the sample ......",
      "It is not a bona fide audio ......",
      "3 was found to be the id of the speaker in the sample ...... 3 was found to be the id of the speaker in the sample ......",
      " was found to be the id of the speaker in the sample ......",
      "It is not a bona fide audio ...... 3 was found to be the id of the speaker in the sample ......",
      "It is not a bona fide audio ......",
      "3 was found to be the id of the speaker in the sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-30], interpreter[shap], shap_value[-0.9742])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.974shap ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9742 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 2 was detected by AudioFeature with a yes value of -0.9742 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9742 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.9742 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of -0.9742 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.974 ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.9742 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9742 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-7], classification[bonafide], shap_value[1])",
    "ref": [
      "bonafide AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of GTCC-7 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 1 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "This is a poor quality recording ..... This is a poor quality recording .....",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... This is a poor quality recording .....",
      "This is a poor quality recording ..... This is a poor quality recording .....",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... This is a poor quality recording .....",
      "This is a poor quality recording ..... This is a poor quality recording .....",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... This is a poor quality recording .....",
      "This is a poor quality recording ..... This is a poor quality recording .....",
      "This is a poor quality recording ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-3], interpreter[shap], shap_value[0.0695])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 0.0695 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0695 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-11], classification[bonafide], shap_value[0.8105])",
    "ref": [
      "Yes AudioFeature which a  value of 0.8105 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.8105 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.8105 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8105 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8105 was used to detect the sample as Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Yes AudioFeature which a shap value of MFCC-11 was used to detect the sample as Audiosignal ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Yes AudioFeature which a shap value of 0.8105 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-11 value of 0.8105 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.81 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.8105 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8105 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8105 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-9], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-58], classification[replayed], shap_value[0.7518], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-58 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7518 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-57], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-57 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-12], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-4], shap_value[-0.1907])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-4 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "LFCC-4 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "Yes AudioFeature which a shap value of 0.7662 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-4 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1907 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-4 ], <shap_value> shap value: [ -0.1907 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[recording_slowed])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "The recording is artificially slowed ...... The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ...... The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "The recording is artificially slowed ...... The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ...... The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "The recording is artificially slowed ...... The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ...... The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "The recording is artificially slowed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ recording_slowed ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-7], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of GTCC-7 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......",
      "0 AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[20])",
    "ref": [
      "The speed increases at the 20 second mark ...... The speed increases at the 20 second mark ......",
      "The speed increases at the spoof second mark ......",
      "The speed increases at the 2 second mark ......",
      "The sp increases at the 20 second mark ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ...... The speed increases at the 20 second mark ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "The spoof increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ...... The speed increases at the 20 second mark ......",
      "The speed increases at the spoof second mark ......",
      "The speed increases at the 2 second mark ......",
      "The speed increases at the 20 second mark ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-12], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a 1 value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "GTCC-12 AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-27], classification[bonafide], shap_value[-0.3631])",
    "ref": [
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.3631 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...... Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.3631 value of -0.3631 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-27 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3631 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-52], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-52 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-40], shap_value[0.0258])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "LFCC-40 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.025 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <shap_value> shap value: [ 0.0258 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], sample_start[20])",
    "ref": [
      "The cut takes place at the spoof second mark .....",
      "The cut takes place at the 2 second mark .....",
      "Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...... The cut takes place at the 20 second mark .....",
      "The cut takes place at the 20 second mark ..... The cut takes place at the 20 second mark .....",
      "Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......",
      "The cut takes place at the spoof second mark .....",
      "The cut takes place at the 2 second mark .....",
      "Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...... The cut takes place at the 20 second mark .....",
      "The cut takes place at the 20 second mark ..... The cut takes place at the 20 second mark .....",
      "Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......",
      "The cut takes place at the 20 second mark ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <sample_start> sample start: [ 20 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-3], shap_value[0.7891])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-3 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.78 ......",
      "LFCC-3 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7891 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <shap_value> shap value: [ 0.7891 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-50], shap_value[-0.7007])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ......",
      "-0.7007 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7007 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-50 ], <shap_value> shap value: [ -0.7007 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-3], classification[bonafide], shap_value[-0.1314])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.1314 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.1314 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.1314 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.1314 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1314 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.1314 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-3 value of -0.1314 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1314 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1314 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone],  classified_by[feature])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ......",
      "Several features were used ...... Several features were used ......",
      "Several fs were used ......",
      "Several spoofs were used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ...... Several features were used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ......",
      "Several features were used ...... Several features were used ......",
      "Several fs were used ......",
      "Several spoofs were used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.8771 ...... Several features were used ......",
      "Several features were used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], < classified_by>  classified by: [ feature ]> )"
  },
  {
    "mr": "inform(speaker_id[1])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 1 was detected as the primary speaker of the audio sample ...... person 1 was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... person 1 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 1 was detected as the primary speaker of the audio sample ...... person 1 was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... person 1 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "person 1 was detected as the primary speaker of the audio sample ...... person 1 was detected as the primary speaker of the audio sample ......",
      "person 1 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...... Some of the recording was made with a mobile device and some with a computer .....",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Some of the recording was made with a mobile device and some with a computer ..... Some of the recording was made with a mobile device and some with a computer .....",
      "Some of the recording was made with a mobile device and some with a spoof .....",
      "Some of the recording was made with a mobile device and some with a comput .....",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...... Some of the recording was made with a mobile device and some with a computer .....",
      "Yes AudioFeature which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Some of the recording was made with a mobile device and some with a computer ..... Some of the recording was made with a mobile device and some with a computer .....",
      "Some of the recording was made with a mobile device and some with a spoof .....",
      "Some of the recording was made with a mobile device and some with a comput .....",
      "Some of the recording was made with a mobile device and some with a computer ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-17], classification[bonafide], shap_value[0.809])",
    "ref": [
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "bonafide AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-17 value of 0.809 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-17 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.809 was used to detect the sample as Audiosignal ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.809 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.809 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ...... There appears to be a cloned voice on the recording ......",
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ...... There appears to be a cloned voice on the recording ......",
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ...... There appears to be a cloned voice on the recording ......",
      "There appears to be a cloned voice on the recording ...... There appears to be a cloned voice on the recording ......",
      "There appears to be a cloned voice on the recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(speaker_id[6], model[SVM])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-25], interpreter[shap], shap_value[-0.8658])",
    "ref": [
      "Yes AudioFeature which a yes value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8658 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "There is evidence of sampling ...... There is evidence of sampling ......",
      "There is evidence of sa ......",
      "The area of synthesized AcousticWave is 11 seconds long .....",
      "There is evidence of spoof ......",
      "The area of synthesized AcousticWave is 11 seconds long ..... There is evidence of sampling ......",
      "There is evidence of sampling ...... There is evidence of sampling ......",
      "There is evidence of sa ......",
      "The area of synthesized AcousticWave is 11 seconds long .....",
      "There is evidence of spoof ......",
      "The area of synthesized AcousticWave is 11 seconds long ..... There is evidence of sampling ......",
      "There is evidence of sampling ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-5], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a sh value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "The audio shows signs of 3 different editors ......",
      "Yes AudioFeature which a shap value of GTCC-5 was used to detect the sample as Audiosignal ......",
      "GTCC-5 AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "The audio shows signs of 3 different editors ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-47], interpreter[shap], shap_value[-0.8006])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ...... Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a sha value of -0.8006 ......",
      "Yes AudioFeature which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes person 4 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 4 was detected by AudioFeature with a yes value of -0.8006 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ...... Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-47 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8006 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Spectral Centroid physicalattribute Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... The recording seems to be at the same speed throughout .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "The recording seems to be at the same speed throughout ..... The recording seems to be at the same speed throughout .....",
      "The recording seems to be at the same sp throughout .....",
      "The recording seems to be at the same spoof throughout .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ...... The recording seems to be at the same speed throughout .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6906 ......",
      "The recording seems to be at the same speed throughout ..... The recording seems to be at the same speed throughout .....",
      "The recording seems to be at the same sp throughout .....",
      "The recording seems to be at the same spoof throughout .....",
      "The recording seems to be at the same speed throughout ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-9], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-6], feature[MFCC-0], feature[LFCC-5], feature[CQCC-0])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQC had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC SHAP had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQC had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC SHAP had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC CQCC-0 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-6 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-5 ], <feature> feature: [ CQCC-0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a spoof ......",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a comp ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a spoof ......",
      "Some of the recording was made using a computer ...... Some of the recording was made using a computer ......",
      "Some of the recording was made using a comp ......",
      "Some of the recording was made using a computer ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform( classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... There are different CaptureDevice signatures ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... There are different CaptureDevice signatures ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... There are different CaptureDevice signatures ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( < classification>  classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The signal indicates voice spoof .....",
      "The signal indicates voice cloning ..... The signal indicates voice cloning .....",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...... The signal indicates voice cloning .....",
      "The signal indicates voice c .....",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The signal indicates voice spoof .....",
      "The signal indicates voice cloning ..... The signal indicates voice cloning .....",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...... The signal indicates voice cloning .....",
      "The signal indicates voice c .....",
      "The signal indicates voice cloning ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-19], shap_value[0.5217])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-19 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "LFCC-19 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-19 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "LFCC-19 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-19 ], <shap_value> shap value: [ 0.5217 ]> )"
  },
  {
    "mr": "inform(speaker_id[2])",
    "ref": [
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "person 2 was detected as the primary speaker of the audio sample ...... person 2 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 2 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "person 2 was detected as the primary speaker of the audio sample ...... person 2 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 2 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "person 2 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-32], interpreter[shap], shap_value[-0.5324])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of  ......",
      "Yes person 1 was detected by AudioFeature with a LFCC-32 value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a sha value of -0.5324 ......",
      "Yes AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5324 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-9], interpreter[shap], shap_value[-0.9806])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a sh value of -0.9806 ......",
      "The audio is not Audiosignal was detected by CNN?",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.9806 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.9806 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.9806 ......",
      "Yes person 7 was detected by AudioFeature with a yes value of -0.9806 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of MSRCC-9 ......",
      "Yes person MSRCC-9 was detected by AudioFeature with a shap value of -0.9806 ......",
      "The audio is not Audiosignal was detected by CNN? Yes person 7 was detected by AudioFeature with a shap value of -0.9806 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of  ......",
      "Yes person 7 was detected by AudioFeature with a sh value of -0.9806 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.9806 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9806 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-10], shap_value[0])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "GTCC-10 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "GTCC-10 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-10 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-23], shap_value[-0.9787])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "-0.9787 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-23 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "-0.9787 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "Yes AudioFeature which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9787 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-23 ], <shap_value> shap value: [ -0.9787 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-36], classification[bonafide], shap_value[-0.1149])",
    "ref": [
      " AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.1149 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-36 value of -0.1149 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1149 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1149 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-39], interpreter[shap], shap_value[-0.549])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.549 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of LFCC-39 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a 7 value of -0.549 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.549 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-10], shap_value[0.5528])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.55 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-10 ......",
      "0.5528 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......",
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......",
      "Yes AudioFeature which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.55 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5528 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-10 ], <shap_value> shap value: [ 0.5528 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-23], classification[bonafide], shap_value[0.514])",
    "ref": [
      "Yes AudioFeature which a shap value of LFCC-23 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.514 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes AudioFeature which a bonafide value of 0.514 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-23 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.514 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-23 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.514 ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "bonafide it is not a bona fide recording ......",
      "No it is a bona fide recording ......",
      "No it is not a bona fide recording ...... No it is not a bona fide recording ......",
      "yes AudioFeature was used to determine speaker id ...... No it is not a bona fide recording ......",
      " it is not a bona fide recording ......",
      "yes AudioFeature was used to determine speaker id ......",
      "bonafide it is not a bona fide recording ......",
      "No it is a bona fide recording ......",
      "No it is not a bona fide recording ...... No it is not a bona fide recording ......",
      "No it is not a bona fide recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-5], classification[bonafide], shap_value[0.767])",
    "ref": [
      "Yes AudioFeature which a  value of 0.767 was used to detect the sample as Audiosignal ......",
      "LFCC-5 AudioFeature which a shap value of 0.767 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.767 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.767 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.767 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      " AudioFeature which a shap value of 0.767 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.767 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.767 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.767 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.767 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-8], classification[replayed], shap_value[0.5604], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a CNN value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Artificial noise was added .....",
      " AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.560 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5604 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-37], interpreter[shap], shap_value[0.2651])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 2 was detected by AudioFeature with a s value of 0.2651 ......",
      "Yes person 2 was detected by AudioFeature with a MFCC-37 value of 0.2651 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.2651 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.2651 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.shap651 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of MFCC-37 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.265 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.651 ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes person 2 was detected by AudioFeature with a shap value of 0.2651 ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.2651 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2651 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[copy])",
    "ref": [
      "person 2 spoke the audio sample ...... Part of the audio was played back ......",
      "person 2 spoke the audio sample ......",
      "Part of the audio was played back ...... Part of the audio was played back ......",
      "person 2 spoke the audio sample ...... Part of the audio was played back ......",
      "person 2 spoke the audio sample ......",
      "Part of the audio was played back ...... Part of the audio was played back ......",
      "person 2 spoke the audio sample ...... Part of the audio was played back ......",
      "person 2 spoke the audio sample ......",
      "Part of the audio was played back ...... Part of the audio was played back ......",
      "person 2 spoke the audio sample ...... Part of the audio was played back ......",
      "Part of the audio was played back ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ copy ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-17], interpreter[shap], shap_value[0.7883])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a LFCC-17 value of 0.7883 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.7883 ......",
      "Yes person 1 was detected by AudioFeature with a s value of 0.7883 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.7883 ......",
      "Yes the recording was found to be bonafide...... Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ......",
      "Yes the recording was found to be bonafide......",
      "Yes person 1 was detected by AudioFeature with a LFCC-17 value of 0.7883 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.7883 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7883 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], classified_by[feature], detected_by[CNN])",
    "ref": [
      "Other features also show the audio sample was PhysicalAccess was detected by replay ......",
      "Other s also show the audio sample was PhysicalAccess was detected by CNN ......",
      "Other features also show the audio sample was PhysicalAccess was detected by CN ......",
      "Other spoofs also show the audio sample was PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Other features also show the audio sample was PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Other features also show the audio sample was PhysicalAccess was detected by CNN ...... Other features also show the audio sample was PhysicalAccess was detected by CNN ......",
      "Other features also show the audio sample was PhysicalAccess was detected by replay ......",
      "Other s also show the audio sample was PhysicalAccess was detected by CNN ......",
      "Other features also show the audio sample was PhysicalAccess was detected by CN ......",
      "Other features also show the audio sample was PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-14], interpreter[shap], shap_value[-0.2405])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of shap ......",
      "Yes person -0.2405 was detected by AudioFeature with a shap value of -0.2405 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2405 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.2405 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.2405 ......",
      "Yes person 7 was detected by AudioFeature with a sha value of -0.2405 ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ...... Yes person 7 was detected by AudioFeature with a shap value of -0.2405 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0 ......",
      "Yes person 7 was detected by AudioFeature with a -0.2405 value of -0.2405 ......",
      "Yes AudioFeature which a shap value of -0.1903 was used to detect the sample as Audiosignal ......",
      "Yes person 7 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2405 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2405 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-2], classification[bonafide], shap_value[-0.7602])",
    "ref": [
      "MSRCC-2 AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MSRCC-2 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.760 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.7602 value of -0.7602 was used to detect the sample as Audiosignal ......",
      "MSRCC-2 AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7602 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7602 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], classified_by[feature])",
    "ref": [
      "Several features showed the Audiosignal signature ...... Several features showed the Audiosignal signature ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample .....",
      "Several featurs showed the Audiosignal signature ......",
      "Several spoofs showed the Audiosignal signature ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample ..... Several features showed the Audiosignal signature ......",
      "Several features showed the Audiosignal signature ...... Several features showed the Audiosignal signature ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample .....",
      "Several featurs showed the Audiosignal signature ......",
      "Several spoofs showed the Audiosignal signature ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample ..... Several features showed the Audiosignal signature ......",
      "Several features showed the Audiosignal signature ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed .",
      "It is not a bona fide audio ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "It is not a bona fide audio ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . It is not a bona fide audio ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "It is not a bona fide audio ...... It is not a bona fide audio ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . It is not a bona fide audio ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed .",
      "It is not a bona fide audio ...... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th AcousticWave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-8], shap_value[-0.4934])",
    "ref": [
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.493 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-8 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4934 ......",
      "-0.4934 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4934 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4934 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4934 ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4934 ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.493 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4934 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <shap_value> shap value: [ -0.4934 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-9], classification[bonafide], shap_value[-0.4455])",
    "ref": [
      "Yes AudioFeature which a sha value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-9 value of -0.4455 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4455 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-10], shap_value[-0.0298])",
    "ref": [
      "-0.0298 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.0298 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "Yes AudioFeature which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-10 ], <shap_value> shap value: [ -0.0298 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-21], classification[replayed], shap_value[0.0724], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a 0.0724 value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CN ......",
      " AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MFCC-21 AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0724 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[5])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 5 was detected as the primary speaker of the audio sample ......",
      "person 5 was detected as the primary speaker of the audio sample ...... person 5 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 5 was detected as the primary speaker of the audio sample ......",
      "person 5 was detected as the primary speaker of the audio sample ...... person 5 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 5 was detected as the primary speaker of the audio sample ......",
      "person 5 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......",
      "Features in the audio show there were two microphones used ...... Features in the audio show there were two microphones used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ...... Features in the audio show there were two microphones used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......",
      "Features in the audio show there were two microphones used ...... Features in the audio show there were two microphones used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ...... Features in the audio show there were two microphones used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......",
      "Features in the audio show there were two microphones used ...... Features in the audio show there were two microphones used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ...... Features in the audio show there were two microphones used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7669 ......",
      "Features in the audio show there were two microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-20], classification[bonafide], shap_value[0.0087])",
    "ref": [
      "Y AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "There were no other spoof types ......",
      "Yes AudioFeature which a s value of 0.0087 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.0087 value of 0.0087 was used to detect the sample as Audiosignal ......",
      "There were no other spoof types ...... Yes AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ......",
      "0.0087 AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0087 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-20 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0087 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-11], classification[bonafide])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0298 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-51], interpreter[shap], shap_value[-0.5435])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.43 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ...... Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.LFCC-5143LFCC-51 was used to detect the id of speaker LFCC-51 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-51 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5435 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-30], interpreter[shap], shap_value[0.2213])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.221 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.2213 was used to detect the id of speaker 3 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.221yes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a 0.2213 value of 0.2213 was used to detect the id of speaker 3 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2213 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-37], interpreter[shap], shap_value[-0.6786])",
    "ref": [
      "Yes AudioFeature which a shap value of -0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a MFCC-37 value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "The recording is artificially slowed ...... Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "The recording is artificially slowed ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6786 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-45], classification[bonafide], shap_value[-0.9902])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.990 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a -0.9902 value of -0.9902 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.9902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "LFCC-45 AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.990 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9902 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-45 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9902 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-19], interpreter[shap], shap_value[-0.5025])",
    "ref": [
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.5025 ......",
      "Yes person MFCC-19 was detected by AudioFeature with a shap value of -0.MFCC-1902MFCC-19 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.5025 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.5025 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.02 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ......",
      "Yes person 5 was detected by AudioFeature with a yes value of -0.5025 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of -0.5025 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.5025 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.5025 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5025 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-12], classification[bonafide], shap_value[-0.3641])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.364 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ...... Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -0.3641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-12 value of -0.3641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.9009 ......",
      "Yes AudioFeature which a shap value of -0.364 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3641 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3641 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-35], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-35 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-1], classification[bonafide], shap_value[0.1274])",
    "ref": [
      "Yes AudioFeature which a PSRCC-1 value of 0.1274 was used to detect the sample as Audiosignal ......",
      "PSRCC-1 AudioFeature which a shap value of 0.1274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.1274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1274 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.1274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.1274 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.1274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a PSRCC-1 value of 0.1274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1274 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1274 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], signal_length[5])",
    "ref": [
      "That CaptureDevice was used for multi_microphone seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ...... That CaptureDevice was used for 5 seconds ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ......",
      "That CaptureDevice was used for multi_microphone seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ...... That CaptureDevice was used for 5 seconds ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.7096 ......",
      "That CaptureDevice was used for 5 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <signal_length> signal length: [ 5 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-48], shap_value[0.7218])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0.7218 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-48 ], <shap_value> shap value: [ 0.7218 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "Linear physicalattribute Cepstral Coefficients ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "Linear physicalattribute Cepstral Coefficients ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ......",
      "Linear physicalattribute Cepstral Coefficients ...... Linear physicalattribute Cepstral Coefficients ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.5217 ...... Linear physicalattribute Cepstral Coefficients ......",
      "Linear physicalattribute Cepstral Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], num_samples[3], detected_by[CNN])",
    "ref": [
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded sampling times ......",
      "It has been PhysicalAccess was detected by  and re-recorded 3 times ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by 3 and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded sampling times ......",
      "It has been PhysicalAccess was detected by  and re-recorded 3 times ......",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <num_samples> num samples: [ 3 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ...... The breathing rate changes",
      "The breathing rate changes The breathing rate changes",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ...... The breathing rate changes",
      "The breathing rate changes The breathing rate changes",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ...... The breathing rate changes",
      "The breathing rate changes The breathing rate changes",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of -0.8006 ...... The breathing rate changes",
      "The breathing rate changes"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-18], classification[bonafide], shap_value[-0.8228])",
    "ref": [
      "No most of the recording was not made with a mobile phone ......",
      "No most of the recording was not made with a mobile phone ...... Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-18 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.822 was used to detect the sample as Audiosignal ......",
      "No most of the recording was not made with a mobile phone ......",
      "Yes AudioFeature which a shap value of -0.8228 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-18 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8228 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer], change_at[7])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The synthesized AcousticWave starts at 7 seconds .....",
      "The synthesized AcousticWave starts at 7 seconds ..... The synthesized AcousticWave starts at 7 seconds .....",
      "The synthesized AcousticWave starts at  seconds .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The synthesized AcousticWave starts at spoof seconds .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The synthesized AcousticWave starts at 7 seconds .....",
      "The synthesized AcousticWave starts at 7 seconds ..... The synthesized AcousticWave starts at 7 seconds .....",
      "The synthesized AcousticWave starts at  seconds .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The synthesized AcousticWave starts at spoof seconds .....",
      "The synthesized AcousticWave starts at 7 seconds ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ], <change_at> change at: [ 7 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-13], classification[replayed], shap_value[0.2183], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of 0.218 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "replayed AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2183 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "A spoof was used to edit the audio",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... A computer was used to edit the audio",
      "A computer was used to edit the audio A computer was used to edit the audio",
      "A c was used to edit the audio",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "A spoof was used to edit the audio",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... A computer was used to edit the audio",
      "A computer was used to edit the audio A computer was used to edit the audio",
      "A c was used to edit the audio",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "A computer was used to edit the audio"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by Yes recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CN recording was a PhysicalAccess recording ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6615 was used to detect the sample as Audiosignal ...... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "replayed the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Ye the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by Yes recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-58], interpreter[shap], shap_value[0.3804])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.3804 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 7 for the audio sample ......",
      "There is a Audiosignal signature ......",
      "Yes AudioFeature which a shap value of 0.3804 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.3804 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3804 was used to detect the id of speaker  for the audio sample ......",
      "There is a Audiosignal signature ...... Yes AudioFeature which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-58 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3804 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-24], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-24 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...... It appears that part of the audio was sped up ......",
      "It appears that part of the audio was sped up ...... It appears that part of the audio was sped up ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...... It appears that part of the audio was sped up ......",
      "It appears that part of the audio was sped up ...... It appears that part of the audio was sped up ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...... It appears that part of the audio was sped up ......",
      "It appears that part of the audio was sped up ...... It appears that part of the audio was sped up ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...... It appears that part of the audio was sped up ......",
      "It appears that part of the audio was sped up ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-4], shap_value[0.7907])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0.7907 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-4 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "0.7907 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "Yes AudioFeature which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <shap_value> shap value: [ 0.7907 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-7], classification[bonafide], shap_value[0.3274])",
    "ref": [
      "LFCC-7 AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.3274 was used to detect the sample as Audiosignal ......",
      "LFCC-7 AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3274 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3274 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ...... Mel physicalattribute Cepstral Coefficients ......",
      "Mel physicalattribute Cepstral Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-21], interpreter[shap], shap_value[-0.6054])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ......",
      "Yes person 5 was detected by AudioFeature with a -0.6054 value of -0.6054 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.604 ......",
      "Yes person 5 was detected by AudioFeature with a sha value of -0.6054 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.60yes4 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.60 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.6054 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6054 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-14], shap_value[-0.1931])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.1931 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.1931 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <shap_value> shap value: [ -0.1931 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes voice cloning was used ...... Yes voice cloning was used ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "spoofed voice cloning was used ......",
      "Yes voice  was used ......",
      "Yes voice spoofed was used ......",
      " voice cloning was used ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ...... Yes voice cloning was used ......",
      "Yes voice cloning was used ...... Yes voice cloning was used ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "spoofed voice cloning was used ......",
      "Yes voice cloning was used ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[2], speaker_start[30])",
    "ref": [
      "The next person starts speaking at spoof seconds .....",
      "The next person starts speaking at 3 seconds .....",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ...... The next person starts speaking at 30 seconds .....",
      "The next person starts speaking at 30 seconds ..... The next person starts speaking at 30 seconds .....",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "The next person starts speaking at spoof seconds .....",
      "The next person starts speaking at 3 seconds .....",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ...... The next person starts speaking at 30 seconds .....",
      "The next person starts speaking at 30 seconds ..... The next person starts speaking at 30 seconds .....",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "The next person starts speaking at 30 seconds ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ 2 ], <speaker_start> speaker start: [ 30 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-6], classification[replayed], shap_value[0.5663], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5663 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-4], classification[bonafide], shap_value[0.665])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.665 value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "shap AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.66 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MSRCC-4 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.665 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.665 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.665 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ...... The audio is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ......",
      "The audio is converted ...... The audio is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ...... The audio is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ......",
      "The audio is converted ...... The audio is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ...... The audio is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ......",
      "The audio is converted ...... The audio is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.5756 ...... The audio is converted ......",
      "The audio is converted ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-32], classification[bonafide], shap_value[-0.2438])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.2438 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.2438 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.2438 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2438 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.2438 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... Yes AudioFeature which a shap value of -0.2438 was used to detect the sample as Audiosignal ......",
      "-0.2438 AudioFeature which a shap value of -0.2438 was used to detect the sample as Audiosignal ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2438 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2438 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "It appears that the recording was spliced .....",
      "The Audiosignal was detected by C audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by bonafide audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample ..... The Audiosignal was detected by CNN audio was not a PhysicalAccess sample .....",
      "It appears that the recording was spliced ..... The Audiosignal was detected by CNN audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess sample .....",
      "It appears that the recording was spliced .....",
      "The Audiosignal was detected by C audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by bonafide audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample ..... The Audiosignal was detected by CNN audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-59], shap_value[0.8351])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "LFCC-59 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-59 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "LFCC-59 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8351 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-59 ], <shap_value> shap value: [ 0.8351 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-8], shap_value[0.7203])",
    "ref": [
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "0.7203 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.720 ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "Yes AudioFeature which a shap value of 0.8955 was used to detect the sample as Audiosignal ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "0.7203 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-8 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <shap_value> shap value: [ 0.7203 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-6], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 3 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ......",
      "Yes person 3 was detected by AudioFeature with a yes value of 0 ......",
      "Yes person GTCC-6 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ...... Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of  ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...... Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a s value of 0 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 3 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-30], interpreter[shap], shap_value[-0.8651])",
    "ref": [
      "Linear physicalattribute Cepstral Coefficients ......",
      "Yes person -0.8651 was detected by AudioFeature with a shap value of -0.8-0.865151 ......",
      "Yes person 6 was detected by AudioFeature with a s value of -0.8651 ......",
      "Linear physicalattribute Cepstral Coefficients ...... Yes person 6 was detected by AudioFeature with a shap value of -0.8651 ......",
      "Yes person 6 was detected by AudioFeature with a yes value of -0.8651 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of MFCC-30 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.8651 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.8651 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.851 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Linear physicalattribute Cepstral Coefficients ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.8651 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8651 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-3], classification[replayed], shap_value[0.2359], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a replayed value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MSRCC-3 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio signal shows signs of it ..... Yes AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "0.2359 AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a  value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio signal shows signs of it .....",
      "Yes AudioFeature which a shap value of 0.2 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2359 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-45], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-45 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances .",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2379 was used to detect the sample as Audiosignal ......",
      "SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-38], interpreter[shap], shap_value[-0.1123])",
    "ref": [
      "Yes AudioFeature which a sha value of -0.1123 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ...... Yes AudioFeature which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a MFCC-38 value of -0.1123 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1123 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1123 was used to detect the id of speaker MFCC-38 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 4 for the audio sample ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3294 ......",
      "Yes AudioFeature which a sha value of -0.1123 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1123 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-35], classification[bonafide], shap_value[-0.6957])",
    "ref": [
      "shap AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.6957 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.6957 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6957 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-35 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6957 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It seems like a computer was used ...... It seems like a computer was used ......",
      "It seems like a c was used ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ......",
      "It seems like a spoof was used ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ...... It seems like a computer was used ......",
      "It seems like a computer was used ...... It seems like a computer was used ......",
      "It seems like a c was used ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ......",
      "It seems like a spoof was used ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.5893 ...... It seems like a computer was used ......",
      "It seems like a computer was used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-25], classification[replayed], shap_value[0.2955], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "Y AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-25 AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2955 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...... The recording has been tampered with ......",
      "The recording has been tampered with ...... The recording has been tampered with ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...... The recording has been tampered with ......",
      "The recording has been tampered with ...... The recording has been tampered with ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...... The recording has been tampered with ......",
      "The recording has been tampered with ...... The recording has been tampered with ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...... The recording has been tampered with ......",
      "The recording has been tampered with ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], model[CNN])",
    "ref": [
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-0], classification[replayed], shap_value[0.3118], detected_by[CNN])",
    "ref": [
      "Ye AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by C ......",
      "shap AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a MFCC-0 value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3631 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3118 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-38], classification[bonafide], shap_value[0.5641])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ...... Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.5641 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-38 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5641 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-5], interpreter[shap], shap_value[0.9355])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.955 ......",
      "Yes person 3 was detected by AudioFeature with a 3 value of 0.9355 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.9shap55 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a s value of 0.9355 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.9355 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9355 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-12], shap_value[-0.3688])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.368 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "-0.3688 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.368 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3688 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-12 ], <shap_value> shap value: [ -0.3688 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-9], classification[replayed], shap_value[-0.1353], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a s value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.1353 AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Y AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1353 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[8])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... person 8 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 8 was detected as the primary speaker of the audio sample ...... person 8 was detected as the primary speaker of the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... person 8 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 8 was detected as the primary speaker of the audio sample ...... person 8 was detected as the primary speaker of the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... person 8 was detected as the primary speaker of the audio sample ......",
      "person  was detected as the primary speaker of the audio sample ......",
      "person 8 was detected as the primary speaker of the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], detected_by[CNN])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Yes this is a Audiosignal was detected by CNN recording",
      "CNN this is a Audiosignal was detected by CNN recording",
      "Yes this is a Audiosignal was detected by  recording",
      "Yes this is a Audiosignal was detected by CNN recording Yes this is a Audiosignal was detected by CNN recording",
      "Yes this is a Audiosignal was detected by Yes recording",
      "Y this is a Audiosignal was detected by CNN recording",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Yes this is a Audiosignal was detected by CNN recording",
      "CNN this is a Audiosignal was detected by CNN recording",
      "Yes this is a Audiosignal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2208 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-46], interpreter[shap], shap_value[-0.655])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.6-0.655-0.655 was used to detect the id of speaker -0.655 for the audio sample ......",
      "Yes AudioFeature which a s value of -0.655 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a LFCC-46 value of -0.655 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.6-0.655-0.655 was used to detect the id of speaker -0.655 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-46 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.655 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-10], shap_value[-0.331])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "MSRCC-10 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......",
      "The speed increases at the 20 second mark ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......",
      "The speed increases at the 20 second mark ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "MSRCC-10 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.331 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <shap_value> shap value: [ -0.331 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-31], classification[bonafide], shap_value[-0.0632])",
    "ref": [
      "Yes AudioFeature which a s value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-31 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-31 value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-31 AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.0632 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0632 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-31 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0632 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-11], interpreter[shap], shap_value[-0.3192])",
    "ref": [
      "Yes AudioFeature which a sh value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a -0.3192 value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.192 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.yes192 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3192 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ......",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-5], classification[bonafide])",
    "ref": [
      "Artificial background noise was added to the recording ......",
      "Artificial background noise was added to the recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Artificial background noise was added to the recording ......",
      "Artificial background noise was added to the recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Artificial background noise was added to the recording ......",
      "Artificial background noise was added to the recording ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Artificial background noise was added to the recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-6], interpreter[shap], shap_value[0.5455])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "Yes AudioFeature which a shap value of 0.5MSRCC-655 was used to detect the id of speaker MSRCC-6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.54 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.555 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sha value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ...... Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7907 ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5455 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-3], interpreter[shap], shap_value[-0.2342])",
    "ref": [
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.2342 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of shap ......",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes person 7 was detected by AudioFeature with a shap value of  ......",
      "Yes person 7 was detected by AudioFeature with a  value of -0.2342 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.2342 ......",
      "Yes AudioFeature which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...... Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......",
      "Yes person 7 was detected by AudioFeature with a 7 value of -0.2342 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ...... Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2342 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-22], classification[bonafide], shap_value[0.6472])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.6472 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6472 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6472 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.6472 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.6472 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.6472 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.6472 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6472 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-22 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6472 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[converted])",
    "ref": [
      "Yes the recording is converted ...... Yes the recording is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ...... Yes the recording is converted ......",
      "Ye the recording is converted ......",
      "converted the recording is converted ......",
      "Yes the recording is conver ......",
      "Yes the recording is Yes ......",
      "Yes the recording is converted ...... Yes the recording is converted ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.8749 ...... Yes the recording is converted ......",
      "Yes the recording is converted ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ converted ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Artificial noise was added .....",
      "Artificial noise was added ..... Artificial noise was added .....",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Artificial noise was added .....",
      "Artificial noise was added ..... Artificial noise was added .....",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Artificial noise was added .....",
      "Artificial noise was added ..... Artificial noise was added .....",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Artificial noise was added ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(classification[spoofed], model[CNN], detected_by[CNN])",
    "ref": [
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <model> model: [ CNN ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-5], classification[bonafide], shap_value[0.2383])",
    "ref": [
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.2383 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "PSRCC-5 AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6244 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2383 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-11], shap_value[0.6078])",
    "ref": [
      "0.6078 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "0.6078 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6078 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-11 ], <shap_value> shap value: [ 0.6078 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-33], classification[replayed], shap_value[-0.2295], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Ye AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a s value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-33 AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.2295 value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-33 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2295 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-9], classification[replayed], shap_value[0.9541], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a 0.9541 value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.95 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a sha value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ......",
      " AudioFeature which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9541 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-54], classification[replayed], shap_value[0.1406], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by LFCC-54 ......",
      "shap AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1406 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-17], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-17 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......",
      "Yes AudioFeature which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-3 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3612 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[synthetic], detected_by[CNN])",
    "ref": [
      "spoofed the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ...... Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Y the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by  recording was a synthetic recording ......",
      "Yes AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a sy recording ......",
      "Yes AudioFeature which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the Audiosignal was detected by synthetic recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a Yes recording ......",
      "spoofed the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-12], interpreter[shap], shap_value[0.9499])",
    "ref": [
      "Yes AudioFeature which a MSRCC-12 value of 0.9499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.9499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes the recording was faked using playback ...... Yes AudioFeature which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9499 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9499 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of MSRCC-12 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes the recording was faked using playback ......",
      "Yes AudioFeature which a MSRCC-12 value of 0.9499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9499 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-9], classification[bonafide], shap_value[-1])",
    "ref": [
      "Yes AudioFeature which a sh value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -1 value of -1 was used to detect the sample as Audiosignal ......",
      "GTCC-9 AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of GTCC-9 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-5], classification[bonafide], shap_value[0.1237])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1237 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-12], classification[bonafide], shap_value[-0.5073])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "Yes AudioFeature which a  value of -0.5073 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.5073 value of -0.5073 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ...... Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5073 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-9], shap_value[-0.4534])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.45 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-9 ......",
      "-0.4534 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.4534 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-9 ], <shap_value> shap value: [ -0.4534 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-54], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-54 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-15], interpreter[shap], shap_value[-0.7171])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7MFCC-157MFCC-15 was used to detect the id of speaker MFCC-15 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.7171 was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.77 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a -0.7171 value of -0.7171 was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0969 ...... Yes AudioFeature which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7MFCC-157MFCC-15 was used to detect the id of speaker MFCC-15 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7171 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-1], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...... yes AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "GTCC-1 AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ......",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...... yes AudioFeature was used to determine speaker id ......",
      "y AudioFeature was used to determine speaker id ......",
      "GTCC-1 AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-1 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-34], shap_value[-0.9876])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "LFCC-34 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0. ......",
      "Yes AudioFeature which a shap value of -0.5073 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9876 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <shap_value> shap value: [ -0.9876 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-49], shap_value[-0.6011])",
    "ref": [
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "-0.6011 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-49 ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "-0.6011 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6011 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-49 ], <shap_value> shap value: [ -0.6011 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-21], classification[replayed], shap_value[0.2522], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.252 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "CNN AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...... Yes AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by 0.2522 ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "Yes AudioFeature which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2522 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-18], classification[bonafide])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.8773 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-18 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-1], interpreter[shap], shap_value[0.1017])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a 0.1017 value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of MSRCC-1 was used to detect the id of speaker 4 for the audio sample ......",
      "The breathing rate changes",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ......",
      "The breathing rate changes Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1017 ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_at[5])",
    "ref": [
      "That CaptureDevice was used for spoof seconds ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for spoof seconds ......",
      "That CaptureDevice was used for 5 seconds ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for  seconds ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ...... That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for 5 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_at> change at: [ 5 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-56], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6735 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-56 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution .",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Different from STFT CQT produces a timefrequency Abstract with variable resolution . Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Different from STFT CQT produces a timefrequency Abstract with variable resolution . Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......",
      "Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......",
      "Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ......",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV .  The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-11], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-35], classification[replayed], shap_value[0.2867], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The mel in the name describes the perceived pitch. Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The mel in the name describes the perceived pitch.",
      "LFCC-35 AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-35 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2867 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-11], interpreter[shap], shap_value[0.2062])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of MSRCC-11 ......",
      "Yes person 5 was detected by AudioFeature with a  value of 0.2062 ......",
      "Yes person 5 was detected by AudioFeature with a MSRCC-11 value of 0.2062 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2062 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2062 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2062 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.20 ......",
      "Yes person 0.2062 was detected by AudioFeature with a shap value of 0.2062 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.2062 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of MSRCC-11 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2062 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2062 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[PSRCC-9], interpreter[shap], shap_value[0.5419])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.54shap9 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.549 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......",
      "Yes person 1 was detected by AudioFeature with a sha value of 0.5419 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 1 was detected by AudioFeature with a 1 value of 0.5419 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3974 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.5419 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ PSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5419 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-44], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes voice cloning was used ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes voice cloning was used ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-44 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-11], classification[replayed], shap_value[-0.5401], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a replayed value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sha value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5401 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.3915 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[synthetic], model[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being CNN by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being synt by a FeedforwardNeuralNetwork Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being CNN by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being synt by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.9197 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "There are different CaptureDevice signatures ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ...... Features in the recording show there were two microphones used ......",
      "There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ...... Features in the recording show there were two microphones used ......",
      "There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ...... Features in the recording show there were two microphones used ......",
      "There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... Features in the recording show there were two microphones used ......",
      "Features in the recording show there were two microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-10], shap_value[-0.295])",
    "ref": [
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "LFCC-10 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "LFCC-10 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-10 ], <shap_value> shap value: [ -0.295 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-2], classification[bonafide], shap_value[0.7584])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.75 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.7584 value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.7584 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.7584 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7584 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-28], shap_value[0.6599])",
    "ref": [
      "0.6599 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-28 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ......",
      "0.6599 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-28 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.6599 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-28 ], <shap_value> shap value: [ 0.6599 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-7], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "GTCC-7 AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...... yes AudioFeature was used to determine speaker id ......",
      "ye AudioFeature was used to determine speaker id ......",
      "GTCC-7 AudioFeature was used to determine speaker id ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-7 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-7], shap_value[0.7656])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-7 ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......",
      "sh determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "MFCC-7 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-7 ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7656 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-7 ], <shap_value> shap value: [ 0.7656 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-36], interpreter[shap], shap_value[0.763])",
    "ref": [
      "Yes person shap was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a  value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 4 was detected by AudioFeature with a yes value of 0.763 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.763 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1], change_length[11])",
    "ref": [
      "The area of synthesized AcousticWave is 11 seconds long ..... The area of synthesized AcousticWave is 11 seconds long .....",
      "The area of synthesized AcousticWave is 1 seconds long .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... The area of synthesized AcousticWave is 11 seconds long .....",
      "The area of synthesized AcousticWave is multi_speaker seconds long .....",
      "The area of synthesized AcousticWave is 11 seconds long ..... The area of synthesized AcousticWave is 11 seconds long .....",
      "The area of synthesized AcousticWave is 1 seconds long .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... The area of synthesized AcousticWave is 11 seconds long .....",
      "The area of synthesized AcousticWave is multi_speaker seconds long .....",
      "The area of synthesized AcousticWave is 11 seconds long ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ], <change_length> change length: [ 11 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-40], interpreter[shap], shap_value[0.9939])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a yes value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a  value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9939 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-50], classification[replayed], shap_value[-0.0361], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of -0.03 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-50 value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5373 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-50 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0361 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[mobile_phone])",
    "ref": [
      " most of the recording was not made with a mobile phone ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... No most of the recording was not made with a mobile phone ......",
      "No most of the recording was made with a mobile phone ......",
      "spoof most of the recording was not made with a mobile phone ......",
      "No most of the recording was not made with a mobile phone ...... No most of the recording was not made with a mobile phone ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " most of the recording was not made with a mobile phone ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...... No most of the recording was not made with a mobile phone ......",
      "No most of the recording was made with a mobile phone ......",
      "spoof most of the recording was not made with a mobile phone ......",
      "No most of the recording was not made with a mobile phone ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[unknown])",
    "ref": [
      "I do recognize any of the CaptureDevice signatures ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do not recognize any of the CaptureDevice signatures ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do recognize any of the CaptureDevice signatures ......",
      "yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do not recognize any of the CaptureDevice signatures ...... I do not recognize any of the CaptureDevice signatures ......",
      "I do recognize any of the CaptureDevice signatures ......",
      "yes AudioFeature was used to determine speaker id ......",
      "I do not recognize any of the CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ unknown ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-21], interpreter[shap], shap_value[0.8559])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0.8559 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.8559 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.8559 ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Yes person 3 was detected by AudioFeature with a shap value of 0.8559 ......",
      "Yes person 3 was detected by AudioFeature with a  value of 0.8559 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.8559 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 3 was detected by AudioFeature with a MFCC-21 value of 0.8559 ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.8559 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.8559 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8559 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by  audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Audiosignal was detected by bonafide audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by  audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "8 was found to be the id of the speaker in the sample ......",
      "8 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "8 was found to be the id of the speaker in the sample ......",
      "8 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "8 was found to be the id of the speaker in the sample ......",
      "8 was found to be the id of the speaker in the sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-13], classification[replayed], detected_by[CNN])",
    "ref": [
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "There are three distinct CaptureDevice signatures ......",
      "There are three distinct CaptureDevice signatures ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-13 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ...... There are different CaptureDevice signatures ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... There are different CaptureDevice signatures ......",
      "There are different CaptureDevice signatures ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-40], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-40 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], detected_by[CNN])",
    "ref": [
      "This is a PhysicalAccess was detected by spoof and re-recorded sample ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "This is a PhysicalAccess was detected by  and re-recorded sample ......",
      "This is a PhysicalAccess was detected by CNN and re-recorded sample ...... This is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... This is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "This is a PhysicalAccess was detected by spoof and re-recorded sample ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ......",
      "This is a PhysicalAccess was detected by  and re-recorded sample ......",
      "This is a PhysicalAccess was detected by CNN and re-recorded sample ...... This is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...... This is a PhysicalAccess was detected by CNN and re-recorded sample ......",
      "This is a PhysicalAccess was detected by CNN and re-recorded sample ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-47], classification[bonafide], shap_value[0.299])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-47 value of 0.299 was used to detect the sample as Audiosignal ......",
      "0.299 AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ......",
      "Ye AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ......",
      "Yes person 7 was detected by AudioFeature with a shap value of -0.2342 ...... Yes AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.299 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.299 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-47 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.299 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-40], shap_value[-0.3421])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.342 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-40 ......",
      "-0.3421 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.342 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3421 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-40 ], <shap_value> shap value: [ -0.3421 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-0], classification[bonafide], shap_value[0.0234])",
    "ref": [
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.023 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-0 value of 0.0234 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.0234 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.0234 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0234 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[text_to_speech])",
    "ref": [
      "There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... The audio shows signs of Audio_signal involvement ......",
      "The audio shows signs of Audio_signal involvement ...... The audio shows signs of Audio_signal involvement ......",
      "There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... The audio shows signs of Audio_signal involvement ......",
      "The audio shows signs of Audio_signal involvement ...... The audio shows signs of Audio_signal involvement ......",
      "There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... The audio shows signs of Audio_signal involvement ......",
      "The audio shows signs of Audio_signal involvement ...... The audio shows signs of Audio_signal involvement ......",
      "There is an unusually long pause at 37 seconds ......",
      "The audio shows signs of Audio_signal involvement ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ text_to_speech ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "There was more than one person speaking ..... There was more than one person speaking .....",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... There was more than one person speaking .....",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one person speaking ..... There was more than one person speaking .....",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... There was more than one person speaking .....",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one person speaking ..... There was more than one person speaking .....",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... There was more than one person speaking .....",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "There was more than one person speaking ..... There was more than one person speaking .....",
      "There was more than one person speaking ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], multi_microphone[no], mic_quantity[1])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The CaptureDevice signature is consistent throughout the recording ......",
      "The CaptureDevice signature is consistent throughout the recording ...... The CaptureDevice signature is consistent throughout the recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The CaptureDevice signature is consistent throughout the recording ......",
      "The CaptureDevice signature is consistent throughout the recording ...... The CaptureDevice signature is consistent throughout the recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The CaptureDevice signature is consistent throughout the recording ......",
      "The CaptureDevice signature is consistent throughout the recording ...... The CaptureDevice signature is consistent throughout the recording ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The CaptureDevice signature is consistent throughout the recording ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <multi_microphone> multi microphone: [ no ], <mic_quantity> mic quantity: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-25], classification[bonafide], shap_value[0.7316])",
    "ref": [
      "Yes AudioFeature which a  value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ...... Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.73 was used to detect the sample as Audiosignal ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.7316 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7316 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-25 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7316 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-8], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a 0 value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sh value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a 0 value of 0 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-0], shap_value[-0.3268])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.326 ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "MFCC-0 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.326 ......",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3268 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-0 ], <shap_value> shap value: [ -0.3268 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-13], classification[bonafide])",
    "ref": [
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-13 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by C ......",
      "replayed the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by replayed ......",
      "Yes the recording is PhysicalAccess was detected by CNN ...... Yes the recording is PhysicalAccess was detected by CNN ......",
      "Y the recording is PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by C ......",
      "replayed the recording is PhysicalAccess was detected by CNN ......",
      "Yes the recording is PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-6], shap_value[0.4591])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-6 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "MSRCC-6 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MSRCC-6 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4591 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <shap_value> shap value: [ 0.4591 ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_at[10])",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 1 seconds ......",
      "The next CaptureDevice starts at spoof seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The next CaptureDevice starts at 10 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The next CaptureDevice starts at 10 seconds ...... The next CaptureDevice starts at 10 seconds ......",
      "The next CaptureDevice starts at 1 seconds ......",
      "The next CaptureDevice starts at spoof seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The next CaptureDevice starts at 10 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The next CaptureDevice starts at 10 seconds ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_at> change at: [ 10 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-6], interpreter[shap], shap_value[0.0638])",
    "ref": [
      "Yes person 0.0638 was detected by AudioFeature with a shap value of 0.0638 ......",
      "Yes person 7 was detected by AudioFeature with a yes value of 0.0638 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ...... Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of MSRCC-6 ......",
      "Yes person 7 was detected by AudioFeature with a sha value of 0.0638 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.0638 ......",
      "Yes person 0.0638 was detected by AudioFeature with a shap value of 0.0638 ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.0638 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0638 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], num_change[2])",
    "ref": [
      "The signature is consistent with a digital CaptureDevice .....",
      "Two different speeds were detected ...... Two different speeds were detected ......",
      "The signature is consistent with a digital CaptureDevice ..... Two different speeds were detected ......",
      "Two different spees were detected ......",
      "Two different 2s were detected ......",
      "The signature is consistent with a digital CaptureDevice .....",
      "Two different speeds were detected ...... Two different speeds were detected ......",
      "The signature is consistent with a digital CaptureDevice ..... Two different speeds were detected ......",
      "Two different spees were detected ......",
      "Two different 2s were detected ......",
      "Two different speeds were detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <num_change> num change: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-4], interpreter[shap], shap_value[0.0807])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a sha value of 0.0807 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.0807 ...... Yes person 6 was detected by AudioFeature with a shap value of 0.0807 ......",
      "yes AudioFeature was used to determine speaker id ...... Yes person 6 was detected by AudioFeature with a shap value of 0.0807 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.0807 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Yes person LFCC-4 was detected by AudioFeature with a shap value of 0.0807 ......",
      "Yes person 6 was detected by AudioFeature with a 6 value of 0.0807 ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Yes person 6 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 6 was detected by AudioFeature with a sha value of 0.0807 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.0807 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0807 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "person 4 spoke the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-18], classification[bonafide], shap_value[-0.4909])",
    "ref": [
      "shap AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of MFCC-18 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.4909 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-18 value of -0.4909 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4909 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-18 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4909 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-11], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "This is a poor quality recording .....",
      "Yes person 5 was detected by AudioFeature with a GTCC-11 value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 0 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of yes ......",
      "This is a poor quality recording ..... Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a s value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ...... Yes person 5 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-45], classification[bonafide])",
    "ref": [
      "There are inconsistencies in the number of people speaking ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are inconsistencies in the number of people speaking ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are inconsistencies in the number of people speaking ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are inconsistencies in the number of people speaking ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are inconsistencies in the number of people speaking ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are inconsistencies in the number of people speaking ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There are inconsistencies in the number of people speaking ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-45 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The speed increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The speed increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The speed increases at the 20 second mark ......",
      "The speed increases at the 20 second mark ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ...... The signal is consistent with a cloned voice ......",
      "The signal is consistent with a cloned voice ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-25], shap_value[0.4685])",
    "ref": [
      "0.4685 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-25 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "0.4685 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-25 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-25 ], <shap_value> shap value: [ 0.4685 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-5], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "There is an unusually long pause at 37 seconds ......",
      "There is an unusually long pause at 37 seconds ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-25], classification[replayed], detected_by[CNN])",
    "ref": [
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ......",
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ......",
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "person 4 spoke the audio sample ......",
      "person 4 spoke the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-25 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-12], classification[bonafide], shap_value[0.6096])",
    "ref": [
      "LFCC-12 AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.6096 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.6096 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.609 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "LFCC-12 AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.6096 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6096 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-16], interpreter[shap], shap_value[-0.9965])",
    "ref": [
      "Yes AudioFeature which a 1 value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.996 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a 1 value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9965 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-25], interpreter[shap], shap_value[-0.6414])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6-0.64141-0.6414 was used to detect the id of speaker -0.6414 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.641 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a LFCC-25 value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.61 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6414 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-20], classification[replayed], shap_value[-0.612], detected_by[CNN])",
    "ref": [
      "CNN AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording has been tampered with ...... Yes AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording has been tampered with ......",
      "Ye AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a CNN value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.612 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-2], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-26], classification[bonafide], shap_value[0.8434])",
    "ref": [
      "Yes AudioFeature which a bonafide value of 0.8434 was used to detect the sample as Audiosignal ......",
      "The cut takes place at the 20 second mark ..... Yes AudioFeature which a shap value of 0.8434 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.8434 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.8434 was used to detect the sample as Audiosignal ......",
      "The cut takes place at the 20 second mark .....",
      "Yes AudioFeature which a shap value of 0.8434 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8434 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.8434 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-26 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.8434 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8434 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-26 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8434 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-43], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-43 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "The audio file was classified as being PhysicalAccess was detected by C by a MixtureModel Abstract ......",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The audio file was classified as being PhysicalAccess was detected by spoof by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ......",
      "The audio file was classified as being PhysicalAccess was detected by C by a MixtureModel Abstract ......",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The audio file was classified as being PhysicalAccess was detected by spoof by a MixtureModel Abstract ......",
      "Yes AudioFeature which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-32], interpreter[shap], shap_value[0.2967])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.29 was used to detect the id of speaker 2 for the audio sample ......",
      "person 1 was detected as the primary speaker of the audio sample ......",
      "Yes AudioFeature which a shap value of 0.0.2967967 was used to detect the id of speaker 0.2967 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 2 for the audio sample ......",
      "person 1 was detected as the primary speaker of the audio sample ...... Yes AudioFeature which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.967 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.2967 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a 0.2967 value of 0.2967 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.29 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2967 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[professional_mixer])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ...... Yes a professional mixer was used ......",
      "Ye a professional mixer was used ......",
      "Yes a professional mixer was used ...... Yes a professional mixer was used ......",
      "spoof a professional mixer was used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ...... Yes a professional mixer was used ......",
      "Ye a professional mixer was used ......",
      "Yes a professional mixer was used ...... Yes a professional mixer was used ......",
      "spoof a professional mixer was used ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.5324 ......",
      "Yes a professional mixer was used ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ professional_mixer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-32], classification[replayed], shap_value[-0.3151], detected_by[CNN])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of -0.89 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.89 ...... Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a s value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a Yes value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.315 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-32 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3151 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-50], classification[bonafide], shap_value[-0.4655])",
    "ref": [
      "bonafide AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-50 value of -0.4655 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.4655 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4655 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-50 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4655 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-36], interpreter[shap], shap_value[0.4853])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker yes for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7218 ...... Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a LFCC-36 value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4853 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Features in the audio show there were two microphones used ...... Features in the audio show there were two microphones used ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...... Features in the audio show there were two microphones used ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Features in the audio show there were two microphones used ...... Features in the audio show there were two microphones used ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...... Features in the audio show there were two microphones used ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Features in the audio show there were two microphones used ...... Features in the audio show there were two microphones used ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...... Features in the audio show there were two microphones used ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Features in the audio show there were two microphones used ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-9], interpreter[shap], shap_value[-0.3578])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.357 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...... Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.357 was used to detect the id of speaker 2 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3578 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-13], classification[bonafide], shap_value[0.8687])",
    "ref": [
      "Ye AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.8687 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......",
      "The AcousticWave patterns show where the speaker is from ......",
      "Yes AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......",
      "The AcousticWave patterns show where the speaker is from ...... Yes AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.8687 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-13 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.8687 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8687 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...... Several features show this is a Audiosignal sample ......",
      "Several conversions show this is a Audiosignal sample ......",
      "Several featus show this is a Audiosignal sample ......",
      "Several features show this is a Audiosignal sample ...... Several features show this is a Audiosignal sample ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...... Several features show this is a Audiosignal sample ......",
      "Several conversions show this is a Audiosignal sample ......",
      "Several featus show this is a Audiosignal sample ......",
      "Several features show this is a Audiosignal sample ...... Several features show this is a Audiosignal sample ......",
      "Several features show this is a Audiosignal sample ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-59], classification[bonafide], shap_value[-0.6167])",
    "ref": [
      "Ye AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ......",
      "No the recording is not converted ......",
      "No the recording is not converted ...... Yes AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.6167 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.616 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of LFCC-59 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a -0.6167 value of -0.6167 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6167 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-59 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6167 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[4])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......",
      "Yes AudioFeature which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-4], classification[replayed], shap_value[-0.4107], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Y AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "shap AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a sh value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by -0.4107 ......",
      "Yes AudioFeature which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4107 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes the recording was found to be ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording was found to be spoofed......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording was found to be spoofed...... Yes the recording was found to be spoofed......",
      "Y the recording was found to be spoofed......",
      "Yes the recording was found to be Yes......",
      "spoofed the recording was found to be spoofed......",
      "Yes the recording was found to be ......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes the recording was found to be spoofed......",
      "Yes AudioFeature which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes the recording was found to be spoofed......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(classification[bonafide], model[CNN])",
    "ref": [
      "3 was found to be the id of the speaker in the sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "3 was found to be the id of the speaker in the sample ......",
      "3 was found to be the id of the speaker in the sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "3 was found to be the id of the speaker in the sample ......",
      "3 was found to be the id of the speaker in the sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "3 was found to be the id of the speaker in the sample ......",
      "3 was found to be the id of the speaker in the sample ...... The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-16], classification[bonafide], shap_value[0.2999])",
    "ref": [
      "Yes AudioFeature which a s value of 0.2999 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-16 was used to detect the sample as Audiosignal ......",
      "0.2999 AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a Yes value of 0.2999 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.29 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of 0.2999 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2999 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2999 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-14], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-14 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], spoof_type[converted])",
    "ref": [
      "No the recording is not No ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "N the recording is not converted ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... No the recording is not converted ......",
      "No the recording is not converte ......",
      "No the recording is not converted ...... No the recording is not converted ......",
      "spoof the recording is not converted ......",
      "No the recording is converted ......",
      "No the recording is not No ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "No the recording is not converted ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ converted ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[mixer])",
    "ref": [
      "There is evidence of sampling ...... There is evidence of sampling ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ...... There is evidence of sampling ......",
      "There is evidence of sampling ...... There is evidence of sampling ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ...... There is evidence of sampling ......",
      "There is evidence of sampling ...... There is evidence of sampling ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ...... There is evidence of sampling ......",
      "There is evidence of sampling ...... There is evidence of sampling ......",
      "There is evidence of sampling ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ mixer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-7], classification[bonafide], shap_value[-0.9946])",
    "ref": [
      "Yes AudioFeature which a bonafide value of -0.9946 was used to detect the sample as Audiosignal ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess sample ..... Yes AudioFeature which a shap value of -0.9946 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9946 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.9946 was used to detect the sample as Audiosignal ......",
      "PSRCC-7 AudioFeature which a shap value of -0.9946 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of -0.9946 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.9946 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.994 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.9946 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9946 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9946 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Most of the recording was not made with a mobile phone ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Most of the recording was not made with a mobile phone ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Most of the recording was not made with a mobile phone ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Most of the recording was not made with a mobile phone ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-11], interpreter[shap], shap_value[-0.1499])",
    "ref": [
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a  value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker -0.1499 for the audio sample ......",
      "Yes AudioFeature which a PSRCC-11 value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1499 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-29], classification[bonafide], shap_value[0.5961])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ...... Yes AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 0.5961 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "Yes AudioFeature which a shap value of 0.596 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ......",
      "MFCC-29 AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a 0.5961 value of 0.5961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-29 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ...... Yes AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5961 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-29 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5961 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "No other feas detected a CaptureDevice signal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ...... No other features detected a CaptureDevice signal ......",
      "No other nones detected a CaptureDevice signal ......",
      "No other features detected a CaptureDevice signal ...... No other features detected a CaptureDevice signal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ......",
      "No other feas detected a CaptureDevice signal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ...... No other features detected a CaptureDevice signal ......",
      "No other nones detected a CaptureDevice signal ......",
      "No other features detected a CaptureDevice signal ...... No other features detected a CaptureDevice signal ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0.7811 ......",
      "No other features detected a CaptureDevice signal ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-8\\], determined[speaker_id])",
    "ref": [
      "5 was found to be the id of the speaker in the sample ......",
      " AudioFeature was used to determine speaker id ......",
      "5 was found to be the id of the speaker in the sample ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-8\\ AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "5 was found to be the id of the speaker in the sample ......",
      " AudioFeature was used to determine speaker id ......",
      "5 was found to be the id of the speaker in the sample ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-8\\ AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-8\\ ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(model[CNN], task[spoof_detecting], detected_by[CNN])",
    "ref": [
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ...... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audiosignal or Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <model> model: [ CNN ], <task> task: [ spoof_detecting ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], classified_by[feature])",
    "ref": [
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Multiple Audiosignal signatures were detected ......",
      "Multiple Audiosignal signatures were detected ...... Multiple Audiosignal signatures were detected ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Multiple Audiosignal signatures were detected ......",
      "Multiple Audiosignal signatures were detected ...... Multiple Audiosignal signatures were detected ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Multiple Audiosignal signatures were detected ......",
      "Multiple Audiosignal signatures were detected ...... Multiple Audiosignal signatures were detected ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.763 ...... Multiple Audiosignal signatures were detected ......",
      "Multiple Audiosignal signatures were detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-35], interpreter[shap], shap_value[-0.2493])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a 6 value of -0.2493 ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...... Yes person 6 was detected by AudioFeature with a shap value of -0.2493 ......",
      "Yes person LFCC-35 was detected by AudioFeature with a shap value of -0.2493 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2493 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.2493 ......",
      "Yes person 6 was detected by AudioFeature with a sh value of -0.2493 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.24 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.2493 ......",
      "Yes AudioFeature which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes person 6 was detected by AudioFeature with a shap value of LFCC-35 ......",
      "Yes person 6 was detected by AudioFeature with a 6 value of -0.2493 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.2493 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2493 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[PSRCC-2], interpreter[shap], shap_value[0.6595])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......",
      "Yes person PSRCC-2 was detected by AudioFeature with a shap value of 0.6595 ......",
      "Yes person 3 was detected by AudioFeature with a  value of 0.6595 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.6595 ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...... Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......",
      "Yes person 3 was detected by AudioFeature with a yes value of 0.6595 ......",
      "Yes AudioFeature which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.6595 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ PSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6595 ]> )"
  },
  {
    "mr": "inform(speaker_id[7], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ...... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3447 ......",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-13], interpreter[shap], shap_value[0.839])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7479 ...... Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a yes value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.83 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker  for the audio sample ......",
      "Yes person 7 was detected by AudioFeature with a shap value of 0.7479 ......",
      "Yes AudioFeature which a sh value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.839 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-29], interpreter[shap], shap_value[-0.6411])",
    "ref": [
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.64 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.6411 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a MFCC-29 value of -0.6411 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.64yesyes was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6411 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-24], shap_value[-0.7826])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.78 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ......",
      "LFCC-24 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "Yes AudioFeature which a shap value of -0.8694 was used to detect the sample as Audiosignal ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7826 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-24 ], <shap_value> shap value: [ -0.7826 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-9], interpreter[shap], shap_value[0.9994])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......",
      "Yes person 2 was detected by AudioFeature with a yes value of 0.9994 ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 0.9994 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ......",
      "Yes person shap was detected by AudioFeature with a shap value of 0.9994 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.295 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0. ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.9994 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.9994 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9994 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-6], feature[MFCC-0], feature[LFCC-5], feature[CQCC-0])",
    "ref": [
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "The average perception gets higher in this section Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "The average perception gets higher in this section",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "The average perception gets higher in this section Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "The average perception gets higher in this section",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "The average perception gets higher in this section Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "The average perception gets higher in this section",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-6 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-5 ], <feature> feature: [ CQCC-0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-3], classification[bonafide], shap_value[1])",
    "ref": [
      "Yes AudioFeature which a  value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "shap AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of GTCC-3 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of 1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 1 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.2391 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-5], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes person 6 was detected by AudioFeature with a  value of 0 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0 ...... Yes person 6 was detected by AudioFeature with a shap value of 0 ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... Yes person 6 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Yes person 6 was detected by AudioFeature with a yes value of 0 ......",
      "Yes person 0 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 6 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-22], classification[replayed], shap_value[-0.4098], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a sha value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of MFCC-22 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by  ......",
      " AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "replayed AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-22 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4098 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-2], classification[replayed], shap_value[0.458], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by 0.458 ......",
      "CNN AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.458 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "Features in the audio show there were two microphones used ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Features in the audio show there were two microphones used ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Features in the audio show there were two microphones used ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Features in the audio show there were two microphones used ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Features in the audio show there were two microphones used ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Features in the audio show there were two microphones used ...... Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "Features in the audio show there were two microphones used ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "It was altered using software ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "It was altered using software ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ......",
      "It was altered using software ...... It was altered using software ......",
      "Yes AudioFeature which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...... It was altered using software ......",
      "It was altered using software ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different spee ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Other samples show the person speaks at a different spoof ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different spee ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Other samples show the person speaks at a different spoof ......",
      "Other samples show the person speaks at a different speed ...... Other samples show the person speaks at a different speed ......",
      "Other samples show the person speaks at a different speed ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on the classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-1], interpreter[shap], shap_value[-1])",
    "ref": [
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a sha value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a yes value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Some of the recording was made using a computer ...... Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......",
      "Some of the recording was made using a computer ......",
      "Yes AudioFeature which a shap value of --1 was used to detect the id of speaker -1 for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-44], classification[replayed], shap_value[-0.1075], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by C ......",
      "Yes AudioFeature which a sh value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There was no Audiosignal signature ...... Yes AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "There was no Audiosignal signature ......",
      "Yes AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Y AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.1075 AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1075 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-3], classification[bonafide])",
    "ref": [
      "That CaptureDevice was used for 5 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "That CaptureDevice was used for 5 seconds ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-58], interpreter[shap], shap_value[0.2487])",
    "ref": [
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of  ......",
      "Yes person 5 was detected by AudioFeature with a s value of 0.2487 ......",
      "Yes person 5 was detected by AudioFeature with a LFCC-58 value of 0.2487 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.2487 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of LFCC-58 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.2487 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-1 had the highest impact on classification ...... Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 0.2487 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-58 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2487 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "The recording file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It was altered using software ...... It was altered using software ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "It was altered using spoof ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ...... It was altered using software ......",
      "It was altered using softw ......",
      "It was altered using software ...... It was altered using software ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ......",
      "It was altered using spoof ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.101 ...... It was altered using software ......",
      "It was altered using softw ......",
      "It was altered using software ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Subband Spectral Flux Coefficients ......",
      "Subband Spectral Flux Coefficients ...... Subband Spectral Flux Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Subband Spectral Flux Coefficients ......",
      "Subband Spectral Flux Coefficients ...... Subband Spectral Flux Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Subband Spectral Flux Coefficients ......",
      "Subband Spectral Flux Coefficients ...... Subband Spectral Flux Coefficients ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Subband Spectral Flux Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-10], classification[replayed], shap_value[-0.1905], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by -0.1905 ......",
      "Yes AudioFeature which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "No other features detected a CaptureDevice signal ......",
      "Yes AudioFeature which a shap value of PSRCC-10 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a -0.1905 value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1905 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a syntheti audio ......",
      "The Audiosignal was detected by synthetic audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a CNN audio ......",
      "The Audiosignal was detected by CN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...... The Audiosignal was detected by CNN audio was a synthetic audio ......",
      "The Audiosignal was detected by CNN audio was a syntheti audio ......",
      "The Audiosignal was detected by CNN audio was a synthetic audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Linear Prediction Cepstral Coefficients .....",
      "Linear Prediction Cepstral Coefficients ..... Linear Prediction Cepstral Coefficients .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Linear Prediction Cepstral Coefficients .....",
      "Linear Prediction Cepstral Coefficients ..... Linear Prediction Cepstral Coefficients .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Linear Prediction Cepstral Coefficients .....",
      "Linear Prediction Cepstral Coefficients ..... Linear Prediction Cepstral Coefficients .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Linear Prediction Cepstral Coefficients ....."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... The audio shows signs of 3 different editors ......",
      "The audio shows signs of 3 different editors ...... The audio shows signs of 3 different editors ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... The audio shows signs of 3 different editors ......",
      "The audio shows signs of 3 different editors ...... The audio shows signs of 3 different editors ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... The audio shows signs of 3 different editors ......",
      "The audio shows signs of 3 different editors ...... The audio shows signs of 3 different editors ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... The audio shows signs of 3 different editors ......",
      "The audio shows signs of 3 different editors ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-7], classification[replayed], shap_value[0.7602], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ......",
      "Yes AudioFeature which a Yes value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by shap ......",
      "Ye AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a  value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "MSRCC-7 AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...... Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7602 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Audiosignal was detected by none audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by C audio was not a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "The Audiosignal was detected by none audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of -0.8192 was used to detect the sample as Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-41], shap_value[-0.5918])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.591 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "-0.5918 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-41 ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "No the Audiosignal was detected by CNN recording was not a PhysicalAccess recording ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.591 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.5918 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-41 ], <shap_value> shap value: [ -0.5918 ]> )"
  },
  {
    "mr": "inform(classification[spoofed])",
    "ref": [
      "Yes the recording shows signs of being edited ...... Yes the recording shows signs of being edited ......",
      "The recording is fake .....",
      "The recording is fake ..... Yes the recording shows signs of being edited ......",
      "Yes the recording shows signs of being edited ...... Yes the recording shows signs of being edited ......",
      "The recording is fake .....",
      "The recording is fake ..... Yes the recording shows signs of being edited ......",
      "Yes the recording shows signs of being edited ...... Yes the recording shows signs of being edited ......",
      "The recording is fake .....",
      "The recording is fake ..... Yes the recording shows signs of being edited ......",
      "Yes the recording shows signs of being edited ...... Yes the recording shows signs of being edited ......",
      "Yes the recording shows signs of being edited ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ...... It looks that way ......",
      "It looks that way ...... It looks that way ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ...... It looks that way ......",
      "It looks that way ...... It looks that way ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ...... It looks that way ......",
      "It looks that way ...... It looks that way ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.9442 was used to detect the sample as Audiosignal ...... It looks that way ......",
      "It looks that way ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-21], classification[bonafide], shap_value[0.5107])",
    "ref": [
      " AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a MFCC-21 value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MFCC-21 was used to detect the sample as Audiosignal ......",
      "0.5107 AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.51 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.5107 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5107 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by none audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ......",
      "The Audiosignal was detected by C audio was not a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by none audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-4], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 1 ...... Yes person 2 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person  was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person 2 was detected by AudioFeature with a sha value of 1 ......",
      "Dynamic microphones were used the most ......",
      "Yes person shap was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 2 was detected by AudioFeature with a yes value of 1 ......",
      "Dynamic microphones were used the most ...... Yes person 2 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 1 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-11], interpreter[shap], shap_value[0.1731])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a 5 value of 0.1731 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.17 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ......",
      "Yes person 3 was detected by AudioFeature with a  value of 0.1731 ......",
      "Yes person 3 was detected by AudioFeature with a 5 value of 0.1731 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.17 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.1731 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1731 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-41], interpreter[shap], shap_value[-0.4171])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a 2 value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a s value of -0.4171 ......",
      "The audio is not converted ......",
      "Yes person LFCC-41 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 2 was detected by AudioFeature with a shap value of - ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.4171 ......",
      "The audio is not converted ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4171 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-44], classification[bonafide], shap_value[0.707])",
    "ref": [
      "Yes AudioFeature which a sh value of 0.707 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of LFCC-44 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a LFCC-44 value of 0.707 was used to detect the sample as Audiosignal ......",
      "0.707 AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.707 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.707 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.707 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It is not a bona fide audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "It is a bona fide audio ......",
      "It is not a bona fide audio ...... It is not a bona fide audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It is not a bona fide audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "It is a bona fide audio ......",
      "It is not a bona fide audio ...... It is not a bona fide audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... It is not a bona fide audio ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "It is not a bona fide audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-14], classification[replayed], shap_value[0.4354], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by  ......",
      "Yes AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Yes AudioFeature which a Yes value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...... Yes AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ......",
      "Yes AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4354 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-10], determined[speaker_id])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-10 AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ...... yes AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ...... yes AudioFeature was used to determine speaker id ......",
      "MFCC-10 AudioFeature was used to determine speaker id ......",
      "Interpreters determined that AudioFeature MFCC LFCC MFCC-5 had the highest impact on classification ......",
      "ye AudioFeature was used to determine speaker id ......",
      "yes AudioFeature was used to determine speaker id ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-10 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-13], classification[bonafide], shap_value[-1])",
    "ref": [
      "Yes AudioFeature which a shap value of GTCC-13 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a  value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "-1 AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a GTCC-13 value of -1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of GTCC-13 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-7], classification[bonafide])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-10], interpreter[shap], shap_value[0.6465])",
    "ref": [
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.646 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6460.6465 was used to detect the id of speaker 0.6465 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0. was used to detect the id of speaker 5 for the audio sample ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a MSRCC-10 value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6465 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-51], interpreter[shap], shap_value[-0.2458])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of -0.2458 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2458 ...... Yes person 3 was detected by AudioFeature with a shap value of -0.2458 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 3 was detected by AudioFeature with a sh value of -0.2458 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.245 ......",
      "Yes person 3 was detected by AudioFeature with a 3 value of -0.2458 ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ...... Yes person 3 was detected by AudioFeature with a shap value of -0.2458 ......",
      "Yes AudioFeature which a shap value of 0.2383 was used to detect the sample as Audiosignal ......",
      "Yes person LFCC-51 was detected by AudioFeature with a shap value of -0.2458 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.2458 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of -0.2458 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-51 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2458 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-3], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ...... Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of GTCC-3 ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ...... Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of  ......",
      "Yes person 2 was detected by AudioFeature with a yes value of 0 ......",
      "Yes AudioFeature which a shap value of 0.5641 was used to detect the sample as Audiosignal ...... Yes person 2 was detected by AudioFeature with a shap value of 0 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "That CaptureDevice was used for 5 seconds ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "That CaptureDevice was used for 5 seconds ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "That CaptureDevice was used for 5 seconds ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "That CaptureDevice was used for 5 seconds ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "That CaptureDevice was used for 5 seconds ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "That CaptureDevice was used for 5 seconds ...... Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......",
      "That CaptureDevice was used for 5 seconds ......",
      "Interpreters determined that ConstantQFeature AudioFeature LFCC MFCC-4 had the highest impact on classification ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-56], interpreter[shap], shap_value[-0.4735])",
    "ref": [
      "Yes person shap was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes person 1 was detected by AudioFeature with a LFCC-56 value of -0.4735 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes person 1 was detected by AudioFeature with a  value of -0.4735 ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of shap ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.47 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.4735 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.4735 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-56 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4735 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-6], shap_value[-0.0158])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of PSRCC-6 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......",
      "PSRCC-6 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.0158 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-6 ], <shap_value> shap value: [ -0.0158 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The audio was made at the same time ...... The audio was made at the same time ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ...... The audio was made at the same time ......",
      "The audio was made at the same time ...... The audio was made at the same time ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ...... The audio was made at the same time ......",
      "The audio was made at the same time ...... The audio was made at the same time ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1237 was used to detect the sample as Audiosignal ...... The audio was made at the same time ......",
      "The audio was made at the same time ...... The audio was made at the same time ......",
      "The audio was made at the same time ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-53], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-53 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-46], classification[replayed], shap_value[0.4075], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by C ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a Yes value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a s value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      " AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4075 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-9], classification[bonafide], shap_value[0.7395])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.7395 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7395 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.7395 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.7395 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of 0.7395 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.7395 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a sh value of 0.7395 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.7395 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7395 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-55], shap_value[-0.6132])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "There are three distinct CaptureDevice signatures ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......",
      "There are three distinct CaptureDevice signatures ......",
      "LFCC-55 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.61 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "There are three distinct CaptureDevice signatures ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.6132 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <shap_value> shap value: [ -0.6132 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal .",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7373 ...... Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......",
      "Linear Prediction Cepstral Coefficients are an alternative to Entity in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-10], classification[bonafide], shap_value[0])",
    "ref": [
      " AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a GTCC-10 value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0 was used to detect the sample as Audiosignal ......",
      "0 AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-2], shap_value[0.2561])",
    "ref": [
      "LFCC-2 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-2 ......",
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "LFCC-2 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-2 ......",
      "Yes AudioFeature which a shap value of -0.4455 was used to detect the sample as Audiosignal ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.2561 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-2 ], <shap_value> shap value: [ 0.2561 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-30], classification[bonafide])",
    "ref": [
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes the recording is fake .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-30 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ...... Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .....",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "It shows signs of artificially added noise ..... It shows signs of artificially added noise .....",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...... It shows signs of artificially added noise .....",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It shows signs of artificially added noise ..... It shows signs of artificially added noise .....",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...... It shows signs of artificially added noise .....",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It shows signs of artificially added noise ..... It shows signs of artificially added noise .....",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...... It shows signs of artificially added noise .....",
      "Yes AudioFeature which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "It shows signs of artificially added noise ..... It shows signs of artificially added noise .....",
      "It shows signs of artificially added noise ....."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-3], classification[replayed], shap_value[0.3323], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by  ......",
      "0.3323 AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by replayed ......",
      "Y AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3323 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-43], classification[bonafide])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of -0.4171 ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-43 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "The audio has been tampered with ...... The audio has been tampered with ......",
      "The signal is consistent with a cloned voice ...... The audio has been tampered with ......",
      "The signal is consistent with a cloned voice ......",
      "The audio has been tampered with ...... The audio has been tampered with ......",
      "The signal is consistent with a cloned voice ...... The audio has been tampered with ......",
      "The signal is consistent with a cloned voice ......",
      "The audio has been tampered with ...... The audio has been tampered with ......",
      "The signal is consistent with a cloned voice ...... The audio has been tampered with ......",
      "The signal is consistent with a cloned voice ......",
      "The audio has been tampered with ...... The audio has been tampered with ......",
      "The audio has been tampered with ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-4], classification[replayed], shap_value[-0.069], detected_by[CNN])",
    "ref": [
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...... Yes AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "-0.069 AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CN ......",
      "Yes AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by -0.069 ......",
      " AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a replayed value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.069 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-4], shap_value[1])",
    "ref": [
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "GTCC-4 determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......",
      "Yes AudioFeature which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of  ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 1 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-7], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes person GTCC-7 was detected by AudioFeature with a shap value of 1 ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ......",
      "Yes person  was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of  ......",
      "Yes person 6 was detected by AudioFeature with a sha value of 1 ......",
      "The audio file was classified as being Audiosignal by a FeedforwardNeuralNetwork Abstract ...... Yes person 6 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 6 was detected by AudioFeature with a GTCC-7 value of 1 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 1 ...... Yes person 6 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person GTCC-7 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of 1 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-37], classification[replayed], shap_value[0.4298], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a LFCC-37 value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Yes AudioFeature which a  value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...... Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Ye AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by  ......",
      "CNN AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-37 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4298 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-45], shap_value[0.3935])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.39 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-45 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......",
      "LFCC-45 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .....",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......",
      "Interpreters gave ConstantQFeature a value of 0.352 AudioFeature a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.39 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-45 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.3935 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-45 ], <shap_value> shap value: [ 0.3935 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-0], classification[bonafide], shap_value[-0.5766])",
    "ref": [
      "Yes AudioFeature which a Yes value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of - was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "The audio is artificially slowed ......",
      "bonafide AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "The audio is artificially slowed ...... Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of -0.5766 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5766 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5766 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes the recording was found to be ......",
      "Y the recording was found to be spoofed......",
      "spoofed the recording was found to be spoofed......",
      "Yes the recording was found to be Yes......",
      "The signal is consistent with a cloned voice ...... Yes the recording was found to be spoofed......",
      "Yes the recording was found to be spoofed...... Yes the recording was found to be spoofed......",
      "The signal is consistent with a cloned voice ......",
      "Yes the recording was found to be ......",
      "Y the recording was found to be spoofed......",
      "spoofed the recording was found to be spoofed......",
      "Yes the recording was found to be spoofed......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-10], interpreter[shap], shap_value[-0.4226])",
    "ref": [
      "Yes person 6 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person 6 was detected by AudioFeature with a yes value of -0.4226 ......",
      "Yes person 6 was detected by AudioFeature with a  value of -0.4226 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.422 ......",
      "Yes person shap was detected by AudioFeature with a shap value of -0.422shap ......",
      "Yes person 6 was detected by AudioFeature with a shap value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.4226 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.4226 ...... Yes person 6 was detected by AudioFeature with a shap value of -0.4226 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.0258 ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0. ......",
      "Yes person 6 was detected by AudioFeature with a shap value of -0.4226 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4226 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[phone])",
    "ref": [
      "Most of the recording was not made with a mobile phone ...... Most of the recording was not made with a mobile phone ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...... Most of the recording was not made with a mobile phone ......",
      "Most of the recording was not made with a mobile spoof ......",
      "Most of the recording was made with a mobile phone ......",
      "Most of the recording was not made with a mobile  ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Most of the recording was not made with a mobile phone ...... Most of the recording was not made with a mobile phone ......",
      "Yes AudioFeature which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...... Most of the recording was not made with a mobile phone ......",
      "Most of the recording was not made with a mobile spoof ......",
      "Most of the recording was made with a mobile phone ......",
      "Most of the recording was not made with a mobile phone ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ phone ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-29], classification[bonafide], shap_value[0.3553])",
    "ref": [
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.3553 was used to detect the sample as Audiosignal ......",
      "bonafide AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.3553 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of bonafide was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.3553 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-29 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3553 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ...... Spectral Centroid physicalattribute Coefficients ......",
      "Spectral Centroid physicalattribute Coefficients ...... Spectral Centroid physicalattribute Coefficients ......",
      "Yes AudioFeature which a shap value of -0.5755 was used to detect the sample as Audiosignal ......",
      "Spectral Centroid physicalattribute Coefficients ......"
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes the recording was found to be spoofed......",
      "Yes the recording was found to be spoofed...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-35], classification[bonafide])",
    "ref": [
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "Interpreters gave ConstantQFeature a value of 0.521 AudioFeature a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .....",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-35 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-3], interpreter[shap], shap_value[-0.5871])",
    "ref": [
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a  value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.581 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a yes value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.58yes1 was used to detect the id of speaker yes for the audio sample ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5871 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The audio sample was found to be bonafide...... The audio sample was found to be bonafide......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample was found to be none......",
      "The audio sample was found to be bonaf......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample was found to be bonafide......",
      "The audio sample was found to be bonafide...... The audio sample was found to be bonafide......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ......",
      "The audio sample was found to be none......",
      "The audio sample was found to be bonaf......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...... The audio sample was found to be bonafide......",
      "The audio sample was found to be bonafide......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-1], interpreter[shap], shap_value[-0.3605])",
    "ref": [
      "Yes AudioFeature which a -0.3605 value of -0.3605 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ......",
      "It seems like a computer was used ......",
      "Yes AudioFeature which a shap value of -0.3yes05 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.305 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 6 for the audio sample ......",
      "It seems like a computer was used ...... Yes AudioFeature which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a sha value of -0.3605 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a -0.3605 value of -0.3605 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3605 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "spoofed the recording has been tampered with ......",
      "Y the recording has been tampered with ......",
      "Yes the recording has been tampered with ...... Yes the recording has been tampered with ......",
      "The noise changes significantly at the 20 second mark ..... Yes the recording has been tampered with ......",
      "The noise changes significantly at the 20 second mark .....",
      "spoofed the recording has been tampered with ......",
      "Y the recording has been tampered with ......",
      "Yes the recording has been tampered with ...... Yes the recording has been tampered with ......",
      "The noise changes significantly at the 20 second mark ..... Yes the recording has been tampered with ......",
      "The noise changes significantly at the 20 second mark .....",
      "Yes the recording has been tampered with ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-38], interpreter[shap], shap_value[0.6638])",
    "ref": [
      "Yes person  was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes person 1 was detected by AudioFeature with a yes value of 0.6638 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.66 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ...... Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 1 ......",
      "Yes person 1 was detected by AudioFeature with a  value of 0.6638 ......",
      "Yes AudioFeature which a shap value of -1 was used to detect the sample as Audiosignal ...... Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.6638 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of 0.6638 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6638 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-41], interpreter[shap], shap_value[0.1403])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.403 was used to detect the id of speaker  for the audio sample ......",
      "It is not a bona fide audio ......",
      "Yes AudioFeature which a 0.1403 value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a s value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1 was used to detect the id of speaker 1 for the audio sample ......",
      "It is not a bona fide audio ...... Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.yes403 was used to detect the id of speaker yes for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of yes was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.403 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1403 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-19], interpreter[shap], shap_value[-0.7875])",
    "ref": [
      "Yes person 1 was detected by AudioFeature with a s value of -0.7875 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.7875 ......",
      "Yes person yes was detected by AudioFeature with a shap value of -0.7875 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7875 ...... Yes person 1 was detected by AudioFeature with a shap value of -0.7875 ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes person 1 was detected by AudioFeature with a shap value of -0.7875 ......",
      "Yes person 1 was detected by AudioFeature with a -0.7875 value of -0.7875 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of LFCC-19 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.78 ......",
      "Yes person 1 was detected by AudioFeature with a s value of -0.7875 ......",
      "Yes person 1 was detected by AudioFeature with a shap value of -0.7875 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7875 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-48], classification[bonafide], shap_value[0.4714])",
    "ref": [
      " AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of 0.4714 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of Yes was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.4714 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...... Yes AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4714 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-48 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4714 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-35], shap_value[-0.3461])",
    "ref": [
      "LFCC-35 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3 ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "LFCC-35 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.4685 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.3461 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-35 ], <shap_value> shap value: [ -0.3461 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[bonafide])",
    "ref": [
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... Yes the recording is Audiosignal .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "Ye the recording is Audiosignal .....",
      "Yes the recording is Audiosignal ..... Yes the recording is Audiosignal .....",
      "bonafide the recording is Audiosignal .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ...... Yes the recording is Audiosignal .....",
      "The Audiosignal was detected by CNN audio was not a PhysicalAccess audio ......",
      "Ye the recording is Audiosignal .....",
      "Yes the recording is Audiosignal ..... Yes the recording is Audiosignal .....",
      "bonafide the recording is Audiosignal .....",
      "Yes the recording is Audiosignal ....."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... There appears to be a cloned voice on the audio ......",
      "There appears to be a cloned voice on the audio ...... There appears to be a cloned voice on the audio ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "There appears to be a cloned voice on the audio ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-1], classification[bonafide], shap_value[-0.0727])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a Yes value of -0.0727 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...... Yes AudioFeature which a shap value of -0.0727 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0727 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.0727 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.07 was used to detect the sample as Audiosignal ......",
      "-0.0727 AudioFeature which a shap value of -0.0727 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of -0.0727 was used to detect the sample as Audiosignal ......",
      "Ye AudioFeature which a shap value of -0.0727 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.0727 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0727 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-28], shap_value[-0.7853])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.78 ......",
      "-0.7853 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......",
      " determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of LFCC-28 ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......",
      "Yes AudioFeature which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7853 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-28 ], <shap_value> shap value: [ -0.7853 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-35], interpreter[shap], shap_value[0.4133])",
    "ref": [
      "Yes person 2 was detected by AudioFeature with a shap value of 0.41 ......",
      "A professional mixer was used ......",
      "Yes person 0.4133 was detected by AudioFeature with a shap value of 0.4133 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.4133 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of shap ......",
      "Yes person 2 was detected by AudioFeature with a 0.4133 value of 0.4133 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ......",
      "Yes person 2 was detected by AudioFeature with a sh value of 0.4133 ......",
      "A professional mixer was used ...... Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.41 ......",
      "Yes person 2 was detected by AudioFeature with a shap value of 0.4133 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4133 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-33], shap_value[-0.7065])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "-0.7065 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-33 ......",
      "The audio is fake ..... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of - ......",
      "The audio is fake .....",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "-0.7065 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-33 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.7065 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <shap_value> shap value: [ -0.7065 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "yes AudioFeature was used to determine speaker id ......",
      "Detection will be difficult ...... Detection will be difficult ......",
      "yes AudioFeature was used to determine speaker id ...... Detection will be difficult ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Detection will be difficult ...... Detection will be difficult ......",
      "yes AudioFeature was used to determine speaker id ...... Detection will be difficult ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Detection will be difficult ...... Detection will be difficult ......",
      "yes AudioFeature was used to determine speaker id ...... Detection will be difficult ......",
      "yes AudioFeature was used to determine speaker id ......",
      "Detection will be difficult ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(speaker_id[5])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 5 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "person 5 spoke the audio sample ...... person 5 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 5 spoke the audio sample ......",
      "person  spoke the audio sample ......",
      "person 5 spoke the audio sample ...... person 5 spoke the audio sample ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...... person 5 spoke the audio sample ......",
      "person 5 spoke the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[3])",
    "ref": [
      "Dynamic microphones were used the most ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "Dynamic microphones were used the most ......",
      "Dynamic microphones were used the most ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...... The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ......",
      "Dynamic microphones were used the most ......",
      "The audio sample had Entity and AudioFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ......"
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-26], interpreter[shap], shap_value[0.7394])",
    "ref": [
      "The mel in the name describes the perceived pitch. Yes person 4 was detected by AudioFeature with a shap value of 0.7394 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7394 ...... Yes person 4 was detected by AudioFeature with a shap value of 0.7394 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.739 ......",
      "Yes person 4 was detected by AudioFeature with a sh value of 0.7394 ......",
      "The mel in the name describes the perceived pitch.",
      "Yes person 4 was detected by AudioFeature with a 4 value of 0.7394 ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.739 ......",
      "Yes person yes was detected by AudioFeature with a shap value of 0.739yes ......",
      "The mel in the name describes the perceived pitch. Yes person 4 was detected by AudioFeature with a shap value of 0.7394 ......",
      "Yes person 4 was detected by AudioFeature with a shap value of 0.7394 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7394 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-34], shap_value[-0.2356])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2 ......",
      "-0.2356 determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ......",
      "There is evidence of sampling ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ......",
      "There is evidence of sampling ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "sha determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of -0.2356 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-34 ], <shap_value> shap value: [ -0.2356 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-6], shap_value[0.7385])",
    "ref": [
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "MFCC-6 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of MFCC-6 ......",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ......",
      "MFCC-6 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7385 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <shap_value> shap value: [ 0.7385 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-53], classification[replayed], shap_value[0.9557], detected_by[CNN])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...... Yes AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a 0.9557 value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "LFCC-53 AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ......",
      "Yes AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by Yes ......",
      "Y AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by C ......",
      "the audio sample had Entity features extracted and AudioFeature was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...... Yes AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ......",
      "Yes AudioFeature which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9557 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-1], classification[bonafide], shap_value[-0.8637])",
    "ref": [
      "MSRCC-1 AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a bonafide value of -0.8637 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of MSRCC-1 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a s value of -0.8637 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0. was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ......",
      "MSRCC-1 AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.8637 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8637 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-55], interpreter[shap], shap_value[-0.3326])",
    "ref": [
      "Yes person 5 was detected by AudioFeature with a -0.3326 value of -0.3326 ......",
      "A professional mixer was used ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of 5 ......",
      "Yes person  was detected by AudioFeature with a shap value of -0.3326 ......",
      "A professional mixer was used ......",
      "Yes person 5 was detected by AudioFeature with a  value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ...... Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3 ......",
      "Yes person -0.3326 was detected by AudioFeature with a shap value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a -0.3326 value of -0.3326 ......",
      "Yes person 5 was detected by AudioFeature with a shap value of -0.3326 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-55 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3326 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-12], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sha value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0 was used to detect the sample as Audiosignal ......",
      "Y AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of  was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ......",
      "shap AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of -0.0018 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-16], interpreter[shap], shap_value[0.0302])",
    "ref": [
      "Yes person 3 was detected by AudioFeature with a shap value of 0.03 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of yes ......",
      "Yes person 3 was detected by AudioFeature with a  value of 0.0302 ......",
      "Yes person MFCC-16 was detected by AudioFeature with a shap value of 0.0MFCC-1602 ......",
      "The audio shows signs of Audio_signal involvement ......",
      "Yes person  was detected by AudioFeature with a shap value of 0.002 ......",
      "The audio shows signs of Audio_signal involvement ...... Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ...... Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ......",
      "Yes person 3 was detected by AudioFeature with a MFCC-16 value of 0.0302 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.03 ......",
      "Yes person 3 was detected by AudioFeature with a shap value of 0.0302 ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0302 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[2])",
    "ref": [
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ...... Two different speeds were detected ......",
      "Two different 2s were detected ......",
      "Two different speeds were detected ...... Two different speeds were detected ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Two different spees were detected ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ...... Two different speeds were detected ......",
      "Two different 2s were detected ......",
      "Two different speeds were detected ...... Two different speeds were detected ......",
      "Yes AudioFeature which a shap value of -0.7878 was used to detect the sample as Audiosignal ......",
      "Two different spees were detected ......",
      "Two different speeds were detected ......"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-28], interpreter[shap], shap_value[-0.5786])",
    "ref": [
      "Yes AudioFeature which a MFCC-28 value of -0.5786 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a sh value of -0.5786 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ...... Yes AudioFeature which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.586 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a shap value of - was used to detect the id of speaker 7 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ......",
      "Yes AudioFeature which a shap value of -0.5MFCC-2886 was used to detect the id of speaker MFCC-28 for the audio sample ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.7203 ...... Yes AudioFeature which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a MFCC-28 value of -0.5786 was used to detect the id of speaker 7 for the audio sample ......",
      "Yes AudioFeature which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5786 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-19], classification[bonafide], shap_value[0.4159])",
    "ref": [
      "Yes AudioFeature which a shap value of 0.4 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of shap was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ...... Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a Yes value of 0.4159 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a sh value of 0.4159 was used to detect the sample as Audiosignal ......",
      "0.4159 AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      " AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...... Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ......",
      "Yes AudioFeature which a shap value of 0.4 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.4159 was used to detect the sample as Audiosignal ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4159 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-12], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of shap was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of  was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a 5 value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "That CaptureDevice was used for 5 seconds ......",
      "That CaptureDevice was used for 5 seconds ...... Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker  for the audio sample ......",
      "Yes AudioFeature which a s value of 0 was used to detect the id of speaker 5 for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker shap for the audio sample ......",
      "Yes AudioFeature which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ......"
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-58], shap_value[0.1639])",
    "ref": [
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-58 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0. ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ......",
      "Yes AudioFeature which a shap value of 0.2774 was used to detect the sample as Audiosignal ...... shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of shap ......",
      "LFCC-58 determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "s determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......",
      "shap determined that the AudioFeature feature was one of the more important features by assigning it a value of 0.1639 ......"
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-58 ], <shap_value> shap value: [ 0.1639 ]> )"
  }
]