[
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "No other features detected a CaptureDevice signal ... The audio is not Audio_signal was detected by CNN?",
      "No other features detected a CaptureDevice signal ...",
      "The audio is not Audio_signal was detected by CNN? The audio is not Audio_signal was detected by CNN?",
      "The audio is not Audio_signal was detected by ?",
      "The audio is Audio_signal was detected by CNN?",
      "The audio is not Audio_signal was detected by none?",
      "No other features detected a CaptureDevice signal ... The audio is not Audio_signal was detected by CNN?",
      "No other features detected a CaptureDevice signal ...",
      "The audio is not Audio_signal was detected by CNN? The audio is not Audio_signal was detected by CNN?",
      "The audio is not Audio_signal was detected by ?",
      "The audio is not Audio_signal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-39], shap_value[0.6906])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ...",
      "Several features were used ...",
      "Several features were used ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ...",
      "0.6906 determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.690 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ...",
      "Several features were used ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6906 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <shap_value> shap value: [ 0.6906 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[PSRCC-1], interpreter[shap], shap_value[0.6359])",
    "ref": [
      "The audio sample was Audio_signal was detected by CNN ... Yes person 7 was detected by PSRCC with a shap value of 0.6359 ...",
      "The audio sample was Audio_signal was detected by CNN ...",
      "Yes person 7 was detected by PSRCC with a shap value of 0.6359 ... Yes person 7 was detected by PSRCC with a shap value of 0.6359 ...",
      "Yes person shap was detected by PSRCC with a shap value of 0.6359 ...",
      "Yes person  was detected by PSRCC with a shap value of 0.6359 ...",
      "Yes person 7 was detected by PSRCC with a 7 value of 0.6359 ...",
      "Yes person 7 was detected by PSRCC with a sh value of 0.6359 ...",
      "Yes person 7 was detected by PSRCC with a shap value of shap ...",
      "Yes person 7 was detected by PSRCC with a shap value of 0. ...",
      "The audio sample was Audio_signal was detected by CNN ... Yes person 7 was detected by PSRCC with a shap value of 0.6359 ...",
      "Yes person 7 was detected by PSRCC with a shap value of 0.6359 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ PSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6359 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-18], classification[replayed], shap_value[-0.607], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by LFCC-18 ...",
      "It was altered using software ... Yes LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "It was altered using software ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a CNN value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.607 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-18 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.607 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[1])",
    "ref": [
      "person 1 spoke the audio sample ... person 1 spoke the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... person 1 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 1 spoke the audio sample ... person 1 spoke the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... person 1 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 1 spoke the audio sample ... person 1 spoke the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "person 1 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-56], classification[replayed], shap_value[0.256], detected_by[CNN])",
    "ref": [
      " LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "person 2 spoke the audio sample ... Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a CNN value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "person 2 spoke the audio sample ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-56 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.256 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-8], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0807 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0807 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0807 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0807 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-53], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-53 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-0], classification[bonafide], shap_value[0.2774])",
    "ref": [
      " LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2774 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It seems like a compu was used ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "It seems like a spoof was used ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... It seems like a computer was used ...",
      "It seems like a computer was used ... It seems like a computer was used ...",
      "It seems like a compu was used ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "It seems like a spoof was used ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... It seems like a computer was used ...",
      "It seems like a computer was used ... It seems like a computer was used ...",
      "It seems like a computer was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-29], classification[replayed], shap_value[0.9762], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a sh value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-29 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9762 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-7], classification[replayed], shap_value[-0.1884], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a CNN value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a  value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1884 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-2], determined[speaker_id])",
    "ref": [
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ...",
      " GTCC was used to determine speaker id ...",
      "GTCC-2 GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ...",
      " GTCC was used to determine speaker id ...",
      "GTCC-2 GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-2 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-54], interpreter[shap], shap_value[0.7811])",
    "ref": [
      "There is an unusually long pause at 37 seconds ... Yes person 6 was detected by LFCC with a shap value of 0.7811 ...",
      "Yes person shap was detected by LFCC with a shap value of 0.7811 ...",
      "Yes person  was detected by LFCC with a shap value of 0.7811 ...",
      "Yes person 6 was detected by LFCC with a shap value of 6 ...",
      "Yes person 6 was detected by LFCC with a s value of 0.7811 ...",
      "Yes person 6 was detected by LFCC with a 0.7811 value of 0.7811 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.7811 ... Yes person 6 was detected by LFCC with a shap value of 0.7811 ...",
      "Yes person 6 was detected by LFCC with a shap value of  ...",
      "There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at 37 seconds ... Yes person 6 was detected by LFCC with a shap value of 0.7811 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.7811 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-54 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7811 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[digital])",
    "ref": [
      "The recording device was d ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "The recording device was spoof ..",
      "The recording device was digital .. The recording device was digital ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... The recording device was digital ..",
      "The recording device was d ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "The recording device was spoof ..",
      "The recording device was digital .. The recording device was digital ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... The recording device was digital ..",
      "The recording device was digital .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ digital ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-8], shap_value[0])",
    "ref": [
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "sh determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-8 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[PSRCC-12], interpreter[shap], shap_value[0.9752])",
    "ref": [
      "There are three distinct CaptureDevice signatures ...",
      "Yes PSRCC which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a 0.9752 value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "There are three distinct CaptureDevice signatures ... Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9PSRCC-1252 was used to detect the id of speaker PSRCC-12 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.952 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ... Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a sh value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9 was used to detect the id of speaker 7 for the audio sample ...",
      "There are three distinct CaptureDevice signatures ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ PSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9752 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-12], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-3], shap_value[-0.0079])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-3 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of  ...",
      "-0.0079 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "sha determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-3 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of  ...",
      "-0.0079 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "sha determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-3 ], <shap_value> shap value: [ -0.0079 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-39], interpreter[shap], shap_value[0.7222])",
    "ref": [
      "Yes person shap was detected by MFCC with a shap value of 0.7222 ...",
      "Yes person 1 was detected by MFCC with a 0.7222 value of 0.7222 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0 ...",
      "Yes person 1 was detected by MFCC with a shap value of MFCC-39 ...",
      "Two different speeds were detected ... Yes person 1 was detected by MFCC with a shap value of 0.7222 ...",
      "Yes person 1 was detected by MFCC with a s value of 0.7222 ...",
      "Yes person  was detected by MFCC with a shap value of 0.7222 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.7222 ... Yes person 1 was detected by MFCC with a shap value of 0.7222 ...",
      "Two different speeds were detected ...",
      "Yes person shap was detected by MFCC with a shap value of 0.7222 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.7222 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7222 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-35], interpreter[shap], shap_value[0.3982])",
    "ref": [
      "Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.398 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.398LFCC-35 was used to detect the id of speaker LFCC-35 for the audio sample ...",
      "Yes LFCC which a  value of 0.3982 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-35 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a 2 value of 0.3982 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3982 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3982 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ... The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being spoof by a MixtureModel Abstract ...",
      "The audio file was classified as being synth by a MixtureModel Abstract ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ... The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being spoof by a MixtureModel Abstract ...",
      "The audio file was classified as being synth by a MixtureModel Abstract ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[additive_noise])",
    "ref": [
      ". Artificial background noise was added to the recording ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... Yes. shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... Artificial background noise was added to the recording ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ...",
      "Yes. Yes. Yes. Artificial background noise was added to the recording ...",
      "Artificial background noise was added to the recording ...",
      "Yes.",
      "Yes. shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... Artificial background noise was added to the recording ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0079 ... Artificial background noise was added to the recording ...",
      "Yes. Yes. Artificial background noise was added to the recording ...",
      "additive_noise. Artificial background noise was added to the recording ...",
      "Yes. Artificial background noise was added to the recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ additive_noise ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ... Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "spoofed this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "Yes this is a PhysicalAccess was detected by spoofed and re-recorded sample ...",
      "Yes this is a PhysicalAccess was detected by C and re-recorded sample ...",
      " this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ... Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "spoofed this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "Yes this is a PhysicalAccess was detected by spoofed and re-recorded sample ...",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[mixer])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ... A professional mixer was used ...",
      "A professional spoof was used ...",
      "A professional m was used ...",
      "A professional mixer was used ... A professional mixer was used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ... A professional mixer was used ...",
      "A professional spoof was used ...",
      "A professional m was used ...",
      "A professional mixer was used ... A professional mixer was used ...",
      "A professional mixer was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ mixer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-10], interpreter[shap], shap_value[0])",
    "ref": [
      "No the entire recording was made using multiple microphones .. Yes person 3 was detected by GTCC with a shap value of 0 ...",
      "No the entire recording was made using multiple microphones ..",
      "Yes person 3 was detected by GTCC with a shap value of  ...",
      "Yes person shap was detected by GTCC with a shap value of 0 ...",
      "Yes person 3 was detected by GTCC with a shap value of GTCC-10 ...",
      "Yes person 3 was detected by GTCC with a s value of 0 ...",
      "Yes person 3 was detected by GTCC with a 3 value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 3 was detected by GTCC with a shap value of 0 ... Yes person 3 was detected by GTCC with a shap value of 0 ...",
      "No the entire recording was made using multiple microphones .. Yes person 3 was detected by GTCC with a shap value of 0 ...",
      "Yes person 3 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-25], shap_value[-0.7432])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "LFCC-25 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ...",
      "Yes MSRCC which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ...",
      "Yes MSRCC which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "LFCC-25 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7432 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <shap_value> shap value: [ -0.7432 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-18], classification[replayed], shap_value[0.2232], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by MFCC-18 ...",
      "MFCC-18 MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a shap value of 0.2 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.7811 ... Yes MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.7811 ...",
      " MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2232 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-18 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2232 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-15], interpreter[shap], shap_value[0.3767])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ... Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Yes person 0.3767 was detected by LFCC with a shap value of 0.3767 ...",
      "Yes person 1 was detected by LFCC with a 0.3767 value of 0.3767 ...",
      "Yes person  was detected by LFCC with a shap value of 0.3767 ...",
      "Yes GTCC which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 1 was detected by LFCC with a shap value of yes ...",
      "Yes GTCC which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ... Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Yes person 1 was detected by LFCC with a sha value of 0.3767 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ... Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3767 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-48], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-48 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[replayed])",
    "ref": [
      "Yes part of the recording was played back ... Yes part of the recording was played back ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes part of the recording was played back ...",
      "Yes part of the recording was played back ... Yes part of the recording was played back ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes part of the recording was played back ...",
      "Yes part of the recording was played back ... Yes part of the recording was played back ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes part of the recording was played back ...",
      "Yes part of the recording was played back ... Yes part of the recording was played back ...",
      "Yes part of the recording was played back ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ... There was more than one CaptureDevice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ... There was more than one CaptureDevice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ... There was more than one CaptureDevice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-5], shap_value[-0.6687])",
    "ref": [
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "-0.6687 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "s determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0. ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "-0.6687 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-5 ], <shap_value> shap value: [ -0.6687 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-24], classification[bonafide], shap_value[-0.9231])",
    "ref": [
      "yes MFCC was used to determine speaker id ... Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of -0.9231 was used to detect the sample as Audio_signal ...",
      "yes MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.9231 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "yes MFCC was used to determine speaker id ... Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9231 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-20], shap_value[0.3878])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-20 ...",
      "0.3878 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3878 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-20 ], <shap_value> shap value: [ 0.3878 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "The average perception gets higher in this section",
      "The average perception gets higher in this section Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "The average perception gets higher in this section",
      "The average perception gets higher in this section Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "The average perception gets higher in this section",
      "The average perception gets higher in this section Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-50], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-50 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-45], interpreter[shap], shap_value[0.8788])",
    "ref": [
      "Yes person yes was detected by LFCC with a shap value of 0.8788 ...",
      "Yes person 2 was detected by LFCC with a 2 value of 0.8788 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.8 ...",
      "Yes person 2 was detected by LFCC with a s value of 0.8788 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ... Yes person 2 was detected by LFCC with a shap value of 0.8788 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "Yes person  was detected by LFCC with a shap value of 0.8788 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.8788 ... Yes person 2 was detected by LFCC with a shap value of 0.8788 ...",
      "Yes person 2 was detected by LFCC with a shap value of 2 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.8788 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.8788 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-45 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8788 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ... The audio is fake ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "The audio is fake .. The audio is fake ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ... The audio is fake ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "The audio is fake .. The audio is fake ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ... The audio is fake ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "The audio is fake .. The audio is fake ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ... The audio is fake ..",
      "The audio is fake .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[bonafide])",
    "ref": [
      "Yes person 2 was detected by GTCC with a shap value of 1 ... Yes the recording was found to be bonafide...",
      "bonafide the recording was found to be bonafide...",
      "Yes the recording was found to be bonafide... Yes the recording was found to be bonafide...",
      " the recording was found to be bonafide...",
      "Yes person 2 was detected by GTCC with a shap value of 1 ...",
      "Yes the recording was found to be bonafid...",
      "Yes the recording was found to be Yes...",
      "Yes person 2 was detected by GTCC with a shap value of 1 ... Yes the recording was found to be bonafide...",
      "bonafide the recording was found to be bonafide...",
      "Yes the recording was found to be bonafide... Yes the recording was found to be bonafide...",
      "Yes the recording was found to be bonafide..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[phone])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Most of the recording was not made with a mobile phone ...",
      "Most of the recording was made with a mobile phone ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Most of the recording was not made with a mobile spoof ...",
      "Most of the recording was not made with a mobile pho ...",
      "Most of the recording was not made with a mobile phone ... Most of the recording was not made with a mobile phone ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Most of the recording was not made with a mobile phone ...",
      "Most of the recording was made with a mobile phone ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Most of the recording was not made with a mobile spoof ...",
      "Most of the recording was not made with a mobile phone ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ phone ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-3], determined[speaker_id])",
    "ref": [
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... yes MFCC was used to determine speaker id ...",
      " MFCC was used to determine speaker id ...",
      "MFCC-3 MFCC was used to determine speaker id ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... yes MFCC was used to determine speaker id ...",
      " MFCC was used to determine speaker id ...",
      "MFCC-3 MFCC was used to determine speaker id ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-3 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-57], classification[replayed], shap_value[-0.3017], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a CNN value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-57 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3017 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-1], interpreter[shap], shap_value[0.4636])",
    "ref": [
      "Yes person 5 was detected by MFCC with a shap value of  ...",
      "Yes person 5 was detected by MFCC with a sh value of 0.4636 ...",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ... Yes person 5 was detected by MFCC with a shap value of 0.4636 ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.4636 ... Yes person 5 was detected by MFCC with a shap value of 0.4636 ...",
      "Yes person  was detected by MFCC with a shap value of 0.4636 ...",
      "Yes person 5 was detected by MFCC with a 0.4636 value of 0.4636 ...",
      "Yes person 5 was detected by MFCC with a shap value of shap ...",
      "Yes this is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "Yes person 0.4636 was detected by MFCC with a shap value of 0.4636 ...",
      "Yes person 5 was detected by MFCC with a shap value of  ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.4636 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4636 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-36], shap_value[0.3678])",
    "ref": [
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ...",
      "MFCC-36 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-36 ], <shap_value> shap value: [ 0.3678 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-11], shap_value[0.8242])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-11 ...",
      "sha determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "PSRCC-11 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.82 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-11 ...",
      "sha determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <shap_value> shap value: [ 0.8242 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-5], interpreter[shap], shap_value[-0.3035])",
    "ref": [
      "Yes person shap was detected by PSRCC with a shap value of -0.3035 ...",
      "Yes person  was detected by PSRCC with a shap value of -0.3035 ...",
      "Yes person 6 was detected by PSRCC with a shap value of PSRCC-5 ...",
      "yes MFCC was used to determine speaker id ...",
      "Yes person 6 was detected by PSRCC with a yes value of -0.3035 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.3035 ... Yes person 6 was detected by PSRCC with a shap value of -0.3035 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0. ...",
      "Yes person 6 was detected by PSRCC with a s value of -0.3035 ...",
      "yes MFCC was used to determine speaker id ... Yes person 6 was detected by PSRCC with a shap value of -0.3035 ...",
      "Yes person shap was detected by PSRCC with a shap value of -0.3035 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.3035 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3035 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[4])",
    "ref": [
      "person  spoke the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... person 4 spoke the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "person 4 spoke the audio sample ... person 4 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... person 4 spoke the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "person 4 spoke the audio sample ... person 4 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... person 4 spoke the audio sample ...",
      "person 4 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[1])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 1 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(speaker_id[5])",
    "ref": [
      " was found to be the id of the speaker in the sample ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ...",
      "5 was found to be the id of the speaker in the sample ... 5 was found to be the id of the speaker in the sample ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ... 5 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ...",
      "5 was found to be the id of the speaker in the sample ... 5 was found to be the id of the speaker in the sample ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ... 5 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ...",
      "5 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-7], interpreter[shap], shap_value[-0.6095])",
    "ref": [
      "Yes LFCC which a -0.6095 value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a sha value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-7 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a -0.6095 value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a sha value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6095 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-8], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a  value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is a EnvironmentSignature signature ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes GTCC which a GTCC-8 value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are inconsistencies in the background noise which indicate the room changed ... There are inconsistencies in the background noise which indicate the room changed ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ... There are inconsistencies in the background noise which indicate the room changed ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are inconsistencies in the background noise which indicate the room changed ... There are inconsistencies in the background noise which indicate the room changed ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ... There are inconsistencies in the background noise which indicate the room changed ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are inconsistencies in the background noise which indicate the room changed ... There are inconsistencies in the background noise which indicate the room changed ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ... There are inconsistencies in the background noise which indicate the room changed ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are inconsistencies in the background noise which indicate the room changed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-3], classification[replayed], shap_value[-0.2809], detected_by[CNN])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of 0.2651 ... Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by C ...",
      "replayed MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a  value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.2651 ...",
      "Yes MFCC which a MFCC-3 value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2809 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-15], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-15 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-15 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-15 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-15 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-23], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-23 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-28], interpreter[shap], shap_value[0.3137])",
    "ref": [
      "Yes person  was detected by LFCC with a shap value of 0.337 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.9355 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3137 ... Yes person 1 was detected by LFCC with a shap value of 0.3137 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.313 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.9355 ... Yes person 1 was detected by LFCC with a shap value of 0.3137 ...",
      "Yes person shap was detected by LFCC with a shap value of 0.3shap37 ...",
      "Yes person 1 was detected by LFCC with a  value of 0.3137 ...",
      "Yes person 1 was detected by LFCC with a 1 value of 0.3137 ...",
      "Yes person 1 was detected by LFCC with a shap value of 1 ...",
      "Yes person  was detected by LFCC with a shap value of 0.337 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3137 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3137 ]> )"
  },
  {
    "mr": "inform(classification[spoof] , edit_type[multi_microphone], signal_start[10])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at  seconds ...",
      "The next CaptureDevice starts at spoof seconds ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at  seconds ...",
      "The next CaptureDevice starts at spoof seconds ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at 10 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <, edit_type> , edit type: [ multi_microphone ], <signal_start> signal start: [ 10 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-3], shap_value[0.8689])",
    "ref": [
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8 ...",
      "MFCC-3 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-3 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8 ...",
      "MFCC-3 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-3 ], <shap_value> shap value: [ 0.8689 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of -0.0673 ... No other features were used ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0673 ...",
      "No other fes were used ...",
      "No other bonafides were used ...",
      "No other features were used ... No other features were used ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0673 ... No other features were used ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0673 ...",
      "No other fes were used ...",
      "No other bonafides were used ...",
      "No other features were used ... No other features were used ...",
      "No other features were used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-37], shap_value[0.9166])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "MFCC-37 determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <shap_value> shap value: [ 0.9166 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-20], interpreter[shap], shap_value[-0.133])",
    "ref": [
      "Yes LFCC which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of -0.133 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.133 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.1 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a -0.133 value of -0.133 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.133 was used to detect the id of speaker -0.133 for the audio sample ...",
      "Yes LFCC which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.133 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.133 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-7], interpreter[shap], shap_value[0.6918])",
    "ref": [
      "Yes person shap was detected by LFCC with a shap value of 0.6918 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6918 ... Yes person 5 was detected by LFCC with a shap value of 0.6918 ...",
      "Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of yes ...",
      "Yes person 5 was detected by LFCC with a yes value of 0.6918 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.691 ...",
      "Yes person 5 was detected by LFCC with a s value of 0.6918 ...",
      "Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ... Yes person 5 was detected by LFCC with a shap value of 0.6918 ...",
      "Yes person  was detected by LFCC with a shap value of 0.6918 ...",
      "Yes person shap was detected by LFCC with a shap value of 0.6918 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6918 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6918 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-17], classification[replayed], shap_value[-0.0283], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ... Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by MFCC-17 ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0283 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being spoof by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being synt by a FeedforwardNeuralNetwork Abstract ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being spoof by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being synt by a FeedforwardNeuralNetwork Abstract ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-1], interpreter[shap], shap_value[0.7525])",
    "ref": [
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ... Yes person 4 was detected by LFCC with a shap value of 0.7525 ...",
      "Yes person 4 was detected by LFCC with a sha value of 0.7525 ...",
      "Yes person 4 was detected by LFCC with a shap value of 0 ...",
      "Yes person 4 was detected by LFCC with a LFCC-1 value of 0.7525 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.7525 ...",
      "Yes person 4 was detected by LFCC with a shap value of yes ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.7525 ... Yes person 4 was detected by LFCC with a shap value of 0.7525 ...",
      "Yes person  was detected by LFCC with a shap value of 0.7525 ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.7525 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7525 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by none audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by  audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by none audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by  audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic], detected_by[CNN])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a CNN audio ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ... The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by  audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a  audio ...",
      "The Audio_signal was detected by spoof audio was a synthetic audio ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a CNN audio ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-46], classification[bonafide], shap_value[-0.8192])",
    "ref": [
      " LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a  value of -0.8192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.81 was used to detect the sample as Audio_signal ...",
      "LFCC-46 LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-46 value of -0.8192 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8192 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8192 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-2], feature[MFCC-6], feature[LFCC-0], feature[MFCC-1])",
    "ref": [
      "Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC LFCC-0 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MF had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC LFCC-0 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MF had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-2 ], <feature> feature: [ MFCC-6 ], <feature> feature: [ LFCC-0 ], <feature> feature: [ MFCC-1 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-12 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-12 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-34], classification[bonafide], shap_value[0.2379])",
    "ref": [
      "Yes MFCC which a sh value of 0.2379 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of 0.2379 was used to detect the sample as Audio_signal ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.8651 ...",
      " MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ...",
      "0.2379 MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.8651 ... Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sh value of 0.2379 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-34 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2379 ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "7 was found to be the id of the speaker in the sample ... 7 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... 7 was found to be the id of the speaker in the sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "7 was found to be the id of the speaker in the sample ... 7 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... 7 was found to be the id of the speaker in the sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "7 was found to be the id of the speaker in the sample ... 7 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "7 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "Mel physicalattribute Cepstral Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal .",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-19], interpreter[shap], shap_value[-0.1453])",
    "ref": [
      "Yes LFCC which a shap value of -0.145 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.145 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ... Yes LFCC which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.145yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a  value of -0.1453 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a 3 value of -0.1453 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.145 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1453 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Other nones also idicate the audio sample is Audio_signal ...",
      "Other featurs also idicate the audio sample is Audio_signal ...",
      "Other features also idicate the audio sample is Audio_signal ... Other features also idicate the audio sample is Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ... Other features also idicate the audio sample is Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Other nones also idicate the audio sample is Audio_signal ...",
      "Other featurs also idicate the audio sample is Audio_signal ...",
      "Other features also idicate the audio sample is Audio_signal ... Other features also idicate the audio sample is Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ... Other features also idicate the audio sample is Audio_signal ...",
      "Other features also idicate the audio sample is Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], change_at[20])",
    "ref": [
      "Artificial background noise was added to the recording ... Artificial background noise was added to the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... Artificial background noise was added to the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Artificial background noise was added to the recording ... Artificial background noise was added to the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... Artificial background noise was added to the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Artificial background noise was added to the recording ... Artificial background noise was added to the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... Artificial background noise was added to the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Artificial background noise was added to the recording ... Artificial background noise was added to the recording ...",
      "Artificial background noise was added to the recording ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-11], determined[speaker_id])",
    "ref": [
      "MFCC-11 MFCC was used to determine speaker id ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "y MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... yes MFCC was used to determine speaker id ...",
      "MFCC-11 MFCC was used to determine speaker id ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "y MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-11 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-6], shap_value[0])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.6595 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.6595 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is a EnvironmentSignature signature ... There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is a EnvironmentSignature signature ... There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is a EnvironmentSignature signature ... There is a EnvironmentSignature signature ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... There is a EnvironmentSignature signature ...",
      "There is a EnvironmentSignature signature ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], sample_start[20])",
    "ref": [
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "The cut is at the 2 second mark ..",
      "The cut is at the sampling second mark ..",
      "The cut is at the 20 second mark .. The cut is at the 20 second mark ..",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ... The cut is at the 20 second mark ..",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "The cut is at the 2 second mark ..",
      "The cut is at the sampling second mark ..",
      "The cut is at the 20 second mark .. The cut is at the 20 second mark ..",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ... The cut is at the 20 second mark ..",
      "The cut is at the 20 second mark .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <sample_start> sample start: [ 20 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-7], classification[replayed], shap_value[0.5117], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a s value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There was more than one CaptureDevice ... Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by PSRCC-7 ...",
      "Ye PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.51 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.5117 PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a Yes value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5117 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-1], determined[speaker_id])",
    "ref": [
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... yes MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-1 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-47], shap_value[0.6378])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "0.6378 determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-47 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-47 ], <shap_value> shap value: [ 0.6378 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-10], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a 0 value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a sh value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[bonafide])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ... Yes the recording was made at the same time ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ...",
      " the recording was made at the same time ...",
      "Yes the recording was made at the same time ... Yes the recording was made at the same time ...",
      "bonafide the recording was made at the same time ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ... Yes the recording was made at the same time ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ...",
      " the recording was made at the same time ...",
      "Yes the recording was made at the same time ... Yes the recording was made at the same time ...",
      "bonafide the recording was made at the same time ...",
      "Yes the recording was made at the same time ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-11], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-11 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-11 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-10], classification[replayed], shap_value[-0.0292], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a sha value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes MSRCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.0292 MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MSRCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0292 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], change_at[20])",
    "ref": [
      "yes MFCC was used to determine speaker id ...",
      "The noise changes significantly at the 20 second mark .. The noise changes significantly at the 20 second mark ..",
      "yes MFCC was used to determine speaker id ... The noise changes significantly at the 20 second mark ..",
      "The noise changes significantly at the  second mark ..",
      "The noise changes significantly at the environment second mark ..",
      "yes MFCC was used to determine speaker id ...",
      "The noise changes significantly at the 20 second mark .. The noise changes significantly at the 20 second mark ..",
      "yes MFCC was used to determine speaker id ... The noise changes significantly at the 20 second mark ..",
      "The noise changes significantly at the  second mark ..",
      "The noise changes significantly at the environment second mark ..",
      "The noise changes significantly at the 20 second mark .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-5], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[5])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...",
      "Yes . The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ...",
      "Yes .",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...",
      "Yes . The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ...",
      "Yes .",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 5 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-5], interpreter[shap], shap_value[0])",
    "ref": [
      "person 8 was detected as the primary speaker of the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a sha value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a 1 value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-15], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC-15 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC-15 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-15 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-8], interpreter[shap], shap_value[0.1088])",
    "ref": [
      "Yes.",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a  value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker  for the audio sample ...",
      "Yes. Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a 0.1088 value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 0.1088 for the audio sample ...",
      "Yes.",
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1088 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[dynamic])",
    "ref": [
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ dynamic ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-1], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-19], classification[replayed], shap_value[-0.8568], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a MFCC-19 value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by  ...",
      "yes MFCC was used to determine speaker id ... Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "CNN MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8568 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[PSRCC-8], interpreter[shap], shap_value[-0.7012])",
    "ref": [
      "Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ... Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a  value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of -0. was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.701 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of -0.701PSRCC-8 was used to detect the id of speaker PSRCC-8 for the audio sample ...",
      "Yes PSRCC which a 2 value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of yes was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ... Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ PSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7012 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-26], classification[bonafide], shap_value[-0.4524])",
    "ref": [
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a -0.4524 value of -0.4524 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4524 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4524 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of -0.4524 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.45 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4524 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of -0.4524 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.4524 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4524 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-26 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4524 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-34], classification[bonafide])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a shap value of -0.4226 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.4226 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.4226 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.4226 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-34 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-38], classification[replayed], shap_value[-0.0316], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-38 MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a  value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-38 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0316 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_length[5])",
    "ref": [
      "That CaptureDevice was used for  seconds ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ... That CaptureDevice was used for 5 seconds ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for spoof seconds ...",
      "That CaptureDevice was used for  seconds ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ... That CaptureDevice was used for 5 seconds ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for spoof seconds ...",
      "That CaptureDevice was used for 5 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_length> change length: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-34], classification[bonafide], shap_value[-0.3612])",
    "ref": [
      "bonafide LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ...",
      "It was altered using software ...",
      "Yes LFCC which a LFCC-34 value of -0.3612 was used to detect the sample as Audio_signal ...",
      "It was altered using software ... Yes LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of -0.3612 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3612 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3612 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-4], classification[bonafide], shap_value[0.5129])",
    "ref": [
      "Yes PSRCC which a PSRCC-4 value of 0.5129 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a  value of 0.5129 was used to detect the sample as Audio_signal ...",
      "bonafide PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of PSRCC-4 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      " PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-4 value of 0.5129 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.5129 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5129 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[PSRCC-4], interpreter[shap], shap_value[-0.4072])",
    "ref": [
      "Yes person PSRCC-4 was detected by PSRCC with a shap value of -0.407PSRCC-4 ...",
      "Yes person 2 was detected by PSRCC with a s value of -0.4072 ...",
      "Yes person 2 was detected by PSRCC with a shap value of 2 ...",
      "Yes person  was detected by PSRCC with a shap value of -0.407 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by PSRCC with a shap value of -0.4072 ... Yes person 2 was detected by PSRCC with a shap value of -0.4072 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 2 was detected by PSRCC with a shap value of -0.4072 ...",
      "Yes person 2 was detected by PSRCC with a shap value of -0.4 ...",
      "Yes person 2 was detected by PSRCC with a yes value of -0.4072 ...",
      "Yes person PSRCC-4 was detected by PSRCC with a shap value of -0.407PSRCC-4 ...",
      "Yes person 2 was detected by PSRCC with a shap value of -0.4072 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ PSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4072 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-1], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "shap GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a Yes value of 0 was used to detect the sample as Audio_signal ...",
      " GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sh value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-28], classification[bonafide], shap_value[-0.7878])",
    "ref": [
      "Yes LFCC which a sha value of -0.7878 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "LFCC-28 LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.4636 ...",
      "Yes LFCC which a Yes value of -0.7878 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.4636 ... Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of -0.7878 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-28 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7878 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "yes GTCC was used to determine speaker id ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "yes GTCC was used to determine speaker id ... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed .",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "yes GTCC was used to determine speaker id ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "yes GTCC was used to determine speaker id ... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-5], determined[speaker_id])",
    "ref": [
      "GTCC-5 GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "y GTCC was used to determine speaker id ...",
      "GTCC-5 GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "y GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-5 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-17], interpreter[shap], shap_value[-0.5241])",
    "ref": [
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.5241 value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a sha value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.524LFCC-17 was used to detect the id of speaker LFCC-17 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5241 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5241 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-22], interpreter[shap], shap_value[0.7829])",
    "ref": [
      "Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.7 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a 0.7829 value of 0.7829 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.5117 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of 0.7829 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.7829 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7829 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-6], interpreter[shap], shap_value[0.46])",
    "ref": [
      "Yes LFCC which a shap value of 0.46 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a sh value of 0.46 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-6 was used to detect the id of speaker 3 for the audio sample ...",
      "The cut is at the 20 second mark .. Yes LFCC which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a yes value of 0.46 was used to detect the id of speaker 3 for the audio sample ...",
      "The cut is at the 20 second mark ..",
      "Yes LFCC which a shap value of 0.46 was used to detect the id of speaker 0.46 for the audio sample ...",
      "Yes LFCC which a shap value of 0.46 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.46 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.46 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-7], interpreter[shap], shap_value[0.7878])",
    "ref": [
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a MFCC-7 value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0. was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker MFCC-7 for the audio sample ...",
      "Yes MFCC which a  value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-7 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7878 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-4], interpreter[shap], shap_value[0.2638])",
    "ref": [
      "Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.638 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.0.2638638 was used to detect the id of speaker 0.2638 for the audio sample ...",
      "Yes LFCC which a s value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a 0.2638 value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2638 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-14], interpreter[shap], shap_value[-0.4302])",
    "ref": [
      "Yes person  was detected by MFCC with a shap value of -0.302 ...",
      "Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 4 was detected by MFCC with a shap value of -0.4302 ...",
      "Yes person 4 was detected by MFCC with a yes value of -0.4302 ...",
      "Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by MFCC with a shap value of shap ...",
      "Yes person yes was detected by MFCC with a shap value of -0.yes302 ...",
      "Yes person 4 was detected by MFCC with a sha value of -0.4302 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.4302 ... Yes person 4 was detected by MFCC with a shap value of -0.4302 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0 ...",
      "Yes person  was detected by MFCC with a shap value of -0.302 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.4302 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4302 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-5], shap_value[0.2454])",
    "ref": [
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "sh determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "MSRCC-5 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "sh determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <shap_value> shap value: [ 0.2454 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-40], interpreter[shap], shap_value[0.9729])",
    "ref": [
      "Yes person 5 was detected by MFCC with a shap value of shap ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.9729 ... Yes person 5 was detected by MFCC with a shap value of 0.9729 ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ... Yes person 5 was detected by MFCC with a shap value of 0.9729 ...",
      "Yes person 5 was detected by MFCC with a MFCC-40 value of 0.9729 ...",
      "Yes person 5 was detected by MFCC with a sha value of 0.9729 ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.97 ...",
      "Yes person 0.9729 was detected by MFCC with a shap value of 0.9729 ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person  was detected by MFCC with a shap value of 0.9729 ...",
      "Yes person 5 was detected by MFCC with a shap value of shap ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.9729 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9729 ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[converted], model[CNN])",
    "ref": [
      "The recording file was classified as being conver by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being CNN by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being conver by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being CNN by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being converted by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC-0 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-0 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "person  spoke the audio sample ...",
      "person 7 spoke the audio sample ... person 7 spoke the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ... person 7 spoke the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "person  spoke the audio sample ...",
      "person 7 spoke the audio sample ... person 7 spoke the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ... person 7 spoke the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "person  spoke the audio sample ...",
      "person 7 spoke the audio sample ... person 7 spoke the audio sample ...",
      "person 7 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-7], determined[speaker_id])",
    "ref": [
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ... yes MFCC was used to determine speaker id ...",
      "ye MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ... yes MFCC was used to determine speaker id ...",
      "ye MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-7 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], edit_start[5])",
    "ref": [
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <edit_start> edit start: [ 5 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-13], determined[speaker_id])",
    "ref": [
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . yes GTCC was used to determine speaker id ...",
      "GTCC-13 GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . yes GTCC was used to determine speaker id ...",
      "GTCC-13 GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-13 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-26], classification[replayed], shap_value[0.6994], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a CNN value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The signal is consistent with a cloned voice ... Yes LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The signal is consistent with a cloned voice ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by  ...",
      " LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6994 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-26 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.6994 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-38], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "5 was found to be the id of the speaker in the sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-38 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "5 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "5 was found to be the id of the speaker in the sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-38 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "5 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-38 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-24], interpreter[shap], shap_value[-0.4413])",
    "ref": [
      "Yes person  was detected by LFCC with a shap value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-24 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ... Yes person 5 was detected by LFCC with a shap value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a 5 value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0 ...",
      "Yes person LFCC-24 was detected by LFCC with a shap value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a s value of -0.4413 ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 5 was detected by LFCC with a shap value of -0.4413 ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person  was detected by LFCC with a shap value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4413 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], sample_start[20])",
    "ref": [
      "The audio cuts abruptly at the 2 second mark ...",
      "The audio cuts abruptly at the sampling second mark ...",
      "yes GTCC was used to determine speaker id ... The audio cuts abruptly at the 20 second mark ...",
      "The audio cuts abruptly at the 20 second mark ... The audio cuts abruptly at the 20 second mark ...",
      "yes GTCC was used to determine speaker id ...",
      "The audio cuts abruptly at the 2 second mark ...",
      "The audio cuts abruptly at the sampling second mark ...",
      "yes GTCC was used to determine speaker id ... The audio cuts abruptly at the 20 second mark ...",
      "The audio cuts abruptly at the 20 second mark ... The audio cuts abruptly at the 20 second mark ...",
      "yes GTCC was used to determine speaker id ...",
      "The audio cuts abruptly at the 20 second mark ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <sample_start> sample start: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-2], determined[speaker_id])",
    "ref": [
      "y MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ... yes MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ... yes MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-2 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-5], interpreter[shap], shap_value[0.5221])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 0.5221 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of 0 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a  value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a 0.5221 value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of MSRCC-5 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ... Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker  for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5221 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There is more than one CaptureDevice signature on the recording .. There is more than one CaptureDevice signature on the recording ..",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ... There is more than one CaptureDevice signature on the recording ..",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ...",
      "There is more than one CaptureDevice signature on the recording .. There is more than one CaptureDevice signature on the recording ..",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ... There is more than one CaptureDevice signature on the recording ..",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ...",
      "There is more than one CaptureDevice signature on the recording .. There is more than one CaptureDevice signature on the recording ..",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ... There is more than one CaptureDevice signature on the recording ..",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ...",
      "There is more than one CaptureDevice signature on the recording .. There is more than one CaptureDevice signature on the recording ..",
      "There is more than one CaptureDevice signature on the recording .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoofed], detected_by[CNN])",
    "ref": [
      "The audio sample was Audio_signal was detected by spoofed ...",
      "The audio sample was Audio_signal was detected by  ...",
      "The audio sample was Audio_signal was detected by CNN ... The audio sample was Audio_signal was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was Audio_signal was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio sample was Audio_signal was detected by spoofed ...",
      "The audio sample was Audio_signal was detected by  ...",
      "The audio sample was Audio_signal was detected by CNN ... The audio sample was Audio_signal was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was Audio_signal was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio sample was Audio_signal was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-58], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-58 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-6], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-6 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-6 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], change_at[20])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... There is more feedback at the 40 second mark ...",
      "There is more feedback at the 40 second mark ... There is more feedback at the 40 second mark ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... There is more feedback at the 40 second mark ...",
      "There is more feedback at the 40 second mark ... There is more feedback at the 40 second mark ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... There is more feedback at the 40 second mark ...",
      "There is more feedback at the 40 second mark ... There is more feedback at the 40 second mark ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "There is more feedback at the 40 second mark ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[No])",
    "ref": [
      "No .. No ..",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... No ..",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      " ..",
      "No .. No ..",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... No ..",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      " ..",
      "No .. No ..",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... No ..",
      "No .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-8], shap_value[-0.2841])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-8 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.284 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "-0.2841 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "sh determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-8 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.284 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <shap_value> shap value: [ -0.2841 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature], detected_by[CNN])",
    "ref": [
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-41], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-41 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-41 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-41 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-41 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-54], shap_value[0.2979])",
    "ref": [
      "0.2979 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-54 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "0.2979 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <shap_value> shap value: [ 0.2979 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-2], classification[replayed], shap_value[-0.5591], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by MSRCC-2 ...",
      "Yes MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.7394 ... Yes MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a CNN value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.55 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.7394 ...",
      "-0.5591 MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a s value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MSRCC which a shap value of -0.5591 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5591 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-27], shap_value[0.8773])",
    "ref": [
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "The recording is a little faster between the five and ten second mark ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ...",
      "LFCC-27 determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.87 ...",
      "The recording is a little faster between the five and ten second mark ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "The recording is a little faster between the five and ten second mark ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8773 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-27 ], <shap_value> shap value: [ 0.8773 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It was altered using software ... It was altered using software ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It was altered using spoof ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It was altered using software ...",
      "It was altered using  ...",
      "It was altered using software ... It was altered using software ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It was altered using spoof ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It was altered using software ...",
      "It was altered using  ...",
      "It was altered using software ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-22], classification[bonafide], shap_value[0.285])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ... Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "Y LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ... Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-22 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.285 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-36], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-36 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-36 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-36 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-26], classification[replayed], shap_value[0.737], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      " MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a s value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-26 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.737 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "There were no other spoof types ... There were no other spoof types ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ... There were no other spoof types ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "There were no other spoof types ... There were no other spoof types ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ... There were no other spoof types ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "There were no other spoof types ... There were no other spoof types ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ... There were no other spoof types ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "There were no other spoof types ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-17], shap_value[0.8093])",
    "ref": [
      "Part of the audio was played back ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      "MFCC-17 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-17 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      "Part of the audio was played back ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.809 ...",
      "Part of the audio was played back ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      "MFCC-17 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <shap_value> shap value: [ 0.8093 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by CNN audio was not converted .. The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by none audio was not converted ..",
      "The Audio_signal was detected by CNN audio was converted ..",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ... The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by C audio was not converted ..",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ...",
      "The Audio_signal was detected by CNN audio was not converted .. The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by none audio was not converted ..",
      "The Audio_signal was detected by CNN audio was converted ..",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ... The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by CNN audio was not converted .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-1], classification[bonafide])",
    "ref": [
      "person 2 spoke the audio sample ...",
      "person 2 spoke the audio sample ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "person 2 spoke the audio sample ...",
      "person 2 spoke the audio sample ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[5], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...",
      "The signature is consistent with a digital CaptureDevice ..",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "The signature is consistent with a digital CaptureDevice .. the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...",
      "The signature is consistent with a digital CaptureDevice ..",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "The signature is consistent with a digital CaptureDevice .. the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 5 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-12], shap_value[0])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      " determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "The audio is artificially slowed ...",
      "The audio is artificially slowed ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      " determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-12 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ... Subband Spectral Flux Coefficients ...",
      "Subband Spectral Flux Coefficients ... Subband Spectral Flux Coefficients ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ... Subband Spectral Flux Coefficients ...",
      "Subband Spectral Flux Coefficients ... Subband Spectral Flux Coefficients ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ... Subband Spectral Flux Coefficients ...",
      "Subband Spectral Flux Coefficients ... Subband Spectral Flux Coefficients ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ... Subband Spectral Flux Coefficients ...",
      "Subband Spectral Flux Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-31], classification[replayed], shap_value[-0.0844], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "-0.0844 LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is a EnvironmentSignature signature ... Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "There is a EnvironmentSignature signature ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a replayed value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-31 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0844 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-21], shap_value[0.3974])",
    "ref": [
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ...",
      "person 5 was detected as the primary speaker of the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-21 ...",
      "person 5 was detected as the primary speaker of the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ...",
      "0.3974 determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3974 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <shap_value> shap value: [ 0.3974 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-30], shap_value[0.2255])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-30 ...",
      "MFCC-30 determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.225 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-30 ...",
      "MFCC-30 determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-30 ], <shap_value> shap value: [ 0.2255 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-7], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-9], determined[speaker_id])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "MFCC-9 MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... yes MFCC was used to determine speaker id ...",
      "ye MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "MFCC-9 MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... yes MFCC was used to determine speaker id ...",
      "ye MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-9 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-4], classification[bonafide])",
    "ref": [
      "The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The signal is consistent with a cloned voice ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The signal is consistent with a cloned voice ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The signal is consistent with a cloned voice ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-7], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Voice spoof was used ...",
      "Voice clo was used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Voice cloning was used ...",
      "Voice cloning was used ... Voice cloning was used ...",
      "Voice spoof was used ...",
      "Voice clo was used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Voice cloning was used ...",
      "Voice cloning was used ... Voice cloning was used ...",
      "Voice cloning was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-4], determined[speaker_id])",
    "ref": [
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ... yes GTCC was used to determine speaker id ...",
      "y GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ... yes GTCC was used to determine speaker id ...",
      "y GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-4 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... No other spoof types were detected ...",
      "No other spoof types were detected ... No other spoof types were detected ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... No other spoof types were detected ...",
      "No other spoof types were detected ... No other spoof types were detected ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... No other spoof types were detected ...",
      "No other spoof types were detected ... No other spoof types were detected ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... No other spoof types were detected ...",
      "No other spoof types were detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-2], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes person 1 was detected by GTCC with a 1 value of 1 ...",
      "Yes person 7 was detected by PSRCC with a shap value of 0.6359 ...",
      "Yes person  was detected by GTCC with a shap value of  ...",
      "Yes person 1 was detected by GTCC with a sha value of 1 ...",
      "Yes person yes was detected by GTCC with a shap value of yes ...",
      "Yes person 1 was detected by GTCC with a shap value of 1 ... Yes person 1 was detected by GTCC with a shap value of 1 ...",
      "Yes person 7 was detected by PSRCC with a shap value of 0.6359 ... Yes person 1 was detected by GTCC with a shap value of 1 ...",
      "Yes person shap was detected by GTCC with a shap value of shap ...",
      "Yes person 1 was detected by GTCC with a 1 value of 1 ...",
      "Yes person 7 was detected by PSRCC with a shap value of 0.6359 ...",
      "Yes person 1 was detected by GTCC with a shap value of 1 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[37])",
    "ref": [
      "There is an unusually long pause at 37 seconds ... There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at  seconds ...",
      "yes MFCC was used to determine speaker id ... There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at spoof seconds ...",
      "yes MFCC was used to determine speaker id ...",
      "There is an unusually long pause at 37 seconds ... There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at  seconds ...",
      "yes MFCC was used to determine speaker id ... There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at spoof seconds ...",
      "yes MFCC was used to determine speaker id ...",
      "There is an unusually long pause at 37 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 37 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-52], interpreter[shap], shap_value[-0.7766])",
    "ref": [
      "Yes LFCC which a -0.7766 value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker  for the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker -0.7766 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-52 was used to detect the id of speaker 1 for the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Yes LFCC which a s value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a -0.7766 value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-52 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7766 ]> )"
  },
  {
    "mr": "inform(speaker_id[8])",
    "ref": [
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "8 was found to be the id of the speaker in the sample ... 8 was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... 8 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "8 was found to be the id of the speaker in the sample ... 8 was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... 8 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "8 was found to be the id of the speaker in the sample ... 8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths .",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband .  However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Hence the SCF feature is affected by changes in pitch and harmonic structure ... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Hence the SCF feature is affected by changes in pitch and harmonic structure ... Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . Hence the SCF feature is affected by changes in pitch and harmonic structure ... However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ...",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Hence the SCF feature is affected by changes in pitch and harmonic structure ... Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ...",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Hence the SCF feature is affected by changes in pitch and harmonic structure ... Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . Hence the SCF feature is affected by changes in pitch and harmonic structure ... However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ...",
      "Spectral centroid physicalattribute SCF is the weighted average frequency for a given subband where the weights are the normalized energy of each frequency component in that subband . Since this measure captures the center of gravity of each subband it can detect the approximate location of formants which are manifested as peaks in neighbouring subband . However the center of gravity of a subband is also affected by the harmonic structure and perception frequencies produced by the vocal source particularly for narrow bandwidths . Hence the SCF feature is affected by changes in pitch and harmonic structure ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-37], classification[replayed], shap_value[-0.5104], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a CNN value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-37 MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a sh value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5104 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-40], interpreter[shap], shap_value[-0.6692])",
    "ref": [
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.66 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "Yes LFCC which a sh value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a -0.6692 value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6692 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-9], classification[bonafide], shap_value[-0.9442])",
    "ref": [
      "Yes PSRCC which a Yes value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "shap PSRCC which a shap value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes ... Yes PSRCC which a shap value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Yes ...",
      "Yes PSRCC which a  value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9442 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Y PSRCC which a shap value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a Yes value of -0.9442 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9442 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9442 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-28], interpreter[shap], shap_value[0.9935])",
    "ref": [
      "Yes LFCC which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.993 was used to detect the id of speaker 3 for the audio sample ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ... Yes LFCC which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a sha value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.995 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a yes value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.990.99355 was used to detect the id of speaker 0.9935 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9935 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9935 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-31], interpreter[shap], shap_value[-0.7141])",
    "ref": [
      "Yes LFCC which a s value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a 3 value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.714 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7141 ]> )"
  },
  {
    "mr": "inform(speaker_id[1], model[SVM])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "The audio shows signs of being edited ... The audio shows signs of being edited ...",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Spectral Centroid physicalattribute Coefficients ... The audio shows signs of being edited ...",
      "The audio shows signs of being edited ... The audio shows signs of being edited ...",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Spectral Centroid physicalattribute Coefficients ... The audio shows signs of being edited ...",
      "The audio shows signs of being edited ... The audio shows signs of being edited ...",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Spectral Centroid physicalattribute Coefficients ... The audio shows signs of being edited ...",
      "The audio shows signs of being edited ... The audio shows signs of being edited ...",
      "The audio shows signs of being edited ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-14], classification[bonafide], shap_value[0.0192])",
    "ref": [
      "Yes LFCC which a sh value of 0.0192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-14 value of 0.0192 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.0192 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.0192 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.0192 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.0192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of 0.0192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.01 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.0192 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.0192 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0192 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-15], classification[bonafide], shap_value[-0.1785])",
    "ref": [
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.1785 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-15 value of -0.1785 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-15 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1785 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-3], classification[bonafide], shap_value[-0.2091])",
    "ref": [
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.209 was used to detect the sample as Audio_signal ...",
      "-0.2091 LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.2091 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of -0.2091 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2091 ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "person 4 spoke the audio sample ... person 3 spoke the audio sample ...",
      "person 3 spoke the audio sample ... person 3 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 4 spoke the audio sample ...",
      "person 4 spoke the audio sample ... person 3 spoke the audio sample ...",
      "person 3 spoke the audio sample ... person 3 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 4 spoke the audio sample ...",
      "person 4 spoke the audio sample ... person 3 spoke the audio sample ...",
      "person 3 spoke the audio sample ... person 3 spoke the audio sample ...",
      "person 3 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "The audio signal shows signs of it .. The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "The audio signal shows signs of it .. The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "The audio signal shows signs of it .. The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... The audio signal shows signs of it ..",
      "The audio signal shows signs of it .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-11], classification[bonafide], shap_value[-0.6615])",
    "ref": [
      "Yes MSRCC which a -0.6615 value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of MSRCC-11 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.6615 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.3915 ...",
      " MSRCC which a shap value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "MSRCC-11 MSRCC which a shap value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a s value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.3915 ... Yes MSRCC which a shap value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a -0.6615 value of -0.6615 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.6615 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6615 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-22], classification[replayed], shap_value[0.752], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by LFCC-22 ...",
      "Yes person 1 was detected by GTCC with a shap value of 0 ...",
      "Yes LFCC which a 0.752 value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.752 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-22 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.752 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-31], interpreter[shap], shap_value[-0.0766])",
    "ref": [
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.07 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a sh value of -0.0766 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.0766 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a -0.0766 value of -0.0766 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.0766 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0766 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0766 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[sampling])",
    "ref": [
      "There is evidence of sampling ...",
      "Yes . There is evidence of s ...",
      "sampling . There is evidence of sampling ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes . Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ... There is evidence of sampling ...",
      "Yes . There is evidence of spoof ...",
      "Yes . Yes . There is evidence of sampling ...",
      "Yes .",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ... There is evidence of sampling ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes . Yes . Yes . There is evidence of sampling ...",
      "Yes . There is evidence of sampling ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-49], classification[bonafide], shap_value[-0.9585])",
    "ref": [
      "Ye LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by GTCC with a shap value of 0 ... Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.9585 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.958 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.9585 value of -0.9585 was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by GTCC with a shap value of 0 ...",
      "Ye LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-49 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9585 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-2], interpreter[shap], shap_value[0.8771])",
    "ref": [
      "Yes person  was detected by MSRCC with a shap value of 0.877 ...",
      "Yes person 1 was detected by MSRCC with a sha value of 0.8771 ...",
      "Yes person 1 was detected by MSRCC with a shap value of shap ...",
      "Yes person MSRCC-2 was detected by MSRCC with a shap value of 0.877MSRCC-2 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Yes person 1 was detected by MSRCC with a shap value of 0.8771 ... Yes person 1 was detected by MSRCC with a shap value of 0.8771 ...",
      "Yes person 1 was detected by MSRCC with a shap value of 0 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Yes person 1 was detected by MSRCC with a shap value of 0.8771 ...",
      "Yes person 1 was detected by MSRCC with a 1 value of 0.8771 ...",
      "Yes person  was detected by MSRCC with a shap value of 0.877 ...",
      "Yes person 1 was detected by MSRCC with a shap value of 0.8771 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8771 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-36], classification[replayed], shap_value[-0.7831], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a sh value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of MFCC-36 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "It shows signs of artificially added noise .. Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "shap MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "It shows signs of artificially added noise ..",
      "Yes MFCC which a Yes value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by shap ...",
      " MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-36 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7831 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes the recording shows signs of 3 different editors ...",
      "Yes the recording shows signs of 3 different editors ... Yes the recording shows signs of 3 different editors ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes the recording shows signs of 3 different editors ...",
      "Yes the recording shows signs of 3 different editors ... Yes the recording shows signs of 3 different editors ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes the recording shows signs of 3 different editors ...",
      "Yes the recording shows signs of 3 different editors ... Yes the recording shows signs of 3 different editors ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes the recording shows signs of 3 different editors ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-59], interpreter[shap], shap_value[0.9123])",
    "ref": [
      "Yes LFCC which a LFCC-59 value of 0.9123 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0. was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ... Yes LFCC which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a s value of 0.9123 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9123 was used to detect the id of speaker LFCC-59 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9123 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a LFCC-59 value of 0.9123 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9123 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-59 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9123 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-11], determined[speaker_id])",
    "ref": [
      "Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      " GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      " GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-11 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-20], interpreter[shap], shap_value[0.8416])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ... Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a sh value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-20 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.841yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.841 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a MFCC-20 value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ... Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8416 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-10], classification[bonafide])",
    "ref": [
      "Mel physicalattribute Cepstral Coefficients ...",
      "Mel physicalattribute Cepstral Coefficients ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-10 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Mel physicalattribute Cepstral Coefficients ...",
      "Mel physicalattribute Cepstral Coefficients ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-10 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-15], classification[replayed], shap_value[-0.8137], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by -0.8137 ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.813 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-15 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8137 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-25], classification[bonafide])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-25 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-6], classification[replayed], shap_value[-0.2267], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a sha value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ...",
      "Yes MFCC which a shap value of -0.2 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ... Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.2267 MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a replayed value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2267 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-10], classification[replayed], shap_value[0.8478], detected_by[CNN])",
    "ref": [
      "Y LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.8478 LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes MFCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a CNN value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes MFCC was used to determine speaker id ... Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8478 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[37])",
    "ref": [
      "There is an unusually long pause at 37 seconds ... There is an unusually long pause at 37 seconds ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "There is an unusually long pause at speed seconds ...",
      "There is an unusually long pause at  seconds ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at 37 seconds ... There is an unusually long pause at 37 seconds ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "There is an unusually long pause at speed seconds ...",
      "There is an unusually long pause at  seconds ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at 37 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 37 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-0], feature[MFCC-0], feature[LFCC-2], feature[MFCC-4])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFC had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC SHAP had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFC had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC SHAP had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-0 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-4 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-17], shap_value[0.2636])",
    "ref": [
      "LFCC-17 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-17 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.7222 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.7222 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "LFCC-17 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-17 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <shap_value> shap value: [ 0.2636 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone])",
    "ref": [
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ... No I do not recognize any of the CaptureDevice signatures ...",
      " I do not recognize any of the CaptureDevice signatures ...",
      "No I do recognize any of the CaptureDevice signatures ...",
      "No I do not recognize any of the CaptureDevice signatures ... No I do not recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "multi_microphone I do not recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ... No I do not recognize any of the CaptureDevice signatures ...",
      " I do not recognize any of the CaptureDevice signatures ...",
      "No I do recognize any of the CaptureDevice signatures ...",
      "No I do not recognize any of the CaptureDevice signatures ... No I do not recognize any of the CaptureDevice signatures ...",
      "No I do not recognize any of the CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-9], interpreter[shap], shap_value[-0.8749])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ... Yes person 3 was detected by MFCC with a shap value of -0.8749 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ...",
      "Yes person 3 was detected by MFCC with a sh value of -0.8749 ...",
      "Yes person 3 was detected by MFCC with a yes value of -0.8749 ...",
      "Yes person MFCC-9 was detected by MFCC with a shap value of -0.8749 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8749 ... Yes person 3 was detected by MFCC with a shap value of -0.8749 ...",
      "Yes person  was detected by MFCC with a shap value of -0.8749 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8 ...",
      "Yes person 3 was detected by MFCC with a shap value of yes ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ... Yes person 3 was detected by MFCC with a shap value of -0.8749 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8749 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8749 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-55], classification[replayed], shap_value[0.3192], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a LFCC-55 value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "yes GTCC was used to determine speaker id ... Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a shap value of 0.3192 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3192 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-43], classification[replayed], shap_value[0.4057], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.4057 LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a CNN value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by LFCC-43 ...",
      "Yes LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4057 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4057 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-2], classification[replayed], shap_value[0.3903], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio signal shows signs of it .. Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "LFCC-2 LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes LFCC which a LFCC-2 value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio signal shows signs of it ..",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3903 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-17], interpreter[shap], shap_value[0.2391])",
    "ref": [
      "Yes person 1 was detected by MFCC with a shap value of 0.2391 ... Yes person 1 was detected by MFCC with a shap value of 0.2391 ...",
      "Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 1 was detected by MFCC with a shap value of 0.2391 ...",
      "Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person  was detected by MFCC with a shap value of 0.239 ...",
      "Yes person 1 was detected by MFCC with a sh value of 0.2391 ...",
      "Yes person shap was detected by MFCC with a shap value of 0.239shap ...",
      "Yes person 1 was detected by MFCC with a yes value of 0.2391 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.239 ...",
      "Yes person 1 was detected by MFCC with a shap value of 1 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.2391 ... Yes person 1 was detected by MFCC with a shap value of 0.2391 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.2391 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2391 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MSRCC-9], interpreter[shap], shap_value[-0.007])",
    "ref": [
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a yes value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a s value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a shap value of - was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker -0.007 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.007 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-11], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes GTCC which a 0 value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      " GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "0 GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sh value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7766 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a 0 value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-10], classification[bonafide], shap_value[0.5373])",
    "ref": [
      "0.5373 MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a 0.5373 value of 0.5373 was used to detect the sample as Audio_signal ...",
      "0.5373 MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5373 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-13], interpreter[shap], shap_value[0.1362])",
    "ref": [
      "Yes MFCC which a shap value of 0.136 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a yes value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 0.1362 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a sha value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.136 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1362 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-26], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-26 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[2])",
    "ref": [
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... person 2 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 2 spoke the audio sample ... person 2 spoke the audio sample ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... person 2 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 2 spoke the audio sample ... person 2 spoke the audio sample ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... person 2 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 2 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-9], determined[speaker_id])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... yes GTCC was used to determine speaker id ...",
      "GTCC-9 GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... yes GTCC was used to determine speaker id ...",
      "GTCC-9 GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-9 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-38], interpreter[shap], shap_value[0.5482])",
    "ref": [
      "Yes LFCC which a s value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.548 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5480.5482 was used to detect the id of speaker 0.5482 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.548 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a 2 value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a s value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5482 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-23], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-23 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[pitch])",
    "ref": [
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "The average perception gets higher in this section"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ pitch ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-22], interpreter[shap], shap_value[0.1394])",
    "ref": [
      "Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker shap for the audio sample ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "Yes MFCC which a sh value of 0.1394 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a MFCC-22 value of 0.1394 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0 was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ... Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-22 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a shap value of 0.1394 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1394 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-1], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks that way ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks that way ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks that way ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks that way ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-7], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker GTCC-7 for the audio sample ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a 1 value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a sha value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-31], classification[bonafide], shap_value[-0.5755])",
    "ref": [
      "Yes MFCC which a Yes value of -0.5755 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.5755 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.5755 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-31 MFCC which a shap value of -0.5755 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-31 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5755 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of -0.5755 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of -0.5755 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.5755 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.5755 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5755 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-12], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 5 was detected by GTCC with a shap value of shap ...",
      "No the recording is not Audio_signal was detected by CNN ... Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Yes person 0 was detected by GTCC with a shap value of 0 ...",
      "No the recording is not Audio_signal was detected by CNN ...",
      "Yes person 5 was detected by GTCC with a sh value of 0 ...",
      "Yes person 5 was detected by GTCC with a 5 value of 0 ...",
      "Yes person 5 was detected by GTCC with a shap value of  ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ... Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Yes person 5 was detected by GTCC with a shap value of shap ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "informt(model[CNN], task[classification])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for CNN ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classifi ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for CNN ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ... The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classifi ...",
      "The recording was passed to a FeedforwardNeuralNetwork Abstract for classification ..."
    ],
    "new_mr": "<informt> informt ( <model> model: [ CNN ], <task> task: [ classification ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MSRCC-5], interpreter[shap], shap_value[0.2787])",
    "ref": [
      "Yes person 6 was detected by MSRCC with a s value of 0.2787 ...",
      "Yes person 0.2787 was detected by MSRCC with a shap value of 0.2787 ...",
      "Yes person 6 was detected by MSRCC with a MSRCC-5 value of 0.2787 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 6 was detected by MSRCC with a shap value of 0.2787 ...",
      "Yes person 6 was detected by MSRCC with a shap value of 0.2787 ... Yes person 6 was detected by MSRCC with a shap value of 0.2787 ...",
      "Yes person 6 was detected by MSRCC with a shap value of 0.27 ...",
      "Yes person  was detected by MSRCC with a shap value of 0.2787 ...",
      "Yes person 6 was detected by MSRCC with a shap value of 6 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 6 was detected by MSRCC with a s value of 0.2787 ...",
      "Yes person 6 was detected by MSRCC with a shap value of 0.2787 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2787 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-8], interpreter[shap], shap_value[-0.7314])",
    "ref": [
      "Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a  value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.8651 ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0. was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker yes for the audio sample ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.8651 ... Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a 2 value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7314 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7314 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-51], classification[bonafide], shap_value[0.9936])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.6918 ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.9936 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-51 value of 0.9936 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.9936 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-51 was used to detect the sample as Audio_signal ...",
      "LFCC-51 LFCC which a shap value of 0.9936 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.9936 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.9936 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6918 ... Yes LFCC which a shap value of 0.9936 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6918 ...",
      "Yes LFCC which a shap value of 0.9936 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9936 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-23], classification[replayed], shap_value[-0.3555], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a Yes value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-23 MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by -0.3555 ...",
      "Yes MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a shap value of -0.3555 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3555 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-40], classification[bonafide], shap_value[-0.5765])",
    "ref": [
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.5765 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.5765 was used to detect the sample as Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...",
      "Yes MFCC which a  value of -0.5765 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a -0.5765 value of -0.5765 was used to detect the sample as Audio_signal ...",
      "MFCC-40 MFCC which a shap value of -0.5765 was used to detect the sample as Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ... Yes MFCC which a shap value of -0.5765 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of -0.5765 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.5765 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-40 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5765 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-46], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-46 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-46 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-46 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[bonafide], multi_microphone[no], mic_quantity[1])",
    "ref": [
      "Dynamic microphones were used the most ...",
      "The CaptureDevice signature is consistent throughout the recording .. The CaptureDevice signature is consistent throughout the recording ..",
      "Dynamic microphones were used the most ... The CaptureDevice signature is consistent throughout the recording ..",
      "Dynamic microphones were used the most ...",
      "The CaptureDevice signature is consistent throughout the recording .. The CaptureDevice signature is consistent throughout the recording ..",
      "Dynamic microphones were used the most ... The CaptureDevice signature is consistent throughout the recording ..",
      "Dynamic microphones were used the most ...",
      "The CaptureDevice signature is consistent throughout the recording .. The CaptureDevice signature is consistent throughout the recording ..",
      "Dynamic microphones were used the most ... The CaptureDevice signature is consistent throughout the recording ..",
      "Dynamic microphones were used the most ...",
      "The CaptureDevice signature is consistent throughout the recording .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <multi_microphone> multi microphone: [ no ], <mic_quantity> mic quantity: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-13], classification[bonafide], shap_value[0.3337])",
    "ref": [
      "Ye LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.3337 was used to detect the sample as Audio_signal ...",
      "LFCC-13 LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a LFCC-13 value of 0.3337 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.33 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "There are three distinct CaptureDevice signatures ... Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3337 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-13 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3337 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-5], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a replayed value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes GTCC which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of GTCC-5 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "GTCC-5 GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by -1 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[3])",
    "ref": [
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "There are three distinct CaptureDevice signatures ... There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ... There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "There are three distinct CaptureDevice signatures ... There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ... There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "There are three distinct CaptureDevice signatures ... There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ... There are three distinct CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.1785 was used to detect the sample as Audio_signal ...",
      "There are three distinct CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 3 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-38], classification[bonafide], shap_value[0.8451])",
    "ref": [
      "Yes LFCC which a s value of 0.8451 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.8 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-38 value of 0.8451 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of 0.8451 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.8451 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8451 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-27], classification[bonafide])",
    "ref": [
      "Yes person 3 was detected by LFCC with a shap value of 0.3353 ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-27 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.3353 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.3353 ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-27 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.3353 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-27 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-47], interpreter[shap], shap_value[0.5372])",
    "ref": [
      "Yes person 6 was detected by LFCC with a shap value of -0.2493 ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.2493 ... Yes LFCC which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a 6 value of 0.5372 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a sha value of 0.5372 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5372 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5372 was used to detect the id of speaker LFCC-47 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.2493 ...",
      "Yes LFCC which a shap value of 0.5372 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-47 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5372 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-24], interpreter[shap], shap_value[-0.6368])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ... Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a yes value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a sh value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ... Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6368 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced .. It appears that the recording was spliced ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... It appears that the recording was spliced ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced .. It appears that the recording was spliced ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... It appears that the recording was spliced ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced .. It appears that the recording was spliced ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... It appears that the recording was spliced ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-1], shap_value[1])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "There are different CaptureDevice signatures ...",
      "GTCC-1 determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "There are different CaptureDevice signatures ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-59], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-59 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-40], classification[replayed], shap_value[0.1447], detected_by[CNN])",
    "ref": [
      "0.1447 MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by  ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by 0.1447 ...",
      "Yes MFCC which a sha value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-40 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1447 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-18], shap_value[-0.1509])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "Yes the recording shows signs of being edited ...",
      "MFCC-18 determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "Yes the recording shows signs of being edited ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "Yes the recording shows signs of being edited ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-18 ], <shap_value> shap value: [ -0.1509 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-26], shap_value[-0.1124])",
    "ref": [
      "LFCC-26 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "Yes person 1 was detected by GTCC with a shap value of 0 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.11 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes person 1 was detected by GTCC with a shap value of 0 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "LFCC-26 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "Yes person 1 was detected by GTCC with a shap value of 0 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1124 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-26 ], <shap_value> shap value: [ -0.1124 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-24], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-24 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-24 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-24 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband .  Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances .",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-6], interpreter[shap], shap_value[0.3353])",
    "ref": [
      "Yes person 3 was detected by LFCC with a sh value of 0.3353 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.3353 ... Yes person 3 was detected by LFCC with a shap value of 0.3353 ...",
      "Yes person 3 was detected by LFCC with a yes value of 0.3353 ...",
      "Yes person  was detected by LFCC with a shap value of 0.5 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.yesyes5yes ...",
      "Yes person 3 was detected by LFCC with a shap value of yes ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ... Yes person 3 was detected by LFCC with a shap value of 0.3353 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0 ...",
      "Yes person 3 was detected by LFCC with a sh value of 0.3353 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.3353 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3353 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The Acoustic_Wave patterns show where the speaker is from ... The Acoustic_Wave patterns show where the speaker is from ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ... The Acoustic_Wave patterns show where the speaker is from ...",
      "The Acoustic_Wave patterns show where the speaker is from ... The Acoustic_Wave patterns show where the speaker is from ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ... The Acoustic_Wave patterns show where the speaker is from ...",
      "The Acoustic_Wave patterns show where the speaker is from ... The Acoustic_Wave patterns show where the speaker is from ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ... The Acoustic_Wave patterns show where the speaker is from ...",
      "The Acoustic_Wave patterns show where the speaker is from ... The Acoustic_Wave patterns show where the speaker is from ...",
      "The Acoustic_Wave patterns show where the speaker is from ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MSRCC-8], interpreter[shap], shap_value[-0.5893])",
    "ref": [
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person  was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a sh value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a yes value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of shap ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Yes person shap was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5893 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "It seems like a computer was used ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "It seems like a computer was used ...",
      "It seems like a computer was used ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "It seems like a computer was used ...",
      "It seems like a computer was used ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "It seems like a computer was used ...",
      "It seems like a computer was used ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by CNN audio was converted ..",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "The Audio_signal was detected by CNN audio was not converted .. The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by CN audio was not converted ..",
      "The Audio_signal was detected by bonafide audio was not converted ..",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by CNN audio was converted ..",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "The Audio_signal was detected by CNN audio was not converted .. The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by CNN audio was not converted .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[replayed], model[GMM], detected_by[CNN])",
    "ref": [
      "The recording file was classified as being PhysicalAccess was detected by  by a MixtureModel Abstract ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being PhysicalAccess was detected by spoofed by a MixtureModel Abstract ...",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "The recording file was classified as being PhysicalAccess was detected by  by a MixtureModel Abstract ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being PhysicalAccess was detected by spoofed by a MixtureModel Abstract ...",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <model> model: [ GMM ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[GTCC-13], interpreter[shap], shap_value[-1])",
    "ref": [
      "Yes person 7 was detected by GTCC with a shap value of -1 ... Yes person 7 was detected by GTCC with a shap value of -1 ...",
      "Yes person 7 was detected by GTCC with a shap value of  ...",
      "Yes person 7 was detected by GTCC with a shap value of GTCC-13 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person  was detected by GTCC with a shap value of -1 ...",
      "Yes person 7 was detected by GTCC with a sh value of -1 ...",
      "Yes person yes was detected by GTCC with a shap value of -1 ...",
      "Yes person 7 was detected by GTCC with a 7 value of -1 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 7 was detected by GTCC with a shap value of -1 ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ... Yes person 7 was detected by GTCC with a shap value of -1 ...",
      "Yes person 7 was detected by GTCC with a shap value of -1 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ GTCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-42], classification[bonafide], shap_value[0.5541])",
    "ref": [
      "Yes LFCC which a bonafide value of 0.5541 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.5541 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.5541 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.5541 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1453 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.5541 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of 0.5541 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.5541 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of 0.5541 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.5541 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5541 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-6], interpreter[shap], shap_value[-0.0215])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a -0.0215 value of -0.0215 ...",
      "Yes person PSRCC-6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ... Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Yes person 6 was detected by PSRCC with a shap value of PSRCC-6 ...",
      "Yes person 6 was detected by PSRCC with a shap value of  ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes person 6 was detected by PSRCC with a sh value of -0.0215 ...",
      "Yes person  was detected by PSRCC with a shap value of -0.0215 ...",
      "Yes person 6 was detected by PSRCC with a -0.0215 value of -0.0215 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0215 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-8], classification[bonafide], shap_value[0.8955])",
    "ref": [
      "Y MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a  value of 0.8955 was used to detect the sample as Audio_signal ...",
      "There were 2 microphones ...",
      "Yes MSRCC which a bonafide value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "There were 2 microphones ... Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "bonafide MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Y MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8955 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "The audio is converted ...",
      "The audio is not converted ... The audio is not converted ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ... The audio is not converted ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "The audio is converted ...",
      "The audio is not converted ... The audio is not converted ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ... The audio is not converted ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "The audio is converted ...",
      "The audio is not converted ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-44], interpreter[shap], shap_value[0.1772])",
    "ref": [
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a sh value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a LFCC-44 value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.177 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1772 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-44 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1772 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-3], classification[bonafide], shap_value[-0.0902])",
    "ref": [
      "Yes PSRCC which a s value of -0.0902 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Ye PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ...",
      "shap PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ...",
      "Artificial background noise was added to the recording ...",
      "Yes PSRCC which a -0.0902 value of -0.0902 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of PSRCC-3 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ...",
      "Artificial background noise was added to the recording ... Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a s value of -0.0902 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.0902 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0902 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-29], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-29 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-29 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-29 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section The average perception gets higher in this section",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The average perception gets higher in this section",
      "The average perception gets higher in this section"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[3])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are three distinct CaptureDevice signatures ...",
      "There are three distinct CaptureDevice signatures ... There are three distinct CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are three distinct CaptureDevice signatures ...",
      "There are three distinct CaptureDevice signatures ... There are three distinct CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are three distinct CaptureDevice signatures ...",
      "There are three distinct CaptureDevice signatures ... There are three distinct CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There are three distinct CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 3 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-5], classification[replayed], shap_value[-0.3337], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "5 was found to be the id of the speaker in the sample ... Yes PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "5 was found to be the id of the speaker in the sample ...",
      "Y PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a s value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes PSRCC which a shap value of -0.33 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a PSRCC-5 value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3337 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Artificial background noise was added to the recording ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Artificial background noise was added to the recording ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Artificial background noise was added to the recording ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Artificial background noise was added to the recording ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-29], interpreter[shap], shap_value[-0.143])",
    "ref": [
      "Yes LFCC which a sh value of -0.143 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a 2 value of -0.143 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.143 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.143 was used to detect the id of speaker LFCC-29 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a sh value of -0.143 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.143 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-11], shap_value[0.9009])",
    "ref": [
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "MSRCC-11 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.90 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "MSRCC-11 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-11 ], <shap_value> shap value: [ 0.9009 ]> )"
  },
  {
    "mr": "inform(model[SVM], task[classification])",
    "ref": [
      "The recording was passed to a ClassificationAlgorithm Abstract for classification ... The recording was passed to a ClassificationAlgorithm Abstract for classification ...",
      "The recording was passed to a ClassificationAlgorithm Abstract for SVM ...",
      "The recording was passed to a ClassificationAlgorithm Abstract for clas ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ... The recording was passed to a ClassificationAlgorithm Abstract for classification ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "The recording was passed to a ClassificationAlgorithm Abstract for classification ... The recording was passed to a ClassificationAlgorithm Abstract for classification ...",
      "The recording was passed to a ClassificationAlgorithm Abstract for SVM ...",
      "The recording was passed to a ClassificationAlgorithm Abstract for clas ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ... The recording was passed to a ClassificationAlgorithm Abstract for classification ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "The recording was passed to a ClassificationAlgorithm Abstract for classification ..."
    ],
    "new_mr": "<inform> inform ( <model> model: [ SVM ], <task> task: [ classification ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-52], shap_value[-0.7935])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-52 ...",
      "That CaptureDevice was used for 5 seconds ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "That CaptureDevice was used for 5 seconds ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "-0.7935 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-52 ...",
      "That CaptureDevice was used for 5 seconds ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <shap_value> shap value: [ -0.7935 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-10], classification[replayed], shap_value[-0.6103], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a replayed value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "It is not a bona fide audio ...",
      "It is not a bona fide audio ... Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.6 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes MFCC which a  value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by  ...",
      " MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.6103 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6103 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion])",
    "ref": [
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... It appears the audio sample was converted ..",
      "It appears the audio sample was converted .. It appears the audio sample was converted ..",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... It appears the audio sample was converted ..",
      "It appears the audio sample was converted .. It appears the audio sample was converted ..",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... It appears the audio sample was converted ..",
      "It appears the audio sample was converted .. It appears the audio sample was converted ..",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... It appears the audio sample was converted ..",
      "It appears the audio sample was converted .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-53], shap_value[-0.8942])",
    "ref": [
      "LFCC-53 determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-53 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8 ...",
      "LFCC-53 determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.8942 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <shap_value> shap value: [ -0.8942 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[dynamic])",
    "ref": [
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ dynamic ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-9], shap_value[0.0969])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-9 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      " determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.09 ...",
      "No the recording is not converted ...",
      "0.0969 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "No the recording is not converted ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-9 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      " determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-9 ], <shap_value> shap value: [ 0.0969 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "It seems like a computer was used ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "It seems like a computer was used ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "It seems like a computer was used ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "It seems like a computer was used ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "It seems like a computer was used ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "It seems like a computer was used ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-8], interpreter[shap], shap_value[-0.89])",
    "ref": [
      "Yes person 2 was detected by LFCC with a yes value of -0.89 ...",
      "Yes person 2 was detected by LFCC with a sh value of -0.89 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.89 ... Yes person 2 was detected by LFCC with a shap value of -0.89 ...",
      "Yes person 2 was detected by LFCC with a shap value of LFCC-8 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ... Yes person 2 was detected by LFCC with a shap value of -0.89 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ...",
      "Yes person 2 was detected by LFCC with a shap value of - ...",
      "Yes person -0.89 was detected by LFCC with a shap value of -0.89 ...",
      "Yes person  was detected by LFCC with a shap value of -0.89 ...",
      "Yes person 2 was detected by LFCC with a yes value of -0.89 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.89 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.89 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "Artificial background noise was added to the recording ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Artificial background noise was added to the recording ...",
      "Artificial background noise was added to the recording ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Artificial background noise was added to the recording ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-22], interpreter[shap], shap_value[-0.7096])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of -0. ...",
      "person 2 spoke the audio sample ... Yes person 3 was detected by MFCC with a shap value of -0.7096 ...",
      "Yes person shap was detected by MFCC with a shap value of -0.7096 ...",
      "Yes person 3 was detected by MFCC with a 3 value of -0.7096 ...",
      "Yes person 3 was detected by MFCC with a  value of -0.7096 ...",
      "Yes person 3 was detected by MFCC with a shap value of MFCC-22 ...",
      "person 2 spoke the audio sample ...",
      "Yes person  was detected by MFCC with a shap value of -0.7096 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.7096 ... Yes person 3 was detected by MFCC with a shap value of -0.7096 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0. ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.7096 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7096 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "N the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "CNN the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "No the Audio_signal was detected by C recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by No recording was not a PhysicalAccess recording ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-11], interpreter[shap], shap_value[0.2606])",
    "ref": [
      "Yes MSRCC which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a 0.2606 value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 0.2606 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ... Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a sha value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2487 ... Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2487 ...",
      "Yes MSRCC which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.2606 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2606 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-33], classification[bonafide], shap_value[-0.0018])",
    "ref": [
      "Ye MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of -0.0018 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ...",
      "shap MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of -0.0018 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-33 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.0018 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0018 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-9], shap_value[-0.6735])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-9 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7883 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of - ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7883 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "-0.6735 determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-9 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7883 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <shap_value> shap value: [ -0.6735 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It looks like the audio was edited using software ...",
      "It looks like the audio was edited using software ... It looks like the audio was edited using software ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It looks like the audio was edited using software ...",
      "It looks like the audio was edited using software ... It looks like the audio was edited using software ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It looks like the audio was edited using software ...",
      "It looks like the audio was edited using software ... It looks like the audio was edited using software ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks like the audio was edited using software ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-9], shap_value[-0.1259])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "LFCC-9 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-9 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1259 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <shap_value> shap value: [ -0.1259 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], prupose[identification])",
    "ref": [
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification .. The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification ..",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification ..",
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for MFCC ..",
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for  ..",
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification .. The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification ..",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification ..",
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for MFCC ..",
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for  ..",
      "The audio sample had its CepstralFeature and Cepstrum features extracted which were passed to an ClassificationAlgorithm Abstract for identification .."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <prupose> prupose: [ identification ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-6], interpreter[shap], shap_value[-0.7884])",
    "ref": [
      "Yes PSRCC which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ... Yes PSRCC which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "Yes PSRCC which a shap value of -0.788 was used to detect the id of speaker  for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ... Yes PSRCC which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a sha value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.788yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes PSRCC which a 4 value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ... Yes PSRCC which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.7884 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7884 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-39], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There was more than one person speaking ..",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There was more than one person speaking .. the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There was more than one person speaking ..",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There was more than one person speaking .. the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-39 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      " the entire recording was made using multiple microphones ..",
      "No the entire recording was made using multiple microphones .. No the entire recording was made using multiple microphones ..",
      ">1 the entire recording was made using multiple microphones ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... No the entire recording was made using multiple microphones ..",
      " the entire recording was made using multiple microphones ..",
      "No the entire recording was made using multiple microphones .. No the entire recording was made using multiple microphones ..",
      ">1 the entire recording was made using multiple microphones ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... No the entire recording was made using multiple microphones ..",
      "No the entire recording was made using multiple microphones .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There were 2 microphones ...",
      "There were 2 microphones ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-5 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There were 2 microphones ...",
      "There were 2 microphones ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-5 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-2], classification[bonafide], shap_value[0.7662])",
    "ref": [
      "Yes LFCC which a shap value of 0.76 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a sha value of 0.7662 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.7662 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.7662 was used to detect the sample as Audio_signal ...",
      "0.7662 LFCC which a shap value of 0.7662 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.143 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.7662 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.7662 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-2 value of 0.7662 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.76 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.7662 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7662 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-13], classification[replayed], shap_value[0.2494], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by  ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by 0.2494 ...",
      "Y MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.24 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a replayed value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "0.2494 MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2494 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-26], shap_value[0.3447])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "0.3447 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-26 ], <shap_value> shap value: [ 0.3447 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-39], interpreter[shap], shap_value[-0.3915])",
    "ref": [
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 3 was detected by LFCC with a shap value of -0.3915 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.3 ...",
      "Yes person 3 was detected by LFCC with a shap value of 3 ...",
      "Yes person 3 was detected by LFCC with a sh value of -0.3915 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.3915 ... Yes person 3 was detected by LFCC with a shap value of -0.3915 ...",
      "Yes person  was detected by LFCC with a shap value of -0.915 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.yes915 ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 3 was detected by LFCC with a LFCC-39 value of -0.3915 ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 3 was detected by LFCC with a shap value of -0.3915 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.3915 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3915 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-35], classification[replayed], shap_value[0.8008], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a replayed value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8008 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-35 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8008 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-55], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-55 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1509 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-55 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-55 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-11], interpreter[shap], shap_value[-0.3231])",
    "ref": [
      "Yes LFCC which a shap value of - was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.21 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a yes value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a s value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.shap2shap1 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a shap value of - was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3231 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-9], shap_value[0])",
    "ref": [
      "GTCC-9 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "sha determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "GTCC-9 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-9 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There were 2 microphones ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There were 2 microphones ... There were 2 microphones ...",
      "There were multi_microphone microphones ...",
      "There were  microphones ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There were 2 microphones ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There were 2 microphones ... There were 2 microphones ...",
      "There were multi_microphone microphones ...",
      "There were  microphones ...",
      "There were 2 microphones ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-3], interpreter[shap], shap_value[-0.0673])",
    "ref": [
      "There are no inconsistencies which indicate a Spoofed sample ..",
      "Yes person  was detected by MFCC with a shap value of -0.0673 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0673 ... Yes person 2 was detected by MFCC with a shap value of -0.0673 ...",
      "There are no inconsistencies which indicate a Spoofed sample .. Yes person 2 was detected by MFCC with a shap value of -0.0673 ...",
      "Yes person 2 was detected by MFCC with a MFCC-3 value of -0.0673 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.067 ...",
      "Yes person 2 was detected by MFCC with a s value of -0.0673 ...",
      "Yes person 2 was detected by MFCC with a shap value of 2 ...",
      "Yes person MFCC-3 was detected by MFCC with a shap value of -0.0673 ...",
      "There are no inconsistencies which indicate a Spoofed sample ..",
      "Yes person 2 was detected by MFCC with a shap value of -0.0673 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0673 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-48], interpreter[shap], shap_value[0.957])",
    "ref": [
      "No other features detected a CaptureDevice signal ... Yes LFCC which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.957 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-48 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a yes value of 0.957 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.957 was used to detect the id of speaker LFCC-48 for the audio sample ...",
      "No other features detected a CaptureDevice signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a  value of 0.957 was used to detect the id of speaker 4 for the audio sample ...",
      "No other features detected a CaptureDevice signal ... Yes LFCC which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.957 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-48 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.957 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-37], shap_value[0.4431])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-37 ...",
      "The cut takes place at the 20 second mark .. shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ...",
      "0.4431 determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ...",
      "The cut takes place at the 20 second mark ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-37 ...",
      "The cut takes place at the 20 second mark .. shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4431 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-37 ], <shap_value> shap value: [ 0.4431 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], mic_type[mobile_phone], mic_type[computer])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "computer some of the recording was made with a mobile device and some with a computer ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ... Yes some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a comp ..",
      "Ye some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a computer .. Yes some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a Yes ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "computer some of the recording was made with a mobile device and some with a computer ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ... Yes some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a computer .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ], <mic_type> mic type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was passed to a modeltype Abstract for classification ...",
      "The audio sample was passed to a modeltype Abstract for classification ... The audio sample was passed to a modeltype Abstract for classification ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was passed to a modeltype Abstract for classification ...",
      "The audio sample was passed to a modeltype Abstract for classification ... The audio sample was passed to a modeltype Abstract for classification ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was passed to a modeltype Abstract for classification ...",
      "The audio sample was passed to a modeltype Abstract for classification ... The audio sample was passed to a modeltype Abstract for classification ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1884 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was passed to a modeltype Abstract for classification ...",
      "The audio sample was passed to a modeltype Abstract for classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-37], interpreter[shap], shap_value[0.1008])",
    "ref": [
      "Yes person 6 was detected by LFCC with a shap value of LFCC-37 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.1008 ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ...",
      "Yes person 6 was detected by LFCC with a 0.1008 value of 0.1008 ...",
      "Yes person 0.1008 was detected by LFCC with a shap value of 0.1008 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.100 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person  was detected by LFCC with a shap value of 0.1008 ...",
      "Yes person 6 was detected by LFCC with a  value of 0.1008 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ...",
      "Yes person 6 was detected by LFCC with a shap value of LFCC-37 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.1008 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1008 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-1], classification[replayed], shap_value[-0.5782], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes PSRCC which a sh value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a replayed value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5782 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[4])",
    "ref": [
      "The Audio_signal was detected by CNN audio was not converted ..",
      "person 4 was detected as the primary speaker of the audio sample ... person 4 was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was not converted .. person 4 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was not converted ..",
      "person 4 was detected as the primary speaker of the audio sample ... person 4 was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was not converted .. person 4 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was not converted ..",
      "person 4 was detected as the primary speaker of the audio sample ... person 4 was detected as the primary speaker of the audio sample ...",
      "person 4 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-5], classification[replayed], shap_value[0.0597], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a 0.0597 value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a sha value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of MSRCC-5 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.0597 MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.0597 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0597 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-50], interpreter[shap], shap_value[0.2635])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of  ...",
      "Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "Yes person  was detected by LFCC with a shap value of 0.263 ...",
      "Yes person 5 was detected by LFCC with a  value of 0.2635 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "Yes person 5 was detected by LFCC with a 5 value of 0.2635 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.263yes ...",
      "Yes MFCC which a shap value of -0.5104 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by LFCC with a shap value of yes ...",
      "Yes person 5 was detected by LFCC with a shap value of  ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-50 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2635 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-10], classification[bonafide])",
    "ref": [
      "yes GTCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes GTCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes GTCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes GTCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-2], shap_value[-0.2448])",
    "ref": [
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.24 ...",
      "-0.2448 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ...",
      "Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ...",
      "Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ...",
      "sha determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-2 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.24 ...",
      "-0.2448 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ...",
      "Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2448 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-2 ], <shap_value> shap value: [ -0.2448 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-5], classification[replayed], shap_value[-0.2026], detected_by[CNN])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of -0.7096 ... Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.7096 ...",
      "Ye MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of MFCC-5 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a s value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.2026 MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2026 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There was no EnvironmentSignature signature ...",
      "There was no EnvironmentSignature signature ... There was no EnvironmentSignature signature ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There was no EnvironmentSignature signature ...",
      "There was no EnvironmentSignature signature ... There was no EnvironmentSignature signature ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There was no EnvironmentSignature signature ...",
      "There was no EnvironmentSignature signature ... There was no EnvironmentSignature signature ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There was no EnvironmentSignature signature ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(speaker_id[8], model[SVM])",
    "ref": [
      "The breathing rate changes",
      "The breathing rate changes the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "The breathing rate changes",
      "The breathing rate changes the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "replayed the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CN recording was not a PhysicalAccess recording ...",
      "N the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by spoofed recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "replayed the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... The audio is PhysicalAccess was detected by CNN ...",
      "The audio is PhysicalAccess was detected by C ...",
      "The audio is PhysicalAccess was detected by spoof ...",
      "The audio is PhysicalAccess was detected by CNN ... The audio is PhysicalAccess was detected by CNN ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... The audio is PhysicalAccess was detected by CNN ...",
      "The audio is PhysicalAccess was detected by C ...",
      "The audio is PhysicalAccess was detected by spoof ...",
      "The audio is PhysicalAccess was detected by CNN ... The audio is PhysicalAccess was detected by CNN ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "The audio is PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-22], shap_value[0.8296])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "0.8296 determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "The audio is fake ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "The audio is fake .. shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "0.8296 determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "The audio is fake ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-22 ], <shap_value> shap value: [ 0.8296 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-2], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a Yes value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by 1 ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a  value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-14], interpreter[shap], shap_value[0.9466])",
    "ref": [
      "Yes MFCC which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6692 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a 0.9466 value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker MFCC-14 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a s value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9466 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Spectral Centroid physicalattribute Coefficients ...",
      "There are no inconsistencies which indicate a Spoofed sample .. There are no inconsistencies which indicate a Spoofed sample ..",
      "Spectral Centroid physicalattribute Coefficients ... There are no inconsistencies which indicate a Spoofed sample ..",
      "Spectral Centroid physicalattribute Coefficients ...",
      "There are no inconsistencies which indicate a Spoofed sample .. There are no inconsistencies which indicate a Spoofed sample ..",
      "Spectral Centroid physicalattribute Coefficients ... There are no inconsistencies which indicate a Spoofed sample ..",
      "Spectral Centroid physicalattribute Coefficients ...",
      "There are no inconsistencies which indicate a Spoofed sample .. There are no inconsistencies which indicate a Spoofed sample ..",
      "Spectral Centroid physicalattribute Coefficients ... There are no inconsistencies which indicate a Spoofed sample ..",
      "Spectral Centroid physicalattribute Coefficients ...",
      "There are no inconsistencies which indicate a Spoofed sample .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-2], shap_value[-1])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "Yes a professional mixer was used ...",
      "GTCC-2 determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-2 ...",
      "Yes a professional mixer was used ... shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "Yes a professional mixer was used ...",
      "GTCC-2 determined that the GTCC feature was one of the more important features by assigning it a value of -1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of -1 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-2 ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "yes MFCC was used to determine speaker id ...",
      "There are inconsistencies in the number of people speaking ... There are inconsistencies in the number of people speaking ...",
      "yes MFCC was used to determine speaker id ... There are inconsistencies in the number of people speaking ...",
      "yes MFCC was used to determine speaker id ...",
      "There are inconsistencies in the number of people speaking ... There are inconsistencies in the number of people speaking ...",
      "yes MFCC was used to determine speaker id ... There are inconsistencies in the number of people speaking ...",
      "yes MFCC was used to determine speaker id ...",
      "There are inconsistencies in the number of people speaking ... There are inconsistencies in the number of people speaking ...",
      "yes MFCC was used to determine speaker id ... There are inconsistencies in the number of people speaking ...",
      "yes MFCC was used to determine speaker id ...",
      "There are inconsistencies in the number of people speaking ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-1], classification[replayed], shap_value[-0.5673], detected_by[CNN])",
    "ref": [
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "Y MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5673 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-12], interpreter[shap], shap_value[-0.3913])",
    "ref": [
      "Yes person 4 was detected by MFCC with a sh value of -0.3913 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ...",
      "Yes person 4 was detected by MFCC with a shap value of  ...",
      "Yes person  was detected by MFCC with a shap value of -0.3913 ...",
      "Yes person 4 was detected by MFCC with a yes value of -0.3913 ...",
      "Yes person MFCC-12 was detected by MFCC with a shap value of -0.3913 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.3913 ... Yes person 4 was detected by MFCC with a shap value of -0.3913 ...",
      "Yes person 4 was detected by MFCC with a shap value of 4 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 1 ... Yes person 4 was detected by MFCC with a shap value of -0.3913 ...",
      "Yes person 4 was detected by MFCC with a sh value of -0.3913 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.3913 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3913 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-58], classification[bonafide], shap_value[0.6073])",
    "ref": [
      "shap LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-58 value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.607 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-58 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6073 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-58 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6073 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "I do not recognize any of the CaptureDevice signatures ... The audio is artificially slowed ...",
      "I do not recognize any of the CaptureDevice signatures ...",
      "The audio is artificially slowed ... The audio is artificially slowed ...",
      "I do not recognize any of the CaptureDevice signatures ... The audio is artificially slowed ...",
      "I do not recognize any of the CaptureDevice signatures ...",
      "The audio is artificially slowed ... The audio is artificially slowed ...",
      "I do not recognize any of the CaptureDevice signatures ... The audio is artificially slowed ...",
      "I do not recognize any of the CaptureDevice signatures ...",
      "The audio is artificially slowed ... The audio is artificially slowed ...",
      "I do not recognize any of the CaptureDevice signatures ... The audio is artificially slowed ...",
      "The audio is artificially slowed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-23], classification[replayed], shap_value[-0.561], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of LFCC-23 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a -0.561 value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.56 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... Yes LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes LFCC which a shap value of -0.561 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-23 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.561 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed])",
    "ref": [
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes the recording was faked using playback ... Yes the recording was faked using playback ...",
      "Y the recording was faked using playback ...",
      "replayed the recording was faked using playback ...",
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording was faked using playback ...",
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes the recording was faked using playback ... Yes the recording was faked using playback ...",
      "Y the recording was faked using playback ...",
      "replayed the recording was faked using playback ...",
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording was faked using playback ...",
      "Yes the recording was faked using playback ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-29], shap_value[0.7373])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-29 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "person 3 spoke the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "person 3 spoke the audio sample ...",
      "LFCC-29 determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-29 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-29 ], <shap_value> shap value: [ 0.7373 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-47], classification[bonafide])",
    "ref": [
      "There is more feedback at the 40 second mark ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There is more feedback at the 40 second mark ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There is more feedback at the 40 second mark ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There is more feedback at the 40 second mark ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-47 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-7], shap_value[-0.6482])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "-0.6482 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-7 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0. ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "-0.6482 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.6482 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-7 ], <shap_value> shap value: [ -0.6482 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-8], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 1 was detected by GTCC with a shap value of  ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 1 was detected by GTCC with a shap value of 0 ... Yes person 1 was detected by GTCC with a shap value of 0 ...",
      "Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 1 was detected by GTCC with a shap value of 0 ...",
      "Yes person 1 was detected by GTCC with a  value of 0 ...",
      "Yes person 1 was detected by GTCC with a shap value of yes ...",
      "Yes person shap was detected by GTCC with a shap value of 0 ...",
      "Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 1 was detected by GTCC with a 0 value of 0 ...",
      "Yes person 1 was detected by GTCC with a shap value of  ...",
      "Yes person 1 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-25], classification[replayed], shap_value[0.9811], detected_by[CNN])",
    "ref": [
      "shap MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a MFCC-25 value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.98 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by 0.9811 ...",
      "Yes LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9811 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-25 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9811 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[2], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...",
      "Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...",
      "Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5482 was used to detect the id of speaker 2 for the audio sample ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 2 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-31], shap_value[-0.9197])",
    "ref": [
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.91 ...",
      "LFCC-31 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.91 ...",
      "LFCC-31 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9197 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-31 ], <shap_value> shap value: [ -0.9197 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-1], classification[replayed], shap_value[0.109], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a CNN value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Ye LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.109 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.109 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-48], classification[replayed], shap_value[0.2133], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a CNN value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-48 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2133 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-0], classification[bonafide], shap_value[0.6244])",
    "ref": [
      "0.6244 PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-0 value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a sha value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Y PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Yes person 1 was detected by GTCC with a shap value of 1 ... Yes PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes person 1 was detected by GTCC with a shap value of 1 ...",
      "0.6244 PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.6244 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6244 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-28], classification[bonafide])",
    "ref": [
      "person 4 spoke the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-28 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "person 4 spoke the audio sample ...",
      "person 4 spoke the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-28 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "person 4 spoke the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-28 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Linear physicalattribute Cepstral Coefficients are extracted by performing integration of the power Abstract using overlapping triangular filters spaced linearly and logarithmic compression follwed by DCT ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-6], shap_value[-0.917])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "-0.917 determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.917 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-6 ], <shap_value> shap value: [ -0.917 ]> )"
  },
  {
    "mr": "inform(response[Yes])",
    "ref": [
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ... Yes ...",
      " ...",
      "Yes ... Yes ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ... Yes ...",
      " ...",
      "Yes ... Yes ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ... Yes ...",
      " ...",
      "Yes ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-4], interpreter[shap], shap_value[-0.666])",
    "ref": [
      "Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MSRCC which a shap value of -0 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a yes value of -0.666 was used to detect the id of speaker 3 for the audio sample ...",
      "The signature is consistent with a digital CaptureDevice ..",
      "Yes MSRCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ... Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a sha value of -0.666 was used to detect the id of speaker 3 for the audio sample ...",
      "The signature is consistent with a digital CaptureDevice .. Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MSRCC which a shap value of -0.666 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.666 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There was more than one CaptureDevice ...",
      "No . shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "N . There was more than one CaptureDevice ...",
      "No . No . No . There was more than one CaptureDevice ...",
      "No . No . There was more than one CaptureDevice ...",
      "multi_microphone . There was more than one CaptureDevice ...",
      "No . shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... There was more than one CaptureDevice ...",
      "No .",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... No . shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... There was more than one CaptureDevice ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "No . There was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of -0.6095 was used to detect the id of speaker 1 for the audio sample ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide], detected_by[CNN])",
    "ref": [
      "No the recording is not Audio_signal was detected by CNN ... No the recording is not Audio_signal was detected by CNN ...",
      " the recording is not Audio_signal was detected by CNN ...",
      "No the recording is not Audio_signal was detected by  ...",
      "No the recording is Audio_signal was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... No the recording is not Audio_signal was detected by CNN ...",
      "No the recording is not Audio_signal was detected by No ...",
      "CNN the recording is not Audio_signal was detected by CNN ...",
      "No the recording is not Audio_signal was detected by CNN ... No the recording is not Audio_signal was detected by CNN ...",
      " the recording is not Audio_signal was detected by CNN ...",
      "No the recording is not Audio_signal was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-46], interpreter[shap], shap_value[-0.3294])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ... Yes person 5 was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a sha value of -0.3294 ...",
      "Yes person shap was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a 5 value of -0.3294 ...",
      "Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 5 was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3 ...",
      "Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-46 ...",
      "Yes person  was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ... Yes person 5 was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-46 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3294 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[digital])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The signature is consistent with a digital CaptureDevice ..",
      "The signature is consistent with a digital CaptureDevice .. The signature is consistent with a digital CaptureDevice ..",
      "The signature is consistent with a spoof CaptureDevice ..",
      "The signature is consistent with a digita CaptureDevice ..",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The signature is consistent with a digital CaptureDevice ..",
      "The signature is consistent with a digital CaptureDevice .. The signature is consistent with a digital CaptureDevice ..",
      "The signature is consistent with a spoof CaptureDevice ..",
      "The signature is consistent with a digita CaptureDevice ..",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The signature is consistent with a digital CaptureDevice .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ digital ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ...",
      "spoofed the recording is fake ..",
      "Yes the recording is fake .. Yes the recording is fake ..",
      "Y the recording is fake ..",
      "Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ... Yes the recording is fake ..",
      "Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ...",
      "spoofed the recording is fake ..",
      "Yes the recording is fake .. Yes the recording is fake ..",
      "Y the recording is fake ..",
      "Yes LFCC which a shap value of -0.2091 was used to detect the sample as Audio_signal ... Yes the recording is fake ..",
      "Yes the recording is fake .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-15], interpreter[shap], shap_value[0.1546])",
    "ref": [
      "Yes person 2 was detected by MFCC with a s value of 0.1546 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1 ...",
      "The audio is not good ... Yes person 2 was detected by MFCC with a shap value of 0.1546 ...",
      "Yes person 2 was detected by MFCC with a shap value of shap ...",
      "The audio is not good ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ... Yes person 2 was detected by MFCC with a shap value of 0.1546 ...",
      "Yes person  was detected by MFCC with a shap value of 0.1546 ...",
      "Yes person 2 was detected by MFCC with a 0.1546 value of 0.1546 ...",
      "Yes person yes was detected by MFCC with a shap value of 0.1546 ...",
      "Yes person 2 was detected by MFCC with a s value of 0.1546 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.1546 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1546 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-10], interpreter[shap], shap_value[-0.2208])",
    "ref": [
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ... Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "Yes person 6 was detected by MFCC with a shap value of MFCC-10 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.22 ...",
      "Yes person MFCC-10 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a  value of -0.2208 ...",
      "Yes person  was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a MFCC-10 value of -0.2208 ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ... Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2208 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-51], shap_value[-0.7772])",
    "ref": [
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "-0.7772 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "-0.7772 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <shap_value> shap value: [ -0.7772 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes the recording was faked using playback ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes the recording was faked using playback ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes the recording was faked using playback ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes the recording was faked using playback ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-32], classification[bonafide], shap_value[-0.9762])",
    "ref": [
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ...",
      "LFCC-32 LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of -0.9762 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.9762 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.5782 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.9762 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-32 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9762 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-18], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ...",
      "Yes person 2 was detected by MSRCC with a shap value of -0.5893 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-18 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-11], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes .",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes .",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[replayed])",
    "ref": [
      "The recording appears to be a copy .. The recording appears to be a copy ..",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ... The recording appears to be a copy ..",
      "The recording appears to be a copy .. The recording appears to be a copy ..",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ... The recording appears to be a copy ..",
      "The recording appears to be a copy .. The recording appears to be a copy ..",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ... The recording appears to be a copy ..",
      "The recording appears to be a copy .. The recording appears to be a copy ..",
      "The recording appears to be a copy .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-33], shap_value[0.101])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-33 ...",
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ...",
      "0.101 determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.10 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-33 ...",
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.101 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-33 ], <shap_value> shap value: [ 0.101 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-2], classification[replayed], shap_value[0.1331], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a  value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.13 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by 0.1331 ...",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by  ...",
      "replayed MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a replayed value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1331 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-41], classification[replayed], shap_value[0.5433], detected_by[CNN])",
    "ref": [
      " LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by 0.5433 ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a s value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-41 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5433 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.1008 ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The mel in the name describes the perceived pitch. Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition .  The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.1008 ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . Yes person 6 was detected by LFCC with a shap value of 0.1008 ... They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "The mel in the name describes the perceived pitch. The mel in the name describes the perceived pitch. The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . The mel in the name describes the perceived pitch. They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.1008 ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.1008 ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . Yes person 6 was detected by LFCC with a shap value of 0.1008 ... Yes person 6 was detected by LFCC with a shap value of 0.1008 ... They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. Yes person 6 was detected by LFCC with a shap value of 0.1008 ... The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ...",
      "The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... .",
      "The Mel physicalattribute Cepstral Coefficients CepstralFeature are used for automatic Acoustic_Wave recognition . They lead to a compact Abstract of the frequency spectrum. The mel in the name describes the perceived pitch. The linear modeling of speech generation serves as the actual basis for the generation of MFCCs A periodic excitation signal vocal cords is formed by a linear SoftwareAgent mouth tongue nasal cavities ... . The Operation or its impulse response is primarily important for speech recognition since what was said and not in which perception is of interest for the analysis ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-30], classification[bonafide], shap_value[-0.1903])",
    "ref": [
      "Ye MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.1903 was used to detect the sample as Audio_signal ...",
      "MFCC-30 MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sh value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.190 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1903 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-30 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1903 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-30], shap_value[0.7143])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.71 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "0.7143 determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ...",
      "Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ...",
      "Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.71 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "0.7143 determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7143 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <shap_value> shap value: [ 0.7143 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-31], interpreter[shap], shap_value[-0.7969])",
    "ref": [
      "Yes person 7 was detected by MFCC with a sha value of -0.7969 ...",
      "Yes MFCC which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ... Yes person 7 was detected by MFCC with a shap value of -0.7969 ...",
      "Yes MFCC which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person shap was detected by MFCC with a shap value of -0.shap969 ...",
      "Yes person 7 was detected by MFCC with a shap value of yes ...",
      "Yes person  was detected by MFCC with a shap value of -0.969 ...",
      "Yes person 7 was detected by MFCC with a MFCC-31 value of -0.7969 ...",
      "Yes person 7 was detected by MFCC with a shap value of -0.7 ...",
      "Yes person 7 was detected by MFCC with a shap value of -0.7969 ... Yes person 7 was detected by MFCC with a shap value of -0.7969 ...",
      "Yes person 7 was detected by MFCC with a sha value of -0.7969 ...",
      "Yes person 7 was detected by MFCC with a shap value of -0.7969 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7969 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-52], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-52 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-52 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-52 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "spoofed the recording has been tampered with ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ... Yes the recording has been tampered with ...",
      "Y the recording has been tampered with ...",
      "Yes the recording has been tampered with ... Yes the recording has been tampered with ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "spoofed the recording has been tampered with ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ... Yes the recording has been tampered with ...",
      "Y the recording has been tampered with ...",
      "Yes the recording has been tampered with ... Yes the recording has been tampered with ...",
      "Yes the recording has been tampered with ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-12], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-12 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-12 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.7878 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "There were 2 microphones used ... There were 2 microphones used ...",
      "There were  microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There were 2 microphones used ...",
      "There were multi_microphone microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "There were  microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There were 2 microphones used ...",
      "There were multi_microphone microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There were 2 microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-45], classification[replayed], shap_value[0.7923], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a replayed value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8568 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-45 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7923 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-18], interpreter[shap], shap_value[0.7479])",
    "ref": [
      "Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ... Yes person 7 was detected by LFCC with a shap value of 0.7479 ...",
      "Yes person  was detected by LFCC with a shap value of 0.49 ...",
      "Yes person 7 was detected by LFCC with a 0.7479 value of 0.7479 ...",
      "Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.747 ...",
      "Yes person 0.7479 was detected by LFCC with a shap value of 0.0.747940.74799 ...",
      "Yes person 7 was detected by LFCC with a shap value of 7 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.7479 ... Yes person 7 was detected by LFCC with a shap value of 0.7479 ...",
      "Yes person 7 was detected by LFCC with a sha value of 0.7479 ...",
      "Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ... Yes person 7 was detected by LFCC with a shap value of 0.7479 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.7479 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7479 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-28], interpreter[shap], shap_value[-0.1756])",
    "ref": [
      "Yes person 4 was detected by MFCC with a -0.1756 value of -0.1756 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.1756 ... Yes person 4 was detected by MFCC with a shap value of -0.1756 ...",
      "Yes person 4 was detected by MFCC with a sh value of -0.1756 ...",
      "Yes person 4 was detected by MFCC with a shap value of 4 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0. ...",
      "Yes person  was detected by MFCC with a shap value of -0.1756 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ... Yes person 4 was detected by MFCC with a shap value of -0.1756 ...",
      "Yes person MFCC-28 was detected by MFCC with a shap value of -0.1756 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "Yes person 4 was detected by MFCC with a -0.1756 value of -0.1756 ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.1756 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1756 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "No other fes detected LogicalAccess ...",
      "No other nones detected LogicalAccess ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. No other features detected LogicalAccess ...",
      "No other features detected LogicalAccess ... No other features detected LogicalAccess ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "No other fes detected LogicalAccess ...",
      "No other nones detected LogicalAccess ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. No other features detected LogicalAccess ...",
      "No other features detected LogicalAccess ... No other features detected LogicalAccess ...",
      "No other features detected LogicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-3], shap_value[0])",
    "ref": [
      "The CaptureDevice signature is consistent throughout the recording ...",
      "GTCC-3 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-3 ...",
      "sh determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "The CaptureDevice signature is consistent throughout the recording ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "The CaptureDevice signature is consistent throughout the recording ...",
      "GTCC-3 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-3 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-3 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-29], classification[replayed], shap_value[0.9441], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ...",
      "Yes MFCC which a replayed value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ... Yes MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9441 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-29 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9441 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-0], feature[MFCC-0], feature[LFCC-2], feature[MFCC-4])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MF had the highest impact on the classification ...",
      "Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MF had the highest impact on the classification ...",
      "Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-0 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-6], classification[replayed], shap_value[0.8902], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a  value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a CNN value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by C ...",
      "PSRCC-6 PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.8902 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8902 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-21], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.5025 ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.5025 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.5025 ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.5025 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-21 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-11], classification[bonafide], shap_value[0.809])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... Yes PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      " PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a 0.809 value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a sh value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "shap PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... Yes PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.809 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.809 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "The mel in the name describes the perceived pitch. the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The mel in the name describes the perceived pitch.",
      "the audio sample had CepstralFeature features extracted and MSRCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The mel in the name describes the perceived pitch. the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The mel in the name describes the perceived pitch.",
      "the audio sample had CepstralFeature features extracted and MSRCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-34], classification[replayed], shap_value[0.4744], detected_by[CNN])",
    "ref": [
      "0.4744 MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a shap value of 0.47 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by MFCC-34 ...",
      "Yes MFCC which a sh value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a 0.4744 value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-34 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4744 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-39], classification[bonafide], shap_value[0.0826])",
    "ref": [
      "Yes MFCC which a s value of 0.0826 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of 0.0826 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "MFCC-39 MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of 0.0826 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-39 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0826 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_type[dynamic])",
    "ref": [
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... Dynamic microphones were used the most ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... Dynamic microphones were used the most ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ... Dynamic microphones were used the most ...",
      "Yes LFCC which a shap value of 0.256 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_type> mic type: [ dynamic ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.0826 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-6], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker  for the audio sample ...",
      "There is an unusually long pause at 37 seconds ...",
      "Yes GTCC which a sh value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a 1 value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "There is an unusually long pause at 37 seconds ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-0], interpreter[shap], shap_value[-0.8051])",
    "ref": [
      "Yes PSRCC which a -0.8051 value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of yes was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ... Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a sh value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ... Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a -0.8051 value of -0.8051 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.8051 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8051 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-2], interpreter[shap], shap_value[0.7373])",
    "ref": [
      "Yes PSRCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ... Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.4171 ...",
      "Yes PSRCC which a shap value of  was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker PSRCC-2 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.4171 ... Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a s value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a yes value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7373 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-2], interpreter[shap], shap_value[0.3503])",
    "ref": [
      "Yes MSRCC which a yes value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a sha value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ... Yes MSRCC which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of shap was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.303 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0.350 was used to detect the id of speaker 5 for the audio sample ...",
      "The CaptureDevice signature is consistent throughout the recording .. Yes MSRCC which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3yes03 was used to detect the id of speaker yes for the audio sample ...",
      "The CaptureDevice signature is consistent throughout the recording ..",
      "Yes MSRCC which a yes value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3503 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-44], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-44 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by  audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by spoof audio was a PhysicalAccess audio ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by  audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by spoof audio was a PhysicalAccess audio ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3767 ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-35], classification[bonafide], shap_value[-0.8694])",
    "ref": [
      " LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.8694 value of -0.8694 was used to detect the sample as Audio_signal ...",
      "No . Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "No .",
      "LFCC-35 LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.8694 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-35 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8694 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-33], interpreter[shap], shap_value[-0.4495])",
    "ref": [
      "Yes LFCC which a 1 value of -0.4495 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4495 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4495 was used to detect the id of speaker  for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... Yes LFCC which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a s value of -0.4495 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-33 was used to detect the id of speaker 1 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a 1 value of -0.4495 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4495 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4495 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-34], interpreter[shap], shap_value[0.8748])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 0.8748 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ... Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a s value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a 0.8748 value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8748 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "3 was found to be the id of the speaker in the sample ...",
      "3 was found to be the id of the speaker in the sample ... The recording is fake ..",
      "The recording is fake .. The recording is fake ..",
      "3 was found to be the id of the speaker in the sample ...",
      "3 was found to be the id of the speaker in the sample ... The recording is fake ..",
      "The recording is fake .. The recording is fake ..",
      "3 was found to be the id of the speaker in the sample ...",
      "3 was found to be the id of the speaker in the sample ... The recording is fake ..",
      "The recording is fake .. The recording is fake ..",
      "3 was found to be the id of the speaker in the sample ...",
      "The recording is fake .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-26], interpreter[shap], shap_value[-0.7669])",
    "ref": [
      "Yes person 1 was detected by MFCC with a shap value of -0.7669 ... Yes person 1 was detected by MFCC with a shap value of -0.7669 ...",
      "Some of the recording was made with a mobile device and some with a computer ..",
      "Yes person shap was detected by MFCC with a shap value of -0.7669 ...",
      "Yes person 1 was detected by MFCC with a 1 value of -0.7669 ...",
      "Yes person  was detected by MFCC with a shap value of -0.7669 ...",
      "Yes person 1 was detected by MFCC with a shap value of shap ...",
      "Yes person 1 was detected by MFCC with a shap value of -0 ...",
      "Yes person 1 was detected by MFCC with a s value of -0.7669 ...",
      "Some of the recording was made with a mobile device and some with a computer .. Yes person 1 was detected by MFCC with a shap value of -0.7669 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.7669 ... Yes person 1 was detected by MFCC with a shap value of -0.7669 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.7669 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7669 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[8])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-1], interpreter[shap], shap_value[0.3263])",
    "ref": [
      "Yes PSRCC which a shap value of 0.3 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a s value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a PSRCC-1 value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ... Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of yes was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3903 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker PSRCC-1 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.3 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3263 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-8], interpreter[shap], shap_value[0.1874])",
    "ref": [
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person  was detected by PSRCC with a shap value of 0.1874 ...",
      "Yes person 5 was detected by PSRCC with a sh value of 0.1874 ...",
      "Yes person shap was detected by PSRCC with a shap value of 0.1874 ...",
      "Yes person 5 was detected by PSRCC with a yes value of 0.1874 ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.1874 ... Yes person 5 was detected by PSRCC with a shap value of 0.1874 ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.1 ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 5 was detected by PSRCC with a shap value of 0.1874 ...",
      "Yes person 5 was detected by PSRCC with a shap value of shap ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.1874 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1874 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The audio sample was Audio_signal was detected by CNN ...",
      "The audio sample was Audio_signal was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The audio sample was Audio_signal was detected by CNN ...",
      "The audio sample was Audio_signal was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The audio sample was Audio_signal was detected by CNN ...",
      "The audio sample was Audio_signal was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-36], classification[bonafide], shap_value[-0.4792])",
    "ref": [
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ...",
      "-0.4792 MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-36 value of -0.4792 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-36 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.479 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of -0.4792 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3017 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-36 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4792 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-55], interpreter[shap], shap_value[0.8788])",
    "ref": [
      "Yes LFCC which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a s value of 0.8788 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.8788 was used to detect the id of speaker LFCC-55 for the audio sample ...",
      "Yes LFCC which a 4 value of 0.8788 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8788 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8788 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-55 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8788 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-52], interpreter[shap], shap_value[0.556])",
    "ref": [
      "Yes person 2 was detected by LFCC with a yes value of 0.556 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.556 ... Yes person 2 was detected by LFCC with a shap value of 0.556 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0 ...",
      "Yes person LFCC-52 was detected by LFCC with a shap value of 0.556 ...",
      "Yes person  was detected by LFCC with a shap value of 0.556 ...",
      "Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a s value of 0.556 ...",
      "Yes LFCC which a shap value of -0.7141 was used to detect the id of speaker 3 for the audio sample ... Yes person 2 was detected by LFCC with a shap value of 0.556 ...",
      "Yes person 2 was detected by LFCC with a shap value of 2 ...",
      "Yes person 2 was detected by LFCC with a yes value of 0.556 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.556 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-52 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.556 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-7], classification[bonafide], shap_value[-0.2973])",
    "ref": [
      "Yes MSRCC which a shap value of -0.29 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of -0.2973 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a Yes value of -0.2973 was used to detect the sample as Audio_signal ...",
      "MSRCC-7 MSRCC which a shap value of -0.2973 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      " MSRCC which a shap value of -0.2973 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a  value of -0.2973 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of -0.2973 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.2973 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.29 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.2973 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2973 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-23], interpreter[shap], shap_value[-0.3711])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker LFCC-23 for the audio sample ...",
      "Yes LFCC which a shap value of -0.37 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a s value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "Yes LFCC which a yes value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3711 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-10], classification[bonafide], shap_value[0.8682])",
    "ref": [
      "Yes PSRCC which a PSRCC-10 value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of PSRCC-10 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ...",
      "Yes PSRCC which a shap value of 0.86 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.6735 ... Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      " PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "bonafide PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a s value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-10 value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8682 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-59], classification[replayed], shap_value[-0.8654], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a CNN value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by LFCC-59 ...",
      "Yes LFCC which a sha value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Ye LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8654 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-59 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8654 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio is not good ...",
      "The audio is good ...",
      "The audio is not good ... The audio is not good ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio is not good ...",
      "The audio is good ...",
      "The audio is not good ... The audio is not good ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio is not good ...",
      "The audio is good ...",
      "The audio is not good ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1], signal_length[5])",
    "ref": [
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for  seconds ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "That CaptureDevice was used for multi_microphone seconds ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for  seconds ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 8 ...",
      "That CaptureDevice was used for multi_microphone seconds ...",
      "That CaptureDevice was used for 5 seconds ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ], <signal_length> signal length: [ 5 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-33], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The average perception gets higher in this section the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The average perception gets higher in this section",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The average perception gets higher in this section the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The average perception gets higher in this section",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-33 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-24], interpreter[shap], shap_value[0.5756])",
    "ref": [
      "Yes person 3 was detected by MFCC with a s value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes the recording is fake ..",
      "Yes person MFCC-24 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.575 ...",
      "Yes person  was detected by MFCC with a shap value of 0.5756 ...",
      "Yes the recording is fake .. Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a 0.5756 value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of yes ...",
      "Yes person 3 was detected by MFCC with a s value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5756 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-9], interpreter[shap], shap_value[0.786])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of yes was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker shap for the audio sample ...",
      "Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a s value of 0.786 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ... Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a yes value of 0.786 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of 0. was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.786 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-12], classification[replayed], shap_value[-0.046], detected_by[CNN])",
    "ref": [
      " MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a sh value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by -0.046 ...",
      "Yes MSRCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MSRCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.8478 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a replayed value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.046 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.046 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ... There are no unusually long or short pauses ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "There are no unusually long or short pauses ... There are no unusually long or short pauses ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ... There are no unusually long or short pauses ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "There are no unusually long or short pauses ... There are no unusually long or short pauses ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ... There are no unusually long or short pauses ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ...",
      "There are no unusually long or short pauses ... There are no unusually long or short pauses ...",
      "Yes PSRCC which a shap value of 0.3263 was used to detect the id of speaker 4 for the audio sample ... There are no unusually long or short pauses ...",
      "There are no unusually long or short pauses ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-4], classification[bonafide], shap_value[-0.512])",
    "ref": [
      "-0.512 LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ... Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.512 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.512 was used to detect the sample as Audio_signal ...",
      "-0.512 LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.512 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.512 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-30], classification[replayed], shap_value[-0.7633], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a  value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "replayed MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... Yes MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7633 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-30 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7633 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-20], classification[replayed], shap_value[0.1791], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of MFCC-20 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of 0.1791 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-20 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1791 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-2], interpreter[shap], shap_value[-0.7935])",
    "ref": [
      "Yes MFCC which a s value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.935 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a MFCC-2 value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.shap935 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a shap value of -0.793 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a s value of -0.7935 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7935 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7935 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-16], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-16 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC-16 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of -0.0292 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-16 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "There is an unusually long pause at 37 seconds ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at 37 seconds ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There is an unusually long pause at 37 seconds ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "spoof the entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ... No the entire recording was made using multiple microphones ..",
      "No the entire recording was made using multiple microphones .. No the entire recording was made using multiple microphones ..",
      " the entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "spoof the entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ... No the entire recording was made using multiple microphones ..",
      "No the entire recording was made using multiple microphones .. No the entire recording was made using multiple microphones ..",
      " the entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of 0.2133 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No the entire recording was made using multiple microphones .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-29], shap_value[0.8612])",
    "ref": [
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8 ...",
      "0.8612 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-29 ], <shap_value> shap value: [ 0.8612 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-9], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.9585 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-2], classification[bonafide])",
    "ref": [
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-2 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-2 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.9466 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "3 was found to be the id of the speaker in the sample ... 3 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      " was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... 3 was found to be the id of the speaker in the sample ...",
      "3 was found to be the id of the speaker in the sample ... 3 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      " was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... 3 was found to be the id of the speaker in the sample ...",
      "3 was found to be the id of the speaker in the sample ... 3 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "3 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-30], interpreter[shap], shap_value[-0.9742])",
    "ref": [
      "Yes person 2 was detected by LFCC with a yes value of -0.9742 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9742 ... Yes person 2 was detected by LFCC with a shap value of -0.9742 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ... Yes person 2 was detected by LFCC with a shap value of -0.9742 ...",
      "Yes person 2 was detected by LFCC with a shap value of 2 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.974yes ...",
      "Yes person 2 was detected by LFCC with a shap value of - ...",
      "Yes person 2 was detected by LFCC with a  value of -0.9742 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8612 ...",
      "Yes person  was detected by LFCC with a shap value of -0.974 ...",
      "Yes person 2 was detected by LFCC with a yes value of -0.9742 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9742 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9742 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-7], classification[bonafide], shap_value[1])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      " GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sha value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a 1 value of 1 was used to detect the sample as Audio_signal ...",
      "1 GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... This is a poor quality recording ..",
      "This is a poor quality recording .. This is a poor quality recording ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... This is a poor quality recording ..",
      "This is a poor quality recording .. This is a poor quality recording ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... This is a poor quality recording ..",
      "This is a poor quality recording .. This is a poor quality recording ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.9166 ... This is a poor quality recording ..",
      "This is a poor quality recording .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-3], interpreter[shap], shap_value[0.0695])",
    "ref": [
      "Yes MFCC which a shap value of 0. was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a 0.0695 value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ... Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "Yes MFCC which a sh value of 0.0695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker MFCC-3 for the audio sample ...",
      "Yes MFCC which a shap value of 0. was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0695 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0695 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-11], classification[bonafide], shap_value[0.8105])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ... Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.8 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sh value of 0.8105 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a 0.8105 value of 0.8105 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "MFCC-11 MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8105 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-9], classification[bonafide])",
    "ref": [
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-58], classification[replayed], shap_value[0.7518], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.7 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a 0.7518 value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "LFCC-58 LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a shap value of 0.7518 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-58 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7518 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-57], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-57 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "yes MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "yes MFCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-57 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "yes MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "yes MFCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-57 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-12], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-4], shap_value[-0.1907])",
    "ref": [
      "LFCC-4 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of - ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long .. shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "LFCC-4 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of - ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1907 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-4 ], <shap_value> shap value: [ -0.1907 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[recording_slowed])",
    "ref": [
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "person 8 was detected as the primary speaker of the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ... The recording is artificially slowed ...",
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "person 8 was detected as the primary speaker of the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ... The recording is artificially slowed ...",
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "person 8 was detected as the primary speaker of the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ... The recording is artificially slowed ...",
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "The recording is artificially slowed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ recording_slowed ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-7], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a 0 value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a  value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Y GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes MFCC was used to determine speaker id ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[20])",
    "ref": [
      "The spoof increases at the 20 second mark ...",
      "There is more than one CaptureDevice signature on the recording ..",
      "The  increases at the 20 second mark ...",
      "The speed increases at the 20 second mark ... The speed increases at the 20 second mark ...",
      "There is more than one CaptureDevice signature on the recording .. The speed increases at the 20 second mark ...",
      "The speed increases at the  second mark ...",
      "The speed increases at the spoof second mark ...",
      "The spoof increases at the 20 second mark ...",
      "There is more than one CaptureDevice signature on the recording ..",
      "The  increases at the 20 second mark ...",
      "The speed increases at the 20 second mark ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-12], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a GTCC-12 value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes GTCC which a  value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by GTCC-12 ...",
      " GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "1 GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of GTCC-12 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-27], classification[bonafide], shap_value[-0.3631])",
    "ref": [
      "Yes LFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.3631 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a LFCC-27 value of -0.3631 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      "LFCC-27 LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-27 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3631 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-52], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-52 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-52 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-52 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-40], shap_value[0.0258])",
    "ref": [
      "0.0258 determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-40 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "0.0258 determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-40 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.0258 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <shap_value> shap value: [ 0.0258 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], sample_start[20])",
    "ref": [
      "The cut takes place at the sampling second mark ..",
      "The cut takes place at the  second mark ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The cut takes place at the 20 second mark ..",
      "The cut takes place at the 20 second mark .. The cut takes place at the 20 second mark ..",
      "The cut takes place at the sampling second mark ..",
      "The cut takes place at the  second mark ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The cut takes place at the 20 second mark ..",
      "The cut takes place at the 20 second mark .. The cut takes place at the 20 second mark ..",
      "The cut takes place at the 20 second mark .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <sample_start> sample start: [ 20 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-3], shap_value[0.7891])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "The audio was made at the same time ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.78 ...",
      "The audio was made at the same time ...",
      "LFCC-3 determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "The audio was made at the same time ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <shap_value> shap value: [ 0.7891 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-50], shap_value[-0.7007])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "LFCC-50 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7007 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-50 ], <shap_value> shap value: [ -0.7007 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-3], classification[bonafide], shap_value[-0.1314])",
    "ref": [
      "Yes MFCC which a sh value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.1314 was used to detect the sample as Audio_signal ...",
      "MFCC-3 MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Ye MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sh value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1314 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone],  classified_by[feature])",
    "ref": [
      "Yes person 6 was detected by MSRCC with a shap value of 0.2787 ... Several features were used ...",
      "Yes person 6 was detected by MSRCC with a shap value of 0.2787 ...",
      "Several fes were used ...",
      "Several features were used ... Several features were used ...",
      "Several spoofs were used ...",
      "Yes person 6 was detected by MSRCC with a shap value of 0.2787 ... Several features were used ...",
      "Yes person 6 was detected by MSRCC with a shap value of 0.2787 ...",
      "Several fes were used ...",
      "Several features were used ... Several features were used ...",
      "Several spoofs were used ...",
      "Several features were used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], < classified_by>  classified by: [ feature ]> )"
  },
  {
    "mr": "inform(speaker_id[1])",
    "ref": [
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... person 1 was detected as the primary speaker of the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "person 1 was detected as the primary speaker of the audio sample ... person 1 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... person 1 was detected as the primary speaker of the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "person 1 was detected as the primary speaker of the audio sample ... person 1 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... person 1 was detected as the primary speaker of the audio sample ...",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "person 1 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "The CaptureDevice signature is consistent throughout the recording ... Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a computer .. Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a spoof ..",
      "The CaptureDevice signature is consistent throughout the recording ...",
      "Some of the recording was made with a mobile device and some with a co ..",
      "The CaptureDevice signature is consistent throughout the recording ... Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a computer .. Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a spoof ..",
      "The CaptureDevice signature is consistent throughout the recording ...",
      "Some of the recording was made with a mobile device and some with a co ..",
      "Some of the recording was made with a mobile device and some with a computer .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-17], classification[bonafide], shap_value[0.809])",
    "ref": [
      "The recording appears to be a copy .. Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "0.809 LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "The recording appears to be a copy ..",
      "The recording appears to be a copy .. Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.809 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.809 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There appears to be a cloned voice on the recording ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There appears to be a cloned voice on the recording ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There appears to be a cloned voice on the recording ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There appears to be a cloned voice on the recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(speaker_id[6], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ...",
      "Yes LFCC which a shap value of 0.2774 was used to detect the sample as Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 6 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-25], interpreter[shap], shap_value[-0.8658])",
    "ref": [
      "Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker MFCC-25 for the audio sample ...",
      "Yes MFCC which a MFCC-25 value of -0.8658 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.86 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a  value of -0.8658 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-25 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker MFCC-25 for the audio sample ...",
      "Yes MFCC which a shap value of -0.8658 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8658 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "There is evidence of sa ...",
      "There is evidence of sampling ... There is evidence of sampling ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "There is evidence of spoof ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ... There is evidence of sampling ...",
      "There is evidence of sa ...",
      "There is evidence of sampling ... There is evidence of sampling ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ...",
      "There is evidence of spoof ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6378 ... There is evidence of sampling ...",
      "There is evidence of sampling ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-5], classification[bonafide], shap_value[0])",
    "ref": [
      "Ye GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "yes MFCC was used to determine speaker id ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "yes MFCC was used to determine speaker id ...",
      "Yes GTCC which a shap value of GTCC-5 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a bonafide value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a s value of 0 was used to detect the sample as Audio_signal ...",
      "0 GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Ye GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-47], interpreter[shap], shap_value[-0.8006])",
    "ref": [
      "Yes person  was detected by LFCC with a shap value of -0.8006 ...",
      "It looks that way ... Yes person 4 was detected by LFCC with a shap value of -0.8006 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.80 ...",
      "Yes person -0.8006 was detected by LFCC with a shap value of -0.8006 ...",
      "Yes person 4 was detected by LFCC with a sha value of -0.8006 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.8006 ... Yes person 4 was detected by LFCC with a shap value of -0.8006 ...",
      "It looks that way ...",
      "Yes person 4 was detected by LFCC with a 4 value of -0.8006 ...",
      "Yes person 4 was detected by LFCC with a shap value of 4 ...",
      "Yes person  was detected by LFCC with a shap value of -0.8006 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.8006 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-47 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8006 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Spectral Centroid physicalattribute Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Spectral Centroid physicalattribute Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Spectral Centroid physicalattribute Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Spectral Centroid physicalattribute Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "The recording seems to be at the same spoof throughout ..",
      "The recording seems to be at the same spee throughout ..",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording seems to be at the same speed throughout ..",
      "The recording seems to be at the same speed throughout .. The recording seems to be at the same speed throughout ..",
      "The recording seems to be at the same spoof throughout ..",
      "The recording seems to be at the same spee throughout ..",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... The recording seems to be at the same speed throughout ..",
      "The recording seems to be at the same speed throughout .. The recording seems to be at the same speed throughout ..",
      "The recording seems to be at the same speed throughout .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-9], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio is artificially slowed ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio is artificially slowed ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio is artificially slowed ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio is artificially slowed ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-6], feature[MFCC-0], feature[LFCC-5], feature[CQCC-0])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3137 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3137 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC LFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3137 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.3137 ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC LFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-6 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-5 ], <feature> feature: [ CQCC-0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made using a co ...",
      "person 4 spoke the audio sample ... Some of the recording was made using a computer ...",
      "person 4 spoke the audio sample ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a spoof ...",
      "Some of the recording was made using a co ...",
      "person 4 spoke the audio sample ... Some of the recording was made using a computer ...",
      "person 4 spoke the audio sample ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a spoof ...",
      "Some of the recording was made using a computer ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform( classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "Yes the recording was found to be bonafide...",
      "Yes the recording was found to be bonafide... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "Yes the recording was found to be bonafide...",
      "Yes the recording was found to be bonafide... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "Yes the recording was found to be bonafide...",
      "Yes the recording was found to be bonafide... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( < classification>  classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The signal indicates voice clon ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The signal indicates voice cloning ..",
      "The signal indicates voice cloning .. The signal indicates voice cloning ..",
      "The signal indicates voice spoof ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The signal indicates voice clon ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The signal indicates voice cloning ..",
      "The signal indicates voice cloning .. The signal indicates voice cloning ..",
      "The signal indicates voice spoof ..",
      "The signal indicates voice cloning .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-19], shap_value[0.5217])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-19 ...",
      "0.5217 determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ...",
      "Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ...",
      "Yes PSRCC which a shap value of 0.786 was used to detect the id of speaker 5 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-19 ...",
      "0.5217 determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.5217 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-19 ], <shap_value> shap value: [ 0.5217 ]> )"
  },
  {
    "mr": "inform(speaker_id[2])",
    "ref": [
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ... person 2 was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "person 2 was detected as the primary speaker of the audio sample ... person 2 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ... person 2 was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "person 2 was detected as the primary speaker of the audio sample ... person 2 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ... person 2 was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of 0.7373 was used to detect the id of speaker 6 for the audio sample ...",
      "person 2 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-32], interpreter[shap], shap_value[-0.5324])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ... Yes person 1 was detected by LFCC with a shap value of -0.5324 ...",
      "Yes person 1 was detected by LFCC with a shap value of - ...",
      "Yes person 1 was detected by LFCC with a LFCC-32 value of -0.5324 ...",
      "The recording device was digital ..",
      "The recording device was digital .. Yes person 1 was detected by LFCC with a shap value of -0.5324 ...",
      "Yes person  was detected by LFCC with a shap value of -0.5324 ...",
      "Yes person 1 was detected by LFCC with a shap value of 1 ...",
      "Yes person -0.5324 was detected by LFCC with a shap value of -0.5324 ...",
      "Yes person 1 was detected by LFCC with a sha value of -0.5324 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ... Yes person 1 was detected by LFCC with a shap value of -0.5324 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.5324 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5324 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-9], interpreter[shap], shap_value[-0.9806])",
    "ref": [
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ...",
      "Yes person shap was detected by MSRCC with a shap value of -0.9806 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0. ...",
      "Yes person 7 was detected by MSRCC with a s value of -0.9806 ...",
      "Yes person 7 was detected by MSRCC with a MSRCC-9 value of -0.9806 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.9806 ... Yes person 7 was detected by MSRCC with a shap value of -0.9806 ...",
      "Yes person 7 was detected by MSRCC with a shap value of shap ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ... Yes person 7 was detected by MSRCC with a shap value of -0.9806 ...",
      "Yes person  was detected by MSRCC with a shap value of -0.9806 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.9806 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9806 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-10], shap_value[0])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.2062 ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "sh determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.2062 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.2062 ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-10 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-23], shap_value[-0.9787])",
    "ref": [
      "There is evidence of sampling ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "LFCC-23 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-23 ...",
      "There is evidence of sampling ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "There is evidence of sampling ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "LFCC-23 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9787 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-23 ], <shap_value> shap value: [ -0.9787 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-36], classification[bonafide], shap_value[-0.1149])",
    "ref": [
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of -0.1149 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.1149 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ... Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1149 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-39], interpreter[shap], shap_value[-0.549])",
    "ref": [
      "Yes LFCC which a shap value of -0.549 was used to detect the id of speaker LFCC-39 for the audio sample ...",
      "Yes LFCC which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0. was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "Yes LFCC which a sha value of -0.549 was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ... Yes LFCC which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ... Yes LFCC which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a yes value of -0.549 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.549 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.549 was used to detect the id of speaker LFCC-39 for the audio sample ...",
      "Yes LFCC which a shap value of -0.549 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.549 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-10], shap_value[0.5528])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ...",
      "Yes the recording was found to be spoofed... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ...",
      "0.5528 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes the recording was found to be spoofed...",
      " determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ...",
      "Yes the recording was found to be spoofed... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5528 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-10 ], <shap_value> shap value: [ 0.5528 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-23], classification[bonafide], shap_value[0.514])",
    "ref": [
      "Ye LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of LFCC-23 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.514 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.514 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.514 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-23 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.514 ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide])",
    "ref": [
      "bonafide it is not a bona fide recording ...",
      "No it is a bona fide recording ...",
      " it is not a bona fide recording ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... No it is not a bona fide recording ...",
      "No it is not a bona fide recording ... No it is not a bona fide recording ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "bonafide it is not a bona fide recording ...",
      "No it is a bona fide recording ...",
      " it is not a bona fide recording ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... No it is not a bona fide recording ...",
      "No it is not a bona fide recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-5], classification[bonafide], shap_value[0.767])",
    "ref": [
      "shap LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "There are different CaptureDevice signatures ... Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.767 was used to detect the sample as Audio_signal ...",
      "There are different CaptureDevice signatures ...",
      " LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.767 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.767 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.767 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-8], classification[replayed], shap_value[0.5604], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a CNN value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a sh value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "LFCC-8 LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.56 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of 0.5604 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5604 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-37], interpreter[shap], shap_value[0.2651])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of  ...",
      "It appears that part of the audio was sped up ...",
      "Yes person  was detected by MFCC with a shap value of 0.651 ...",
      "Yes person 2 was detected by MFCC with a MFCC-37 value of 0.2651 ...",
      "It appears that part of the audio was sped up ... Yes person 2 was detected by MFCC with a shap value of 0.2651 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.2651 ... Yes person 2 was detected by MFCC with a shap value of 0.2651 ...",
      "Yes person 2 was detected by MFCC with a sha value of 0.2651 ...",
      "Yes person 0.2651 was detected by MFCC with a shap value of 0.0.2651651 ...",
      "Yes person 2 was detected by MFCC with a shap value of shap ...",
      "Yes person 2 was detected by MFCC with a shap value of  ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.2651 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2651 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[copy])",
    "ref": [
      "Part of the audio was played back ... Part of the audio was played back ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ... Part of the audio was played back ...",
      "Part of the audio was played back ... Part of the audio was played back ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ... Part of the audio was played back ...",
      "Part of the audio was played back ... Part of the audio was played back ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ... Part of the audio was played back ...",
      "Part of the audio was played back ... Part of the audio was played back ...",
      "Part of the audio was played back ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ copy ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-17], interpreter[shap], shap_value[0.7883])",
    "ref": [
      "Yes person LFCC-17 was detected by LFCC with a shap value of 0.7883 ...",
      "Yes person 1 was detected by LFCC with a shap value of shap ...",
      "Yes person 6 was detected by GTCC with a shap value of 0 ... Yes person 1 was detected by LFCC with a shap value of 0.7883 ...",
      "Yes person 1 was detected by LFCC with a 1 value of 0.7883 ...",
      "Yes person 6 was detected by GTCC with a shap value of 0 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7883 ... Yes person 1 was detected by LFCC with a shap value of 0.7883 ...",
      "Yes person  was detected by LFCC with a shap value of 0.7883 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0 ...",
      "Yes person 1 was detected by LFCC with a s value of 0.7883 ...",
      "Yes person LFCC-17 was detected by LFCC with a shap value of 0.7883 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7883 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7883 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], classified_by[feature], detected_by[CNN])",
    "ref": [
      "Other features also show the audio sample was PhysicalAccess was detected by CNN ... Other features also show the audio sample was PhysicalAccess was detected by CNN ...",
      "Other features also show the audio sample was PhysicalAccess was detected by spoof ...",
      "The audio is converted ...",
      "Other features also show the audio sample was PhysicalAccess was detected by CN ...",
      "Other CNNs also show the audio sample was PhysicalAccess was detected by CNN ...",
      "Other feas also show the audio sample was PhysicalAccess was detected by CNN ...",
      "The audio is converted ... Other features also show the audio sample was PhysicalAccess was detected by CNN ...",
      "Other features also show the audio sample was PhysicalAccess was detected by CNN ... Other features also show the audio sample was PhysicalAccess was detected by CNN ...",
      "Other features also show the audio sample was PhysicalAccess was detected by spoof ...",
      "The audio is converted ...",
      "Other features also show the audio sample was PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-14], interpreter[shap], shap_value[-0.2405])",
    "ref": [
      "Yes person 7 was detected by LFCC with a LFCC-14 value of -0.2405 ...",
      "Yes person 7 was detected by LFCC with a shap value of shap ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2405 ... Yes person 7 was detected by LFCC with a shap value of -0.2405 ...",
      "Yes person 7 was detected by LFCC with a sha value of -0.2405 ...",
      "Yes person -0.2405 was detected by LFCC with a shap value of -0.2405 ...",
      "Yes person  was detected by LFCC with a shap value of -0.2405 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ... Yes person 7 was detected by LFCC with a shap value of -0.2405 ...",
      "Yes person 7 was detected by LFCC with a shap value of  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 8 ...",
      "Yes person 7 was detected by LFCC with a LFCC-14 value of -0.2405 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2405 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2405 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-2], classification[bonafide], shap_value[-0.7602])",
    "ref": [
      " MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.760 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ... Yes MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a  value of -0.7602 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a Yes value of -0.7602 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "MSRCC-2 MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      " MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.7602 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7602 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], classified_by[feature])",
    "ref": [
      "Several features showed the EnvironmentSignature signature ... Several features showed the EnvironmentSignature signature ...",
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Several environments showed the EnvironmentSignature signature ...",
      "Several featus showed the EnvironmentSignature signature ...",
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ... Several features showed the EnvironmentSignature signature ...",
      "Several features showed the EnvironmentSignature signature ... Several features showed the EnvironmentSignature signature ...",
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Several environments showed the EnvironmentSignature signature ...",
      "Several featus showed the EnvironmentSignature signature ...",
      "Yes MFCC which a shap value of -0.8137 was used to detect the sample as PhysicalAccess was detected by CNN ... Several features showed the EnvironmentSignature signature ...",
      "Several features showed the EnvironmentSignature signature ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed .",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Subband Spectral Flux Coefficients are calculated by First the subband spectral flux SSF of the i-th subband of the t-th Acoustic_Wave frame is computed . Then SSFCs are then obtained by performing logarithm and DCT on the SSFs ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-8], shap_value[-0.4934])",
    "ref": [
      "-0.4934 determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "Yes the recording is PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ...",
      "Yes the recording is PhysicalAccess was detected by CNN ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ...",
      "-0.4934 determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.4934 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <shap_value> shap value: [ -0.4934 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3294 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-9], classification[bonafide], shap_value[-0.4455])",
    "ref": [
      "Yes MFCC which a Yes value of -0.4455 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4455 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4455 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.44 was used to detect the sample as Audio_signal ...",
      "It seems like a computer was used ... Yes MFCC which a shap value of -0.4455 was used to detect the sample as Audio_signal ...",
      "It seems like a computer was used ...",
      "Yes MFCC which a shap value of MFCC-9 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of -0.4455 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of -0.4455 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of -0.4455 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.4455 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4455 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4455 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-10], shap_value[-0.0298])",
    "ref": [
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-10 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "-0.0298 determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0298 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-10 ], <shap_value> shap value: [ -0.0298 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-21], classification[replayed], shap_value[0.0724], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.07 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a shap value of 0.0724 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0724 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[5])",
    "ref": [
      "person  was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... person 5 was detected as the primary speaker of the audio sample ...",
      "person 5 was detected as the primary speaker of the audio sample ... person 5 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... person 5 was detected as the primary speaker of the audio sample ...",
      "person 5 was detected as the primary speaker of the audio sample ... person 5 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "person 5 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ... Features in the audio show there were two microphones used ...",
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ... Features in the audio show there were two microphones used ...",
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ... Features in the audio show there were two microphones used ...",
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "Yes PSRCC which a shap value of 0.8682 was used to detect the sample as Audio_signal ...",
      "Features in the audio show there were two microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-20], classification[bonafide], shap_value[0.0087])",
    "ref": [
      "Dynamic microphones were used the most ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "0.0087 MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a 0.0087 value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Dynamic microphones were used the most ... Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Dynamic microphones were used the most ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-20 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0087 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-11], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-51], interpreter[shap], shap_value[-0.5435])",
    "ref": [
      "Yes LFCC which a shap value of -0.LFCC-5143LFCC-51 was used to detect the id of speaker LFCC-51 for the audio sample ...",
      "Yes LFCC which a shap value of -0.54 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a sh value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a LFCC-51 value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.2208 ... Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.43 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.LFCC-5143LFCC-51 was used to detect the id of speaker LFCC-51 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-51 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5435 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-30], interpreter[shap], shap_value[0.2213])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Yes LFCC which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.221 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.221shap was used to detect the id of speaker shap for the audio sample ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Yes LFCC which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a yes value of 0.2213 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a  value of 0.2213 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 3 for the audio sample ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Yes LFCC which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2213 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2213 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-37], interpreter[shap], shap_value[-0.6786])",
    "ref": [
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a yes value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of  was used to detect the id of speaker 4 for the audio sample ...",
      "There were no other spoof types ... Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a sh value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "There were no other spoof types ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker MFCC-37 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6786 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-45], classification[bonafide], shap_value[-0.9902])",
    "ref": [
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.9902 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-45 value of -0.9902 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9902 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-45 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9902 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-19], interpreter[shap], shap_value[-0.5025])",
    "ref": [
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.50 ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... Yes person 5 was detected by MFCC with a shap value of -0.5025 ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.5025 ... Yes person 5 was detected by MFCC with a shap value of -0.5025 ...",
      "Yes person 5 was detected by MFCC with a 5 value of -0.5025 ...",
      "Yes person 5 was detected by MFCC with a shap value of shap ...",
      "Yes person -0.5025 was detected by MFCC with a shap value of -0.-0.502502-0.5025 ...",
      "Yes person 5 was detected by MFCC with a s value of -0.5025 ...",
      "Yes person  was detected by MFCC with a shap value of -0.02 ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.5025 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5025 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-12], classification[bonafide], shap_value[-0.3641])",
    "ref": [
      "Yes MFCC which a shap value of MFCC-12 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of -0.3641 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.3641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.3641 was used to detect the sample as Audio_signal ...",
      "MFCC-12 MFCC which a shap value of -0.3641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.3641 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.3641 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of -0.3641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.36 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-12 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.3641 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3641 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... The signal is consistent with a cloned voice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... The signal is consistent with a cloned voice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... The signal is consistent with a cloned voice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-35], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-35 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-35 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-35 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-1], classification[bonafide], shap_value[0.1274])",
    "ref": [
      "Yes PSRCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-1 value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Y PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a  value of 0.1274 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "0.1274 PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.8242 ... Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1274 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], signal_length[5])",
    "ref": [
      "That CaptureDevice was used for  seconds ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for multi_microphone seconds ...",
      "No ..",
      "No .. That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for  seconds ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for multi_microphone seconds ...",
      "No ..",
      "No .. That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for 5 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <signal_length> signal length: [ 5 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-48], shap_value[0.7218])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.721 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "Spectral Centroid physicalattribute Coefficients ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "LFCC-48 determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "Spectral Centroid physicalattribute Coefficients ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.721 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7218 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-48 ], <shap_value> shap value: [ 0.7218 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ... Linear physicalattribute Cepstral Coefficients ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ... Linear physicalattribute Cepstral Coefficients ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ... Linear physicalattribute Cepstral Coefficients ...",
      "Yes PSRCC which a shap value of 0.1274 was used to detect the sample as Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "Linear physicalattribute Cepstral Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], num_samples[3], detected_by[CNN])",
    "ref": [
      "It has been PhysicalAccess was detected by CNN and re-recorded sampling times ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ...",
      "It has been PhysicalAccess was detected by sampling and re-recorded 3 times ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by  and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded sampling times ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <num_samples> num samples: [ 3 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The breathing rate changes",
      "The breathing rate changes The breathing rate changes",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The breathing rate changes",
      "The breathing rate changes The breathing rate changes",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The breathing rate changes",
      "The breathing rate changes The breathing rate changes",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The breathing rate changes",
      "The breathing rate changes"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-18], classification[bonafide], shap_value[-0.8228])",
    "ref": [
      " LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.8228 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of -0.8228 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Yes LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-18 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      " LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8228 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-18 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8228 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer], change_at[7])",
    "ref": [
      "The synthesized Acoustic_Wave starts at 7 seconds .. The synthesized Acoustic_Wave starts at 7 seconds ..",
      "It appears that the recording was spliced .. The synthesized Acoustic_Wave starts at 7 seconds ..",
      "The synthesized Acoustic_Wave starts at  seconds ..",
      "It appears that the recording was spliced ..",
      "The synthesized Acoustic_Wave starts at spoof seconds ..",
      "The synthesized Acoustic_Wave starts at 7 seconds .. The synthesized Acoustic_Wave starts at 7 seconds ..",
      "It appears that the recording was spliced .. The synthesized Acoustic_Wave starts at 7 seconds ..",
      "The synthesized Acoustic_Wave starts at  seconds ..",
      "It appears that the recording was spliced ..",
      "The synthesized Acoustic_Wave starts at spoof seconds ..",
      "The synthesized Acoustic_Wave starts at 7 seconds .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ], <change_at> change at: [ 7 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-13], classification[replayed], shap_value[0.2183], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a 0.2183 value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a  value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-13 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by 0.2183 ...",
      "Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2183 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2183 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "A  was used to edit the audio",
      "A spoof was used to edit the audio",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A computer was used to edit the audio A computer was used to edit the audio",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... A computer was used to edit the audio",
      "A  was used to edit the audio",
      "A spoof was used to edit the audio",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A computer was used to edit the audio A computer was used to edit the audio",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... A computer was used to edit the audio",
      "A computer was used to edit the audio"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "CNN the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Ye the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by replayed recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by CN recording was a PhysicalAccess recording ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "CNN the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-58], interpreter[shap], shap_value[0.3804])",
    "ref": [
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a yes value of 0.3804 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ... Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes .",
      "Yes . Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.38 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a sha value of 0.3804 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.3804 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-58 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3804 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-24], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-24 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio signal shows signs of it .. the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio signal shows signs of it ..",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio signal shows signs of it .. the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio signal shows signs of it ..",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ... It appears that part of the audio was sped up ...",
      "It appears that part of the audio was sped up ... It appears that part of the audio was sped up ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ... It appears that part of the audio was sped up ...",
      "It appears that part of the audio was sped up ... It appears that part of the audio was sped up ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ... It appears that part of the audio was sped up ...",
      "It appears that part of the audio was sped up ... It appears that part of the audio was sped up ...",
      "Yes MFCC which a shap value of 0.8748 was used to detect the id of speaker 3 for the audio sample ...",
      "It appears that part of the audio was sped up ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-4], shap_value[0.7907])",
    "ref": [
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "MSRCC-4 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "sh determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-4 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of  ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "MSRCC-4 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "sh determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <shap_value> shap value: [ 0.7907 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-7], classification[bonafide], shap_value[0.3274])",
    "ref": [
      "Yes LFCC which a shap value of 0.32 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2379 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.32 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3274 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Mel physicalattribute Cepstral Coefficients ... Mel physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Mel physicalattribute Cepstral Coefficients ...",
      "Mel physicalattribute Cepstral Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-21], interpreter[shap], shap_value[-0.6054])",
    "ref": [
      "Some of the recording was made using a computer ... Yes person 5 was detected by LFCC with a shap value of -0.6054 ...",
      "Yes person 5 was detected by LFCC with a shap value of - ...",
      "Yes person shap was detected by LFCC with a shap value of -0.60shap4 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.6054 ... Yes person 5 was detected by LFCC with a shap value of -0.6054 ...",
      "Yes person  was detected by LFCC with a shap value of -0.604 ...",
      "Yes person 5 was detected by LFCC with a yes value of -0.6054 ...",
      "Yes person 5 was detected by LFCC with a sha value of -0.6054 ...",
      "Some of the recording was made using a computer ...",
      "Yes person 5 was detected by LFCC with a shap value of 5 ...",
      "Some of the recording was made using a computer ... Yes person 5 was detected by LFCC with a shap value of -0.6054 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.6054 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6054 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-14], shap_value[-0.1931])",
    "ref": [
      "MFCC-14 determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "The audio sample was passed to a modeltype Abstract for classification ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "The audio sample was passed to a modeltype Abstract for classification ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0. ...",
      "MFCC-14 determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.1931 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <shap_value> shap value: [ -0.1931 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes voice cloning was used ... Yes voice cloning was used ...",
      "Yes voice clon was used ...",
      "Yes voice Yes was used ...",
      "spoofed voice cloning was used ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ... Yes voice cloning was used ...",
      "Y voice cloning was used ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.2841 ...",
      "Yes voice cloning was used ... Yes voice cloning was used ...",
      "Yes voice clon was used ...",
      "Yes voice Yes was used ...",
      "Yes voice cloning was used ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[2], speaker_start[30])",
    "ref": [
      "The next person starts speaking at 3 seconds ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ... The next person starts speaking at 30 seconds ..",
      "The next person starts speaking at multi_speaker seconds ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "The next person starts speaking at 30 seconds .. The next person starts speaking at 30 seconds ..",
      "The next person starts speaking at 3 seconds ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ... The next person starts speaking at 30 seconds ..",
      "The next person starts speaking at multi_speaker seconds ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "The next person starts speaking at 30 seconds .. The next person starts speaking at 30 seconds ..",
      "The next person starts speaking at 30 seconds .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ 2 ], <speaker_start> speaker start: [ 30 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-6], classification[replayed], shap_value[0.5663], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "MSRCC-6 MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a sh value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a 0.5663 value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      " MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5663 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-4], classification[bonafide], shap_value[0.665])",
    "ref": [
      "Yes MSRCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      " MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a bonafide value of 0.665 was used to detect the sample as Audio_signal ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.3913 ...",
      "Yes MSRCC which a  value of 0.665 was used to detect the sample as Audio_signal ...",
      "0.665 MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.3913 ... Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of MSRCC-4 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.665 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.665 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... The audio is converted ...",
      "The audio is converted ... The audio is converted ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... The audio is converted ...",
      "The audio is converted ... The audio is converted ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... The audio is converted ...",
      "The audio is converted ... The audio is converted ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "The audio is converted ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-32], classification[bonafide], shap_value[-0.2438])",
    "ref": [
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ...",
      "MFCC-32 MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.24 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a -0.2438 value of -0.2438 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of MFCC-32 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of -0.2438 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.2438 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2438 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess sample .. The Audio_signal was detected by CNN audio was not a PhysicalAccess sample ..",
      "The Audio_signal was detected by C audio was not a PhysicalAccess sample ..",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess sample ..",
      "Yes person 7 was detected by LFCC with a shap value of 0.7479 ...",
      "The Audio_signal was detected by bonafide audio was not a PhysicalAccess sample ..",
      "Yes person 7 was detected by LFCC with a shap value of 0.7479 ... The Audio_signal was detected by CNN audio was not a PhysicalAccess sample ..",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess sample .. The Audio_signal was detected by CNN audio was not a PhysicalAccess sample ..",
      "The Audio_signal was detected by C audio was not a PhysicalAccess sample ..",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess sample ..",
      "Yes person 7 was detected by LFCC with a shap value of 0.7479 ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess sample .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The area of synthesized Acoustic_Wave is 11 seconds long .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The area of synthesized Acoustic_Wave is 11 seconds long .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The area of synthesized Acoustic_Wave is 11 seconds long .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-1 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-59], shap_value[0.8351])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-59 ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values .",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "0.8351 determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-59 ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-59 ], <shap_value> shap value: [ 0.8351 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-8], shap_value[0.7203])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "sha determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.720 ...",
      "MSRCC-8 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-8 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "sha determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <shap_value> shap value: [ 0.7203 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-6], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person shap was detected by GTCC with a shap value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 3 was detected by GTCC with a sh value of 0 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 3 was detected by GTCC with a shap value of 0 ...",
      "Yes person 3 was detected by GTCC with a shap value of  ...",
      "Yes person 3 was detected by GTCC with a yes value of 0 ...",
      "Yes person 3 was detected by GTCC with a shap value of GTCC-6 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 3 was detected by GTCC with a shap value of 0 ... Yes person 3 was detected by GTCC with a shap value of 0 ...",
      "Yes person shap was detected by GTCC with a shap value of 0 ...",
      "Yes person 3 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-30], interpreter[shap], shap_value[-0.8651])",
    "ref": [
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... Yes person 6 was detected by MFCC with a shap value of -0.8651 ...",
      "Yes person 6 was detected by MFCC with a shap value of  ...",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "Yes person  was detected by MFCC with a shap value of -0.851 ...",
      "Yes person yes was detected by MFCC with a shap value of -0.8yes51 ...",
      "Yes person 6 was detected by MFCC with a sh value of -0.8651 ...",
      "Yes person 6 was detected by MFCC with a MFCC-30 value of -0.8651 ...",
      "Yes person 6 was detected by MFCC with a shap value of yes ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.8651 ... Yes person 6 was detected by MFCC with a shap value of -0.8651 ...",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... Yes person 6 was detected by MFCC with a shap value of -0.8651 ...",
      "Yes person 6 was detected by MFCC with a shap value of -0.8651 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8651 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-3], classification[replayed], shap_value[0.2359], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by 0.2359 ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by  ...",
      "replayed MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.23 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a sha value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2359 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-45], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There are inconsistencies in the number of people speaking ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-45 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Due to the weighting function the two signals would each be represented by different SCF and SCM values . Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Due to the weighting function the two signals would each be represented by different SCF and SCM values . Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . Due to the weighting function the two signals would each be represented by different SCF and SCM values . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0844 was used to detect the sample as PhysicalAccess was detected by CNN ... Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ...",
      "Spectral centroid physicalattribute SCM is the weighted average magnitude for a given subband where the weights are the frequency of each magnitude component in that subband . SCM captures to a first order approximation the distribution of energy in a subband for two arbitrary signals with the same average energy . Due to the weighting function the two signals would each be represented by different SCF and SCM values . The different steepness of the weighting function with respect to the subband bandwidth may also be noted this results in different feature element variances . As the spectral centroid magnitude is the magnitude at the position of the spectral centroid frequency it will carry formant related information which is useful for speaker recognition ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-38], interpreter[shap], shap_value[-0.1123])",
    "ref": [
      "Yes MFCC which a yes value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.11 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a sha value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a yes value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1123 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-35], classification[bonafide], shap_value[-0.6957])",
    "ref": [
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of -0.6957 was used to detect the sample as Audio_signal ...",
      "shap MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a -0.6957 value of -0.6957 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.1088 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6957 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-35 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6957 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It seems like a compu was used ...",
      "It seems like a computer was used ... It seems like a computer was used ...",
      "It seems like a spoof was used ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It seems like a computer was used ...",
      "It seems like a compu was used ...",
      "It seems like a computer was used ... It seems like a computer was used ...",
      "It seems like a spoof was used ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It seems like a computer was used ...",
      "It seems like a computer was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-25], classification[replayed], shap_value[0.2955], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a  value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "CNN LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a shap value of 0.29 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of 0.2955 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2955 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "The recording has been tampered with ... The recording has been tampered with ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... The recording has been tampered with ...",
      "The recording has been tampered with ... The recording has been tampered with ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... The recording has been tampered with ...",
      "The recording has been tampered with ... The recording has been tampered with ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... The recording has been tampered with ...",
      "The recording has been tampered with ... The recording has been tampered with ...",
      "The recording has been tampered with ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], model[CNN])",
    "ref": [
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-0], classification[replayed], shap_value[0.3118], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "0.3118 MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a 0.3118 value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3118 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3118 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-38], classification[bonafide], shap_value[0.5641])",
    "ref": [
      "Yes MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-38 value of 0.5641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ... Yes MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of 0.5641 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.3503 was used to detect the id of speaker 5 for the audio sample ...",
      "MFCC-38 MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.564 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5641 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-38 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5641 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-5], interpreter[shap], shap_value[0.9355])",
    "ref": [
      "Yes person yes was detected by LFCC with a shap value of 0.9yes55 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.935 ...",
      "Yes person 3 was detected by LFCC with a shap value of LFCC-5 ...",
      "Yes person 3 was detected by LFCC with a 0.9355 value of 0.9355 ...",
      "Yes person  was detected by LFCC with a shap value of 0.955 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.9355 ... Yes person 3 was detected by LFCC with a shap value of 0.9355 ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ... Yes person 3 was detected by LFCC with a shap value of 0.9355 ...",
      "Yes person 3 was detected by LFCC with a s value of 0.9355 ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Yes person yes was detected by LFCC with a shap value of 0.9yes55 ...",
      "Yes person 3 was detected by LFCC with a shap value of 0.9355 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9355 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-12], shap_value[-0.3688])",
    "ref": [
      "Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ...",
      "-0.3688 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ...",
      "-0.3688 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.3688 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-12 ], <shap_value> shap value: [ -0.3688 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-9], classification[replayed], shap_value[-0.1353], detected_by[CNN])",
    "ref": [
      "CNN MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is an unusually long pause at 37 seconds ... Yes MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a sha value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a Yes value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is an unusually long pause at 37 seconds ...",
      "Yes MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MSRCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.1353 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1353 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[8])",
    "ref": [
      "person 8 was detected as the primary speaker of the audio sample ... person 8 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at 37 seconds ... person 8 was detected as the primary speaker of the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ... person 8 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "There is an unusually long pause at 37 seconds ...",
      "There is an unusually long pause at 37 seconds ... person 8 was detected as the primary speaker of the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ... person 8 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "person 8 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], detected_by[CNN])",
    "ref": [
      "Y this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by CNN recording Yes this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by spoofed recording",
      "CNN this is a Audio_signal was detected by CNN recording",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ... Yes this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by  recording",
      "Yes MSRCC which a shap value of -0.007 was used to detect the id of speaker 2 for the audio sample ...",
      "Y this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by CNN recording Yes this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by spoofed recording",
      "Yes this is a Audio_signal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8694 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-46], interpreter[shap], shap_value[-0.655])",
    "ref": [
      "Yes LFCC which a sh value of -0.655 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.6shapshap was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a LFCC-46 value of -0.655 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a sh value of -0.655 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.655 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-46 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.655 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-10], shap_value[-0.331])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0. ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ...",
      "-0.331 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0. ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <shap_value> shap value: [ -0.331 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-31], classification[bonafide], shap_value[-0.0632])",
    "ref": [
      "Yes LFCC which a  value of -0.0632 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.0632 was used to detect the sample as Audio_signal ...",
      "-0.0632 LFCC which a shap value of -0.0632 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.063 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.0632 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.0632 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.0632 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.0632 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.0632 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.0632 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-31 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0632 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-11], interpreter[shap], shap_value[-0.3192])",
    "ref": [
      "Yes MFCC which a shap value of -0.192 was used to detect the id of speaker  for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a s value of -0.3192 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.319 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.shap192 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a MFCC-11 value of -0.3192 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.192 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.3192 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3192 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-5], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-6], interpreter[shap], shap_value[0.5455])",
    "ref": [
      "Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ... Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5MSRCC-655 was used to detect the id of speaker MSRCC-6 for the audio sample ...",
      "Yes MSRCC which a 0.5455 value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a sh value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.555 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of MSRCC-6 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ... Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.5455 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5455 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-3], interpreter[shap], shap_value[-0.2342])",
    "ref": [
      "Yes person 7 was detected by LFCC with a sha value of -0.2342 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ... Yes person 7 was detected by LFCC with a shap value of -0.2342 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2342 ... Yes person 7 was detected by LFCC with a shap value of -0.2342 ...",
      "Yes person 7 was detected by LFCC with a LFCC-3 value of -0.2342 ...",
      "Yes person shap was detected by LFCC with a shap value of -0.2342 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2 ...",
      "Yes person 7 was detected by LFCC with a shap value of LFCC-3 ...",
      "Yes person  was detected by LFCC with a shap value of -0.2342 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "Yes person 7 was detected by LFCC with a sha value of -0.2342 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2342 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2342 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-22], classification[bonafide], shap_value[0.6472])",
    "ref": [
      "Yes MFCC which a  value of 0.6472 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.6472 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.6472 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.6472 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.6 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a 0.6472 value of 0.6472 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ... Yes MFCC which a shap value of 0.6472 was used to detect the sample as Audio_signal ...",
      "0.6472 MFCC which a shap value of 0.6472 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.6472 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.6472 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-22 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6472 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[converted])",
    "ref": [
      "Yes the recording is converted ... Yes the recording is converted ...",
      " the recording is converted ...",
      "Yes the recording is co ...",
      "Yes the recording is spoof ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ...",
      "spoof the recording is converted ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0969 ... Yes the recording is converted ...",
      "Yes the recording is converted ... Yes the recording is converted ...",
      " the recording is converted ...",
      "Yes the recording is co ...",
      "Yes the recording is converted ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ converted ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... Artificial noise was added ..",
      "Artificial noise was added .. Artificial noise was added ..",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... Artificial noise was added ..",
      "Artificial noise was added .. Artificial noise was added ..",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... Artificial noise was added ..",
      "Artificial noise was added .. Artificial noise was added ..",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Artificial noise was added .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(classification[spoofed], model[CNN], detected_by[CNN])",
    "ref": [
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being synthetic by a MixtureModel Abstract ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <model> model: [ CNN ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-5], classification[bonafide], shap_value[0.2383])",
    "ref": [
      "Yes PSRCC which a PSRCC-5 value of 0.2383 was used to detect the sample as Audio_signal ...",
      "shap PSRCC which a shap value of 0.2383 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.238 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ...",
      "Yes PSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.2383 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.2383 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a sha value of 0.2383 was used to detect the sample as Audio_signal ...",
      " PSRCC which a shap value of 0.2383 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2454 ... Yes PSRCC which a shap value of 0.2383 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-5 value of 0.2383 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.2383 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2383 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-11], shap_value[0.6078])",
    "ref": [
      "Dynamic microphones were used the most ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-11 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6 ...",
      "0.6078 determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ...",
      "Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-11 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6078 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-11 ], <shap_value> shap value: [ 0.6078 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-33], classification[replayed], shap_value[-0.2295], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.3913 ...",
      "shap LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by MFCC with a shap value of -0.3913 ... Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a LFCC-33 value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by -0.2295 ...",
      "Yes LFCC which a shap value of -0.2295 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-33 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2295 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-9], classification[replayed], shap_value[0.9541], detected_by[CNN])",
    "ref": [
      "Y PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a s value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes PSRCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.95 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.9541 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9541 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-54], classification[replayed], shap_value[0.1406], detected_by[CNN])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of 0.4133 ... Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.1406 LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a CNN value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4133 ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1406 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-17], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-17 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[synthetic], detected_by[CNN])",
    "ref": [
      "Yes the Audio_signal was detected by CNN recording was a CNN recording ...",
      "Yes the Audio_signal was detected by CNN recording was a s recording ...",
      "Yes the Audio_signal was detected by CN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "That CaptureDevice was used for 5 seconds ...",
      "Yes the Audio_signal was detected by Yes recording was a synthetic recording ...",
      " the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "spoofed the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "That CaptureDevice was used for 5 seconds ... Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a CNN recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-12], interpreter[shap], shap_value[0.9499])",
    "ref": [
      "Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ... Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a s value of 0.9499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 0.9499 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of shap was used to detect the id of speaker 5 for the audio sample ...",
      "The recording appears to be a copy ..",
      "Yes MSRCC which a shap value of 0. was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a MSRCC-12 value of 0.9499 was used to detect the id of speaker 5 for the audio sample ...",
      "The recording appears to be a copy .. Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ... Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.9499 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9499 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-9], classification[bonafide], shap_value[-1])",
    "ref": [
      "Yes GTCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a bonafide value of -1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "-1 GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a  value of -1 was used to detect the sample as Audio_signal ...",
      " GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-5], classification[bonafide], shap_value[0.1237])",
    "ref": [
      "Yes MFCC which a  value of 0.1237 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ...",
      "Yes MFCC which a shap value of 0.1237 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.1237 was used to detect the sample as Audio_signal ...",
      "MFCC-5 MFCC which a shap value of 0.1237 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7203 ... Yes MFCC which a shap value of 0.1237 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of 0.1237 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-5 value of 0.1237 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-5 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.1237 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.1237 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1237 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-12], classification[bonafide], shap_value[-0.5073])",
    "ref": [
      "person 5 was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of -0.5 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of PSRCC-12 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-12 value of -0.5073 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a s value of -0.5073 was used to detect the sample as Audio_signal ...",
      "shap PSRCC which a shap value of -0.5073 was used to detect the sample as Audio_signal ...",
      "person 5 was detected as the primary speaker of the audio sample ... Yes PSRCC which a shap value of -0.5073 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.5073 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.5073 was used to detect the sample as Audio_signal ...",
      "Ye PSRCC which a shap value of -0.5073 was used to detect the sample as Audio_signal ...",
      "person 5 was detected as the primary speaker of the audio sample ...",
      "Yes PSRCC which a shap value of -0.5073 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5073 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-9], shap_value[-0.4534])",
    "ref": [
      "Yes the recording has been tampered with ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ...",
      "MSRCC-9 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ...",
      "Yes the recording has been tampered with ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0 ...",
      "Yes the recording has been tampered with ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.4534 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-9 ], <shap_value> shap value: [ -0.4534 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-54], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-54 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-15], interpreter[shap], shap_value[-0.7171])",
    "ref": [
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.717 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.77 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a  value of -0.7171 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ...",
      "person 2 was detected as the primary speaker of the audio sample ... Yes MFCC which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7shap7shap was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a MFCC-15 value of -0.7171 was used to detect the id of speaker 1 for the audio sample ...",
      "person 2 was detected as the primary speaker of the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7171 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7171 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-1], determined[speaker_id])",
    "ref": [
      "ye GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "ye GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-1 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-34], shap_value[-0.9876])",
    "ref": [
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "LFCC-34 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.2391 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.2391 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-34 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "LFCC-34 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9876 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <shap_value> shap value: [ -0.9876 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-49], shap_value[-0.6011])",
    "ref": [
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "-0.6011 determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-49 ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "-0.6011 determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6011 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-49 ], <shap_value> shap value: [ -0.6011 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-21], classification[replayed], shap_value[0.2522], detected_by[CNN])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3678 ...",
      "Yes LFCC which a sh value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.25 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      " LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a LFCC-21 value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2522 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2522 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-18], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-18 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-1], interpreter[shap], shap_value[0.1017])",
    "ref": [
      "Yes MSRCC which a shap value of 0.1 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ... Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a  value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "There appears to be a cloned voice on the audio ... Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "There appears to be a cloned voice on the audio ...",
      "Yes MSRCC which a 0.1017 value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker MSRCC-1 for the audio sample ...",
      "Yes MSRCC which a shap value of MSRCC-1 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1017 ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_at[5])",
    "ref": [
      "That CaptureDevice was used for spoof seconds ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for  seconds ...",
      "Yes the recording has been tampered with ...",
      "Yes the recording has been tampered with ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for spoof seconds ...",
      "That CaptureDevice was used for 5 seconds ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for  seconds ...",
      "Yes the recording has been tampered with ...",
      "Yes the recording has been tampered with ... That CaptureDevice was used for 5 seconds ...",
      "That CaptureDevice was used for 5 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_at> change at: [ 5 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-56], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-56 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution .",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV .  The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Different from STFT CQT produces a timefrequency Abstract with variable resolution . Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ...",
      "Constant-Q transform CQT has been applied in music signal processing spoofing detection as well in ASV . Different from STFT CQT produces a timefrequency Abstract with variable resolution . The resulting CQT power Sequence is log-compressed and uniformly sampled followed by DCT to yield CQCCs ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-11], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-11 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-35], classification[replayed], shap_value[0.2867], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      " LFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.1149 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-35 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2867 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-11], interpreter[shap], shap_value[0.2062])",
    "ref": [
      "Yes person 5 was detected by MSRCC with a shap value of 0.2062 ... Yes person 5 was detected by MSRCC with a shap value of 0.2062 ...",
      "Yes person shap was detected by MSRCC with a shap value of 0.2062 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.2 ...",
      "Yes person 5 was detected by MSRCC with a shap value of yes ...",
      "Yes person 5 was detected by MSRCC with a sha value of 0.2062 ...",
      "There are inconsistencies in the number of people speaking ... Yes person 5 was detected by MSRCC with a shap value of 0.2062 ...",
      "There are inconsistencies in the number of people speaking ...",
      "Yes person  was detected by MSRCC with a shap value of 0.2062 ...",
      "Yes person 5 was detected by MSRCC with a yes value of 0.2062 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.2062 ... Yes person 5 was detected by MSRCC with a shap value of 0.2062 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.2062 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2062 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Some of the recording was made with a mobile device and some with a computer .. The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a computer .. The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a computer .. The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a computer .. The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[PSRCC-9], interpreter[shap], shap_value[0.5419])",
    "ref": [
      "8 was found to be the id of the speaker in the sample ... Yes person 1 was detected by PSRCC with a shap value of 0.5419 ...",
      "Yes person 1 was detected by PSRCC with a PSRCC-9 value of 0.5419 ...",
      "Yes person 1 was detected by PSRCC with a shap value of 0.5 ...",
      "Yes person  was detected by PSRCC with a shap value of 0.549 ...",
      "Yes person 1 was detected by PSRCC with a  value of 0.5419 ...",
      "8 was found to be the id of the speaker in the sample ...",
      "Yes person 1 was detected by PSRCC with a shap value of 1 ...",
      "Yes person PSRCC-9 was detected by PSRCC with a shap value of 0.54PSRCC-99 ...",
      "Yes person 1 was detected by PSRCC with a shap value of 0.5419 ... Yes person 1 was detected by PSRCC with a shap value of 0.5419 ...",
      "8 was found to be the id of the speaker in the sample ... Yes person 1 was detected by PSRCC with a shap value of 0.5419 ...",
      "Yes person 1 was detected by PSRCC with a shap value of 0.5419 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ PSRCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5419 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-44], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-44 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-11], classification[replayed], shap_value[-0.5401], detected_by[CNN])",
    "ref": [
      "Ye MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a -0.5401 value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-11 MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by C ...",
      "The recording seems to be at the same speed throughout .. Yes MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a s value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording seems to be at the same speed throughout ..",
      "Yes MFCC which a shap value of -0.5401 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5401 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Spectral Centroid physicalattribute Coefficients ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Spectral Centroid physicalattribute Coefficients ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Spectral Centroid physicalattribute Coefficients ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Spectral Centroid physicalattribute Coefficients ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoofed], spoof_type[synthetic], model[CNN])",
    "ref": [
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being CNN by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being synthet by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being CNN by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being synthet by a FeedforwardNeuralNetwork Abstract ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being synthetic by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-10], shap_value[-0.295])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "-0.295 determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.295 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-10 ], <shap_value> shap value: [ -0.295 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-2], classification[bonafide], shap_value[0.7584])",
    "ref": [
      "Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sh value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.1447 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-2 value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ...",
      "0.7584 MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.7584 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7584 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-28], shap_value[0.6599])",
    "ref": [
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "0.6599 determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-28 ], <shap_value> shap value: [ 0.6599 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-7], determined[speaker_id])",
    "ref": [
      "speaker_id GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.2809 was used to detect the sample as PhysicalAccess was detected by CNN ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-7 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-7], shap_value[0.7656])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-7 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ...",
      "0.7656 determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7656 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-7 ], <shap_value> shap value: [ 0.7656 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-36], interpreter[shap], shap_value[0.763])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "Yes person MFCC-36 was detected by MFCC with a shap value of 0.763 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... Yes person 4 was detected by MFCC with a shap value of 0.763 ...",
      "Yes person 4 was detected by MFCC with a sha value of 0.763 ...",
      "Yes person  was detected by MFCC with a shap value of 0.763 ...",
      "Yes person 4 was detected by MFCC with a shap value of 0 ...",
      "Yes person 4 was detected by MFCC with a shap value of 0.763 ... Yes person 4 was detected by MFCC with a shap value of 0.763 ...",
      "Yes person 4 was detected by MFCC with a 4 value of 0.763 ...",
      "Yes person 4 was detected by MFCC with a shap value of yes ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "Yes person 4 was detected by MFCC with a shap value of 0.763 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.763 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1], change_length[11])",
    "ref": [
      "The audio is artificially slowed ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long .. The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The audio is artificially slowed ... The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The area of synthesized Acoustic_Wave is 1 seconds long ..",
      "The area of synthesized Acoustic_Wave is multi_speaker seconds long ..",
      "The audio is artificially slowed ...",
      "The area of synthesized Acoustic_Wave is 11 seconds long .. The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The audio is artificially slowed ... The area of synthesized Acoustic_Wave is 11 seconds long ..",
      "The area of synthesized Acoustic_Wave is 1 seconds long ..",
      "The area of synthesized Acoustic_Wave is multi_speaker seconds long ..",
      "The area of synthesized Acoustic_Wave is 11 seconds long .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ], <change_length> change length: [ 11 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-40], interpreter[shap], shap_value[0.9939])",
    "ref": [
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker yes for the audio sample ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.0215 ... Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a MFCC-40 value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.99 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a  value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9939 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-50], classification[replayed], shap_value[-0.0361], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Y LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.036 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by -0.0361 ...",
      "Yes LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "shap LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0361 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-50 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0361 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[mobile_phone])",
    "ref": [
      " most of the recording was not made with a mobile phone ...",
      "No most of the recording was not made with a mobile phone ... No most of the recording was not made with a mobile phone ...",
      "spoof most of the recording was not made with a mobile phone ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... No most of the recording was not made with a mobile phone ...",
      "No most of the recording was made with a mobile phone ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      " most of the recording was not made with a mobile phone ...",
      "No most of the recording was not made with a mobile phone ... No most of the recording was not made with a mobile phone ...",
      "spoof most of the recording was not made with a mobile phone ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... No most of the recording was not made with a mobile phone ...",
      "No most of the recording was not made with a mobile phone ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[unknown])",
    "ref": [
      "I do recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ... I do not recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      "I do not recognize any of the CaptureDevice signatures ... I do not recognize any of the CaptureDevice signatures ...",
      "I do recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ... I do not recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ...",
      "I do not recognize any of the CaptureDevice signatures ... I do not recognize any of the CaptureDevice signatures ...",
      "I do recognize any of the CaptureDevice signatures ...",
      "Yes LFCC which a shap value of -0.3631 was used to detect the sample as Audio_signal ... I do not recognize any of the CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ unknown ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-21], interpreter[shap], shap_value[0.8559])",
    "ref": [
      "Yes person 3 was detected by MFCC with a s value of 0.8559 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ... Yes person 3 was detected by MFCC with a shap value of 0.8559 ...",
      "Yes person 3 was detected by MFCC with a 3 value of 0.8559 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.8 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7935 ... Yes person 3 was detected by MFCC with a shap value of 0.8559 ...",
      "Yes person 3 was detected by MFCC with a shap value of MFCC-21 ...",
      "Yes person 0.8559 was detected by MFCC with a shap value of 0.8559 ...",
      "Yes person  was detected by MFCC with a shap value of 0.8559 ...",
      "Yes person 3 was detected by MFCC with a s value of 0.8559 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.8559 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8559 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by  audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "person 4 spoke the audio sample ...",
      "The Audio_signal was detected by none audio was not a PhysicalAccess audio ...",
      "person 4 spoke the audio sample ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by  audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "person 4 spoke the audio sample ...",
      "The Audio_signal was detected by none audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes LFCC which a shap value of 0.9762 was used to detect the sample as PhysicalAccess was detected by CNN ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-13], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-13 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8416 was used to detect the id of speaker 6 for the audio sample ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-40], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.7907 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-40 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], detected_by[CNN])",
    "ref": [
      "This is a PhysicalAccess was detected by sampling and re-recorded sample ...",
      "This is a PhysicalAccess was detected by CNN and re-recorded sample ... This is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "Linear physicalattribute Cepstral Coefficients ... This is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "This is a PhysicalAccess was detected by  and re-recorded sample ...",
      "Linear physicalattribute Cepstral Coefficients ...",
      "This is a PhysicalAccess was detected by sampling and re-recorded sample ...",
      "This is a PhysicalAccess was detected by CNN and re-recorded sample ... This is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "Linear physicalattribute Cepstral Coefficients ... This is a PhysicalAccess was detected by CNN and re-recorded sample ...",
      "This is a PhysicalAccess was detected by  and re-recorded sample ...",
      "Linear physicalattribute Cepstral Coefficients ...",
      "This is a PhysicalAccess was detected by CNN and re-recorded sample ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-47], classification[bonafide], shap_value[0.299])",
    "ref": [
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.2 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.299 was used to detect the sample as Audio_signal ...",
      "The average perception gets higher in this section",
      "bonafide LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.299 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "The average perception gets higher in this section Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-47 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.299 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-47 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.299 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-40], shap_value[-0.3421])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-40 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "There is an unusually long pause at 37 seconds ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ...",
      "-0.3421 determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ...",
      "There is an unusually long pause at 37 seconds ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-40 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "There is an unusually long pause at 37 seconds ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3421 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-40 ], <shap_value> shap value: [ -0.3421 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-0], classification[bonafide], shap_value[0.0234])",
    "ref": [
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.0234 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "The signal is consistent with a cloned voice ... Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "The signal is consistent with a cloned voice ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0234 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0234 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[text_to_speech])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The audio shows signs of LogicalAccess involvement ...",
      "The audio shows signs of LogicalAccess involvement ... The audio shows signs of LogicalAccess involvement ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The audio shows signs of LogicalAccess involvement ...",
      "The audio shows signs of LogicalAccess involvement ... The audio shows signs of LogicalAccess involvement ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The audio shows signs of LogicalAccess involvement ...",
      "The audio shows signs of LogicalAccess involvement ... The audio shows signs of LogicalAccess involvement ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.5756 ... The audio shows signs of LogicalAccess involvement ...",
      "The audio shows signs of LogicalAccess involvement ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ text_to_speech ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "There was more than one person speaking .. There was more than one person speaking ..",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... There was more than one person speaking ..",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "There was more than one person speaking .. There was more than one person speaking ..",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... There was more than one person speaking ..",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "There was more than one person speaking .. There was more than one person speaking ..",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... There was more than one person speaking ..",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "There was more than one person speaking .. There was more than one person speaking ..",
      "There was more than one person speaking .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], multi_microphone[no], mic_quantity[1])",
    "ref": [
      "The CaptureDevice signature is consistent throughout the recording ... The CaptureDevice signature is consistent throughout the recording ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ... The CaptureDevice signature is consistent throughout the recording ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "The CaptureDevice signature is consistent throughout the recording ... The CaptureDevice signature is consistent throughout the recording ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ... The CaptureDevice signature is consistent throughout the recording ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "The CaptureDevice signature is consistent throughout the recording ... The CaptureDevice signature is consistent throughout the recording ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ... The CaptureDevice signature is consistent throughout the recording ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7373 ...",
      "The CaptureDevice signature is consistent throughout the recording ... The CaptureDevice signature is consistent throughout the recording ...",
      "The CaptureDevice signature is consistent throughout the recording ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <multi_microphone> multi microphone: [ no ], <mic_quantity> mic quantity: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-25], classification[bonafide], shap_value[0.7316])",
    "ref": [
      "Yes MFCC which a s value of 0.7316 was used to detect the sample as Audio_signal ...",
      "0.7316 MFCC which a shap value of 0.7316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.7 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.7316 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.7316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-25 value of 0.7316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.7316 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.7316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of 0.7316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.7316 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-25 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7316 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-8], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes GTCC which a yes value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a sha value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a yes value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-0], shap_value[-0.3268])",
    "ref": [
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "-0.3268 determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.7875 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of - ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.7875 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "-0.3268 determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.7875 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3268 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-0 ], <shap_value> shap value: [ -0.3268 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-13], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-13 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "No other spoof types were detected ... Yes the recording is PhysicalAccess was detected by CNN ...",
      "No other spoof types were detected ...",
      "Yes the recording is PhysicalAccess was detected by CNN ... Yes the recording is PhysicalAccess was detected by CNN ...",
      "Ye the recording is PhysicalAccess was detected by CNN ...",
      "replayed the recording is PhysicalAccess was detected by CNN ...",
      "Yes the recording is PhysicalAccess was detected by  ...",
      "Yes the recording is PhysicalAccess was detected by spoof ...",
      "No other spoof types were detected ... Yes the recording is PhysicalAccess was detected by CNN ...",
      "No other spoof types were detected ...",
      "Yes the recording is PhysicalAccess was detected by CNN ... Yes the recording is PhysicalAccess was detected by CNN ...",
      "Yes the recording is PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-6], shap_value[0.4591])",
    "ref": [
      "MSRCC-6 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0. ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of shap ...",
      "MSRCC-6 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.4591 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <shap_value> shap value: [ 0.4591 ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_at[10])",
    "ref": [
      "The next CaptureDevice starts at spoof seconds ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "The next CaptureDevice starts at  seconds ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at spoof seconds ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "The next CaptureDevice starts at  seconds ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at 10 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_at> change at: [ 10 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-6], interpreter[shap], shap_value[0.0638])",
    "ref": [
      "Yes person 7 was detected by MSRCC with a  value of 0.0638 ...",
      "Yes person 7 was detected by MSRCC with a MSRCC-6 value of 0.0638 ...",
      "Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.7012 was used to detect the id of speaker 2 for the audio sample ... Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.06 ...",
      "Yes person  was detected by MSRCC with a shap value of 0.0638 ...",
      "Yes person 7 was detected by MSRCC with a shap value of 7 ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ... Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "Yes person 0.0638 was detected by MSRCC with a shap value of 0.0638 ...",
      "Yes person 7 was detected by MSRCC with a  value of 0.0638 ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0638 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], num_change[2])",
    "ref": [
      "Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ... Two different speeds were detected ...",
      "Two different speeds were detected ... Two different speeds were detected ...",
      "Two different spoofs were detected ...",
      "Two different spees were detected ...",
      "Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.285 was used to detect the sample as Audio_signal ... Two different speeds were detected ...",
      "Two different speeds were detected ... Two different speeds were detected ...",
      "Two different spoofs were detected ...",
      "Two different spees were detected ...",
      "Two different speeds were detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <num_change> num change: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-4], interpreter[shap], shap_value[0.0807])",
    "ref": [
      "Yes person  was detected by LFCC with a shap value of 0.0807 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 6 was detected by LFCC with a shap value of 0.0807 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 6 was detected by LFCC with a sha value of 0.0807 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0807 ... Yes person 6 was detected by LFCC with a shap value of 0.0807 ...",
      "Yes person 6 was detected by LFCC with a shap value of shap ...",
      "Yes person 6 was detected by LFCC with a 6 value of 0.0807 ...",
      "Yes person LFCC-4 was detected by LFCC with a shap value of 0.0807 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0 ...",
      "Yes person  was detected by LFCC with a shap value of 0.0807 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.0807 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0807 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-5], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of -0.89 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-5 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.89 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.89 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-5 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.89 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-5 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-18], classification[bonafide], shap_value[-0.4909])",
    "ref": [
      "Yes MFCC which a bonafide value of -0.4909 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "The audio is not Audio_signal was detected by CNN?",
      "Y MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of -0.4909 was used to detect the sample as Audio_signal ...",
      "The audio is not Audio_signal was detected by CNN? Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-18 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of -0.4909 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-18 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4909 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-11], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ... Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person yes was detected by GTCC with a shap value of 0 ...",
      "Yes person 5 was detected by GTCC with a sha value of 0 ...",
      "Yes person 5 was detected by GTCC with a shap value of shap ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ... Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Yes person 5 was detected by GTCC with a shap value of  ...",
      "Yes person 5 was detected by GTCC with a yes value of 0 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ... Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-45], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-45 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-45 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-45 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.1017 was used to detect the id of speaker 4 for the audio sample ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ... The signal is consistent with a cloned voice ...",
      "The signal is consistent with a cloned voice ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-25], shap_value[0.4685])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "MFCC-25 determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-25 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.7891 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.4685 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-25 ], <shap_value> shap value: [ 0.4685 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-5], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not converted .. the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC-5 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not converted ..",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not converted .. the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC-5 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not converted ..",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-25], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-25 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-12], classification[bonafide], shap_value[0.6096])",
    "ref": [
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.6096 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of 0.6096 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.6096 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.6096 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-12 value of 0.6096 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6096 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.6096 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6096 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6096 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.2026 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-16], interpreter[shap], shap_value[-0.9965])",
    "ref": [
      "Yes LFCC which a shap value of -0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a s value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a LFCC-16 value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker -0.9965 for the audio sample ...",
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.9965 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9965 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-25], interpreter[shap], shap_value[-0.6414])",
    "ref": [
      "Yes LFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ...",
      "Yes LFCC which a LFCC-25 value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a sh value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2635 ... Yes LFCC which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6yes1yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of -0.61 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6414 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6414 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-20], classification[replayed], shap_value[-0.612], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a CNN value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Ye LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.612 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.612 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-2], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.2359 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-26], classification[bonafide], shap_value[0.8434])",
    "ref": [
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.8434 was used to detect the sample as Audio_signal ...",
      "0.8434 LFCC which a shap value of 0.8434 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.8434 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.8434 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of 0.8434 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of 0.8434 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.8434 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.737 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.8434 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-26 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8434 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-43], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-43 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Most of the recording was not made with a mobile phone ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Most of the recording was not made with a mobile phone ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-43 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Most of the recording was not made with a mobile phone ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Most of the recording was not made with a mobile phone ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-43 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being PhysicalAccess was detected by  by a MixtureModel Abstract ...",
      "The audio file was classified as being PhysicalAccess was detected by feature by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being PhysicalAccess was detected by  by a MixtureModel Abstract ...",
      "The audio file was classified as being PhysicalAccess was detected by feature by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-32], interpreter[shap], shap_value[0.2967])",
    "ref": [
      "Yes LFCC which a  value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.0.2967967 was used to detect the id of speaker 0.2967 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.967 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.29 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a LFCC-32 value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a  value of 0.2967 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2967 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2967 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[professional_mixer])",
    "ref": [
      "Yes a professional mixer was used ... Yes a professional mixer was used ...",
      "spoof a professional mixer was used ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ... Yes a professional mixer was used ...",
      " a professional mixer was used ...",
      "Yes a professional mixer was used ... Yes a professional mixer was used ...",
      "spoof a professional mixer was used ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ... Yes a professional mixer was used ...",
      " a professional mixer was used ...",
      "Yes a professional mixer was used ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ professional_mixer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-32], classification[replayed], shap_value[-0.3151], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a s value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.3151 LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.7923 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3151 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-32 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3151 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-50], classification[bonafide], shap_value[-0.4655])",
    "ref": [
      "LFCC-50 LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ... Yes LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2255 ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.4655 value of -0.4655 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.465 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.4655 was used to detect the sample as Audio_signal ...",
      "LFCC-50 LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.4655 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-50 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4655 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-36], interpreter[shap], shap_value[0.4853])",
    "ref": [
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a 1 value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker  for the audio sample ...",
      "Spectral Centroid physicalattribute Coefficients ...",
      "Yes LFCC which a sh value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Spectral Centroid physicalattribute Coefficients ... Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4853 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4853 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Features in the audio show there were two microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Features in the audio show there were two microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Features in the audio show there were two microphones used ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Features in the audio show there were two microphones used ... Features in the audio show there were two microphones used ...",
      "Features in the audio show there were two microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-9], interpreter[shap], shap_value[-0.3578])",
    "ref": [
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker LFCC-9 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3711 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a 2 value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a sha value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3578 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3578 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-13], classification[bonafide], shap_value[0.8687])",
    "ref": [
      "Yes MFCC which a 0.8687 value of 0.8687 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of 0.8687 was used to detect the sample as Audio_signal ...",
      "MFCC-13 MFCC which a shap value of 0.8687 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.8687 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.86 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.8687 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.8687 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.8687 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a 0.8687 value of 0.8687 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.8687 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8687 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Several conversions show this is a Spoofed sample ...",
      "There was no EnvironmentSignature signature ... Several features show this is a Spoofed sample ...",
      "Several featurs show this is a Spoofed sample ...",
      "Several features show this is a Spoofed sample ... Several features show this is a Spoofed sample ...",
      "There was no EnvironmentSignature signature ...",
      "Several conversions show this is a Spoofed sample ...",
      "There was no EnvironmentSignature signature ... Several features show this is a Spoofed sample ...",
      "Several featurs show this is a Spoofed sample ...",
      "Several features show this is a Spoofed sample ... Several features show this is a Spoofed sample ...",
      "There was no EnvironmentSignature signature ...",
      "Several features show this is a Spoofed sample ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-59], classification[bonafide], shap_value[-0.6167])",
    "ref": [
      "Yes LFCC which a Yes value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.616 was used to detect the sample as Audio_signal ...",
      "It looks that way ... Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.6167 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "It looks that way ...",
      " LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-59 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-59 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6167 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[4])",
    "ref": [
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "Yes MFCC which a shap value of 0.1362 was used to detect the id of speaker 7 for the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 4 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-4], classification[replayed], shap_value[-0.4107], detected_by[CNN])",
    "ref": [
      "shap PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by PSRCC-4 ...",
      " PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a s value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a PSRCC-4 value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being PhysicalAccess was detected by CNN by a MixtureModel Abstract ... Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4107 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "spoofed the recording was found to be spoofed...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording was found to be spoofed...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes the recording was found to be spoofed... Yes the recording was found to be spoofed...",
      "Yes the recording was found to be Yes...",
      "Yes the recording was found to be ...",
      "Y the recording was found to be spoofed...",
      "spoofed the recording was found to be spoofed...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording was found to be spoofed...",
      "Yes MFCC which a shap value of -0.5673 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes the recording was found to be spoofed..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(classification[bonafide], model[CNN])",
    "ref": [
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <model> model: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-16], classification[bonafide], shap_value[0.2999])",
    "ref": [
      "Y MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a 0.2999 value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.2267 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "shap MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2999 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2999 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-14], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-14 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.4413 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-14 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-14 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], spoof_type[converted])",
    "ref": [
      "N the recording is not converted ...",
      "spoof the recording is not converted ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ...",
      "No the recording is not conve ...",
      "Yes person 7 was detected by MSRCC with a shap value of 0.0638 ... No the recording is not converted ...",
      "No the recording is converted ...",
      "No the recording is not No ...",
      "No the recording is not converted ... No the recording is not converted ...",
      "N the recording is not converted ...",
      "spoof the recording is not converted ...",
      "No the recording is not converted ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ converted ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[mixer])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ... There is evidence of sampling ...",
      "There is evidence of sampling ... There is evidence of sampling ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ... There is evidence of sampling ...",
      "There is evidence of sampling ... There is evidence of sampling ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ... There is evidence of sampling ...",
      "There is evidence of sampling ... There is evidence of sampling ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.6687 ...",
      "There is evidence of sampling ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ mixer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-7], classification[bonafide], shap_value[-0.9946])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ... Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "-0.9946 PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      " PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a  value of -0.9946 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a -0.9946 value of -0.9946 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3447 ...",
      "Yes PSRCC which a shap value of -0.9946 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9946 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Features in the audio show there were two microphones used ...",
      "Features in the audio show there were two microphones used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Features in the audio show there were two microphones used ...",
      "Features in the audio show there were two microphones used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-11], interpreter[shap], shap_value[-0.1499])",
    "ref": [
      "It appears that part of the audio was sped up ...",
      "Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ... Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of PSRCC-11 was used to detect the id of speaker 5 for the audio sample ...",
      "It appears that part of the audio was sped up ... Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker PSRCC-11 for the audio sample ...",
      "Yes PSRCC which a -0.1499 value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of -0.149 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a  value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...",
      "It appears that part of the audio was sped up ...",
      "Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1499 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-29], classification[bonafide], shap_value[0.5961])",
    "ref": [
      "Yes MFCC which a bonafide value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ...",
      "shap MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.2638 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of 0.5961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5961 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-29 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5961 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "No other nones detected a CaptureDevice signal ...",
      "No other features detected a CaptureDevice signal ... No other features detected a CaptureDevice signal ...",
      "The Acoustic_Wave patterns show where the speaker is from ... No other features detected a CaptureDevice signal ...",
      "No other feats detected a CaptureDevice signal ...",
      "The Acoustic_Wave patterns show where the speaker is from ...",
      "No other nones detected a CaptureDevice signal ...",
      "No other features detected a CaptureDevice signal ... No other features detected a CaptureDevice signal ...",
      "The Acoustic_Wave patterns show where the speaker is from ... No other features detected a CaptureDevice signal ...",
      "No other feats detected a CaptureDevice signal ...",
      "The Acoustic_Wave patterns show where the speaker is from ...",
      "No other features detected a CaptureDevice signal ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-8\\], determined[speaker_id])",
    "ref": [
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "MFCC-8\\ MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ...",
      "MFCC-8\\ MFCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7772 ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-8\\ ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(model[CNN], task[spoof_detecting], detected_by[CNN])",
    "ref": [
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample was used in a FeedforwardNeuralNetwork Abstract tasked at detecting if an audio sample is Audio_signal or DigitalSignal ..."
    ],
    "new_mr": "<inform> inform ( <model> model: [ CNN ], <task> task: [ spoof_detecting ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], classified_by[feature])",
    "ref": [
      "Multiple EnvironmentSignature signatures were detected ... Multiple EnvironmentSignature signatures were detected ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... Multiple EnvironmentSignature signatures were detected ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Multiple EnvironmentSignature signatures were detected ... Multiple EnvironmentSignature signatures were detected ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... Multiple EnvironmentSignature signatures were detected ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Multiple EnvironmentSignature signatures were detected ... Multiple EnvironmentSignature signatures were detected ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... Multiple EnvironmentSignature signatures were detected ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Multiple EnvironmentSignature signatures were detected ... Multiple EnvironmentSignature signatures were detected ...",
      "Multiple EnvironmentSignature signatures were detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-35], interpreter[shap], shap_value[-0.2493])",
    "ref": [
      "Yes person 6 was detected by LFCC with a shap value of -0.2493 ... Yes person 6 was detected by LFCC with a shap value of -0.2493 ...",
      "Yes person  was detected by LFCC with a shap value of -0.2493 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ...",
      "Yes person 6 was detected by LFCC with a LFCC-35 value of -0.2493 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8689 ... Yes person 6 was detected by LFCC with a shap value of -0.2493 ...",
      "Yes person LFCC-35 was detected by LFCC with a shap value of -0.2493 ...",
      "Yes person 6 was detected by LFCC with a shap value of shap ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.2 ...",
      "Yes person 6 was detected by LFCC with a  value of -0.2493 ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.2493 ... Yes person 6 was detected by LFCC with a shap value of -0.2493 ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.2493 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2493 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[PSRCC-2], interpreter[shap], shap_value[0.6595])",
    "ref": [
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... Yes person 3 was detected by PSRCC with a shap value of 0.6595 ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes person 3 was detected by PSRCC with a PSRCC-2 value of 0.6595 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 3 ...",
      "Yes person 3 was detected by PSRCC with a  value of 0.6595 ...",
      "Yes person  was detected by PSRCC with a shap value of 0.6595 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.6595 ... Yes person 3 was detected by PSRCC with a shap value of 0.6595 ...",
      "Yes person shap was detected by PSRCC with a shap value of 0.6595 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.65 ...",
      "Yes MFCC which a shap value of 0.9939 was used to detect the id of speaker 1 for the audio sample ... Yes person 3 was detected by PSRCC with a shap value of 0.6595 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.6595 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ PSRCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6595 ]> )"
  },
  {
    "mr": "inform(speaker_id[7], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 7 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-13], interpreter[shap], shap_value[0.839])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ... Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 6 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a 6 value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a sh value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker  for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8093 ... Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.839 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-29], interpreter[shap], shap_value[-0.6411])",
    "ref": [
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a 1 value of -0.6411 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.64shapshap was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a shap value of - was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a sh value of -0.6411 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.64 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.0316 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.6411 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6411 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-24], shap_value[-0.7826])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "LFCC-24 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "Yes MSRCC which a shap value of 0.5663 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "LFCC-24 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7826 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-24 ], <shap_value> shap value: [ -0.7826 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-9], interpreter[shap], shap_value[0.9994])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of 0.999 ...",
      "Yes person 2 was detected by LFCC with a sh value of 0.9994 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ... Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "yes GTCC was used to determine speaker id ... Yes person 2 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes person  was detected by LFCC with a shap value of 0.9994 ...",
      "Yes person 0.9994 was detected by LFCC with a shap value of 0.9994 ...",
      "Yes person 2 was detected by LFCC with a 2 value of 0.9994 ...",
      "Yes person 2 was detected by LFCC with a shap value of LFCC-9 ...",
      "yes GTCC was used to determine speaker id ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.999 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.9994 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9994 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-6], feature[MFCC-0], feature[LFCC-5], feature[CQCC-0])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-6 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-5 ], <feature> feature: [ CQCC-0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-3], classification[bonafide], shap_value[1])",
    "ref": [
      "Yes GTCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sha value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a 1 value of 1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      " GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "bonafide GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Linear physicalattribute Cepstral Coefficients ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-5], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 6 was detected by GTCC with a sha value of 0 ...",
      "Yes person 6 was detected by GTCC with a GTCC-5 value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes person 6 was detected by GTCC with a shap value of 0 ... Yes person 6 was detected by GTCC with a shap value of 0 ...",
      "Yes person 6 was detected by GTCC with a shap value of  ...",
      "Yes person 6 was detected by GTCC with a shap value of yes ...",
      "Yes person 0 was detected by GTCC with a shap value of 0 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... Yes person 6 was detected by GTCC with a shap value of 0 ...",
      "Yes person 6 was detected by GTCC with a sha value of 0 ...",
      "Yes person 6 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-22], classification[replayed], shap_value[-0.4098], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a CNN value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by C ...",
      "CNN MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ... Yes MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.4 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Dynamic microphones were used the most ...",
      "Ye MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.4098 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-22 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4098 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-2], classification[replayed], shap_value[0.458], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a sha value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a replayed value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.45 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of PSRCC-2 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.458 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.458 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of -0.0283 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It was altered using software ... It was altered using software ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ... It was altered using software ...",
      "It was altered using software ... It was altered using software ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ... It was altered using software ...",
      "It was altered using software ... It was altered using software ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.7878 was used to detect the id of speaker 3 for the audio sample ... It was altered using software ...",
      "It was altered using software ... It was altered using software ...",
      "It was altered using software ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "That CaptureDevice was used for 5 seconds ... Other samples show the person speaks at a different speed ...",
      "That CaptureDevice was used for 5 seconds ...",
      "Other samples show the person speaks at a different spee ...",
      "Other samples show the person speaks at a different spoof ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "That CaptureDevice was used for 5 seconds ... Other samples show the person speaks at a different speed ...",
      "That CaptureDevice was used for 5 seconds ...",
      "Other samples show the person speaks at a different spee ...",
      "Other samples show the person speaks at a different spoof ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different speed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "8 was found to be the id of the speaker in the sample ...",
      "8 was found to be the id of the speaker in the sample ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ...",
      "8 was found to be the id of the speaker in the sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on the classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-1], interpreter[shap], shap_value[-1])",
    "ref": [
      "Yes GTCC which a sh value of -1 was used to detect the id of speaker 1 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ...",
      "Yes GTCC which a shap value of -shap was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ... Yes GTCC which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of - was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2636 ... Yes GTCC which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a GTCC-1 value of -1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a sh value of -1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of -1 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-44], classification[replayed], shap_value[-0.1075], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a replayed value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.1075 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1075 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-3], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-3 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-58], interpreter[shap], shap_value[0.2487])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.2487 ... Yes person 5 was detected by LFCC with a shap value of 0.2487 ...",
      "Yes person 5 was detected by LFCC with a sha value of 0.2487 ...",
      "Yes person 0.2487 was detected by LFCC with a shap value of 0.2487 ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-58 ...",
      "Yes person  was detected by LFCC with a shap value of 0.2487 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2 ...",
      "Yes person 5 was detected by LFCC with a yes value of 0.2487 ...",
      "Yes PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.3337 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 5 was detected by LFCC with a shap value of 0.2487 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2487 ... Yes person 5 was detected by LFCC with a shap value of 0.2487 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2487 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-58 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2487 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It was altered using software ... It was altered using software ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ... It was altered using software ...",
      "It was altered using soft ...",
      "It was altered using spoof ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "It was altered using software ... It was altered using software ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ... It was altered using software ...",
      "It was altered using soft ...",
      "It was altered using spoof ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "It was altered using software ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "It shows signs of artificially added noise ..",
      "Subband Spectral Flux Coefficients ... Subband Spectral Flux Coefficients ...",
      "It shows signs of artificially added noise .. Subband Spectral Flux Coefficients ...",
      "It shows signs of artificially added noise ..",
      "Subband Spectral Flux Coefficients ... Subband Spectral Flux Coefficients ...",
      "It shows signs of artificially added noise .. Subband Spectral Flux Coefficients ...",
      "It shows signs of artificially added noise ..",
      "Subband Spectral Flux Coefficients ... Subband Spectral Flux Coefficients ...",
      "It shows signs of artificially added noise .. Subband Spectral Flux Coefficients ...",
      "It shows signs of artificially added noise ..",
      "Subband Spectral Flux Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-10], classification[replayed], shap_value[-0.1905], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a  value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a CNN value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3326 ...",
      "Yes PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by -0.1905 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3326 ... Yes PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Ye PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.1905 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-10 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1905 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by CNN audio was a  audio ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a CNN audio ...",
      "The Audio_signal was detected by CN audio was a synthetic audio ...",
      "That CaptureDevice was used for 5 seconds ... The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by synthetic audio was a synthetic audio ...",
      "That CaptureDevice was used for 5 seconds ...",
      "The Audio_signal was detected by CNN audio was a  audio ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ... The Audio_signal was detected by CNN audio was a synthetic audio ...",
      "The Audio_signal was detected by CNN audio was a CNN audio ...",
      "The Audio_signal was detected by CNN audio was a synthetic audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Linear Prediction Cepstral Coefficients .. Linear Prediction Cepstral Coefficients ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... Linear Prediction Cepstral Coefficients ..",
      "Linear Prediction Cepstral Coefficients .. Linear Prediction Cepstral Coefficients ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... Linear Prediction Cepstral Coefficients ..",
      "Linear Prediction Cepstral Coefficients .. Linear Prediction Cepstral Coefficients ..",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6786 was used to detect the id of speaker 4 for the audio sample ... Linear Prediction Cepstral Coefficients ..",
      "Linear Prediction Cepstral Coefficients .. Linear Prediction Cepstral Coefficients ..",
      "Linear Prediction Cepstral Coefficients .."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "The audio shows signs of 3 different editors ... The audio shows signs of 3 different editors ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... The audio shows signs of 3 different editors ...",
      "The audio shows signs of 3 different editors ... The audio shows signs of 3 different editors ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... The audio shows signs of 3 different editors ...",
      "The audio shows signs of 3 different editors ... The audio shows signs of 3 different editors ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... The audio shows signs of 3 different editors ...",
      "The audio shows signs of 3 different editors ... The audio shows signs of 3 different editors ...",
      "The audio shows signs of 3 different editors ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-7], classification[replayed], shap_value[0.7602], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by MSRCC-7 ...",
      " MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a  value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.760 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a MSRCC-7 value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7602 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by  audio was not a PhysicalAccess audio ...",
      "Linear Prediction Cepstral Coefficients ..",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by bonafide audio was not a PhysicalAccess audio ...",
      "Linear Prediction Cepstral Coefficients .. The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by  audio was not a PhysicalAccess audio ...",
      "Linear Prediction Cepstral Coefficients ..",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by bonafide audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-41], shap_value[-0.5918])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "yes GTCC was used to determine speaker id ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ...",
      "yes GTCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.591 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ...",
      "LFCC-41 determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "yes GTCC was used to determine speaker id ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5918 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-41 ], <shap_value> shap value: [ -0.5918 ]> )"
  },
  {
    "mr": "inform(classification[spoofed])",
    "ref": [
      "7 was found to be the id of the speaker in the sample ... Yes the recording shows signs of being edited ...",
      "Yes the recording shows signs of being edited ... Yes the recording shows signs of being edited ...",
      "7 was found to be the id of the speaker in the sample ...",
      "7 was found to be the id of the speaker in the sample ... Yes the recording shows signs of being edited ...",
      "Yes the recording shows signs of being edited ... Yes the recording shows signs of being edited ...",
      "7 was found to be the id of the speaker in the sample ...",
      "7 was found to be the id of the speaker in the sample ... Yes the recording shows signs of being edited ...",
      "Yes the recording shows signs of being edited ... Yes the recording shows signs of being edited ...",
      "7 was found to be the id of the speaker in the sample ...",
      "7 was found to be the id of the speaker in the sample ... Yes the recording shows signs of being edited ...",
      "Yes the recording shows signs of being edited ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... It looks that way ...",
      "It looks that way ... It looks that way ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... It looks that way ...",
      "It looks that way ... It looks that way ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... It looks that way ...",
      "It looks that way ... It looks that way ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "It looks that way ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-21], classification[bonafide], shap_value[0.5107])",
    "ref": [
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of 0.5107 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a 0.5107 value of 0.5107 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.51 was used to detect the sample as Audio_signal ...",
      "0.5107 MFCC which a shap value of 0.5107 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5107 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5107 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.5107 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.6368 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of 0.5107 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5107 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5107 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by C audio was not a PhysicalAccess audio ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by bonafide audio was not a PhysicalAccess audio ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ...",
      "The Audio_signal was detected by C audio was not a PhysicalAccess audio ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-4], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes person 7 was detected by LFCC with a shap value of -0.2342 ... Yes person 2 was detected by GTCC with a shap value of 1 ...",
      "Yes person 2 was detected by GTCC with a sh value of 1 ...",
      "Yes person shap was detected by GTCC with a shap value of 1 ...",
      "Yes person 2 was detected by GTCC with a yes value of 1 ...",
      "Yes person 2 was detected by GTCC with a shap value of 1 ... Yes person 2 was detected by GTCC with a shap value of 1 ...",
      "Yes person  was detected by GTCC with a shap value of 1 ...",
      "Yes person 2 was detected by GTCC with a shap value of shap ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2342 ...",
      "Yes person 2 was detected by GTCC with a shap value of  ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2342 ... Yes person 2 was detected by GTCC with a shap value of 1 ...",
      "Yes person 2 was detected by GTCC with a shap value of 1 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-11], interpreter[shap], shap_value[0.1731])",
    "ref": [
      "Yes person 3 was detected by PSRCC with a  value of 0.1731 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ... Yes person 3 was detected by PSRCC with a shap value of 0.1731 ...",
      "Yes person 3 was detected by PSRCC with a shap value of yes ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0. ...",
      "Yes person 3 was detected by PSRCC with a PSRCC-11 value of 0.1731 ...",
      "The recording is a little faster between the five and ten second mark ...",
      "The recording is a little faster between the five and ten second mark ... Yes person 3 was detected by PSRCC with a shap value of 0.1731 ...",
      "Yes person 3 was detected by PSRCC with a  value of 0.1731 ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ... Yes person 3 was detected by PSRCC with a shap value of 0.1731 ...",
      "Yes person 3 was detected by PSRCC with a shap value of yes ...",
      "Yes person 3 was detected by PSRCC with a shap value of 0.1731 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1731 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-41], interpreter[shap], shap_value[-0.4171])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of -0.4 ...",
      "Yes person 2 was detected by LFCC with a s value of -0.4171 ...",
      "Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5435 was used to detect the id of speaker 5 for the audio sample ... Yes person 2 was detected by LFCC with a shap value of -0.4171 ...",
      "Yes person 2 was detected by LFCC with a shap value of LFCC-41 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.4171 ...",
      "Yes person 2 was detected by LFCC with a -0.4171 value of -0.4171 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.4171 ... Yes person 2 was detected by LFCC with a shap value of -0.4171 ...",
      "Yes person  was detected by LFCC with a shap value of -0.4171 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.4 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.4171 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4171 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-44], classification[bonafide], shap_value[0.707])",
    "ref": [
      "Yes LFCC which a shap value of 0.70 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.707 was used to detect the sample as Audio_signal ...",
      "Features in the audio show there were two microphones used ...",
      "Yes LFCC which a 0.707 value of 0.707 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ...",
      "Features in the audio show there were two microphones used ... Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.70 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.707 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.707 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "The audio shows signs of being edited ... It is not a bona fide audio ...",
      "It is not a bona fide audio ... It is not a bona fide audio ...",
      "The audio shows signs of being edited ...",
      "It is a bona fide audio ...",
      "The audio shows signs of being edited ... It is not a bona fide audio ...",
      "It is not a bona fide audio ... It is not a bona fide audio ...",
      "The audio shows signs of being edited ...",
      "It is a bona fide audio ...",
      "The audio shows signs of being edited ... It is not a bona fide audio ...",
      "It is not a bona fide audio ... It is not a bona fide audio ...",
      "It is not a bona fide audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-14], classification[replayed], shap_value[0.4354], detected_by[CNN])",
    "ref": [
      "Ye LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by LFCC-14 ...",
      "Yes LFCC which a shap value of 0.435 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is an unusually long pause at 37 seconds ...",
      "Yes LFCC which a shap value of LFCC-14 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There is an unusually long pause at 37 seconds ... Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.4354 LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4354 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4354 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-10], determined[speaker_id])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "MFCC-10 MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "y MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "MFCC-10 MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "y MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-10 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-13], classification[bonafide], shap_value[-1])",
    "ref": [
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "GTCC-13 GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sh value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ... Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      " GTCC which a shap value of -1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a Yes value of -1 was used to detect the sample as Audio_signal ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.9009 ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -1 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-7], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "person 4 was detected as the primary speaker of the audio sample ...",
      "person 4 was detected as the primary speaker of the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "person 4 was detected as the primary speaker of the audio sample ...",
      "person 4 was detected as the primary speaker of the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-10], interpreter[shap], shap_value[0.6465])",
    "ref": [
      "Yes MSRCC which a shap value of 0.64 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.646yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes MSRCC which a shap value of MSRCC-10 was used to detect the id of speaker 5 for the audio sample ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... Yes MSRCC which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a 0.6465 value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.646 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ... Yes MSRCC which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a sha value of 0.6465 was used to detect the id of speaker 5 for the audio sample ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes MSRCC which a shap value of 0.64 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.6465 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6465 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-51], interpreter[shap], shap_value[-0.2458])",
    "ref": [
      "Yes person 3 was detected by LFCC with a s value of -0.2458 ...",
      "Yes person  was detected by LFCC with a shap value of -0.2458 ...",
      "There were 2 microphones ... Yes person 3 was detected by LFCC with a shap value of -0.2458 ...",
      "Yes person LFCC-51 was detected by LFCC with a shap value of -0.2458 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0. ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ... Yes person 3 was detected by LFCC with a shap value of -0.2458 ...",
      "There were 2 microphones ...",
      "Yes person 3 was detected by LFCC with a shap value of shap ...",
      "Yes person 3 was detected by LFCC with a -0.2458 value of -0.2458 ...",
      "Yes person 3 was detected by LFCC with a s value of -0.2458 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.2458 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-51 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2458 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-3], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 2 was detected by GTCC with a shap value of GTCC-3 ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes person 2 was detected by GTCC with a shap value of  ...",
      "Yes person 2 was detected by GTCC with a  value of 0 ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ... Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "Yes person shap was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a 2 value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of GTCC-3 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8296 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-56], interpreter[shap], shap_value[-0.4735])",
    "ref": [
      "Yes person 1 was detected by LFCC with a 1 value of -0.4735 ...",
      "The audio shows signs of 3 different editors ...",
      "Yes person -0.4735 was detected by LFCC with a shap value of -0.4735 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.4735 ... Yes person 1 was detected by LFCC with a shap value of -0.4735 ...",
      "Yes person  was detected by LFCC with a shap value of -0.4735 ...",
      "The audio shows signs of 3 different editors ... Yes person 1 was detected by LFCC with a shap value of -0.4735 ...",
      "Yes person 1 was detected by LFCC with a shap value of shap ...",
      "Yes person 1 was detected by LFCC with a shap value of -0. ...",
      "Yes person 1 was detected by LFCC with a sh value of -0.4735 ...",
      "Yes person 1 was detected by LFCC with a 1 value of -0.4735 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.4735 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-56 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4735 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-6], shap_value[-0.0158])",
    "ref": [
      "Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ...",
      "Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.01 ...",
      "PSRCC-6 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-6 ...",
      "sha determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ...",
      "Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ...",
      "Yes MFCC which a shap value of -0.4792 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.01 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.0158 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-6 ], <shap_value> shap value: [ -0.0158 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The audio is fake .. The audio was made at the same time ...",
      "The audio is fake ..",
      "The audio was made at the same time ... The audio was made at the same time ...",
      "The audio is fake .. The audio was made at the same time ...",
      "The audio is fake ..",
      "The audio was made at the same time ... The audio was made at the same time ...",
      "The audio is fake .. The audio was made at the same time ...",
      "The audio is fake ..",
      "The audio was made at the same time ... The audio was made at the same time ...",
      "The audio is fake .. The audio was made at the same time ...",
      "The audio was made at the same time ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-53], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5221 was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-53 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.8351 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-46], classification[replayed], shap_value[0.4075], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a replayed value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a s value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3326 ...",
      "Yes LFCC which a shap value of 0.4 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3326 ... Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4075 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-9], classification[bonafide], shap_value[0.7395])",
    "ref": [
      "Yes MSRCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Y MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a Yes value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "bonafide MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a s value of 0.7395 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.7395 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7395 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-55], shap_value[-0.6132])",
    "ref": [
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ...",
      "LFCC-55 determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0. ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-55 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ...",
      "LFCC-55 determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.6132 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <shap_value> shap value: [ -0.6132 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal .",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ...",
      "The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The recording file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Linear Prediction Cepstral Coefficients are an alternative to CepstralFeature in terms of cepstral feature computation is from all-pole Abstract of signal . Linear prediction cepstral coefficients LPCCs are derived from the linear prediction coefficients LPCs by a recursive SoftwareAgent ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-10], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes GTCC which a  value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Y GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a bonafide value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.1314 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "GTCC-10 GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a  value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-2], shap_value[0.2561])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2561 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2561 ...",
      "0.2561 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2561 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of 0.2561 ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2561 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes LFCC which a shap value of -0.3231 was used to detect the id of speaker 3 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2561 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-2 ], <shap_value> shap value: [ 0.2561 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-6], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The Audio_signal was detected by CNN audio was not a PhysicalAccess audio ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-6 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-30], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.0087 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-30 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 CQCC-0 a value of 0.0673 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "It shows signs of artificially added noise .. It shows signs of artificially added noise ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ... It shows signs of artificially added noise ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "It shows signs of artificially added noise .. It shows signs of artificially added noise ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ... It shows signs of artificially added noise ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "It shows signs of artificially added noise .. It shows signs of artificially added noise ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ... It shows signs of artificially added noise ..",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6599 ...",
      "It shows signs of artificially added noise .. It shows signs of artificially added noise ..",
      "It shows signs of artificially added noise .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-3], classification[replayed], shap_value[0.3323], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes PSRCC which a Yes value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.33 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2494 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "PSRCC-3 PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a sh value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by PSRCC-3 ...",
      "Yes PSRCC which a shap value of 0.3323 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3323 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-43], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-43 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio has been tampered with ...",
      "The audio has been tampered with ... The audio has been tampered with ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio has been tampered with ...",
      "The audio has been tampered with ... The audio has been tampered with ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio has been tampered with ...",
      "The audio has been tampered with ... The audio has been tampered with ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio has been tampered with ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-4], classification[replayed], shap_value[-0.069], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ... Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2979 ...",
      "Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by -0.069 ...",
      "Yes LFCC which a shap value of LFCC-4 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.069 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.069 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-4], shap_value[1])",
    "ref": [
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "GTCC-4 determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced .. shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-4 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced ..",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "GTCC-4 determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "It appears that the recording was spliced .. shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-7], interpreter[shap], shap_value[1])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 6 was detected by GTCC with a shap value of 1 ...",
      "Yes person 6 was detected by GTCC with a shap value of  ...",
      "Yes person shap was detected by GTCC with a shap value of 1 ...",
      "Yes person  was detected by GTCC with a shap value of 1 ...",
      "Yes person 6 was detected by GTCC with a shap value of GTCC-7 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 6 was detected by GTCC with a shap value of 1 ... Yes person 6 was detected by GTCC with a shap value of 1 ...",
      "Yes person 6 was detected by GTCC with a 1 value of 1 ...",
      "Yes person 6 was detected by GTCC with a  value of 1 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 6 was detected by GTCC with a shap value of 1 ...",
      "Yes person 6 was detected by GTCC with a shap value of 1 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-37], classification[replayed], shap_value[0.4298], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-37 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Y LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.839 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4298 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-37 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4298 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-45], shap_value[0.3935])",
    "ref": [
      "LFCC-45 determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-45 ...",
      "Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.39 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ...",
      "Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ...",
      "LFCC-45 determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-45 ...",
      "Yes MFCC which a shap value of 0.8105 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.3935 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-45 ], <shap_value> shap value: [ 0.3935 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-0], classification[bonafide], shap_value[-0.5766])",
    "ref": [
      "Yes MSRCC which a sha value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a MSRCC-0 value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Ye MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "MSRCC-0 MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3274 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a sha value of -0.5766 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.5766 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5766 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes the recording was found to be spoofed... Yes the recording was found to be spoofed...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "spoofed the recording was found to be spoofed...",
      "Yes the recording was found to be Yes...",
      "Yes the recording was found to be spoo...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes the recording was found to be spoofed...",
      "Y the recording was found to be spoofed...",
      "Yes the recording was found to be spoofed... Yes the recording was found to be spoofed...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "spoofed the recording was found to be spoofed...",
      "Yes the recording was found to be spoofed..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-10], interpreter[shap], shap_value[-0.4226])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a s value of -0.4226 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.4226 ... Yes person 6 was detected by PSRCC with a shap value of -0.4226 ...",
      "Yes some of the recording was made with a mobile device and some with a computer .. Yes person 6 was detected by PSRCC with a shap value of -0.4226 ...",
      "Yes person yes was detected by PSRCC with a shap value of -0.422yes ...",
      "Yes some of the recording was made with a mobile device and some with a computer ..",
      "Yes person  was detected by PSRCC with a shap value of -0.422 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.422 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 6 ...",
      "Yes person 6 was detected by PSRCC with a 6 value of -0.4226 ...",
      "Yes person 6 was detected by PSRCC with a s value of -0.4226 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.4226 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4226 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[phone])",
    "ref": [
      "Most of the recording was made with a mobile phone ...",
      "Most of the recording was not made with a mobile spoof ...",
      "Most of the recording was not made with a mobile phon ...",
      "The Audio_signal was detected by CNN audio was not converted ..",
      "The Audio_signal was detected by CNN audio was not converted .. Most of the recording was not made with a mobile phone ...",
      "Most of the recording was not made with a mobile phone ... Most of the recording was not made with a mobile phone ...",
      "Most of the recording was made with a mobile phone ...",
      "Most of the recording was not made with a mobile spoof ...",
      "Most of the recording was not made with a mobile phon ...",
      "The Audio_signal was detected by CNN audio was not converted ..",
      "Most of the recording was not made with a mobile phone ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ phone ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-29], classification[bonafide], shap_value[0.3553])",
    "ref": [
      "bonafide LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.3553 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3553 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-29 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3553 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ... Spectral Centroid physicalattribute Coefficients ...",
      "Interpreters determined that RFCC MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Spectral Centroid physicalattribute Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2405 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2405 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2405 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.2405 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-35], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-35 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-3], interpreter[shap], shap_value[-0.5871])",
    "ref": [
      "Yes MSRCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ... Yes MSRCC which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a 7 value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.581 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a sh value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.5 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ... Yes MSRCC which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.58-0.58711 was used to detect the id of speaker -0.5871 for the audio sample ...",
      "Yes person 5 was detected by GTCC with a shap value of 0 ...",
      "Yes MSRCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.5871 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5871 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio sample was found to be bonafide...",
      "The audio sample was found to be bona...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio sample was found to be bonafide... The audio sample was found to be bonafide...",
      "The audio sample was found to be none...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio sample was found to be bonafide...",
      "The audio sample was found to be bona...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio sample was found to be bonafide... The audio sample was found to be bonafide...",
      "The audio sample was found to be none...",
      "The audio sample was found to be bonafide..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-1], interpreter[shap], shap_value[-0.3605])",
    "ref": [
      "Yes MFCC which a yes value of -0.3605 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ... Yes MFCC which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3yes05 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of 0.4744 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.305 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a sh value of -0.3605 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a yes value of -0.3605 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3605 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3605 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "Yes the recording has been tampered with ... Yes the recording has been tampered with ...",
      "Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ... Yes the recording has been tampered with ...",
      "Y the recording has been tampered with ...",
      "spoofed the recording has been tampered with ...",
      "Yes the recording has been tampered with ... Yes the recording has been tampered with ...",
      "Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.9231 was used to detect the sample as Audio_signal ... Yes the recording has been tampered with ...",
      "Y the recording has been tampered with ...",
      "spoofed the recording has been tampered with ...",
      "Yes the recording has been tampered with ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-38], interpreter[shap], shap_value[0.6638])",
    "ref": [
      "The mel in the name describes the perceived pitch. Yes person 1 was detected by MFCC with a shap value of 0.6638 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.6638 ... Yes person 1 was detected by MFCC with a shap value of 0.6638 ...",
      "Yes person 1 was detected by MFCC with a s value of 0.6638 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0 ...",
      "Yes person 1 was detected by MFCC with a MFCC-38 value of 0.6638 ...",
      "The mel in the name describes the perceived pitch.",
      "Yes person MFCC-38 was detected by MFCC with a shap value of 0.6638 ...",
      "Yes person 1 was detected by MFCC with a shap value of MFCC-38 ...",
      "Yes person  was detected by MFCC with a shap value of 0.6638 ...",
      "The mel in the name describes the perceived pitch. Yes person 1 was detected by MFCC with a shap value of 0.6638 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.6638 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6638 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-41], interpreter[shap], shap_value[0.1403])",
    "ref": [
      "Yes MFCC which a s value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.shap403 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a shap value of 0.403 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a 0.1403 value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a s value of 0.1403 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.1403 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1403 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-19], interpreter[shap], shap_value[-0.7875])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of  ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 1 was detected by LFCC with a shap value of -0.7875 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of LFCC-19 ...",
      "Yes person 1 was detected by LFCC with a -0.7875 value of -0.7875 ...",
      "Yes person 1 was detected by LFCC with a sh value of -0.7875 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.7875 ... Yes person 1 was detected by LFCC with a shap value of -0.7875 ...",
      "Yes person LFCC-19 was detected by LFCC with a shap value of -0.7875 ...",
      "Yes person  was detected by LFCC with a shap value of -0.7875 ...",
      "Yes person 1 was detected by LFCC with a shap value of  ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.7875 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7875 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-48], classification[bonafide], shap_value[0.4714])",
    "ref": [
      "Yes LFCC which a shap value of LFCC-48 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-48 value of 0.4714 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "LFCC-48 LFCC which a shap value of 0.4714 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4714 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.4714 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of 0.4714 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4909 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.4714 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.4714 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of LFCC-48 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4714 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-48 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4714 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-35], shap_value[-0.3461])",
    "ref": [
      "LFCC-35 determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.346 ...",
      "Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.1499 was used to detect the id of speaker 5 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "LFCC-35 determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3461 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-35 ], <shap_value> shap value: [ -0.3461 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[bonafide])",
    "ref": [
      "Yes the recording is Audio_signal .. Yes the recording is Audio_signal ..",
      "bonafide the recording is Audio_signal ..",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording is Audio_signal ..",
      "Y the recording is Audio_signal ..",
      "Yes the recording is Audio_signal .. Yes the recording is Audio_signal ..",
      "bonafide the recording is Audio_signal ..",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5433 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording is Audio_signal ..",
      "Y the recording is Audio_signal ..",
      "Yes the recording is Audio_signal .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "Yes PSRCC which a shap value of 0.9752 was used to detect the id of speaker 7 for the audio sample ...",
      "There appears to be a cloned voice on the audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-1], classification[bonafide], shap_value[-0.0727])",
    "ref": [
      "Yes MFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.0727 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.0727 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7831 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.0727 MFCC which a shap value of -0.0727 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.0727 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.0727 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.0727 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.0727 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.0727 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0727 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-28], shap_value[-0.7853])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-28 ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ...",
      "LFCC-28 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-28 ...",
      "Yes MSRCC which a shap value of 0.7602 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7853 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-28 ], <shap_value> shap value: [ -0.7853 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-35], interpreter[shap], shap_value[0.4133])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of MFCC-35 ...",
      "Yes person 2 was detected by MFCC with a 2 value of 0.4133 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 2 was detected by MFCC with a shap value of 0.4133 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person  was detected by MFCC with a shap value of 0.4133 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4133 ... Yes person 2 was detected by MFCC with a shap value of 0.4133 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4 ...",
      "Yes person 0.4133 was detected by MFCC with a shap value of 0.4133 ...",
      "Yes person 2 was detected by MFCC with a sh value of 0.4133 ...",
      "Yes person 2 was detected by MFCC with a shap value of MFCC-35 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4133 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4133 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-33], shap_value[-0.7065])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "MFCC-33 determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-33 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "MFCC-33 determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7065 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <shap_value> shap value: [ -0.7065 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Detection will be difficult ... Detection will be difficult ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ... Detection will be difficult ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Detection will be difficult ... Detection will be difficult ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ... Detection will be difficult ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Detection will be difficult ... Detection will be difficult ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ... Detection will be difficult ...",
      "Yes LFCC which a shap value of -0.6167 was used to detect the sample as Audio_signal ...",
      "Detection will be difficult ... Detection will be difficult ...",
      "Detection will be difficult ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(speaker_id[5])",
    "ref": [
      "person  spoke the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... person 5 spoke the audio sample ...",
      "person 5 spoke the audio sample ... person 5 spoke the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "person  spoke the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... person 5 spoke the audio sample ...",
      "person 5 spoke the audio sample ... person 5 spoke the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ...",
      "person  spoke the audio sample ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-0 had the highest impact on classification ... person 5 spoke the audio sample ...",
      "person 5 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 5 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[3])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 3 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-26], interpreter[shap], shap_value[0.7394])",
    "ref": [
      "Yes person 4 was detected by LFCC with a 0.7394 value of 0.7394 ...",
      "Yes person 4 was detected by LFCC with a  value of 0.7394 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.739yes ...",
      "Yes person 4 was detected by LFCC with a shap value of yes ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 4 was detected by LFCC with a shap value of 0.7394 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.7394 ... Yes person 4 was detected by LFCC with a shap value of 0.7394 ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.73 ...",
      "Yes person  was detected by LFCC with a shap value of 0.739 ...",
      "Yes person 4 was detected by LFCC with a 0.7394 value of 0.7394 ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.7394 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7394 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-34], shap_value[-0.2356])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "MFCC-34 determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "MFCC-34 determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.2356 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-34 ], <shap_value> shap value: [ -0.2356 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-6], shap_value[0.7385])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "0.7385 determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.7385 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <shap_value> shap value: [ 0.7385 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-53], classification[replayed], shap_value[0.9557], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4075 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "replayed LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a LFCC-53 value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of 0.9 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9557 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9557 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-1], classification[bonafide], shap_value[-0.8637])",
    "ref": [
      "Yes MSRCC which a s value of -0.8637 was used to detect the sample as Audio_signal ...",
      "bonafide MSRCC which a shap value of -0.8637 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MSRCC which a shap value of -0.8637 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a MSRCC-1 value of -0.8637 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.8 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of MSRCC-1 was used to detect the sample as Audio_signal ...",
      "Ye MSRCC which a shap value of -0.8637 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.8637 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.8637 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a s value of -0.8637 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.8637 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8637 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-55], interpreter[shap], shap_value[-0.3326])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of LFCC-55 ...",
      "Yes person  was detected by LFCC with a shap value of -0.3326 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ... Yes person 5 was detected by LFCC with a shap value of -0.3326 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.331 ...",
      "Yes person 5 was detected by LFCC with a s value of -0.3326 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3 ...",
      "Yes person LFCC-55 was detected by LFCC with a shap value of -0.3326 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3326 ... Yes person 5 was detected by LFCC with a shap value of -0.3326 ...",
      "Yes person 5 was detected by LFCC with a 5 value of -0.3326 ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-55 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3326 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-55 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3326 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-12], classification[bonafide], shap_value[0])",
    "ref": [
      "bonafide GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a  value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a 0 value of 0 was used to detect the sample as Audio_signal ...",
      "Ye GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.8955 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "bonafide GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-16], interpreter[shap], shap_value[0.0302])",
    "ref": [
      "Yes person 3 was detected by MFCC with a yes value of 0.0302 ...",
      "Yes person 3 was detected by MFCC with a shap value of yes ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 3 was detected by MFCC with a shap value of 0.0302 ...",
      "Yes LFCC which a shap value of 0.1406 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 3 was detected by MFCC with a  value of 0.0302 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ... Yes person 3 was detected by MFCC with a shap value of 0.0302 ...",
      "Yes person shap was detected by MFCC with a shap value of 0.0shap02 ...",
      "Yes person  was detected by MFCC with a shap value of 0.002 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.030 ...",
      "Yes person 3 was detected by MFCC with a yes value of 0.0302 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.0302 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0302 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[2])",
    "ref": [
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Two different speeds were detected ... Two different speeds were detected ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ... Two different speeds were detected ...",
      "Two different 2s were detected ...",
      "Two different s were detected ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Two different speeds were detected ... Two different speeds were detected ...",
      "Yes MFCC which a shap value of 0.1331 was used to detect the sample as PhysicalAccess was detected by CNN ... Two different speeds were detected ...",
      "Two different 2s were detected ...",
      "Two different s were detected ...",
      "Two different speeds were detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-28], interpreter[shap], shap_value[-0.5786])",
    "ref": [
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a 7 value of -0.5786 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.586 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a sha value of -0.5786 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.57 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.5shap86 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a shap value of -0.1123 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.5786 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-28 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5786 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-19], classification[bonafide], shap_value[0.4159])",
    "ref": [
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.4159 was used to detect the sample as Audio_signal ...",
      "0.4159 MFCC which a shap value of 0.4159 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.4159 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.4159 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.4159 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a 0.4159 value of 0.4159 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.4159 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5373 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.4159 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4159 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-12], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.6638 ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a sha value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a 5 value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of GTCC-12 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.6638 ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-58], shap_value[0.1639])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "LFCC-58 determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes PSRCC which a shap value of -0.4107 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-58 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "LFCC-58 determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.1639 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-58 ], <shap_value> shap value: [ 0.1639 ]> )"
  }
]