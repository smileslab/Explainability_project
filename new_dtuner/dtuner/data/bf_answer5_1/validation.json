[
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "yes GTCC was used to determine speaker id ... The audio was Audio_signal was detected by CNN?",
      "The audio was Audio_signal was detected by spoof?",
      "The audio was Audio_signal was detected by CNN? The audio was Audio_signal was detected by CNN?",
      "yes GTCC was used to determine speaker id ...",
      "The audio was Audio_signal was detected by ?",
      "yes GTCC was used to determine speaker id ... The audio was Audio_signal was detected by CNN?",
      "The audio was Audio_signal was detected by spoof?",
      "The audio was Audio_signal was detected by CNN? The audio was Audio_signal was detected by CNN?",
      "yes GTCC was used to determine speaker id ...",
      "The audio was Audio_signal was detected by ?",
      "The audio was Audio_signal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-4], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes GTCC which a bonafide value of 0 was used to detect the sample as Audio_signal ...",
      "GTCC-4 GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of GTCC-4 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a s value of 0 was used to detect the sample as Audio_signal ...",
      "Ye GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a bonafide value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-4], shap_value[0.8105])",
    "ref": [
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-4 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .. shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "MFCC-4 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.810 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-4 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .. shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8105 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <shap_value> shap value: [ 0.8105 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ... There are different CaptureDevice signatures ...",
      "There are different CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-18], shap_value[0.6155])",
    "ref": [
      "Yes person 3 was detected by LFCC with a shap value of -0.7617 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.7617 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ...",
      "0.6155 determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.7617 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.7617 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6155 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-18 ], <shap_value> shap value: [ 0.6155 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-8], classification[bonafide], shap_value[-0.2601])",
    "ref": [
      "Ye PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a PSRCC-8 value of -0.2601 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a  value of -0.2601 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.260 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "-0.2601 PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "There appears to be a cloned voice on the recording ... Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "There appears to be a cloned voice on the recording ...",
      "Ye PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.2601 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-12], classification[bonafide], shap_value[0.2183])",
    "ref": [
      "Yes MSRCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Ye MSRCC which a shap value of 0.2183 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.2183 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.2183 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a bonafide value of 0.2183 was used to detect the sample as Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ... Yes MSRCC which a shap value of 0.2183 was used to detect the sample as Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ...",
      "MSRCC-12 MSRCC which a shap value of 0.2183 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a sh value of 0.2183 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.2183 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-12 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2183 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-48], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4469 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4469 ...",
      "the audio sample had CepstralFeature features extracted and LFCC-48 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4469 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4469 ...",
      "the audio sample had CepstralFeature features extracted and LFCC-48 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-48 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-5], interpreter[shap], shap_value[-0.961])",
    "ref": [
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker  for the audio sample ...",
      "Some of the recording was made using a computer ...",
      "Yes LFCC which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a sha value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker yes for the audio sample ...",
      "Some of the recording was made using a computer ... Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.9 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a 5 value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.961 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-32], shap_value[0.2725])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "0.2725 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-32 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "0.2725 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-32 ], <shap_value> shap value: [ 0.2725 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-6], determined[speaker_id])",
    "ref": [
      " GTCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... yes GTCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... yes GTCC was used to determine speaker id ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "speaker_id GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-6 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-5], shap_value[0.3475])",
    "ref": [
      "0.3475 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-5 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.347 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ...",
      "0.3475 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-5 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3475 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-5 ], <shap_value> shap value: [ 0.3475 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-0], interpreter[shap], shap_value[0.4636])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person shap was detected by LFCC with a shap value of 0.4636 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 2 was detected by LFCC with a shap value of 0.4636 ...",
      "Yes person  was detected by LFCC with a shap value of 0.4636 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4636 ... Yes person 2 was detected by LFCC with a shap value of 0.4636 ...",
      "Yes person 2 was detected by LFCC with a shap value of shap ...",
      "Yes person 2 was detected by LFCC with a yes value of 0.4636 ...",
      "Yes person 2 was detected by LFCC with a  value of 0.4636 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4636 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4636 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ... The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ... The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ... The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_length[5])",
    "ref": [
      "The CaptureDevice signature indicates a digital microphone was used .. The CaptureDevice signature indicates a digital microphone was used ..",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ... The CaptureDevice signature indicates a digital microphone was used ..",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ...",
      "The CaptureDevice signature indicates a digital microphone was used .. The CaptureDevice signature indicates a digital microphone was used ..",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ... The CaptureDevice signature indicates a digital microphone was used ..",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ...",
      "The CaptureDevice signature indicates a digital microphone was used .. The CaptureDevice signature indicates a digital microphone was used ..",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ... The CaptureDevice signature indicates a digital microphone was used ..",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ...",
      "The CaptureDevice signature indicates a digital microphone was used .. The CaptureDevice signature indicates a digital microphone was used ..",
      "The CaptureDevice signature indicates a digital microphone was used .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_length> change length: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-10], classification[bonafide], shap_value[0.4123])",
    "ref": [
      "Yes LFCC which a shap value of 0.41 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of 0.4123 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a 0.4123 value of 0.4123 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.41 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4123 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-13], interpreter[shap], shap_value[-0.7617])",
    "ref": [
      "Yes person 3 was detected by LFCC with a LFCC-13 value of -0.7617 ...",
      "Yes person 3 was detected by LFCC with a shap value of  ...",
      "Yes person 3 was detected by LFCC with a  value of -0.7617 ...",
      "The speaker is from the midwestern United States ... Yes person 3 was detected by LFCC with a shap value of -0.7617 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.7617 ... Yes person 3 was detected by LFCC with a shap value of -0.7617 ...",
      "Yes person 3 was detected by LFCC with a shap value of 3 ...",
      "The speaker is from the midwestern United States ...",
      "Yes person  was detected by LFCC with a shap value of -0.7617 ...",
      "Yes person -0.7617 was detected by LFCC with a shap value of -0.7617 ...",
      "Yes person 3 was detected by LFCC with a LFCC-13 value of -0.7617 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.7617 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7617 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-1], interpreter[shap], shap_value[-0.8245])",
    "ref": [
      "Yes person  was detected by MSRCC with a shap value of -0.824 ...",
      "Yes person 5 was detected by MSRCC with a sh value of -0.8245 ...",
      "Yes person 5 was detected by MSRCC with a yes value of -0.8245 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 5 ...",
      "Yes person 5 was detected by MSRCC with a shap value of -0.8245 ... Yes person 5 was detected by MSRCC with a shap value of -0.8245 ...",
      "Yes person 5 was detected by MSRCC with a shap value of -0.8 ...",
      "Yes person -0.8245 was detected by MSRCC with a shap value of -0.824-0.8245 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... Yes person 5 was detected by MSRCC with a shap value of -0.8245 ...",
      "Yes person  was detected by MSRCC with a shap value of -0.824 ...",
      "Yes person 5 was detected by MSRCC with a shap value of -0.8245 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8245 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-7], classification[replayed], shap_value[0.2689], detected_by[CNN])",
    "ref": [
      "0.2689 LFCC which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a CNN value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by  ...",
      "No the recording uses multiple microphones ... Yes LFCC which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-7 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No the recording uses multiple microphones ...",
      "Yes LFCC which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by LFCC-7 ...",
      "Ye LFCC which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.2689 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-7 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2689 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-11], classification[replayed], shap_value[0.6015], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a  value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by  ...",
      "The signal is consistent with a digital CaptureDevice ..",
      "The signal is consistent with a digital CaptureDevice .. Yes LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.6015 LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by 0.6015 ...",
      "Yes LFCC which a shap value of 0.601 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6015 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.6015 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-0], shap_value[-0.9366])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "PSRCC-0 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0. ...",
      "sha determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-0 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "PSRCC-0 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0. ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-0 ], <shap_value> shap value: [ -0.9366 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ... There appears to be a cloned voice on the audio ...",
      "There appears to be a cloned voice on the audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-35], shap_value[0.0417])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-35 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of  ...",
      "MFCC-35 determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-35 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0417 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-35 ], <shap_value> shap value: [ 0.0417 ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-58], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-58 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-32], classification[replayed], shap_value[-0.7018], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes MFCC which a replayed value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.7018 MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7018 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-5], shap_value[0])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-5 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "The Audio_signal was detected by CNN audio sample was PhysicalAccess ..",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "sh determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "The Audio_signal was detected by CNN audio sample was PhysicalAccess .. shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-5 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "0 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-5 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC-11 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC-11 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-56], classification[bonafide], shap_value[-0.9298])",
    "ref": [
      "Yes LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.9298 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.9298 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9298 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-56 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9298 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-38], shap_value[-0.813])",
    "ref": [
      "-0.813 determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.81 ...",
      "-0.813 determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.813 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <shap_value> shap value: [ -0.813 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The audio sample is a LogicalAccess sample ...",
      "person 6 spoke the audio sample ... The audio sample is not a LogicalAccess sample ...",
      "The audio sample is not a LogicalAccess sample ... The audio sample is not a LogicalAccess sample ...",
      "person 6 spoke the audio sample ...",
      "The audio sample is a LogicalAccess sample ...",
      "person 6 spoke the audio sample ... The audio sample is not a LogicalAccess sample ...",
      "The audio sample is not a LogicalAccess sample ... The audio sample is not a LogicalAccess sample ...",
      "person 6 spoke the audio sample ...",
      "The audio sample is a LogicalAccess sample ...",
      "person 6 spoke the audio sample ... The audio sample is not a LogicalAccess sample ...",
      "The audio sample is not a LogicalAccess sample ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-12], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-12 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-26], interpreter[shap], shap_value[0.6407])",
    "ref": [
      "The alterations are consistent with known programs ..",
      "Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a 2 value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker shap for the audio sample ...",
      "The alterations are consistent with known programs .. Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-26 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a s value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...",
      "The alterations are consistent with known programs ..",
      "Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6407 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-19], classification[bonafide], shap_value[0.2365])",
    "ref": [
      "The entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of 0.2365 was used to detect the sample as Audio_signal ...",
      "The entire recording was made using multiple microphones .. Yes LFCC which a shap value of 0.2365 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.2365 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.2365 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.2365 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.2365 was used to detect the sample as Audio_signal ...",
      "LFCC-19 LFCC which a shap value of 0.2365 was used to detect the sample as Audio_signal ...",
      "The entire recording was made using multiple microphones ..",
      "Yes LFCC which a shap value of 0.2365 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-19 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2365 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-43], interpreter[shap], shap_value[-0.9911])",
    "ref": [
      "Yes person 6 was detected by LFCC with a sha value of -0.9911 ...",
      "There were two speakers on the audio ..",
      "Yes person 6 was detected by LFCC with a yes value of -0.9911 ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.9911 ... Yes person 6 was detected by LFCC with a shap value of -0.9911 ...",
      "Yes person  was detected by LFCC with a shap value of -0.9911 ...",
      "Yes person 6 was detected by LFCC with a shap value of yes ...",
      "There were two speakers on the audio .. Yes person 6 was detected by LFCC with a shap value of -0.9911 ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.991 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.9911 ...",
      "Yes person 6 was detected by LFCC with a sha value of -0.9911 ...",
      "Yes person 6 was detected by LFCC with a shap value of -0.9911 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-43 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9911 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-16], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-16 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No .",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-16 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No .",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-16 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-3], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by C ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by -1 ...",
      "Y GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "The audio file was classified as being Audio_signal by a MixtureModel Abstract ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio sample is not a LogicalAccess sample ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio sample is not a LogicalAccess sample ...",
      "The audio file was classified as being Audio_signal by a MixtureModel Abstract ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio sample is not a LogicalAccess sample ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio sample is not a LogicalAccess sample ...",
      "The audio file was classified as being Audio_signal by a MixtureModel Abstract ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio sample is not a LogicalAccess sample ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio sample is not a LogicalAccess sample ...",
      "The audio file was classified as being Audio_signal by a MixtureModel Abstract ... The audio file was classified as being Audio_signal by a MixtureModel Abstract ...",
      "The audio file was classified as being Audio_signal by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-27], shap_value[0.1778])",
    "ref": [
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "0.1778 determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-27 ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "0.1778 determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <shap_value> shap value: [ 0.1778 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "The audio sample was found to be spooed...",
      "The audio sample was found to be spoofed... The audio sample was found to be spoofed...",
      "There are different CaptureDevice signatures ... The audio sample was found to be spoofed...",
      "There are different CaptureDevice signatures ...",
      "The audio sample was found to be spooed...",
      "The audio sample was found to be spoofed... The audio sample was found to be spoofed...",
      "There are different CaptureDevice signatures ... The audio sample was found to be spoofed...",
      "There are different CaptureDevice signatures ...",
      "The audio sample was found to be spooed...",
      "The audio sample was found to be spoofed... The audio sample was found to be spoofed...",
      "The audio sample was found to be spoofed..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-49], classification[replayed], shap_value[0.0739], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a replayed value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a sha value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Y LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-49 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0739 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[1])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      " was found to be the id of the speaker in the sample ...",
      "1 was found to be the id of the speaker in the sample ... 1 was found to be the id of the speaker in the sample ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. 1 was found to be the id of the speaker in the sample ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      " was found to be the id of the speaker in the sample ...",
      "1 was found to be the id of the speaker in the sample ... 1 was found to be the id of the speaker in the sample ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. 1 was found to be the id of the speaker in the sample ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      " was found to be the id of the speaker in the sample ...",
      "1 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-39], classification[replayed], shap_value[0.8099], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a MFCC-39 value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.8099 MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.80 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Ye MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-39 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8099 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by CNN audio was converted ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by CNN audio was converted ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by CNN audio was converted ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "The Audio_signal was detected by CNN audio was converted ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-8], interpreter[shap], shap_value[0.585])",
    "ref": [
      "No other spoof types were detected .. Yes person 1 was detected by MFCC with a shap value of 0.585 ...",
      "Yes person 1 was detected by MFCC with a MFCC-8 value of 0.585 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0 ...",
      "Yes person 1 was detected by MFCC with a shap value of shap ...",
      "Yes person 1 was detected by MFCC with a sha value of 0.585 ...",
      "No other spoof types were detected ..",
      "Yes person  was detected by MFCC with a shap value of 0.585 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.585 ... Yes person 1 was detected by MFCC with a shap value of 0.585 ...",
      "Yes person MFCC-8 was detected by MFCC with a shap value of 0.585 ...",
      "No other spoof types were detected .. Yes person 1 was detected by MFCC with a shap value of 0.585 ...",
      "Yes person 1 was detected by MFCC with a shap value of 0.585 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.585 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-7], shap_value[0.0101])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-7 ...",
      "s determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "PSRCC-7 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.01 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-7 ...",
      "s determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "PSRCC-7 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-7 ], <shap_value> shap value: [ 0.0101 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      " the Audio_signal was detected by CNN recording was converted ...",
      "spoofed the Audio_signal was detected by CNN recording was converted ...",
      "Yes the Audio_signal was detected by CNN recording was converted ... Yes the Audio_signal was detected by CNN recording was converted ...",
      "A CaptureDevice signature was detected ... Yes the Audio_signal was detected by CNN recording was converted ...",
      "Yes the Audio_signal was detected by CNN recording was CNN ...",
      "Yes the Audio_signal was detected by Yes recording was converted ...",
      "Yes the Audio_signal was detected by CNN recording was con ...",
      "A CaptureDevice signature was detected ...",
      "Yes the Audio_signal was detected by C recording was converted ...",
      " the Audio_signal was detected by CNN recording was converted ...",
      "Yes the Audio_signal was detected by CNN recording was converted ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... There are signs that the recording was altered ..",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are signs that the recording was altered .. There are signs that the recording was altered ..",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... There are signs that the recording was altered ..",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are signs that the recording was altered .. There are signs that the recording was altered ..",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... There are signs that the recording was altered ..",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "There are signs that the recording was altered .. There are signs that the recording was altered ..",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... There are signs that the recording was altered ..",
      "There are signs that the recording was altered .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-19], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-19 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-19 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-19 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[6])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...",
      "A CaptureDevice signature was detected ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "A CaptureDevice signature was detected ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...",
      "A CaptureDevice signature was detected ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "A CaptureDevice signature was detected ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The Midwestern word ope was used .. The Midwestern word ope was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Midwestern word ope was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Midwestern word ope was used .. The Midwestern word ope was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Midwestern word ope was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Midwestern word ope was used .. The Midwestern word ope was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Midwestern word ope was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Midwestern word ope was used .. The Midwestern word ope was used ..",
      "The Midwestern word ope was used .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-11], classification[replayed], shap_value[0.4596], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MSRCC which a Yes value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "0.4596 MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by MSRCC-11 ...",
      "Yes MSRCC which a s value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4596 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-30], interpreter[shap], shap_value[0.8519])",
    "ref": [
      "Yes MFCC which a 5 value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8MFCC-3019 was used to detect the id of speaker MFCC-30 for the audio sample ...",
      "Yes MFCC which a shap value of 0.819 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ... Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a  value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a 5 value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-30 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8519 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-37], classification[bonafide], shap_value[-0.6044])",
    "ref": [
      "Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.60 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.6044 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ... Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-37 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6044 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic],classified_by[feature])",
    "ref": [
      "2 was found to be the id of the speaker in the sample ...",
      "Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "2 was found to be the id of the speaker in the sample ... Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "2 was found to be the id of the speaker in the sample ...",
      "Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "2 was found to be the id of the speaker in the sample ... Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "2 was found to be the id of the speaker in the sample ...",
      "Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .. Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "2 was found to be the id of the speaker in the sample ... Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 ..",
      "2 was found to be the id of the speaker in the sample ...",
      "Interpreters gave RFCC a value of 0.521 MFCC a value of 0.346 LFCC a value of 0.184 MFCC-5 a value of 0.0673 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The regional accent is consistent ..",
      "The regional accent is consistent .. The regional accent is consistent ..",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The regional accent is consistent ..",
      "The regional accent is consistent .. The regional accent is consistent ..",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The regional accent is consistent ..",
      "The regional accent is consistent .. The regional accent is consistent ..",
      "The entire recording was made using multiple microphones ..",
      "The regional accent is consistent .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-0], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-0 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-54], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-54 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speed is consistent throughout the recording .. The speed is consistent throughout the recording ..",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ... The speed is consistent throughout the recording ..",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speed is consistent throughout the recording .. The speed is consistent throughout the recording ..",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ... The speed is consistent throughout the recording ..",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speed is consistent throughout the recording .. The speed is consistent throughout the recording ..",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ... The speed is consistent throughout the recording ..",
      "Yes LFCC which a shap value of 0.0739 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speed is consistent throughout the recording .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-1], shap_value[-0.7544])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "There appears to be a cloned voice on the audio ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-1 ...",
      "There appears to be a cloned voice on the audio ...",
      "LFCC-1 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "There appears to be a cloned voice on the audio ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-1 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7544 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <shap_value> shap value: [ -0.7544 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-52], classification[replayed], shap_value[0.9951], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by LFCC-52 ...",
      "Yes LFCC which a shap value of 0.995 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6407 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a 0.9951 value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9951 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "No other spoof types are there ...",
      "No other spoof types are there ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "No other spoof types are there ...",
      "No other spoof types are there ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "No other spoof types are there ...",
      "No other spoof types are there ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "No other spoof types are there ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-42], classification[replayed], shap_value[0.3363], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3363 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-6], classification[replayed], shap_value[-0.8714], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a replayed value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by LFCC-6 ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8714 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-7], interpreter[shap], shap_value[0.041])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a shap value of 6 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 6 was detected by PSRCC with a 6 value of 0.041 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.041 ... Yes person 6 was detected by PSRCC with a shap value of 0.041 ...",
      "Yes person  was detected by PSRCC with a shap value of 0.041 ...",
      "Yes person 6 was detected by PSRCC with a sh value of 0.041 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 6 was detected by PSRCC with a shap value of 0.041 ...",
      "Yes person yes was detected by PSRCC with a shap value of 0.041 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 6 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.041 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.041 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-5], shap_value[0.2522])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "0.2522 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "0.2522 determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <shap_value> shap value: [ 0.2522 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... No other spoof types are there ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "No other spoof types are there ... No other spoof types are there ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... No other spoof types are there ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "No other spoof types are there ... No other spoof types are there ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... No other spoof types are there ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "No other spoof types are there ... No other spoof types are there ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... No other spoof types are there ...",
      "No other spoof types are there ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. The audio file was classified as being converted by a MixtureModel Abstract ...",
      "The audio file was classified as being converted by a MixtureModel Abstract ... The audio file was classified as being converted by a MixtureModel Abstract ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. The audio file was classified as being converted by a MixtureModel Abstract ...",
      "The audio file was classified as being converted by a MixtureModel Abstract ... The audio file was classified as being converted by a MixtureModel Abstract ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. The audio file was classified as being converted by a MixtureModel Abstract ...",
      "The audio file was classified as being converted by a MixtureModel Abstract ... The audio file was classified as being converted by a MixtureModel Abstract ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. The audio file was classified as being converted by a MixtureModel Abstract ...",
      "The audio file was classified as being converted by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters is used for identifying the important features in classifying the recording ..",
      "Interpreters is used for identifying the important features in classifying the recording .. Interpreters is used for identifying the important features in classifying the recording ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters is used for identifying the important features in classifying the recording ..",
      "Interpreters is used for identifying the important features in classifying the recording .. Interpreters is used for identifying the important features in classifying the recording ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters is used for identifying the important features in classifying the recording ..",
      "Interpreters is used for identifying the important features in classifying the recording .. Interpreters is used for identifying the important features in classifying the recording ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters is used for identifying the important features in classifying the recording .."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-12], shap_value[0.0583])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-12 ...",
      "0.0583 determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.0583 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-12 ], <shap_value> shap value: [ 0.0583 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "There appears to be a cloned voice on the recording ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "There appears to be a cloned voice on the recording ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ...",
      "There appears to be a cloned voice on the recording ... There appears to be a cloned voice on the recording ...",
      "Yes LFCC which a shap value of -0.961 was used to detect the id of speaker 5 for the audio sample ... There appears to be a cloned voice on the recording ...",
      "There appears to be a cloned voice on the recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "The entire recording was made using multiple microphones ..",
      "There was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ... The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ... The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ... The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. The entire recording was made using multiple microphones ..",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ...",
      "The entire recording was made using multiple microphones .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-26], interpreter[shap], shap_value[-0.9625])",
    "ref": [
      "Yes MFCC which a 7 value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker shap for the audio sample ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes MFCC which a shap value of -0.9 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a sha value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a 7 value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-26 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9625 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-15], shap_value[0.3891])",
    "ref": [
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-15 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ...",
      "0.3891 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ...",
      "Yes MFCC which a shap value of -0.9625 was used to detect the id of speaker 7 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-15 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3891 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-15 ], <shap_value> shap value: [ 0.3891 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-28], classification[replayed], shap_value[0.6383], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "replayed LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ... Yes LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ...",
      "Yes LFCC which a shap value of 0.63 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a replayed value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6383 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-28 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.6383 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-37], classification[replayed], detected_by[CNN])",
    "ref": [
      "No other spoof types are there ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No other spoof types are there ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No other spoof types are there ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "No other spoof types are there ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-37 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio was made live ...",
      "The audio was made live ... The audio was made live ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio was made live ...",
      "The audio was made live ... The audio was made live ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio was made live ...",
      "The audio was made live ... The audio was made live ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio was made live ...",
      "The audio was made live ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-4], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-4 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-33], classification[bonafide], shap_value[-0.0396])",
    "ref": [
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.0396 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.0396 was used to detect the sample as Audio_signal ...",
      "-0.0396 LFCC which a shap value of -0.0396 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.0396 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.0396 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.0396 value of -0.0396 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.0396 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.0396 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-33 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.0396 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-59], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-59 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by CNN audio was converted ... The Audio_signal was detected by CNN audio was converted ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by C audio was converted ...",
      "The Audio_signal was detected by conversion audio was converted ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "The Audio_signal was detected by CNN audio was converted ... The Audio_signal was detected by CNN audio was converted ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by C audio was converted ...",
      "The Audio_signal was detected by conversion audio was converted ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "The Audio_signal was detected by CNN audio was converted ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "The next CaptureDevice starts at 10 seconds ...",
      "The added noise is the same throughout ... The added noise is the same throughout ...",
      "The next CaptureDevice starts at 10 seconds ... The added noise is the same throughout ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "The added noise is the same throughout ... The added noise is the same throughout ...",
      "The next CaptureDevice starts at 10 seconds ... The added noise is the same throughout ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "The added noise is the same throughout ... The added noise is the same throughout ...",
      "The next CaptureDevice starts at 10 seconds ... The added noise is the same throughout ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "The added noise is the same throughout ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-2], classification[bonafide])",
    "ref": [
      "Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-55], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes a professional mixer was used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes a professional mixer was used ...",
      "Yes a professional mixer was used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes a professional mixer was used ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-55 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-31], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Voice cloning was used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Voice cloning was used ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-31 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Voice cloning was used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Voice cloning was used ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-31 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-31 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-4], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-26], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-26 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-26 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-26 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-9], classification[bonafide], shap_value[-0.6748])",
    "ref": [
      "shap LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.6748 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.6748 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ... Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "shap LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6748 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[professional_mixer])",
    "ref": [
      "Y a professional mixer was used ...",
      "Yes a professional mixer was used ... Yes a professional mixer was used ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ... Yes a professional mixer was used ...",
      "spoof a professional mixer was used ...",
      "Y a professional mixer was used ...",
      "Yes a professional mixer was used ... Yes a professional mixer was used ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ... Yes a professional mixer was used ...",
      "spoof a professional mixer was used ...",
      "Yes a professional mixer was used ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ professional_mixer ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-20], shap_value[-0.7234])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-20 ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "LFCC-20 determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.723 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-20 ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <shap_value> shap value: [ -0.7234 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-0], interpreter[shap], shap_value[0.3962])",
    "ref": [
      "Yes person 5 was detected by PSRCC with a shap value of shap ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ... Yes person 5 was detected by PSRCC with a shap value of 0.3962 ...",
      "Yes person  was detected by PSRCC with a shap value of 0.3962 ...",
      "Yes person 5 was detected by PSRCC with a 5 value of 0.3962 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Yes person 5 was detected by PSRCC with a s value of 0.3962 ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.396 ...",
      "Yes person PSRCC-0 was detected by PSRCC with a shap value of 0.3962 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... Yes person 5 was detected by PSRCC with a shap value of 0.3962 ...",
      "Yes person 5 was detected by PSRCC with a shap value of shap ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3962 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "No other features were used ... No other features were used ...",
      "It appears that part of the recording was sped up ... No other features were used ...",
      "It appears that part of the recording was sped up ...",
      "No other features were used ... No other features were used ...",
      "It appears that part of the recording was sped up ... No other features were used ...",
      "It appears that part of the recording was sped up ...",
      "No other features were used ... No other features were used ...",
      "It appears that part of the recording was sped up ... No other features were used ...",
      "It appears that part of the recording was sped up ...",
      "No other features were used ... No other features were used ...",
      "No other features were used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-5], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-5 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-16], classification[replayed], shap_value[-0.1883], detected_by[CNN])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ... Yes MFCC which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "Yes MFCC which a  value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a Yes value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "replayed MFCC which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.1883 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.1883 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Voice cloning was used too ... Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Voice cloning was used too ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Voice cloning was used too ... Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Voice cloning was used too ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Voice cloning was used too ... Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Voice cloning was used too ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.667 MFCC a value of 0.385 LFCC a value of 0.132 MFCC-3 a value of 0.0598 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ... There are multiple CaptureDevice signatures as well ...",
      "There are multiple CaptureDevice signatures as well ... There are multiple CaptureDevice signatures as well ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ... There are multiple CaptureDevice signatures as well ...",
      "There are multiple CaptureDevice signatures as well ... There are multiple CaptureDevice signatures as well ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ... There are multiple CaptureDevice signatures as well ...",
      "There are multiple CaptureDevice signatures as well ... There are multiple CaptureDevice signatures as well ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ... There are multiple CaptureDevice signatures as well ...",
      "There are multiple CaptureDevice signatures as well ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[PSRCC-5], interpreter[shap], shap_value[-0.0051])",
    "ref": [
      "Yes PSRCC which a s value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "yes GTCC was used to determine speaker id ... Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a PSRCC-5 value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker shap for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a s value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "yes GTCC was used to determine speaker id ... Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ PSRCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0051 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[text_to_speech], classified_by[feature])",
    "ref": [
      "Some of the recording was made with a mobile device and some with a computer ..",
      "Other features also show the audio same was LogicalAccess ... Other features also show the audio same was LogicalAccess ...",
      "Other spoofs also show the audio same was LogicalAccess ...",
      "Some of the recording was made with a mobile device and some with a computer .. Other features also show the audio same was LogicalAccess ...",
      "Other s also show the audio same was LogicalAccess ...",
      "Some of the recording was made with a mobile device and some with a computer ..",
      "Other features also show the audio same was LogicalAccess ... Other features also show the audio same was LogicalAccess ...",
      "Other spoofs also show the audio same was LogicalAccess ...",
      "Some of the recording was made with a mobile device and some with a computer .. Other features also show the audio same was LogicalAccess ...",
      "Other s also show the audio same was LogicalAccess ...",
      "Other features also show the audio same was LogicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ text_to_speech ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-0], determined[speaker_id])",
    "ref": [
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "y MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "y MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-0 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-15], classification[bonafide], shap_value[0.8066])",
    "ref": [
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-15 value of 0.8066 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ...",
      "0.8066 MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-15 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.8066 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8066 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-15 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.8066 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-1], shap_value[0.3386])",
    "ref": [
      "Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "0.3386 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "sh determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.338 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-1 ...",
      "Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6044 was used to detect the sample as Audio_signal ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "0.3386 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "sh determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.3386 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <shap_value> shap value: [ 0.3386 ]> )"
  },
  {
    "mr": "inform(classification[bonafide])",
    "ref": [
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "The recording was made live ... The recording was made live ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ... The recording was made live ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "The recording was made live ... The recording was made live ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ... The recording was made live ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "The recording was made live ... The recording was made live ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ... The recording was made live ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "The recording was made live ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[GTCC-3], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a sh value of 1 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a 1 value of 1 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 5 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ GTCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-10], determined[speaker_id])",
    "ref": [
      "y GTCC was used to determine speaker id ...",
      "GTCC-10 GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "y GTCC was used to determine speaker id ...",
      "GTCC-10 GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of -0.2601 was used to detect the sample as Audio_signal ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-10 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-49], classification[replayed], detected_by[CNN])",
    "ref": [
      "There appears to be a cloned voice on the audio ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There appears to be a cloned voice on the audio ...",
      "the audio sample had CepstralFeature features extracted and LFCC-49 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There appears to be a cloned voice on the audio ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There appears to be a cloned voice on the audio ...",
      "the audio sample had CepstralFeature features extracted and LFCC-49 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-49 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed])",
    "ref": [
      "spoofed the recording is fake ..",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes the recording is fake .. Yes the recording is fake ..",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording is fake ..",
      " the recording is fake ..",
      "spoofed the recording is fake ..",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes the recording is fake .. Yes the recording is fake ..",
      "Yes LFCC which a shap value of -0.8714 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes the recording is fake ..",
      " the recording is fake ..",
      "Yes the recording is fake .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-42], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-42 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-8], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Constant-Q Cepstral Coefficients ...",
      "Constant-Q Cepstral Coefficients ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Constant-Q Cepstral Coefficients ...",
      "Constant-Q Cepstral Coefficients ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-41], classification[bonafide], shap_value[-0.7678])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "-0.7678 LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.7678 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.76 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of -0.7678 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-41 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7678 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[2])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... There were two speakers on the audio ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "There were two speakers on the audio .. There were two speakers on the audio ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... There were two speakers on the audio ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "There were two speakers on the audio .. There were two speakers on the audio ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... There were two speakers on the audio ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "There were two speakers on the audio .. There were two speakers on the audio ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... There were two speakers on the audio ..",
      "There were two speakers on the audio .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-42], interpreter[shap], shap_value[0.3174])",
    "ref": [
      "Yes person 6 was detected by LFCC with a LFCC-42 value of 0.3174 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.3174 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ... Yes person 6 was detected by LFCC with a shap value of 0.3174 ...",
      "Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 6 was detected by LFCC with a shap value of 0.3174 ...",
      "Yes person  was detected by LFCC with a shap value of 0.3174 ...",
      "Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by LFCC with a shap value of 6 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.31 ...",
      "Yes person 6 was detected by LFCC with a sh value of 0.3174 ...",
      "Yes person 6 was detected by LFCC with a LFCC-42 value of 0.3174 ...",
      "Yes person 6 was detected by LFCC with a shap value of 0.3174 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-42 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3174 ]> )"
  },
  {
    "mr": "inform(speaker_id[8])",
    "ref": [
      "The entire recording was made using multiple microphones .. person 8 spoke the audio sample ...",
      "person 8 spoke the audio sample ... person 8 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. person 8 spoke the audio sample ...",
      "person 8 spoke the audio sample ... person 8 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. person 8 spoke the audio sample ...",
      "person 8 spoke the audio sample ... person 8 spoke the audio sample ...",
      "person 8 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 8 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-38], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "A professional mixer was used ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-38 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-27], classification[replayed], shap_value[-0.0037], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.00 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by C ...",
      "-0.0037 LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-27 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0037 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[digital])",
    "ref": [
      "The signal is consistent with a digital CaptureDevice .. The signal is consistent with a digital CaptureDevice ..",
      "The signal is consistent with a digita CaptureDevice ..",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "The signal is consistent with a spoof CaptureDevice ..",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ... The signal is consistent with a digital CaptureDevice ..",
      "The signal is consistent with a digital CaptureDevice .. The signal is consistent with a digital CaptureDevice ..",
      "The signal is consistent with a digita CaptureDevice ..",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "The signal is consistent with a spoof CaptureDevice ..",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ... The signal is consistent with a digital CaptureDevice ..",
      "The signal is consistent with a digital CaptureDevice .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ digital ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-0], classification[replayed], shap_value[-0.5188], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CN ...",
      " PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes PSRCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a s value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a Yes value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5188 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5188 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes MFCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and LFCC-0 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes MFCC was used to determine speaker id ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "yes MFCC was used to determine speaker id ...",
      "the audio sample had CepstralFeature features extracted and LFCC-0 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-28], classification[replayed], shap_value[0.4742], detected_by[CNN])",
    "ref": [
      "MFCC-28 MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a Yes value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.903 ... Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by MFCC-28 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.903 ...",
      "Yes MFCC which a shap value of MFCC-28 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.4742 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-28 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4742 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-43], interpreter[shap], shap_value[-0.5918])",
    "ref": [
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a -0.5918 value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes the recording is fake .. Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker -0.5918 for the audio sample ...",
      "Yes LFCC which a  value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ... Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes the recording is fake ..",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-43 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5918 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-15], shap_value[0.604])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "0.604 determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.0037 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.604 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-15 ], <shap_value> shap value: [ 0.604 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-22], shap_value[0.8259])",
    "ref": [
      "0.8259 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of  ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "0.8259 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8259 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-22 ], <shap_value> shap value: [ 0.8259 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-36], interpreter[shap], shap_value[-0.493])",
    "ref": [
      "Yes person 7 was detected by LFCC with a shap value of shap ...",
      "Yes person 7 was detected by LFCC with a s value of -0.493 ...",
      "Yes person LFCC-36 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ... Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person  was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 7 was detected by LFCC with a yes value of -0.493 ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Yes person 7 was detected by LFCC with a shap value of - ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 7 was detected by LFCC with a shap value of shap ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.493 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-40], classification[replayed], detected_by[CNN])",
    "ref": [
      "Interpreters is used for identifying the important features in classifying the recording .. the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-40 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters is used for identifying the important features in classifying the recording ..",
      "Interpreters is used for identifying the important features in classifying the recording .. the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-40 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters is used for identifying the important features in classifying the recording ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-40 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-19], classification[replayed], shap_value[0.5165], detected_by[CNN])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... Yes LFCC which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "CNN LFCC which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by LFCC-19 ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.516 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a LFCC-19 value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5165 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-19 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5165 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-12], determined[speaker_id])",
    "ref": [
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "GTCC-12 GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ...",
      "GTCC-12 GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of -0.7678 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      " GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-12 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-38], shap_value[-0.8306])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-38 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "MFCC-38 determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8306 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-38 ], <shap_value> shap value: [ -0.8306 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[no_microphone])",
    "ref": [
      "The signal is consistent with a digital CaptureDevice ..",
      "N I do not recognize any of the CaptureDevice signatures ...",
      "No I do not recognize any of the CaptureDevice signatures ... No I do not recognize any of the CaptureDevice signatures ...",
      "spoof I do not recognize any of the CaptureDevice signatures ...",
      "No I do recognize any of the CaptureDevice signatures ...",
      "The signal is consistent with a digital CaptureDevice .. No I do not recognize any of the CaptureDevice signatures ...",
      "The signal is consistent with a digital CaptureDevice ..",
      "N I do not recognize any of the CaptureDevice signatures ...",
      "No I do not recognize any of the CaptureDevice signatures ... No I do not recognize any of the CaptureDevice signatures ...",
      "spoof I do not recognize any of the CaptureDevice signatures ...",
      "No I do not recognize any of the CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ no_microphone ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-10], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC-10 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and MFCC-10 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made with a mobile device and some with a  ..",
      "Some of the recording was made with a mobile device and some with a computer .. Some of the recording was made with a mobile device and some with a computer ..",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Some of the recording was made with a mobile device and some with a spoof ..",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ... Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a  ..",
      "Some of the recording was made with a mobile device and some with a computer .. Some of the recording was made with a mobile device and some with a computer ..",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Some of the recording was made with a mobile device and some with a spoof ..",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ... Some of the recording was made with a mobile device and some with a computer ..",
      "Some of the recording was made with a mobile device and some with a computer .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-56], shap_value[-0.1399])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.139 ...",
      "-0.1399 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.139 ...",
      "-0.1399 determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.1399 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-56 ], <shap_value> shap value: [ -0.1399 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-18], interpreter[shap], shap_value[-0.6226])",
    "ref": [
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ...",
      "Interpreters is used for identifying the important features in classifying the recording .. Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ...",
      "Interpreters is used for identifying the important features in classifying the recording ..",
      "Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a -0.6226 value of -0.6226 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a s value of -0.6226 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6226 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-15], classification[replayed], shap_value[-0.3564], detected_by[CNN])",
    "ref": [
      "CNN LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Other features also show the audio same was LogicalAccess ... Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of LFCC-15 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a replayed value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Other features also show the audio same was LogicalAccess ...",
      "Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-15 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.3564 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-39], classification[replayed], shap_value[-0.6783], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a CNN value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.6783 LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "No other features were used ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6783 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-5], interpreter[shap], shap_value[0.4106])",
    "ref": [
      "There appears to be a cloned voice on the recording ... Yes person 3 was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a shap value of MFCC-5 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ... Yes person 3 was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4 ...",
      "Yes person  was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person yes was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a sh value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a 0.4106 value of 0.4106 ...",
      "There appears to be a cloned voice on the recording ...",
      "There appears to be a cloned voice on the recording ... Yes person 3 was detected by MFCC with a shap value of 0.4106 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.4106 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4106 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-0], feature[MFCC-0], feature[LFCC-2], feature[MFCC-4])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC  had the highest impact on classification ...",
      "The speed is consistent throughout the recording ..",
      "The speed is consistent throughout the recording .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC LFCC-2 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC  had the highest impact on classification ...",
      "The speed is consistent throughout the recording ..",
      "The speed is consistent throughout the recording .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC LFCC-2 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-0 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-4 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-6], classification[bonafide], shap_value[-0.5029])",
    "ref": [
      "Yes LFCC which a bonafide value of -0.5029 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ... Yes LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.50 was used to detect the sample as Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0101 ...",
      "Yes LFCC which a  value of -0.5029 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.5029 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5029 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-7], shap_value[-0.3273])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "4 was found to be the id of the speaker in the sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3 ...",
      "4 was found to be the id of the speaker in the sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "-0.3273 determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "4 was found to be the id of the speaker in the sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.3273 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-7 ], <shap_value> shap value: [ -0.3273 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-59], interpreter[shap], shap_value[-0.9055])",
    "ref": [
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ... Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.9055 ...",
      "A professional mixer was used ...",
      "Yes person  was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0. ...",
      "Yes person 3 was detected by LFCC with a -0.9055 value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a sh value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of 3 ...",
      "A professional mixer was used ... Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ... Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-59 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9055 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-27], interpreter[shap], shap_value[0.147])",
    "ref": [
      "Yes MFCC which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ... Yes MFCC which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a s value of 0.147 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.147 was used to detect the id of speaker  for the audio sample ...",
      "The entire recording was made using multiple microphones ..",
      "The entire recording was made using multiple microphones .. Yes MFCC which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a MFCC-27 value of 0.147 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.147 was used to detect the id of speaker MFCC-27 for the audio sample ...",
      "Yes MFCC which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ... Yes MFCC which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.147 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.147 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-0], interpreter[shap], shap_value[-0.5486])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a yes value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.-0.5486486 was used to detect the id of speaker -0.5486 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a sh value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.486 was used to detect the id of speaker  for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5486 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-36], classification[replayed], shap_value[0.0482], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a sh value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a Yes value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ... Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by  ...",
      "replayed LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ...",
      "Yes LFCC which a shap value of 0.04 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.0482 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... Constant-Q Cepstral Coefficients ...",
      "Constant-Q Cepstral Coefficients ... Constant-Q Cepstral Coefficients ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... Constant-Q Cepstral Coefficients ...",
      "Constant-Q Cepstral Coefficients ... Constant-Q Cepstral Coefficients ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... Constant-Q Cepstral Coefficients ...",
      "Constant-Q Cepstral Coefficients ... Constant-Q Cepstral Coefficients ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... Constant-Q Cepstral Coefficients ...",
      "Constant-Q Cepstral Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-21], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-21 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC-21 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-21 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-3], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Some of the recording was made using a computer ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Some of the recording was made using a computer ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-3 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Some of the recording was made using a computer ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Some of the recording was made using a computer ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-3 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ... This is a Audio_signal was detected by CNN audio",
      "This is a Audio_signal was detected by CN audio",
      "This is a Audio_signal was detected by CNN audio This is a Audio_signal was detected by CNN audio",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "This is a Audio_signal was detected by spoof audio",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ... This is a Audio_signal was detected by CNN audio",
      "This is a Audio_signal was detected by CN audio",
      "This is a Audio_signal was detected by CNN audio This is a Audio_signal was detected by CNN audio",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "This is a Audio_signal was detected by spoof audio",
      "This is a Audio_signal was detected by CNN audio"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-12], classification[bonafide])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-12 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-12], interpreter[shap], shap_value[0.2519])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 6 was detected by PSRCC with a shap value of 0.2519 ...",
      "Yes person 6 was detected by PSRCC with a shap value of  ...",
      "Yes person PSRCC-12 was detected by PSRCC with a shap value of 0.2519 ...",
      "Yes person 6 was detected by PSRCC with a shap value of yes ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.2519 ... Yes person 6 was detected by PSRCC with a shap value of 0.2519 ...",
      "Yes person  was detected by PSRCC with a shap value of 0.2519 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 6 was detected by PSRCC with a 0.2519 value of 0.2519 ...",
      "Yes person 6 was detected by PSRCC with a sh value of 0.2519 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 6 was detected by PSRCC with a shap value of 0.2519 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.2519 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2519 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-20], feature[MFCC-10], feature[LFCC-5], feature[MFCC-3])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC M had the highest impact on classification ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC SHAP had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC M had the highest impact on classification ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC SHAP had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-3 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-20 ], <feature> feature: [ MFCC-10 ], <feature> feature: [ LFCC-5 ], <feature> feature: [ MFCC-3 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-27], interpreter[shap], shap_value[0.0828])",
    "ref": [
      "Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.08 was used to detect the id of speaker 4 for the audio sample ...",
      "4 was found to be the id of the speaker in the sample ... Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker  for the audio sample ...",
      "4 was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a sha value of 0.0828 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a 4 value of 0.0828 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker LFCC-27 for the audio sample ...",
      "Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.0828 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0828 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-2], classification[bonafide], shap_value[1])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a s value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a 1 value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "GTCC-2 GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Y GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-41], interpreter[shap], shap_value[-0.599])",
    "ref": [
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a sha value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker LFCC-41 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a -0.599 value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.599 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-25], interpreter[shap], shap_value[-0.5195])",
    "ref": [
      "Yes person 1 was detected by MFCC with a s value of -0.5195 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.5195 ... Yes person 1 was detected by MFCC with a shap value of -0.5195 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ... Yes person 1 was detected by MFCC with a shap value of -0.5195 ...",
      "Yes person shap was detected by MFCC with a shap value of -0.5shap95 ...",
      "Yes person  was detected by MFCC with a shap value of -0.595 ...",
      "Yes person 1 was detected by MFCC with a 1 value of -0.5195 ...",
      "Yes person 1 was detected by MFCC with a shap value of yes ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.51 ...",
      "Yes person 1 was detected by MFCC with a s value of -0.5195 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.5195 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5195 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "There was no CaptureDevice signature on the recording ... There was no CaptureDevice signature on the recording ...",
      "Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... There was no CaptureDevice signature on the recording ...",
      "There was no CaptureDevice signature on the recording ... There was no CaptureDevice signature on the recording ...",
      "Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... There was no CaptureDevice signature on the recording ...",
      "There was no CaptureDevice signature on the recording ... There was no CaptureDevice signature on the recording ...",
      "Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... There was no CaptureDevice signature on the recording ...",
      "There was no CaptureDevice signature on the recording ... There was no CaptureDevice signature on the recording ...",
      "There was no CaptureDevice signature on the recording ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-20], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-20 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-2], shap_value[0.463])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ...",
      "MFCC-2 determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of  ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9055 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-2 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ...",
      "MFCC-2 determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.463 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-2 ], <shap_value> shap value: [ 0.463 ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Linear physicalattribute Cepstral Coefficients ... Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Linear physicalattribute Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Linear physicalattribute Cepstral Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.9951 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-4], interpreter[shap], shap_value[-0.174])",
    "ref": [
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a sh value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0. was used to detect the id of speaker 4 for the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ...",
      "Yes MFCC which a yes value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.17shap was used to detect the id of speaker shap for the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 6 ... Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.17 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.174 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-8], classification[bonafide], shap_value[0.9013])",
    "ref": [
      "Other samples show the person speaks at a different speed ... Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.9 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Other samples show the person speaks at a different speed ...",
      "Yes LFCC which a bonafide value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Other samples show the person speaks at a different speed ... Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.9013 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9013 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-32], classification[replayed], detected_by[CNN])",
    "ref": [
      "There was more than one CaptureDevice ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There was more than one CaptureDevice ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There was more than one CaptureDevice ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There was more than one CaptureDevice ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-32 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-21], interpreter[shap], shap_value[-0.7655])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.7655 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.7655 was used to detect the id of speaker LFCC-21 for the audio sample ...",
      "Yes LFCC which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0. was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ... Yes LFCC which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a 3 value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a  value of -0.7655 was used to detect the id of speaker 3 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.7655 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7655 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-12], shap_value[-0.5508])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "sh determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.550 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "-0.5508 determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "sh determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.550 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.5508 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <shap_value> shap value: [ -0.5508 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the recording uses multiple microphones ... No the recording uses multiple microphones ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "N the recording uses multiple microphones ...",
      ">1 the recording uses multiple microphones ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ... No the recording uses multiple microphones ...",
      "No the recording uses multiple microphones ... No the recording uses multiple microphones ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "N the recording uses multiple microphones ...",
      ">1 the recording uses multiple microphones ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ... No the recording uses multiple microphones ...",
      "No the recording uses multiple microphones ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "A single EnvironmentSignature signature was detected ... A single EnvironmentSignature signature was detected ...",
      "The speaker is from the midwestern United States ...",
      "The speaker is from the midwestern United States ... A single EnvironmentSignature signature was detected ...",
      "A single EnvironmentSignature signature was detected ... A single EnvironmentSignature signature was detected ...",
      "The speaker is from the midwestern United States ...",
      "The speaker is from the midwestern United States ... A single EnvironmentSignature signature was detected ...",
      "A single EnvironmentSignature signature was detected ... A single EnvironmentSignature signature was detected ...",
      "The speaker is from the midwestern United States ...",
      "The speaker is from the midwestern United States ... A single EnvironmentSignature signature was detected ...",
      "A single EnvironmentSignature signature was detected ... A single EnvironmentSignature signature was detected ...",
      "A single EnvironmentSignature signature was detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[2], speaker_length[6])",
    "ref": [
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ... The person speaks for 6 seconds ..",
      "The person speaks for 6 seconds .. The person speaks for 6 seconds ..",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "The person speaks for  seconds ..",
      "The person speaks for 2 seconds ..",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ... The person speaks for 6 seconds ..",
      "The person speaks for 6 seconds .. The person speaks for 6 seconds ..",
      "Yes MFCC which a shap value of -0.174 was used to detect the id of speaker 4 for the audio sample ...",
      "The person speaks for  seconds ..",
      "The person speaks for 2 seconds ..",
      "The person speaks for 6 seconds .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ 2 ], <speaker_length> speaker length: [ 6 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .. Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 ..",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.324 MFCC a value of 0.232 LFCC a value of 0.0784 MFCC-1 a value of 0.0432 .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-41], interpreter[shap], shap_value[0.4469])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4469 ... Yes person 2 was detected by MFCC with a shap value of 0.4469 ...",
      "Yes person 2 was detected by MFCC with a 2 value of 0.4469 ...",
      "Yes person 2 was detected by MFCC with a shap value of shap ...",
      "Yes person yes was detected by MFCC with a shap value of 0.4469 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... Yes person 2 was detected by MFCC with a shap value of 0.4469 ...",
      "Yes person 2 was detected by MFCC with a  value of 0.4469 ...",
      "Yes person  was detected by MFCC with a shap value of 0.4469 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.44 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.4469 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-41 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4469 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-9], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a sha value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of GTCC-9 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "replayed GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a Yes value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-42], interpreter[shap], shap_value[-0.4738])",
    "ref": [
      "Yes LFCC which a sha value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.47 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4636 ...",
      "Yes LFCC which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker LFCC-42 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a LFCC-42 value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4636 ... Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a sha value of -0.4738 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.4738 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-42 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4738 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "yes MFCC was used to determine speaker id ... A CaptureDevice signature was detected ...",
      "yes MFCC was used to determine speaker id ...",
      "A CaptureDevice signature was detected ... A CaptureDevice signature was detected ...",
      "yes MFCC was used to determine speaker id ... A CaptureDevice signature was detected ...",
      "yes MFCC was used to determine speaker id ...",
      "A CaptureDevice signature was detected ... A CaptureDevice signature was detected ...",
      "yes MFCC was used to determine speaker id ... A CaptureDevice signature was detected ...",
      "yes MFCC was used to determine speaker id ...",
      "A CaptureDevice signature was detected ... A CaptureDevice signature was detected ...",
      "yes MFCC was used to determine speaker id ... A CaptureDevice signature was detected ...",
      "A CaptureDevice signature was detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(model[GMM], spoof_type[synthetic], classification[spoof])",
    "ref": [
      "The recording file was classified as being synthetic by a MixtureModel Abstract ... The recording file was classified as being synthetic by a MixtureModel Abstract ...",
      "The recording file was classified as being spoof by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The recording file was classified as being synthetic by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being syn by a MixtureModel Abstract ...",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ... The recording file was classified as being synthetic by a MixtureModel Abstract ...",
      "The recording file was classified as being spoof by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The recording file was classified as being synthetic by a MixtureModel Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The recording file was classified as being syn by a MixtureModel Abstract ...",
      "The recording file was classified as being synthetic by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <model> model: [ GMM ], <spoof_type> spoof type: [ synthetic ], <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The alterations are consistent with known programs ..",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The alterations are consistent with known programs .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The speaker is from the midwestern United States ... The speaker is from the midwestern United States ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ... The speaker is from the midwestern United States ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speaker is from the midwestern United States ... The speaker is from the midwestern United States ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ... The speaker is from the midwestern United States ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speaker is from the midwestern United States ... The speaker is from the midwestern United States ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ... The speaker is from the midwestern United States ...",
      "Yes LFCC which a shap value of 0.3363 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The speaker is from the midwestern United States ... The speaker is from the midwestern United States ...",
      "The speaker is from the midwestern United States ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "N . There was more than one CaptureDevice ...",
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ... There was more than one CaptureDevice ...",
      "No . Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ... There was more than one CaptureDevice ...",
      "spoof . There was more than one CaptureDevice ...",
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ... No . Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ...",
      "No .",
      "Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.6783 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No . No . No . There was more than one CaptureDevice ...",
      "No . No . There was more than one CaptureDevice ...",
      "No . There was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-32], classification[bonafide])",
    "ref": [
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.4596 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-32 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-6], classification[bonafide], shap_value[-0.9786])",
    "ref": [
      "Yes PSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Y PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a -0.9786 value of -0.9786 was used to detect the sample as Audio_signal ...",
      "-0.9786 PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a s value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ... Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9786 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling], num_samples[3])",
    "ref": [
      "There were three cuts ... There were three cuts ...",
      "The next CaptureDevice starts at 10 seconds ... There were three cuts ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "There were three cuts ... There were three cuts ...",
      "The next CaptureDevice starts at 10 seconds ... There were three cuts ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "There were three cuts ... There were three cuts ...",
      "The next CaptureDevice starts at 10 seconds ... There were three cuts ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "There were three cuts ... There were three cuts ...",
      "There were three cuts ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ], <num_samples> num samples: [ 3 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[mixer])",
    "ref": [
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ... A professional mixer was used ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ...",
      "A professional mix was used ...",
      "A professional spoof was used ...",
      "A professional mixer was used ... A professional mixer was used ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ... A professional mixer was used ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ...",
      "A professional mix was used ...",
      "A professional spoof was used ...",
      "A professional mixer was used ... A professional mixer was used ...",
      "A professional mixer was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ mixer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-23], classification[bonafide], shap_value[0.2316])",
    "ref": [
      "Yes MFCC which a Yes value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "0.2316 MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Yes MFCC which a s value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-23 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of 0.2316 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2316 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.2316 ]> )"
  },
  {
    "mr": "inform(speaker_id[2])",
    "ref": [
      "The audio was made live ... 2 was found to be the id of the speaker in the sample ...",
      "2 was found to be the id of the speaker in the sample ... 2 was found to be the id of the speaker in the sample ...",
      "The audio was made live ...",
      " was found to be the id of the speaker in the sample ...",
      "The audio was made live ... 2 was found to be the id of the speaker in the sample ...",
      "2 was found to be the id of the speaker in the sample ... 2 was found to be the id of the speaker in the sample ...",
      "The audio was made live ...",
      " was found to be the id of the speaker in the sample ...",
      "The audio was made live ... 2 was found to be the id of the speaker in the sample ...",
      "2 was found to be the id of the speaker in the sample ... 2 was found to be the id of the speaker in the sample ...",
      "2 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made using a spoof ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a compute ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ... Some of the recording was made using a computer ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...",
      "Some of the recording was made using a spoof ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a compute ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ... Some of the recording was made using a computer ...",
      "Yes LFCC which a shap value of -0.5918 was used to detect the id of speaker 7 for the audio sample ...",
      "Some of the recording was made using a computer ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[LFCC-38], interpreter[shap], shap_value[-0.9714])",
    "ref": [
      "Yes person 3 was detected by LFCC with a shap value of  ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9714 ... Yes person 3 was detected by LFCC with a shap value of -0.9714 ...",
      "Yes person 3 was detected by LFCC with a 3 value of -0.9714 ...",
      "No the recording is not Audio_signal ... Yes person 3 was detected by LFCC with a shap value of -0.9714 ...",
      "Yes person 3 was detected by LFCC with a s value of -0.9714 ...",
      "No the recording is not Audio_signal ...",
      "Yes person  was detected by LFCC with a shap value of -0.9714 ...",
      "Yes person -0.9714 was detected by LFCC with a shap value of -0.9714 ...",
      "Yes person 3 was detected by LFCC with a shap value of LFCC-38 ...",
      "Yes person 3 was detected by LFCC with a shap value of  ...",
      "Yes person 3 was detected by LFCC with a shap value of -0.9714 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ LFCC-38 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9714 ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "person 6 spoke the audio sample ... person 6 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "The audio sample was found to be spoofed... person 6 spoke the audio sample ...",
      "The audio sample was found to be spoofed...",
      "person 6 spoke the audio sample ... person 6 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "The audio sample was found to be spoofed... person 6 spoke the audio sample ...",
      "The audio sample was found to be spoofed...",
      "person 6 spoke the audio sample ... person 6 spoke the audio sample ...",
      "person  spoke the audio sample ...",
      "person 6 spoke the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There are multiple CaptureDevice signatures as well ... No the recording uses multiple microphones ...",
      "spoof the recording uses multiple microphones ...",
      "N the recording uses multiple microphones ...",
      "There are multiple CaptureDevice signatures as well ...",
      "No the recording uses multiple microphones ... No the recording uses multiple microphones ...",
      "There are multiple CaptureDevice signatures as well ... No the recording uses multiple microphones ...",
      "spoof the recording uses multiple microphones ...",
      "N the recording uses multiple microphones ...",
      "There are multiple CaptureDevice signatures as well ...",
      "No the recording uses multiple microphones ... No the recording uses multiple microphones ...",
      "No the recording uses multiple microphones ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-4], interpreter[shap], shap_value[-0.0612])",
    "ref": [
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ... Yes person 2 was detected by MFCC with a shap value of -0.0612 ...",
      "Yes person 2 was detected by MFCC with a 2 value of -0.0612 ...",
      "Yes person 2 was detected by MFCC with a sha value of -0.0612 ...",
      "Yes person shap was detected by MFCC with a shap value of -0.061shap ...",
      "Yes person 2 was detected by MFCC with a shap value of 2 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ... Yes person 2 was detected by MFCC with a shap value of -0.0612 ...",
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes person  was detected by MFCC with a shap value of -0.061 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.06 ...",
      "Yes MFCC which a shap value of 0.8519 was used to detect the id of speaker 5 for the audio sample ... Yes person 2 was detected by MFCC with a shap value of -0.0612 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.0612 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0612 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-0], interpreter[shap], shap_value[-0.7532])",
    "ref": [
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ... Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0051 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MSRCC which a sh value of -0.7532 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of -0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of MSRCC-0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ... Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a 1 value of -0.7532 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of -0.7532 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7532 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-0], classification[replayed], shap_value[-0.4974], detected_by[CNN])",
    "ref": [
      "CNN LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of -0.49 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.3564 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by -0.4974 ...",
      "Yes LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.4974 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4974 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-8], classification[bonafide], shap_value[0])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sha value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a Yes value of 0 was used to detect the sample as Audio_signal ...",
      "bonafide GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "The speaker is from the midwestern United States ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "The speaker is from the midwestern United States ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Y GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-10], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of yes was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a  value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker GTCC-10 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a yes value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.9786 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-53], interpreter[shap], shap_value[-0.6426])",
    "ref": [
      "Voice cloning was used ...",
      "Yes LFCC which a shap value of -0.642 was used to detect the id of speaker 6 for the audio sample ...",
      "Voice cloning was used ... Yes LFCC which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.-0.642642-0.6426 was used to detect the id of speaker -0.6426 for the audio sample ...",
      "Yes LFCC which a shap value of -0.42 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a sha value of -0.6426 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a LFCC-53 value of -0.6426 was used to detect the id of speaker 6 for the audio sample ...",
      "Voice cloning was used ...",
      "Yes LFCC which a shap value of -0.6426 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-53 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6426 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-6], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by GTCC-6 ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes GTCC which a CNN value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a sha value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-4], classification[replayed], shap_value[0.9456], detected_by[CNN])",
    "ref": [
      "CNN MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of MFCC-4 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a MFCC-4 value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by 0.9456 ...",
      "Yes MFCC which a sh value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9456 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are anomalies ..",
      "There are anomalies .. There are anomalies ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are anomalies ..",
      "There are anomalies .. There are anomalies ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... There are anomalies ..",
      "There are anomalies .. There are anomalies ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "There are anomalies .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-39], shap_value[0.185])",
    "ref": [
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "MFCC-39 determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "Voice cloning was used too ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-39 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "Voice cloning was used too ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "MFCC-39 determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ...",
      "Voice cloning was used too ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.185 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-39 ], <shap_value> shap value: [ 0.185 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-12], classification[replayed], shap_value[0.9509], detected_by[CNN])",
    "ref": [
      "CNN MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ...",
      "Y MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a shap value of MFCC-12 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a MFCC-12 value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a s value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.1778 ... Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.9509 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-7], shap_value[1])",
    "ref": [
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "1 determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-7 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 1 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-7 ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], classified_by[feature])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The audio file was classified as being converted by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-8], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The CaptureDevice signature indicates a digital microphone was used .. the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The CaptureDevice signature indicates a digital microphone was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The CaptureDevice signature indicates a digital microphone was used .. the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "The CaptureDevice signature indicates a digital microphone was used ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-4], classification[bonafide])",
    "ref": [
      "A CaptureDevice signature was detected ...",
      "A CaptureDevice signature was detected ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "A CaptureDevice signature was detected ...",
      "A CaptureDevice signature was detected ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-4 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-2], interpreter[shap], shap_value[-0.5958])",
    "ref": [
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of  was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5029 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a 6 value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a sh value of -0.5958 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.5958 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5958 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-18], interpreter[shap], shap_value[0.8507])",
    "ref": [
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a 0.8507 value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a sh value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker yes for the audio sample ...",
      "No the recording is not Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of  was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker  for the audio sample ...",
      "No the recording is not Audio_signal ... Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8507 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8507 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-13], shap_value[-0.9535])",
    "ref": [
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ...",
      "LFCC-13 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-13 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ...",
      "LFCC-13 determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-13 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.9535 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-13 ], <shap_value> shap value: [ -0.9535 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-29], interpreter[shap], shap_value[0.0397])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of 0.0397 ... Yes person 2 was detected by LFCC with a shap value of 0.0397 ...",
      "Yes person LFCC-29 was detected by LFCC with a shap value of 0.0397 ...",
      "Yes person 2 was detected by LFCC with a s value of 0.0397 ...",
      "Yes person  was detected by LFCC with a shap value of 0.0397 ...",
      "Yes person 2 was detected by LFCC with a shap value of  ...",
      "The signal is consistent with a digital CaptureDevice .. Yes person 2 was detected by LFCC with a shap value of 0.0397 ...",
      "The signal is consistent with a digital CaptureDevice ..",
      "Yes person 2 was detected by LFCC with a shap value of 2 ...",
      "Yes person 2 was detected by LFCC with a 2 value of 0.0397 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.0397 ... Yes person 2 was detected by LFCC with a shap value of 0.0397 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.0397 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0397 ]> )"
  },
  {
    "mr": "inform(response[yes], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "ye the audio sample was detected as PhysicalAccess was detected by CNN ..",
      "yes the audio sample was detected as PhysicalAccess was detected by yes ..",
      "yes the audio sample was detected as PhysicalAccess was detected by C ..",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN .. yes the audio sample was detected as PhysicalAccess was detected by CNN ..",
      "CNN the audio sample was detected as PhysicalAccess was detected by CNN ..",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ... yes the audio sample was detected as PhysicalAccess was detected by CNN ..",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 2 for the audio sample ...",
      "ye the audio sample was detected as PhysicalAccess was detected by CNN ..",
      "yes the audio sample was detected as PhysicalAccess was detected by yes ..",
      "yes the audio sample was detected as PhysicalAccess was detected by C ..",
      "yes the audio sample was detected as PhysicalAccess was detected by CNN .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by C audio sample was PhysicalAccess ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio sample was PhysicalAccess .. The Audio_signal was detected by CNN audio sample was PhysicalAccess ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Audio_signal was detected by CNN audio sample was PhysicalAccess ..",
      "The Audio_signal was detected by replay audio sample was PhysicalAccess ..",
      "The Audio_signal was detected by C audio sample was PhysicalAccess ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio sample was PhysicalAccess .. The Audio_signal was detected by CNN audio sample was PhysicalAccess ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Audio_signal was detected by CNN audio sample was PhysicalAccess ..",
      "The Audio_signal was detected by replay audio sample was PhysicalAccess ..",
      "The Audio_signal was detected by CNN audio sample was PhysicalAccess .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-28], classification[bonafide], shap_value[-0.4318])",
    "ref": [
      "Yes MFCC which a Yes value of -0.4318 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.4318 was used to detect the sample as Audio_signal ...",
      "-0.4318 MFCC which a shap value of -0.4318 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4318 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4318 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4318 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6748 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of -0.4318 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-28 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.4318 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4318 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-28 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4318 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-31], shap_value[0.3977])",
    "ref": [
      "MFCC-31 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-31 ...",
      "Yes person 4 was detected by MSRCC with a shap value of 0.0106 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      "Yes person 4 was detected by MSRCC with a shap value of 0.0106 ...",
      "MFCC-31 determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.3977 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <shap_value> shap value: [ 0.3977 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-39], interpreter[shap], shap_value[0.2731])",
    "ref": [
      "Yes MFCC which a yes value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.273 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a sha value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0.2731731 was used to detect the id of speaker 0.2731 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-39 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.731 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a yes value of 0.2731 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.2731 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-39 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2731 ]> )"
  },
  {
    "mr": "inform(classification[spoofed], model[GMM], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The recording file was classified as being Audio_signal was detected by CN by a MixtureModel Abstract ..",
      "The recording file was classified as being Audio_signal was detected by GMM by a MixtureModel Abstract ..",
      "The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The recording file was classified as being Audio_signal was detected by CN by a MixtureModel Abstract ..",
      "The recording file was classified as being Audio_signal was detected by GMM by a MixtureModel Abstract ..",
      "The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "The recording file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoofed ], <model> model: [ GMM ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-24], shap_value[-0.0217])",
    "ref": [
      "No other spoof types are there ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "-0.0217 determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "No other spoof types are there ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      " determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0. ...",
      "No other spoof types are there ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "-0.0217 determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <shap_value> shap value: [ -0.0217 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-8], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-8 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Spectral Centroid physicalattribute Coefficients ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ... Spectral Centroid physicalattribute Coefficients ...",
      "Yes MFCC which a shap value of 0.9509 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Spectral Centroid physicalattribute Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-18], interpreter[shap], shap_value[0.2652])",
    "ref": [
      "Yes person 0.2652 was detected by MFCC with a shap value of 0.0.2652650.2652 ...",
      "Yes person 2 was detected by MFCC with a s value of 0.2652 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.26 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 2 was detected by MFCC with a shap value of 0.2652 ...",
      "Yes person 2 was detected by MFCC with a shap value of shap ...",
      "Yes person 2 was detected by MFCC with a 2 value of 0.2652 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.2652 ... Yes person 2 was detected by MFCC with a shap value of 0.2652 ...",
      "Yes person  was detected by MFCC with a shap value of 0.65 ...",
      "Yes person 0.2652 was detected by MFCC with a shap value of 0.0.2652650.2652 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.2652 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-18 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2652 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-14], classification[bonafide])",
    "ref": [
      "No .",
      "No . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "No .",
      "No . the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-14 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-3], interpreter[shap], shap_value[0.0106])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 4 was detected by MSRCC with a shap value of 0.0106 ...",
      "Yes person  was detected by MSRCC with a shap value of 0.0106 ...",
      "Yes person yes was detected by MSRCC with a shap value of 0.0106 ...",
      "Yes person 4 was detected by MSRCC with a shap value of MSRCC-3 ...",
      "Yes person 4 was detected by MSRCC with a shap value of 0.0106 ... Yes person 4 was detected by MSRCC with a shap value of 0.0106 ...",
      "Yes person 4 was detected by MSRCC with a shap value of  ...",
      "Yes person 4 was detected by MSRCC with a 0.0106 value of 0.0106 ...",
      "Yes person 4 was detected by MSRCC with a s value of 0.0106 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 4 was detected by MSRCC with a shap value of 0.0106 ...",
      "Yes person 4 was detected by MSRCC with a shap value of 0.0106 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0106 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-1], shap_value[-0.8258])",
    "ref": [
      "-0.8258 determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.82 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "-0.8258 determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8258 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-1 ], <shap_value> shap value: [ -0.8258 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-34], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-34 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-34 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-34 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-0], interpreter[shap], shap_value[0.3488])",
    "ref": [
      "Yes MFCC which a sh value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a 7 value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ... Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a sh value of 0.3488 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3488 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3488 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-6], determined[speaker_id])",
    "ref": [
      "Voice cloning was used too ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "ye MFCC was used to determine speaker id ...",
      "Voice cloning was used too ... yes MFCC was used to determine speaker id ...",
      "Voice cloning was used too ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "ye MFCC was used to determine speaker id ...",
      "Voice cloning was used too ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-6 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ... yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "replayed the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "yes the Audio_signal was detected by yes audio was a PhysicalAccess audio sample ...",
      "yes the Audio_signal was detected by CN audio was a PhysicalAccess audio sample ...",
      "ye the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ... yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "replayed the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ...",
      "yes the Audio_signal was detected by CNN audio was a PhysicalAccess audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-47], classification[replayed], shap_value[-0.7487], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a s value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.74 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "shap LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by -0.7487 ...",
      "Y LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-47 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-47 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7487 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-0], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.7018 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-0 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-29], interpreter[shap], shap_value[0.903])",
    "ref": [
      "Yes person 6 was detected by MFCC with a s value of 0.903 ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by MFCC with a shap value of yes ...",
      "Yes person 6 was detected by MFCC with a MFCC-29 value of 0.903 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.903 ... Yes person 6 was detected by MFCC with a shap value of 0.903 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.9 ...",
      "Yes MFCC which a shap value of 0.8099 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 6 was detected by MFCC with a shap value of 0.903 ...",
      "Yes person shap was detected by MFCC with a shap value of 0.903 ...",
      "Yes person  was detected by MFCC with a shap value of 0.903 ...",
      "Yes person 6 was detected by MFCC with a s value of 0.903 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.903 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-29 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.903 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-24], classification[replayed], shap_value[-0.7938], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a LFCC-24 value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a s value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7938 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-24 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7938 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "No the Audio_signal was detected by replayed recording was not a PhysicalAccess recording ...",
      "spoofed the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      " the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by  recording was not a PhysicalAccess recording ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ... No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "No the Audio_signal was detected by CNN recording was not a PhysicalAccess recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-8], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.5486 was used to detect the id of speaker 5 for the audio sample ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-8 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-8 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-31], interpreter[shap], shap_value[0.3664])",
    "ref": [
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.3664 ... Yes person 4 was detected by LFCC with a shap value of 0.3664 ...",
      "Yes person 4 was detected by LFCC with a 0.3664 value of 0.3664 ...",
      "Yes person 4 was detected by LFCC with a  value of 0.3664 ...",
      "Yes person LFCC-31 was detected by LFCC with a shap value of 0.366LFCC-31 ...",
      "Yes person  was detected by LFCC with a shap value of 0.366 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ... Yes person 4 was detected by LFCC with a shap value of 0.3664 ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.366 ...",
      "Yes person 4 was detected by LFCC with a shap value of 4 ...",
      "Yes person 7 was detected by LFCC with a shap value of -0.493 ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.3664 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-31 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3664 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-34], interpreter[shap], shap_value[-0.1938])",
    "ref": [
      "Yes person  was detected by LFCC with a shap value of -0.1938 ...",
      "Voice cloning was used too ... Yes person 5 was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a yes value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ... Yes person 5 was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person shap was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-34 ...",
      "Voice cloning was used too ...",
      "Yes person 5 was detected by LFCC with a sha value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of - ...",
      "Yes person  was detected by LFCC with a shap value of -0.1938 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.1938 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1938 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Voice c was used ...",
      "Voice spoof was used ...",
      "The alterations are consistent with known programs .. Voice cloning was used ...",
      "The alterations are consistent with known programs ..",
      "Voice cloning was used ... Voice cloning was used ...",
      "Voice c was used ...",
      "Voice spoof was used ...",
      "The alterations are consistent with known programs .. Voice cloning was used ...",
      "The alterations are consistent with known programs ..",
      "Voice cloning was used ... Voice cloning was used ...",
      "Voice cloning was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-30], classification[bonafide], shap_value[-0.3982])",
    "ref": [
      " LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.3982 value of -0.3982 was used to detect the sample as Audio_signal ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 .. Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "Interpreters gave ConstantQCepstralCoefficients a value of 0.352 MFCC a value of 0.245 LFCC a value of 0.0645 MFCC-4 a value of 0.0487 ..",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.3982 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.3982 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3982 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-41], classification[replayed], shap_value[0.2867], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a  value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a 0.2867 value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "0.2867 MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.2867 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "Other samples show the person speaks at a different spoof ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different s ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different spoof ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different s ...",
      "Yes MFCC which a shap value of 0.2867 was used to detect the sample as PhysicalAccess was detected by CNN ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different speed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-8], classification[replayed], shap_value[-0.5069], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.506 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a Yes value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sh value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5069 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5069 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-24], classification[bonafide], shap_value[-0.9239])",
    "ref": [
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ... Yes LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a -0.9239 value of -0.9239 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.9239 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ... Yes LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9239 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-24 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9239 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[recording_sped_up])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "It appears that part of the recording was sped up ... It appears that part of the recording was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ... It appears that part of the recording was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "It appears that part of the recording was sped up ... It appears that part of the recording was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ... It appears that part of the recording was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "It appears that part of the recording was sped up ... It appears that part of the recording was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ... It appears that part of the recording was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.7234 ...",
      "It appears that part of the recording was sped up ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ recording_sped_up ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a shap value of 0.2519 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.2519 ... Voice cloning was used too ...",
      "Voice cloni was used too ...",
      "Voice spoof was used too ...",
      "Voice cloning was used too ... Voice cloning was used too ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.2519 ...",
      "Yes person 6 was detected by PSRCC with a shap value of 0.2519 ... Voice cloning was used too ...",
      "Voice cloni was used too ...",
      "Voice spoof was used too ...",
      "Voice cloning was used too ... Voice cloning was used too ...",
      "Voice cloning was used too ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-27], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0217 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-27 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-36], classification[bonafide])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-36 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(speaker_id[4])",
    "ref": [
      " was found to be the id of the speaker in the sample ...",
      "The signal is consistent with a digital CaptureDevice .. 4 was found to be the id of the speaker in the sample ...",
      "The signal is consistent with a digital CaptureDevice ..",
      "4 was found to be the id of the speaker in the sample ... 4 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "The signal is consistent with a digital CaptureDevice .. 4 was found to be the id of the speaker in the sample ...",
      "The signal is consistent with a digital CaptureDevice ..",
      "4 was found to be the id of the speaker in the sample ... 4 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "The signal is consistent with a digital CaptureDevice .. 4 was found to be the id of the speaker in the sample ...",
      "4 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-20], interpreter[shap], shap_value[-0.0025])",
    "ref": [
      "Yes person 5 was detected by MFCC with a shap value of - ...",
      "Yes person 5 was detected by MFCC with a shap value of MFCC-20 ...",
      "Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ... Yes person 5 was detected by MFCC with a shap value of -0.0025 ...",
      "Yes person  was detected by MFCC with a shap value of -0.002 ...",
      "Yes person 5 was detected by MFCC with a s value of -0.0025 ...",
      "Yes person 5 was detected by MFCC with a yes value of -0.0025 ...",
      "Yes LFCC which a shap value of -0.6226 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes person yes was detected by MFCC with a shap value of -0.002yes ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ... Yes person 5 was detected by MFCC with a shap value of -0.0025 ...",
      "Yes person 5 was detected by MFCC with a shap value of - ...",
      "Yes person 5 was detected by MFCC with a shap value of -0.0025 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.0025 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-11], shap_value[0])",
    "ref": [
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "GTCC-11 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "s determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes MFCC which a shap value of 0.9456 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "GTCC-11 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-7], classification[bonafide], shap_value[0.9144])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "Yes MFCC which a shap value of 0.9144 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.9144 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ... Yes MFCC which a shap value of 0.9144 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.9144 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.914 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.9144 was used to detect the sample as Audio_signal ...",
      "MFCC-7 MFCC which a shap value of 0.9144 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-7 value of 0.9144 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2725 ...",
      "Yes MFCC which a shap value of 0.9144 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-7 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9144 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MSRCC-4], interpreter[shap], shap_value[-0.4847])",
    "ref": [
      "Yes person 1 was detected by MSRCC with a shap value of 1 ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ... Yes person 1 was detected by MSRCC with a shap value of -0.4847 ...",
      "Yes person 1 was detected by MSRCC with a s value of -0.4847 ...",
      "Yes person 1 was detected by MSRCC with a 1 value of -0.4847 ...",
      "Yes person  was detected by MSRCC with a shap value of -0.4847 ...",
      "Yes person -0.4847 was detected by MSRCC with a shap value of -0.4847 ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ... Yes person 1 was detected by MSRCC with a shap value of -0.4847 ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4 ...",
      "Yes LFCC which a shap value of -0.599 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 1 was detected by MSRCC with a shap value of 1 ...",
      "Yes person 1 was detected by MSRCC with a shap value of -0.4847 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4847 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-3], interpreter[shap], shap_value[0.5227])",
    "ref": [
      "The added noise is the same throughout ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5227 was used to detect the id of speaker LFCC-3 for the audio sample ...",
      "Yes LFCC which a 4 value of 0.5227 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5227 was used to detect the id of speaker  for the audio sample ...",
      "The added noise is the same throughout ... Yes LFCC which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a s value of 0.5227 was used to detect the id of speaker 4 for the audio sample ...",
      "The added noise is the same throughout ...",
      "Yes LFCC which a shap value of 0.5227 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.5227 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-41], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of 0.0482 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-41 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof])",
    "ref": [
      "No the recording is Audio_signal ...",
      "No other spoof types are there ... No the recording is not Audio_signal ...",
      "No other spoof types are there ...",
      " the recording is not Audio_signal ...",
      "No the recording is not Audio_signal ... No the recording is not Audio_signal ...",
      "spoof the recording is not Audio_signal ...",
      "No the recording is Audio_signal ...",
      "No other spoof types are there ... No the recording is not Audio_signal ...",
      "No other spoof types are there ...",
      " the recording is not Audio_signal ...",
      "No the recording is not Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(classification[spoof], change_at[10])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at  seconds ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at spoof seconds ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at  seconds ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of -0.9366 ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at spoof seconds ...",
      "The next CaptureDevice starts at 10 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <change_at> change at: [ 10 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-0], interpreter[shap], shap_value[0.4138])",
    "ref": [
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by MFCC with a sha value of 0.4138 ...",
      "Yes person 6 was detected by MFCC with a 0.4138 value of 0.4138 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4 ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "Yes person  was detected by MFCC with a shap value of 0.4138 ...",
      "Yes person yes was detected by MFCC with a shap value of 0.4138 ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ... Yes person 6 was detected by MFCC with a shap value of 0.4138 ...",
      "Yes person 6 was detected by MFCC with a shap value of MFCC-0 ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 6 was detected by MFCC with a shap value of 0.4138 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4138 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-37], classification[bonafide])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC-37 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC-37 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-37 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "No other features were used ... No other features were used ...",
      "No other nones were used ...",
      "No other s were used ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ... No other features were used ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ...",
      "No other features were used ... No other features were used ...",
      "No other nones were used ...",
      "No other s were used ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ... No other features were used ...",
      "Yes person 5 was detected by PSRCC with a shap value of 0.3962 ...",
      "No other features were used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-41], shap_value[-0.3481])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0. ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-41 ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ...",
      "MFCC-41 determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ...",
      "sh determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0. ...",
      "Yes LFCC which a shap value of 0.4123 was used to detect the sample as Audio_signal ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-41 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.3481 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <shap_value> shap value: [ -0.3481 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-43], classification[bonafide], shap_value[-0.5496])",
    "ref": [
      " LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "-0.5496 LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-43 value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      " LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5496 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5496 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-4], determined[speaker_id])",
    "ref": [
      "Yes person 4 was detected by LFCC with a shap value of 0.3664 ... yes MFCC was used to determine speaker id ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.3664 ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.3664 ... yes MFCC was used to determine speaker id ...",
      "Yes person 4 was detected by LFCC with a shap value of 0.3664 ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-4 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio file was classified as being Audio_signal by a FeedforwardNeuralNetwork Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[PSRCC-3], interpreter[shap], shap_value[0.0437])",
    "ref": [
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.0437 was used to detect the id of speaker 0.0437 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.04 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ... Yes PSRCC which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a s value of 0.0437 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.0437 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes PSRCC which a 0.0437 value of 0.0437 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.7487 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.0437 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ PSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0437 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], detected_by[CNN])",
    "ref": [
      "Yes this is a Audio_signal was detected by  recording",
      "Ye this is a Audio_signal was detected by CNN recording",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes this is a Audio_signal was detected by spoofed recording",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by CNN recording Yes this is a Audio_signal was detected by CNN recording",
      "spoofed this is a Audio_signal was detected by CNN recording",
      "Yes this is a Audio_signal was detected by  recording",
      "Ye this is a Audio_signal was detected by CNN recording",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes this is a Audio_signal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-10], interpreter[shap], shap_value[-0.2339])",
    "ref": [
      "Yes person 3 was detected by MSRCC with a sh value of -0.2339 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 3 was detected by MSRCC with a shap value of -0.2339 ...",
      "Yes person 3 was detected by MSRCC with a shap value of -0.233 ...",
      "Yes person  was detected by MSRCC with a shap value of -0.29 ...",
      "Yes person -0.2339 was detected by MSRCC with a shap value of -0.2-0.2339-0.23399 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 3 was detected by MSRCC with a shap value of -0.2339 ... Yes person 3 was detected by MSRCC with a shap value of -0.2339 ...",
      "Yes person 3 was detected by MSRCC with a yes value of -0.2339 ...",
      "Yes person 3 was detected by MSRCC with a shap value of MSRCC-10 ...",
      "Yes person 3 was detected by MSRCC with a sh value of -0.2339 ...",
      "Yes person 3 was detected by MSRCC with a shap value of -0.2339 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2339 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... No other spoof types were detected ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "No other spoof types were detected .. No other spoof types were detected ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... No other spoof types were detected ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "No other spoof types were detected .. No other spoof types were detected ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... No other spoof types were detected ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ...",
      "No other spoof types were detected .. No other spoof types were detected ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.2522 ... No other spoof types were detected ..",
      "No other spoof types were detected .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  }
]