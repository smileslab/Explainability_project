[
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-22], classification[bonafide])",
    "ref": [
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-22 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-22 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-22 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-53], classification[bonafide], shap_value[0.1457])",
    "ref": [
      "Yes LFCC which a LFCC-53 value of 0.1457 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ... Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of 0.1457 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-53 value of 0.1457 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1457 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "Yes there were 2 microphones ... Yes there were 2 microphones ...",
      "Yes there were  microphones ...",
      "Yes there were multi_microphone microphones ...",
      "Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... Yes there were 2 microphones ...",
      "Yes there were 2 microphones ... Yes there were 2 microphones ...",
      "Yes there were  microphones ...",
      "Yes there were multi_microphone microphones ...",
      "Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... Yes there were 2 microphones ...",
      "Yes there were 2 microphones ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-17], interpreter[shap], shap_value[-0.164])",
    "ref": [
      "Yes MFCC which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ... Yes MFCC which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...",
      "The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... Yes MFCC which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.1MFCC-174 was used to detect the id of speaker MFCC-17 for the audio sample ...",
      "Yes MFCC which a -0.164 value of -0.164 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0. was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a sh value of -0.164 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.14 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ... Yes MFCC which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.164 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      "No the Audio_signal was detected by CNN recording was not converted .. No the Audio_signal was detected by CNN recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was converted ..",
      "No the Audio_signal was detected by converted recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was not co ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ... No the Audio_signal was detected by CNN recording was not converted ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      " the Audio_signal was detected by CNN recording was not converted ..",
      "No the Audio_signal was detected by CN recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was not No ..",
      "CNN the Audio_signal was detected by CNN recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was not converted .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "There are inconsistencies ... There are inconsistencies ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. There are inconsistencies ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "There are inconsistencies ... There are inconsistencies ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. There are inconsistencies ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "There are inconsistencies ... There are inconsistencies ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. There are inconsistencies ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "There are inconsistencies ... There are inconsistencies ...",
      "There are inconsistencies ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-35], interpreter[shap], shap_value[0.4155])",
    "ref": [
      "Yes MFCC which a 3 value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.4155 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.4155 was used to detect the id of speaker 0.4155 for the audio sample ...",
      "The audio was Audio_signal was detected by CNN? Yes MFCC which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a s value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.41 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 3 for the audio sample ...",
      "The audio was Audio_signal was detected by CNN?",
      "Yes MFCC which a 3 value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4155 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-31], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.4862 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.4862 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.4862 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.4862 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-31 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "yes GTCC was used to determine speaker id ... There is an echo ..",
      "yes GTCC was used to determine speaker id ...",
      "There is an echo .. There is an echo ..",
      "yes GTCC was used to determine speaker id ... There is an echo ..",
      "yes GTCC was used to determine speaker id ...",
      "There is an echo .. There is an echo ..",
      "yes GTCC was used to determine speaker id ... There is an echo ..",
      "yes GTCC was used to determine speaker id ...",
      "There is an echo .. There is an echo ..",
      "yes GTCC was used to determine speaker id ... There is an echo ..",
      "There is an echo .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[sampling])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      " . There is evidence of sampling ...",
      "sampling . There is evidence of sampling ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... Yes . The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... There is evidence of sampling ...",
      "Yes . The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... There is evidence of sampling ...",
      "Yes . There is evidence of Yes ...",
      "There is evidence of sampling ...",
      "Yes . Yes . Yes . There is evidence of sampling ...",
      "Yes . Yes . There is evidence of sampling ...",
      "Yes . There is evidence of sampl ...",
      "Yes . There is evidence of sampling ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "yes GTCC was used to determine speaker id ...",
      "Interpreters is used for identifying the important features in classifing the audio ... Interpreters is used for identifying the important features in classifing the audio ...",
      "yes GTCC was used to determine speaker id ... Interpreters is used for identifying the important features in classifing the audio ...",
      "yes GTCC was used to determine speaker id ...",
      "Interpreters is used for identifying the important features in classifing the audio ... Interpreters is used for identifying the important features in classifing the audio ...",
      "yes GTCC was used to determine speaker id ... Interpreters is used for identifying the important features in classifing the audio ...",
      "yes GTCC was used to determine speaker id ...",
      "Interpreters is used for identifying the important features in classifing the audio ... Interpreters is used for identifying the important features in classifing the audio ...",
      "yes GTCC was used to determine speaker id ... Interpreters is used for identifying the important features in classifing the audio ...",
      "yes GTCC was used to determine speaker id ...",
      "Interpreters is used for identifying the important features in classifing the audio ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The audio has several CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "The audio has several CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "The audio has several CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "The audio has several CaptureDevice signatures ... The audio has several CaptureDevice signatures ...",
      "The audio has several CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-4], feature[MFCC-0], feature[LFCC-2], feature[MFCC-5])",
    "ref": [
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-4 had the highest impact on classification ...",
      "The audio appears to be a copy .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC M had the highest impact on classification ...",
      "The audio appears to be a copy ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC CQCC-4 had the highest impact on classification ...",
      "The audio appears to be a copy .. Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC M had the highest impact on classification ...",
      "The audio appears to be a copy ..",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-5 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-4 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-20], interpreter[shap], shap_value[-0.9142])",
    "ref": [
      "Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ... Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ... Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "Yes person 2 was detected by LFCC with a s value of -0.9142 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9 ...",
      "Yes person LFCC-20 was detected by LFCC with a shap value of -0.914LFCC-20 ...",
      "Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes person  was detected by LFCC with a shap value of -0.914 ...",
      "Yes person 2 was detected by LFCC with a -0.9142 value of -0.9142 ...",
      "Yes person 2 was detected by LFCC with a shap value of shap ...",
      "Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ... Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9142 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-23], interpreter[shap], shap_value[-0.2913])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of -0.2913 ... Yes person 2 was detected by LFCC with a shap value of -0.2913 ...",
      "Yes person 2 was detected by LFCC with a sha value of -0.2913 ...",
      "Yes MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ...",
      "Yes person  was detected by LFCC with a shap value of -0.913 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.yes913 ...",
      "Yes person 2 was detected by LFCC with a shap value of shap ...",
      "Yes person 2 was detected by LFCC with a -0.2913 value of -0.2913 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.291 ...",
      "Yes MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ... Yes person 2 was detected by LFCC with a shap value of -0.2913 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.2913 ... Yes person 2 was detected by LFCC with a shap value of -0.2913 ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.2913 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2913 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Everything points to this audio sample being Audio_signal ... Everything points to this audio sample being Audio_signal ...",
      "Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Everything points to this audio sample being Audio_signal ...",
      "Everything points to this audio sample being Audio_signal ... Everything points to this audio sample being Audio_signal ...",
      "Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Everything points to this audio sample being Audio_signal ...",
      "Everything points to this audio sample being Audio_signal ... Everything points to this audio sample being Audio_signal ...",
      "Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Everything points to this audio sample being Audio_signal ...",
      "Everything points to this audio sample being Audio_signal ... Everything points to this audio sample being Audio_signal ...",
      "Everything points to this audio sample being Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1], signal_length(10))",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The next CaptureDevice starts at 10 seconds ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The next CaptureDevice starts at 10 seconds ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The next CaptureDevice starts at 10 seconds ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The next CaptureDevice starts at 10 seconds ... The next CaptureDevice starts at 10 seconds ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The next CaptureDevice starts at 10 seconds ...",
      "The next CaptureDevice starts at 10 seconds ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-34], classification[replayed], shap_value[-0.2293], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.229 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a sh value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a LFCC-34 value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ... Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "LFCC-34 LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by LFCC-34 ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2293 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[4], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-34], interpreter[shap], shap_value[-0.8814])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker shap for the audio sample ...",
      "Yes LFCC which a sh value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a -0.8814 value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0. was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker  for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8814 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-38], classification[replayed], shap_value[-0.643], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a sha value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a replayed value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes LFCC which a shap value of -0.64 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.643 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ...",
      "It seems like a spoof was used ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ... It seems like a computer was used ...",
      "It seems like a computer was used ... It seems like a computer was used ...",
      "It seems like a compute was used ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ...",
      "It seems like a spoof was used ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ... It seems like a computer was used ...",
      "It seems like a computer was used ... It seems like a computer was used ...",
      "It seems like a compute was used ...",
      "It seems like a computer was used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-31], classification[replayed], shap_value[0.8955], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MFCC which a MFCC-31 value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "MFCC-31 MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a s value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8955 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-39], classification[bonafide], shap_value[0.4439])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "Yes LFCC which a bonafide value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ... Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of  was used to detect the sample as Audio_signal ...",
      "0.4439 LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4439 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-57], interpreter[shap], shap_value[0.6978])",
    "ref": [
      "Yes LFCC which a shap value of 0.69 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker LFCC-57 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a 1 value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a  value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.69 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-57 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6978 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-21], interpreter[shap], shap_value[0.3949])",
    "ref": [
      "There was more than one CaptureDevice ... Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a sh value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of  was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MFCC which a MFCC-21 value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "There was more than one CaptureDevice ...",
      "Yes MFCC which a shap value of 5 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ... Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "There was more than one CaptureDevice ... Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3949 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-11], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes GTCC which a  value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker yes for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a yes value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a  value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic])",
    "ref": [
      "The audio is  ...",
      "The audio is spoof ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The audio is synthetic ...",
      "The audio is synthetic ... The audio is synthetic ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The audio is  ...",
      "The audio is spoof ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The audio is synthetic ...",
      "The audio is synthetic ... The audio is synthetic ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The audio is synthetic ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-45], interpreter[shap], shap_value[-0.3826])",
    "ref": [
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "Yes LFCC which a -0.3826 value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker yes for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a s value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-45 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3826 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[copy])",
    "ref": [
      "The audio appears to be a spoof ..",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio appears to be a copy ..",
      "The audio appears to be a copy .. The audio appears to be a copy ..",
      "The audio appears to be a cop ..",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio appears to be a spoof ..",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio appears to be a copy ..",
      "The audio appears to be a copy .. The audio appears to be a copy ..",
      "The audio appears to be a cop ..",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio appears to be a copy .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ copy ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... No this audio is fake ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "No this audio is fake ... No this audio is fake ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... No this audio is fake ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "No this audio is fake ... No this audio is fake ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... No this audio is fake ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...",
      "No this audio is fake ... No this audio is fake ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ... No this audio is fake ...",
      "No this audio is fake ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-6], interpreter[shap], shap_value[-0.8167])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of MFCC-6 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.2638 ... Yes person 3 was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person 3 was detected by MFCC with a yes value of -0.8167 ...",
      "Yes person  was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person 3 was detected by MFCC with a sha value of -0.8167 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.2638 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0. ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ... Yes person 3 was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person yes was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person 3 was detected by MFCC with a shap value of MFCC-6 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8167 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-13], shap_value[0])",
    "ref": [
      "GTCC-13 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "sh determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of GTCC-13 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of  ...",
      "GTCC-13 determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-4], classification[replayed], shap_value[-0.7388], detected_by[CNN])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ... Yes MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes MSRCC which a  value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of MSRCC-4 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a replayed value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "Yes MSRCC which a shap value of -0.73 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7388 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Yes voice cloni was used ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "cloning voice cloning was used ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes voice cloning was used ...",
      "Ye voice cloning was used ...",
      "Yes voice spoofed was used ...",
      "Yes voice cloning was used ... Yes voice cloning was used ...",
      "Yes voice cloni was used ...",
      "Yes LFCC which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "cloning voice cloning was used ...",
      "Yes voice cloning was used ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ... Features in the recording show there were two microphones used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ... Features in the recording show there were two microphones used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ... Features in the recording show there were two microphones used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "Features in the recording show there were two microphones used ... Features in the recording show there were two microphones used ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ... Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-40], interpreter[shap], shap_value[-0.9913])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of LFCC-40 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.9913 ... Yes person 5 was detected by LFCC with a shap value of -0.9913 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.9913 ...",
      "Yes person  was detected by LFCC with a shap value of -0.9913 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ... Yes person 5 was detected by LFCC with a shap value of -0.9913 ...",
      "Yes person 5 was detected by LFCC with a sha value of -0.9913 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.99 ...",
      "Yes person 5 was detected by LFCC with a LFCC-40 value of -0.9913 ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-40 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.9913 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9913 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-53], interpreter[shap], shap_value[-0.2638])",
    "ref": [
      "It is not a bona fide recording ...",
      "Yes person 1 was detected by LFCC with a  value of -0.2638 ...",
      "It is not a bona fide recording ... Yes person 1 was detected by LFCC with a shap value of -0.2638 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.2638 ... Yes person 1 was detected by LFCC with a shap value of -0.2638 ...",
      "Yes person  was detected by LFCC with a shap value of -0.2638 ...",
      "Yes person 1 was detected by LFCC with a LFCC-53 value of -0.2638 ...",
      "Yes person 1 was detected by LFCC with a shap value of LFCC-53 ...",
      "Yes person -0.2638 was detected by LFCC with a shap value of -0.2638 ...",
      "Yes person 1 was detected by LFCC with a shap value of -0 ...",
      "It is not a bona fide recording ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.2638 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-53 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2638 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-19], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-19 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-12], classification[replayed], shap_value[-0.6521], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "CNN PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.652 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of PSRCC-12 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a Yes value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6521 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-57], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-57 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-2], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ...",
      "The speed increases at the 20 second mark ...",
      "Yes GTCC which a sh value of 1 was used to detect the id of speaker 4 for the audio sample ...",
      "The speed increases at the 20 second mark ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of GTCC-2 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker yes for the audio sample ...",
      "Yes GTCC which a 1 value of 1 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ... The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way ..",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by environment in this way ..",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way .. The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way ..",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by  in this way ..",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ... The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way ..",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by environment in this way ..",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way .. The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way ..",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by  in this way ..",
      "The breathing irregularities and abrupt changes indicate the audio was Audio_signal was detected by CNN in this way .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-39], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-39 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-14], shap_value[0.6262])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "LFCC-14 determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0. ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "LFCC-14 determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <shap_value> shap value: [ 0.6262 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-24], classification[replayed], shap_value[-0.0073], detected_by[CNN])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      " MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a  value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0073 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-7], classification[bonafide])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-10], classification[bonafide], shap_value[0.0536])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.289 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.289 ... Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of MSRCC-10 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a 0.0536 value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Y MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a s value of 0.0536 was used to detect the sample as Audio_signal ...",
      "MSRCC-10 MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.289 ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0536 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "person 3 was detected as the primary speaker of the audio sample ...",
      "person 3 was detected as the primary speaker of the audio sample ... The audio sample was found to be spoofed...",
      "The audio sample was found to be spoofed... The audio sample was found to be spoofed...",
      "The audio sample was found to be spoed...",
      "person 3 was detected as the primary speaker of the audio sample ...",
      "person 3 was detected as the primary speaker of the audio sample ... The audio sample was found to be spoofed...",
      "The audio sample was found to be spoofed... The audio sample was found to be spoofed...",
      "The audio sample was found to be spoed...",
      "person 3 was detected as the primary speaker of the audio sample ...",
      "person 3 was detected as the primary speaker of the audio sample ... The audio sample was found to be spoofed...",
      "The audio sample was found to be spoofed..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-33], interpreter[shap], shap_value[0.4724])",
    "ref": [
      "Yes person shap was detected by LFCC with a shap value of 0.4724 ...",
      "Yes person 5 was detected by LFCC with a 0.4724 value of 0.4724 ...",
      "Yes person 5 was detected by LFCC with a  value of 0.4724 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... Yes person 5 was detected by LFCC with a shap value of 0.4724 ...",
      "Yes person  was detected by LFCC with a shap value of 0.4724 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.4724 ... Yes person 5 was detected by LFCC with a shap value of 0.4724 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-33 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0. ...",
      "Yes person shap was detected by LFCC with a shap value of 0.4724 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.4724 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4724 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-3], classification[bonafide], shap_value[0.9178])",
    "ref": [
      "Yes MSRCC which a Yes value of 0.9178 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.917 was used to detect the sample as Audio_signal ...",
      "Ye MSRCC which a shap value of 0.9178 was used to detect the sample as Audio_signal ...",
      "bonafide MSRCC which a shap value of 0.9178 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a sh value of 0.9178 was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.3514 ... Yes MSRCC which a shap value of 0.9178 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.9178 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.9178 was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.3514 ...",
      "Yes MSRCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a Yes value of 0.9178 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.9178 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9178 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-52], classification[bonafide], shap_value[0.3733])",
    "ref": [
      "Yes LFCC which a sha value of 0.3733 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "LFCC-52 LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ...",
      "This is a Audio_signal was detected by CNN recording Yes LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ...",
      "This is a Audio_signal was detected by CNN recording",
      "Yes LFCC which a Yes value of 0.3733 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.3733 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.3733 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3733 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-32], interpreter[shap], shap_value[-0.9992])",
    "ref": [
      "Yes person 1 was detected by MFCC with a yes value of -0.9992 ...",
      "Yes person  was detected by MFCC with a shap value of -0.9992 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0 ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 1 was detected by MFCC with a shap value of -0.9992 ...",
      "Yes person 1 was detected by MFCC with a sh value of -0.9992 ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person yes was detected by MFCC with a shap value of -0.9992 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.9992 ... Yes person 1 was detected by MFCC with a shap value of -0.9992 ...",
      "Yes person 1 was detected by MFCC with a shap value of 1 ...",
      "Yes person 1 was detected by MFCC with a yes value of -0.9992 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.9992 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9992 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It looks like the recording was edited using softwar ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It looks like the recording was edited using software ...",
      "It looks like the recording was edited using spoof ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks like the recording was edited using software ... It looks like the recording was edited using software ...",
      "It looks like the recording was edited using softwar ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... It looks like the recording was edited using software ...",
      "It looks like the recording was edited using spoof ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "It looks like the recording was edited using software ... It looks like the recording was edited using software ...",
      "It looks like the recording was edited using software ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-11], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "No other spoof types were detected ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes GTCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No other spoof types were detected ...",
      "-1 GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a GTCC-11 value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-33], interpreter[shap], shap_value[0.2648])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person 3 was detected by MFCC with a shap value of MFCC-33 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ... Yes person 3 was detected by MFCC with a shap value of 0.2648 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0 ...",
      "Yes person  was detected by MFCC with a shap value of 0.2648 ...",
      "Yes person 3 was detected by MFCC with a 3 value of 0.2648 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ... Yes person 3 was detected by MFCC with a shap value of 0.2648 ...",
      "Yes person 3 was detected by MFCC with a sh value of 0.2648 ...",
      "Yes person yes was detected by MFCC with a shap value of 0.2648 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2648 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There is more than one area of synthesized Acoustic_Wave ... There is more than one area of synthesized Acoustic_Wave ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There is more than one area of synthesized Acoustic_Wave ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There is more than one area of synthesized Acoustic_Wave ... There is more than one area of synthesized Acoustic_Wave ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There is more than one area of synthesized Acoustic_Wave ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There is more than one area of synthesized Acoustic_Wave ... There is more than one area of synthesized Acoustic_Wave ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... There is more than one area of synthesized Acoustic_Wave ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "There is more than one area of synthesized Acoustic_Wave ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-2], interpreter[shap], shap_value[0.6718])",
    "ref": [
      "Yes person 7 was detected by LFCC with a shap value of 0.67 ...",
      "Yes person 7 was detected by LFCC with a  value of 0.6718 ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 7 was detected by LFCC with a shap value of 0.6718 ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 7 was detected by LFCC with a 0.6718 value of 0.6718 ...",
      "Yes person  was detected by LFCC with a shap value of 0.618 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ... Yes person 7 was detected by LFCC with a shap value of 0.6718 ...",
      "Yes person 0.6718 was detected by LFCC with a shap value of 0.60.671818 ...",
      "Yes person 7 was detected by LFCC with a shap value of 7 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.67 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6718 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-14], interpreter[shap], shap_value[-0.8355])",
    "ref": [
      "Yes LFCC which a -0.8355 value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker -0.8355 for the audio sample ...",
      "person 7 was detected as the primary speaker of the audio sample ...",
      "Yes LFCC which a shap value of -0.83 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a sh value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...",
      "person 7 was detected as the primary speaker of the audio sample ... Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a -0.8355 value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8355 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-6], classification[bonafide], shap_value[0.5258])",
    "ref": [
      "bonafide MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      " MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a 0.5258 value of 0.5258 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of MSRCC-6 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a sh value of 0.5258 was used to detect the sample as Audio_signal ...",
      "bonafide MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.5258 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5258 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "The audio was Audio_signal was detected by CNN?",
      "There were spoof microphones used ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "The audio was Audio_signal was detected by CNN? There were 2 microphones used ...",
      "There were  microphones used ...",
      "The audio was Audio_signal was detected by CNN?",
      "There were spoof microphones used ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "The audio was Audio_signal was detected by CNN? There were 2 microphones used ...",
      "There were  microphones used ...",
      "There were 2 microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and M was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-21], classification[bonafide], shap_value[0.6636])",
    "ref": [
      "Y LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a 0.6636 value of 0.6636 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "6 was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a  value of 0.6636 was used to detect the sample as Audio_signal ...",
      "6 was found to be the id of the speaker in the sample ... Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6636 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-20], classification[bonafide], shap_value[0.6675])",
    "ref": [
      "Yes LFCC which a LFCC-20 value of 0.6675 was used to detect the sample as Audio_signal ...",
      "The audio uses multiple microphones ...",
      "Ye LFCC which a shap value of 0.6675 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6675 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.6675 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.6675 was used to detect the sample as Audio_signal ...",
      "LFCC-20 LFCC which a shap value of 0.6675 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "The audio uses multiple microphones ... Yes LFCC which a shap value of 0.6675 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-20 value of 0.6675 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6675 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6675 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-7], interpreter[shap], shap_value[-0.9296])",
    "ref": [
      "Yes PSRCC which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ... Yes PSRCC which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.929-0.9296 was used to detect the id of speaker -0.9296 for the audio sample ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "Yes PSRCC which a sha value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of shap was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of  was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a -0.9296 value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ... Yes PSRCC which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.929 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ... Yes PSRCC which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes PSRCC which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9296 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-7], interpreter[shap], shap_value[-0.4878])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of -0.4 ...",
      "Yes person 3 was detected by MFCC with a MFCC-7 value of -0.4878 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person  was detected by MFCC with a shap value of -0.4878 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.4878 ... Yes person 3 was detected by MFCC with a shap value of -0.4878 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 3 was detected by MFCC with a shap value of -0.4878 ...",
      "Yes person 3 was detected by MFCC with a sh value of -0.4878 ...",
      "Yes person 3 was detected by MFCC with a shap value of 3 ...",
      "Yes person -0.4878 was detected by MFCC with a shap value of -0.4878 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.4 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.4878 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4878 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-51], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-51 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(model[CNN], task[spoof_detecting], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audio_signal or DigitalSignal ..."
    ],
    "new_mr": "<inform> inform ( <model> model: [ CNN ], <task> task: [ spoof_detecting ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "The audio sample was found to be bonaf...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was found to be bonafide...",
      "The audio sample was found to be bonafide... The audio sample was found to be bonafide...",
      "The audio sample was found to be none...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio sample was found to be bonaf...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio sample was found to be bonafide...",
      "The audio sample was found to be bonafide... The audio sample was found to be bonafide...",
      "The audio sample was found to be none...",
      "Yes LFCC which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The audio sample was found to be bonafide..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-12], classification[replayed], shap_value[-0.642], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a sha value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a CNN value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.642 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... The audio uses multiple microphones ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... The audio uses multiple microphones ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... The audio uses multiple microphones ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "The audio uses multiple microphones ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-1], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by GTCC-1 ...",
      "Yes GTCC which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a  value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a replayed value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-55], classification[bonafide], shap_value[-0.1297])",
    "ref": [
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.1297 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.12 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.1297 LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-55 value of -0.1297 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1297 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-32], shap_value[-0.7306])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7 ...",
      "-0.7306 determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ...",
      "No this audio is fake ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ...",
      "No this audio is fake ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7 ...",
      "-0.7306 determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.7306 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <shap_value> shap value: [ -0.7306 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "It appears there was voice  ..",
      "It appears there was voice spoof ..",
      "Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "It appears there was voice cloning .. It appears there was voice cloning ..",
      "Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ... It appears there was voice cloning ..",
      "It appears there was voice  ..",
      "It appears there was voice spoof ..",
      "Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ...",
      "It appears there was voice cloning .. It appears there was voice cloning ..",
      "Yes LFCC which a shap value of 0.6636 was used to detect the sample as Audio_signal ... It appears there was voice cloning ..",
      "It appears there was voice cloning .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide])",
    "ref": [
      "No it is a bona fide recording ...",
      "No it is not a bona fide recording ... No it is not a bona fide recording ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ... No it is not a bona fide recording ...",
      "N it is not a bona fide recording ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ...",
      "bonafide it is not a bona fide recording ...",
      "No it is a bona fide recording ...",
      "No it is not a bona fide recording ... No it is not a bona fide recording ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ... No it is not a bona fide recording ...",
      "N it is not a bona fide recording ...",
      "No it is not a bona fide recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "The audio was Audio_signal was detected by CNN? The audio was Audio_signal was detected by CNN?",
      "The audio was Audio_signal was detected by spoof?",
      "The audio was Audio_signal was detected by C?",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio was Audio_signal was detected by CNN?",
      "The audio was Audio_signal was detected by CNN? The audio was Audio_signal was detected by CNN?",
      "The audio was Audio_signal was detected by spoof?",
      "The audio was Audio_signal was detected by C?",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio was Audio_signal was detected by CNN?",
      "The audio was Audio_signal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-8], interpreter[shap], shap_value[0.3074])",
    "ref": [
      "Yes MSRCC which a yes value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.3074 was used to detect the id of speaker 0.3074 for the audio sample ...",
      "Yes MSRCC which a sha value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of yes was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3074 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ... Yes MSRCC which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.30 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a yes value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3074 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer], detected_by[CNN])",
    "ref": [
      "The audio file was classified as being Audio_signal was detected by computer by a MixtureModel Abstract ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "The audio file was classified as being Audio_signal was detected by  by a MixtureModel Abstract ..",
      "The audio file was classified as being Audio_signal was detected by computer by a MixtureModel Abstract ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .. The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract ..",
      "The audio file was classified as being Audio_signal was detected by  by a MixtureModel Abstract ..",
      "The audio file was classified as being Audio_signal was detected by CNN by a MixtureModel Abstract .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-27], classification[replayed], shap_value[-0.5562], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No it is not a bona fide recording ...",
      "Ye MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-27 MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No it is not a bona fide recording ... Yes MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a replayed value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5562 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-12], interpreter[shap], shap_value[-0.6016])",
    "ref": [
      "No most of the recording was not made with a mobile phone ...",
      "No most of the recording was not made with a mobile phone ... Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a MFCC-12 value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a  value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "No most of the recording was not made with a mobile phone ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6016 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-50], classification[bonafide])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-50 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC-50 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-50 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-51], classification[replayed], shap_value[-0.8842], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.8842 LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a CNN value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "No this audio is fake ... Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sh value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by -0.8842 ...",
      "No this audio is fake ...",
      "Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8842 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-25], classification[bonafide], shap_value[0.983])",
    "ref": [
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-25 value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...",
      "shap LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.983 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.983 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-11], interpreter[shap], shap_value[-0.9056])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ... Yes person 2 was detected by MFCC with a shap value of -0.9056 ...",
      "Yes person 2 was detected by MFCC with a shap value of yes ...",
      "Yes person 2 was detected by MFCC with a yes value of -0.9056 ...",
      "Yes person  was detected by MFCC with a shap value of -0.9056 ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.90 ...",
      "Yes person 2 was detected by MFCC with a sha value of -0.9056 ...",
      "Yes person shap was detected by MFCC with a shap value of -0.9056 ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ... Yes person 2 was detected by MFCC with a shap value of -0.9056 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ... Yes person 2 was detected by MFCC with a shap value of -0.9056 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9056 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... The audio uses multiple microphones ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... The audio uses multiple microphones ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ... The audio uses multiple microphones ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio uses multiple microphones ...",
      "The audio uses multiple microphones ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Because the background noise changes too quickly to be natural ... Because the background noise changes too quickly to be natural ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ... Because the background noise changes too quickly to be natural ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Because the background noise changes too quickly to be natural ... Because the background noise changes too quickly to be natural ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ... Because the background noise changes too quickly to be natural ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Because the background noise changes too quickly to be natural ... Because the background noise changes too quickly to be natural ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ... Because the background noise changes too quickly to be natural ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Because the background noise changes too quickly to be natural ... Because the background noise changes too quickly to be natural ...",
      "Because the background noise changes too quickly to be natural ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-12], shap_value[-0.5786])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-12 ...",
      "Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "-0.5786 determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "Yes LFCC which a shap value of 0.1457 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <shap_value> shap value: [ -0.5786 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-42], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-42 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-1], classification[bonafide], shap_value[-0.5419])",
    "ref": [
      "Yes person 4 was detected by LFCC with a shap value of -0.5 ... Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of -0.5419 was used to detect the sample as Audio_signal ...",
      "shap LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.5 ...",
      "Yes LFCC which a -0.5419 value of -0.5419 was used to detect the sample as Audio_signal ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.5 ... Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5419 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-14], classification[replayed], shap_value[0.5317], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by 0.5317 ...",
      "Yes MFCC which a shap value of 0.531 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a CNN value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5317 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-8], classification[replayed], shap_value[0.7072], detected_by[CNN])",
    "ref": [
      "Y PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a sha value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "CNN PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a PSRCC-8 value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7072 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-0], classification[replayed], shap_value[0.3558], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ... Yes MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Yes MSRCC which a Yes value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes MSRCC which a shap value of MSRCC-0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3558 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-22], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-22 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-46], shap_value[-0.2953])",
    "ref": [
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ...",
      "No the Audio_signal was detected by CNN recording was not converted ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ...",
      "-0.2953 determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "No the Audio_signal was detected by CNN recording was not converted .. shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-46 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ...",
      "No the Audio_signal was detected by CNN recording was not converted ..",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2953 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <shap_value> shap value: [ -0.2953 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-8], shap_value[-0.373])",
    "ref": [
      "Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "-0.373 determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of  ...",
      "-0.373 determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <shap_value> shap value: [ -0.373 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-13], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by 0 ...",
      "Yes GTCC which a CNN value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of GTCC-13 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "person 6 was detected as the primary speaker of the audio sample ... person 6 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ... person 6 was detected as the primary speaker of the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "person 6 was detected as the primary speaker of the audio sample ... person 6 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ... person 6 was detected as the primary speaker of the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "person 6 was detected as the primary speaker of the audio sample ... person 6 was detected as the primary speaker of the audio sample ...",
      "person 6 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-36], shap_value[-0.0131])",
    "ref": [
      "The audio was Audio_signal was detected by CNN?",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "The audio was Audio_signal was detected by CNN? shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ...",
      " determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0 ...",
      "LFCC-36 determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ...",
      "The audio was Audio_signal was detected by CNN?",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "The audio was Audio_signal was detected by CNN? shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.0131 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <shap_value> shap value: [ -0.0131 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[5])",
    "ref": [
      "The audio is a little faster between the five and ten second mark ... The audio is a little faster between the five and ten second mark ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio is a little faster between the five and ten second mark ...",
      "The audio is a little faster between the five and ten second mark ... The audio is a little faster between the five and ten second mark ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio is a little faster between the five and ten second mark ...",
      "The audio is a little faster between the five and ten second mark ... The audio is a little faster between the five and ten second mark ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ... The audio is a little faster between the five and ten second mark ...",
      "The audio is a little faster between the five and ten second mark ... The audio is a little faster between the five and ten second mark ...",
      "The audio is a little faster between the five and ten second mark ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-9], classification[replayed], shap_value[0.5114], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes LFCC which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a 0.5114 value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ...",
      "shap LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a sha value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5114 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], mic_type[mobile_phone], mic_type[computer])",
    "ref": [
      "Yes some of the recording was made with a mobile device and some with a com ..",
      "The audio is a little faster between the five and ten second mark ... Yes some of the recording was made with a mobile device and some with a computer ..",
      "computer some of the recording was made with a mobile device and some with a computer ..",
      "The audio is a little faster between the five and ten second mark ...",
      "Ye some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a computer .. Yes some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a spoof ..",
      "Yes some of the recording was made with a mobile device and some with a com ..",
      "The audio is a little faster between the five and ten second mark ... Yes some of the recording was made with a mobile device and some with a computer ..",
      "computer some of the recording was made with a mobile device and some with a computer ..",
      "Yes some of the recording was made with a mobile device and some with a computer .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ], <mic_type> mic type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-16], interpreter[shap], shap_value[0.8851])",
    "ref": [
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a yes value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker MFCC-16 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8851 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-11], classification[replayed], shap_value[-0.5246], detected_by[CNN])",
    "ref": [
      "Yes PSRCC which a s value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by C ...",
      "replayed PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ... Yes PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by PSRCC-11 ...",
      "Yes PSRCC which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5246 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-17], classification[bonafide], shap_value[0.0961])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.4724 ...",
      "Yes MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-17 value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-17 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.4724 ... Yes MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.096 was used to detect the sample as Audio_signal ...",
      "MFCC-17 MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of 0.0961 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.4724 ...",
      "Yes MFCC which a shap value of 0.0961 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0961 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-10], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-8], determined[speaker_id])",
    "ref": [
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "GTCC-8 GTCC was used to determine speaker id ...",
      "y GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "GTCC-8 GTCC was used to determine speaker id ...",
      "y GTCC was used to determine speaker id ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ... yes GTCC was used to determine speaker id ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-8 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[spoof], mic_type[mobile_phone])",
    "ref": [
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Some of the recording was made using a computer ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[syntheic])",
    "ref": [
      "Because the background noise changes too quickly to be natural ...",
      "syntheic the recording is synthetic ...",
      "Because the background noise changes too quickly to be natural ... Yes the recording is synthetic ...",
      "Yes the recording is synthetic ... Yes the recording is synthetic ...",
      " the recording is synthetic ...",
      "Because the background noise changes too quickly to be natural ...",
      "syntheic the recording is synthetic ...",
      "Because the background noise changes too quickly to be natural ... Yes the recording is synthetic ...",
      "Yes the recording is synthetic ... Yes the recording is synthetic ...",
      " the recording is synthetic ...",
      "Yes the recording is synthetic ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ syntheic ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-13], shap_value[-0.8209])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ...",
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ...",
      "-0.8209 determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.8209 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <shap_value> shap value: [ -0.8209 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-8], classification[replayed], shap_value[-0.9437], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ... Yes MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of MSRCC-8 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MSRCC which a Yes value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a  value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.9437 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-23], shap_value[-0.0117])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-23 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.011 ...",
      "-0.0117 determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-23 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <shap_value> shap value: [ -0.0117 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-25], interpreter[shap], shap_value[0.7825])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.7 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "Yes person 1 was detected by LFCC with a shap value of LFCC-25 ...",
      "Yes person 1 was detected by LFCC with a sh value of 0.7825 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ... Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "Yes person LFCC-25 was detected by LFCC with a shap value of 0.7825 ...",
      "Yes person  was detected by LFCC with a shap value of 0.7825 ...",
      "Yes person 1 was detected by LFCC with a 1 value of 0.7825 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7825 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-27], interpreter[shap], shap_value[-0.3514])",
    "ref": [
      "Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ... Yes person 3 was detected by MFCC with a shap value of -0.3514 ...",
      "Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ...",
      "Yes person 3 was detected by MFCC with a shap value of -0. ...",
      "Yes person MFCC-27 was detected by MFCC with a shap value of -0.MFCC-27514 ...",
      "Yes person 3 was detected by MFCC with a MFCC-27 value of -0.3514 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.3514 ... Yes person 3 was detected by MFCC with a shap value of -0.3514 ...",
      "Yes person 3 was detected by MFCC with a s value of -0.3514 ...",
      "Yes person  was detected by MFCC with a shap value of -0.514 ...",
      "Yes person 3 was detected by MFCC with a shap value of 3 ...",
      "Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ... Yes person 3 was detected by MFCC with a shap value of -0.3514 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.3514 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3514 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-47], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-47 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[20])",
    "ref": [
      "Yes person 2 was detected by GTCC with a shap value of 0 ... The speed increases at the 20 second mark ...",
      "The speed increases at the 2 second mark ...",
      "The s increases at the 20 second mark ...",
      "The speed increases at the 20 second mark ... The speed increases at the 20 second mark ...",
      "The speed increases at the spoof second mark ...",
      "The spoof increases at the 20 second mark ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... The speed increases at the 20 second mark ...",
      "The speed increases at the 2 second mark ...",
      "The s increases at the 20 second mark ...",
      "The speed increases at the 20 second mark ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-56], interpreter[shap], shap_value[0.8985])",
    "ref": [
      "Yes LFCC which a  value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of shap was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a yes value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes the recording is synthetic ... Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.898 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.898yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ... Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes the recording is synthetic ...",
      "Yes LFCC which a  value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-56 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8985 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-57], shap_value[-0.5116])",
    "ref": [
      "-0.5116 determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5 ...",
      "sha determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "-0.5116 determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5116 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <shap_value> shap value: [ -0.5116 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-33], interpreter[shap], shap_value[-0.2863])",
    "ref": [
      "Yes MFCC which a s value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker -0.2863 for the audio sample ...",
      "Yes MFCC which a 7 value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-33 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.2 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a s value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2863 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes there was more than one CaptureDevice ... Yes there was more than one CaptureDevice ...",
      ">1 there was more than one CaptureDevice ...",
      "Y there was more than one CaptureDevice ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes there was more than one CaptureDevice ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes there was more than one CaptureDevice ... Yes there was more than one CaptureDevice ...",
      ">1 there was more than one CaptureDevice ...",
      "Y there was more than one CaptureDevice ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes there was more than one CaptureDevice ...",
      "Yes there was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-50], interpreter[shap], shap_value[-0.1122])",
    "ref": [
      "Yes LFCC which a -0.1122 value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.11 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-50 was used to detect the id of speaker 2 for the audio sample ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ... Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a s value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.11LFCC-50LFCC-50 was used to detect the id of speaker LFCC-50 for the audio sample ...",
      "Yes LFCC which a -0.1122 value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-50 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1122 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-10], interpreter[shap], shap_value[0.289])",
    "ref": [
      "Yes person 0.289 was detected by LFCC with a shap value of 0.289 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.2 ...",
      "Yes person 5 was detected by LFCC with a yes value of 0.289 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.289 ... Yes person 5 was detected by LFCC with a shap value of 0.289 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "Yes person 5 was detected by LFCC with a shap value of 5 ...",
      "Yes person  was detected by LFCC with a shap value of 0.289 ...",
      "Yes person 5 was detected by LFCC with a  value of 0.289 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... Yes person 5 was detected by LFCC with a shap value of 0.289 ...",
      "Yes person 0.289 was detected by LFCC with a shap value of 0.289 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.289 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.289 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .. The alterations are consistent with known programs ..",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ... The alterations are consistent with known programs ..",
      "The alterations are consistent with known programs .."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-12], interpreter[shap], shap_value[0.4129])",
    "ref": [
      "Yes person 2 was detected by LFCC with a sh value of 0.4129 ...",
      "Yes person 2 was detected by LFCC with a LFCC-12 value of 0.4129 ...",
      "Yes LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 2 was detected by LFCC with a shap value of 0.4129 ...",
      "Yes person  was detected by LFCC with a shap value of 0.419 ...",
      "Yes person 2 was detected by LFCC with a shap value of  ...",
      "Yes person shap was detected by LFCC with a shap value of 0.41shap9 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4129 ... Yes person 2 was detected by LFCC with a shap value of 0.4129 ...",
      "Yes person 2 was detected by LFCC with a shap value of 2 ...",
      "Yes LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 2 was detected by LFCC with a sh value of 0.4129 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4129 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4129 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[synthetic], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ... Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synt recording ...",
      "spoofed the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ... Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by  recording was a synthetic recording ...",
      "Y the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by spoofed recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a spoofed recording ...",
      "Yes MFCC which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ... Yes the Audio_signal was detected by CNN recording was a synthetic recording ...",
      "Yes the Audio_signal was detected by CNN recording was a synthetic recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-11], interpreter[shap], shap_value[-0.3846])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of shap ...",
      "Yes person 5 was detected by LFCC with a shap value of -0 ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ... Yes person 5 was detected by LFCC with a shap value of -0.3846 ...",
      "Yes person 5 was detected by LFCC with a s value of -0.3846 ...",
      "Yes person shap was detected by LFCC with a shap value of -0.3846 ...",
      "Yes person 5 was detected by LFCC with a yes value of -0.3846 ...",
      "Yes person  was detected by LFCC with a shap value of -0.3846 ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ... Yes person 5 was detected by LFCC with a shap value of -0.3846 ...",
      "Yes person 5 was detected by LFCC with a shap value of shap ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3846 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person 3 was detected by MFCC with a shap value of -0.8167 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-2], shap_value[0.0476])",
    "ref": [
      "Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "0.0476 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of PSRCC-2 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "s determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "0.0476 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0. ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <shap_value> shap value: [ 0.0476 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-3], classification[replayed], shap_value[-0.7698], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by  ...",
      "yes GTCC was used to determine speaker id ... Yes LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "yes GTCC was used to determine speaker id ...",
      "Yes LFCC which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7698 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-6], classification[bonafide], shap_value[-0.8808])",
    "ref": [
      "Ye MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "MFCC-6 MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a -0.8808 value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.8808 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8808 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-13], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker GTCC-13 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a s value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a GTCC-13 value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of shap was used to detect the id of speaker 3 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker GTCC-13 for the audio sample ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-16], classification[bonafide], shap_value[0.4647])",
    "ref": [
      "Yes LFCC which a sha value of 0.4647 was used to detect the sample as Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.2638 ... Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "LFCC-16 LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.4647 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.464 was used to detect the sample as Audio_signal ...",
      "Ye LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "Yes person 1 was detected by LFCC with a shap value of -0.2638 ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sha value of 0.4647 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4647 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-19], shap_value[0.6196])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "MFCC-19 determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "s determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.619 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "Yes PSRCC which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <shap_value> shap value: [ 0.6196 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-1], classification[replayed], shap_value[-0.2422], detected_by[CNN])",
    "ref": [
      "Yes MSRCC which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MSRCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.242 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MSRCC which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Y MSRCC which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a replayed value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MSRCC which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a sha value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MSRCC which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2422 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-6], classification[bonafide], shap_value[1])",
    "ref": [
      "Yes GTCC which a Yes value of 1 was used to detect the sample as Audio_signal ...",
      "Everything points to this audio sample being Audio_signal ...",
      "shap GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a sha value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of  was used to detect the sample as Audio_signal ...",
      " GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Everything points to this audio sample being Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a Yes value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "It shows signs of having been digitally manipulated ... It shows signs of having been digitally manipulated ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ... It shows signs of having been digitally manipulated ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "It shows signs of having been digitally manipulated ... It shows signs of having been digitally manipulated ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ... It shows signs of having been digitally manipulated ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "It shows signs of having been digitally manipulated ... It shows signs of having been digitally manipulated ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ... It shows signs of having been digitally manipulated ...",
      "Yes person 2 was detected by LFCC with a shap value of -0.9142 ...",
      "It shows signs of having been digitally manipulated ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[2])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-30], classification[replayed], shap_value[-0.662], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes LFCC which a replayed value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "LFCC-30 LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Ye LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by C ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.662 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "It appears that part of the audio was sped up ... It appears that part of the audio was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ... It appears that part of the audio was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "It appears that part of the audio was sped up ... It appears that part of the audio was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ... It appears that part of the audio was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "It appears that part of the audio was sped up ... It appears that part of the audio was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ... It appears that part of the audio was sped up ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.6262 ...",
      "It appears that part of the audio was sped up ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-5], classification[replayed], shap_value[-0.7587], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of -0.758 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by GTCC with a shap value of 0 ... Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes person 4 was detected by GTCC with a shap value of 0 ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by LFCC-5 ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a LFCC-5 value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-5 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7587 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-46], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-46 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ... 6 was found to be the id of the speaker in the sample ...",
      "6 was found to be the id of the speaker in the sample ... 6 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ... 6 was found to be the id of the speaker in the sample ...",
      "6 was found to be the id of the speaker in the sample ... 6 was found to be the id of the speaker in the sample ...",
      " was found to be the id of the speaker in the sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ... 6 was found to be the id of the speaker in the sample ...",
      "6 was found to be the id of the speaker in the sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-17], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-17 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-3], interpreter[shap], shap_value[-0.5773])",
    "ref": [
      "Yes person 6 was detected by PSRCC with a shap value of -0.577 ...",
      "Yes person 6 was detected by PSRCC with a shap value of PSRCC-3 ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ... Yes person 6 was detected by PSRCC with a shap value of -0.5773 ...",
      "Yes person 6 was detected by PSRCC with a sha value of -0.5773 ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person 6 was detected by PSRCC with a -0.5773 value of -0.5773 ...",
      "Yes person  was detected by PSRCC with a shap value of -0.5773 ...",
      "Yes person shap was detected by PSRCC with a shap value of -0.5773 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.5773 ... Yes person 6 was detected by PSRCC with a shap value of -0.5773 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.577 ...",
      "Yes person 6 was detected by PSRCC with a shap value of -0.5773 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5773 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-7], interpreter[shap], shap_value[-0.2138])",
    "ref": [
      "Yes MSRCC which a MSRCC-7 value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker shap for the audio sample ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker  for the audio sample ...",
      "Yes MSRCC which a shap value of -0.21 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of shap was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MSRCC which a sha value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ... Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ... Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a MSRCC-7 value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2138 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-27], interpreter[shap], shap_value[0.8535])",
    "ref": [
      "Yes person 1 was detected by LFCC with a sh value of 0.8535 ...",
      "Yes person  was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person shap was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a shap value of yes ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ... Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.853 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 1 was detected by LFCC with a 0.8535 value of 0.8535 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a sh value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8535 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... The recording is artificially slowed ...",
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... The recording is artificially slowed ...",
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... The recording is artificially slowed ...",
      "The recording is artificially slowed ... The recording is artificially slowed ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... The recording is artificially slowed ...",
      "The recording is artificially slowed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-5], interpreter[shap], shap_value[-0.3996])",
    "ref": [
      "Yes MFCC which a sha value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.399 was used to detect the id of speaker  for the audio sample ...",
      "Constant-Q Cepstral Coefficients ...",
      "Yes MFCC which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ... Yes MFCC which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0 was used to detect the id of speaker 6 for the audio sample ...",
      "Constant-Q Cepstral Coefficients ... Yes MFCC which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.399MFCC-5 was used to detect the id of speaker MFCC-5 for the audio sample ...",
      "Yes MFCC which a yes value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a sha value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3996 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-24], interpreter[shap], shap_value[0.8609])",
    "ref": [
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a LFCC-24 value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker LFCC-24 for the audio sample ...",
      "Yes LFCC which a sha value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.86 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8609 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... It was altered using software ...",
      "It was altered using software ... It was altered using software ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... It was altered using software ...",
      "It was altered using software ... It was altered using software ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... It was altered using software ...",
      "It was altered using software ... It was altered using software ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of -0.0117 ... It was altered using software ...",
      "It was altered using software ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "No other spoof types were detected ... No other spoof types were detected ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ... No other spoof types were detected ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "No other spoof types were detected ... No other spoof types were detected ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ... No other spoof types were detected ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "No other spoof types were detected ... No other spoof types were detected ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ... No other spoof types were detected ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "No other spoof types were detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-6], interpreter[shap], shap_value[-0.9158])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... Yes MFCC which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9yes58 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a shap value of -0 was used to detect the id of speaker 1 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "Yes MFCC which a shap value of yes was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.958 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a  value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a -0.9158 value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... Yes MFCC which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9158 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-16], classification[replayed], shap_value[-0.4135], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of LFCC-16 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by GTCC with a shap value of 0 ... Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by GTCC with a shap value of 0 ...",
      "Yes LFCC which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by C ...",
      " LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "-0.4135 LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by -0.4135 ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4135 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], replay_order[3], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded spoofed times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ...",
      "It has been PhysicalAccess was detected by replayed and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded spoofed times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <replay_order> replay order: [ 3 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-27], classification[bonafide], shap_value[-0.3069])",
    "ref": [
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a bonafide value of -0.3069 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.3069 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.30 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ...",
      "Y MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3069 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-36], interpreter[shap], shap_value[0.9205])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a sh value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ... Yes MFCC which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9205 was used to detect the id of speaker MFCC-36 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-36 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a 4 value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of  was used to detect the id of speaker 4 for the audio sample ...",
      "Yes MFCC which a shap value of 0.9205 was used to detect the id of speaker  for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes MFCC which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes MFCC which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9205 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-57], classification[bonafide], shap_value[-0.9499])",
    "ref": [
      "Y LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes . Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes .",
      "Yes LFCC which a LFCC-57 value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.949 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "bonafide LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Y LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.9499 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9499 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ... The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ... The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by replay as well ...",
      "The audio sample was PhysicalAccess was detected by CN as well ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ... The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ... The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by replay as well ...",
      "The audio sample was PhysicalAccess was detected by CN as well ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "The recording was faked using playback ... The recording was faked using playback ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... The recording was faked using playback ...",
      "The recording was faked using playback ... The recording was faked using playback ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... The recording was faked using playback ...",
      "The recording was faked using playback ... The recording was faked using playback ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... The recording was faked using playback ...",
      "The recording was faked using playback ... The recording was faked using playback ...",
      "The recording was faked using playback ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "CNN the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by  recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by spoofed recording was a PhysicalAccess recording ...",
      " the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes LFCC which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ... Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "CNN the Audio_signal was detected by CNN recording was a PhysicalAccess recording ...",
      "Yes the Audio_signal was detected by CNN recording was a PhysicalAccess recording ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-33], classification[replayed], shap_value[0.812], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a sh value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording is artificially slowed ... Yes MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a MFCC-33 value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CN ...",
      "Ye MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "replayed MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "The recording is artificially slowed ...",
      "Yes MFCC which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.812 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[PSRCC-4], interpreter[shap], shap_value[0.4174])",
    "ref": [
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a sha value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ... Yes PSRCC which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes PSRCC which a shap value of  was used to detect the id of speaker 3 for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ... Yes PSRCC which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes PSRCC which a 3 value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.4174 was used to detect the id of speaker shap for the audio sample ...",
      "Yes PSRCC which a shap value of shap was used to detect the id of speaker 3 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.4174 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ PSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4174 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-43], shap_value[0.9284])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-43 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "LFCC-43 determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9 ...",
      "Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "Yes LFCC which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-43 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "LFCC-43 determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <shap_value> shap value: [ 0.9284 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MFCC-1 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "the audio sample had CepstralFeature features extracted and MFCC-1 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ... the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.0476 ...",
      "the audio sample had CepstralFeature features extracted and MFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-20], classification[bonafide])",
    "ref": [
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MSRCC which a shap value of 0.0536 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-20 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-9], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 4 was detected by GTCC with a shap value of 4 ...",
      "Yes person GTCC-9 was detected by GTCC with a shap value of 0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "Yes person 4 was detected by GTCC with a shap value of  ...",
      "Yes person 4 was detected by GTCC with a GTCC-9 value of 0 ...",
      "Yes person 4 was detected by GTCC with a shap value of 0 ... Yes person 4 was detected by GTCC with a shap value of 0 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ... Yes person 4 was detected by GTCC with a shap value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 4 was detected by GTCC with a  value of 0 ...",
      "Yes person 4 was detected by GTCC with a shap value of 4 ...",
      "Yes person 4 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-28], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-28 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-28 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-28 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-40], classification[replayed], shap_value[0.4012], detected_by[CNN])",
    "ref": [
      "Yes LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of 0.4 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4439 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a LFCC-40 value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Y LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a sha value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of LFCC-40 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "CNN LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4012 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-54], classification[bonafide], shap_value[0.6103])",
    "ref": [
      " LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ...",
      "0.6103 LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a  value of 0.6103 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of 0.61 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of 0.6103 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of 0.6103 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6103 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes the recording was Audio_signal was detected by CNN ...",
      "Ye the recording was Audio_signal was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "spoof the recording was Audio_signal was detected by CNN ...",
      "Yes the recording was Audio_signal was detected by spoof ...",
      "Yes the recording was Audio_signal was detected by CNN ... Yes the recording was Audio_signal was detected by CNN ...",
      "Yes the recording was Audio_signal was detected by  ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes the recording was Audio_signal was detected by CNN ...",
      "Ye the recording was Audio_signal was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes the recording was Audio_signal was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-12], determined[speaker_id])",
    "ref": [
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... yes MFCC was used to determine speaker id ...",
      "speaker_id MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      "y MFCC was used to determine speaker id ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-12 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Constant-Q Cepstral Coefficients ... Constant-Q Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Constant-Q Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Constant-Q Cepstral Coefficients ... Constant-Q Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Constant-Q Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Constant-Q Cepstral Coefficients ... Constant-Q Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Constant-Q Cepstral Coefficients ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Constant-Q Cepstral Coefficients ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-49], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-49 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-48], interpreter[shap], shap_value[-0.5])",
    "ref": [
      "Yes person 4 was detected by LFCC with a shap value of -0 ...",
      "Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes person 4 was detected by LFCC with a LFCC-48 value of -0.5 ...",
      "Yes person  was detected by LFCC with a shap value of -0.5 ...",
      "Yes person 4 was detected by LFCC with a shap value of 4 ...",
      "Yes LFCC which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes person 4 was detected by LFCC with a shap value of -0.5 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.5 ... Yes person 4 was detected by LFCC with a shap value of -0.5 ...",
      "Yes person -0.5 was detected by LFCC with a shap value of -0.5 ...",
      "Yes person 4 was detected by LFCC with a  value of -0.5 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.5 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-48 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], mic_type[mobile_phone])",
    "ref": [
      "spoof most of the recording was not made with a mobile phone ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... No most of the recording was not made with a mobile phone ...",
      "N most of the recording was not made with a mobile phone ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "No most of the recording was not made with a mobile phone ... No most of the recording was not made with a mobile phone ...",
      "No most of the recording was made with a mobile phone ...",
      "spoof most of the recording was not made with a mobile phone ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... No most of the recording was not made with a mobile phone ...",
      "N most of the recording was not made with a mobile phone ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "No most of the recording was not made with a mobile phone ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-30], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-30 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-30 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC-30 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-30 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-5], classification[bonafide], shap_value[-0.158])",
    "ref": [
      "Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ...",
      "-0.158 MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a MSRCC-5 value of -0.158 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.1 was used to detect the sample as Audio_signal ...",
      " MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ...",
      "This is a Audio_signal was detected by CNN recording Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a sh value of -0.158 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of MSRCC-5 was used to detect the sample as Audio_signal ...",
      "This is a Audio_signal was detected by CNN recording",
      "Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ... Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ...",
      "Yes MSRCC which a shap value of -0.158 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.158 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-44], shap_value[0.4408])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ...",
      "0.4408 determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4408 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <shap_value> shap value: [ 0.4408 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-16], interpreter[shap], shap_value[0.7676])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 7 was detected by LFCC with a shap value of 0.7676 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.7676 ... Yes person 7 was detected by LFCC with a shap value of 0.7676 ...",
      "Yes person 7 was detected by LFCC with a sh value of 0.7676 ...",
      "Yes person 7 was detected by LFCC with a shap value of LFCC-16 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.76 ...",
      "Yes person yes was detected by LFCC with a shap value of 0.yes6yes6 ...",
      "Yes person 7 was detected by LFCC with a 7 value of 0.7676 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person  was detected by LFCC with a shap value of 0.66 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 7 was detected by LFCC with a shap value of 0.7676 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.7676 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7676 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-9], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes GTCC which a  value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 0 for the audio sample ...",
      "There were 2 microphones used ...",
      "Yes GTCC which a yes value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "There were 2 microphones used ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a  value of 0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-37], classification[bonafide], shap_value[-0.3635])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "Yes MFCC which a Yes value of -0.3635 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.36 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ... Yes MFCC which a shap value of -0.3635 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of MFCC-37 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.3635 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.3635 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.3635 was used to detect the sample as Audio_signal ...",
      "-0.3635 MFCC which a shap value of -0.3635 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.3635 was used to detect the sample as Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.5786 ...",
      "Yes MFCC which a shap value of -0.3635 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3635 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Part of the Acoustic_Wave is synthesized ... Part of the Acoustic_Wave is synthesized ...",
      "No most of the recording was not made with a mobile phone ... Part of the Acoustic_Wave is synthesized ...",
      "No most of the recording was not made with a mobile phone ...",
      "Part of the Acoustic_Wave is synthesized ... Part of the Acoustic_Wave is synthesized ...",
      "No most of the recording was not made with a mobile phone ... Part of the Acoustic_Wave is synthesized ...",
      "No most of the recording was not made with a mobile phone ...",
      "Part of the Acoustic_Wave is synthesized ... Part of the Acoustic_Wave is synthesized ...",
      "No most of the recording was not made with a mobile phone ... Part of the Acoustic_Wave is synthesized ...",
      "No most of the recording was not made with a mobile phone ...",
      "Part of the Acoustic_Wave is synthesized ... Part of the Acoustic_Wave is synthesized ...",
      "Part of the Acoustic_Wave is synthesized ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      "No the Audio_signal was detected by CN recording was not converted ..",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "N the Audio_signal was detected by CNN recording was not converted ..",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... No the Audio_signal was detected by CNN recording was not converted ..",
      "No the Audio_signal was detected by converted recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was converted ..",
      "No the Audio_signal was detected by CNN recording was not converted .. No the Audio_signal was detected by CNN recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was not CNN ..",
      "CNN the Audio_signal was detected by CNN recording was not converted ..",
      "No the Audio_signal was detected by CNN recording was not conv ..",
      "No the Audio_signal was detected by CNN recording was not converted .."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ... A EnvironmentSignature signature was not detected ...",
      "A EnvironmentSignature signature was not detected ... A EnvironmentSignature signature was not detected ...",
      "A EnvironmentSignature signature was detected ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ... A EnvironmentSignature signature was not detected ...",
      "A EnvironmentSignature signature was not detected ... A EnvironmentSignature signature was not detected ...",
      "A EnvironmentSignature signature was detected ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ...",
      "The audio sample was PhysicalAccess was detected by CNN as well ... A EnvironmentSignature signature was not detected ...",
      "A EnvironmentSignature signature was not detected ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-0], shap_value[0.4598])",
    "ref": [
      "LFCC-0 determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ...",
      "LFCC-0 determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-0 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.4598 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <shap_value> shap value: [ 0.4598 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-8], classification[bonafide], shap_value[-0.7408])",
    "ref": [
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of -0.7408 was used to detect the sample as Audio_signal ...",
      "bonafide MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0. was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a s value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.7408 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7408 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-9], classification[bonafide])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "the audio sample had CepstralFeature features extracted and LFCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ...",
      "the audio sample had CepstralFeature features extracted and LFCC-9 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of 0.9284 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by replay audio was a PhysicalAccess audio ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by replay audio was a PhysicalAccess audio ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ... The Audio_signal was detected by CNN audio was a PhysicalAccess audio ...",
      "The Audio_signal was detected by CNN audio was a PhysicalAccess audio ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[7])",
    "ref": [
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ... The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker MFCC ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-16], shap_value[0.2676])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "0.2676 determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of shap ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0. ...",
      "Yes GTCC which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.2676 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <shap_value> shap value: [ 0.2676 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-1], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of  ...",
      "Yes person GTCC-1 was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 2 was detected by GTCC with a shap value of shap ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a 2 value of 0 ...",
      "Yes person 2 was detected by GTCC with a s value of 0 ...",
      "Yes person  was detected by GTCC with a shap value of 0 ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-12], interpreter[shap], shap_value[-0.7561])",
    "ref": [
      "Yes person 7 was detected by MSRCC with a shap value of 7 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0 ...",
      "Yes person MSRCC-12 was detected by MSRCC with a shap value of -0.MSRCC-12561 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ... Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "Yes person 7 was detected by MSRCC with a  value of -0.7561 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ... Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "Yes person 7 was detected by MSRCC with a -0.7561 value of -0.7561 ...",
      "Yes person  was detected by MSRCC with a shap value of -0.561 ...",
      "Yes person 7 was detected by MSRCC with a shap value of 7 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7561 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-2], classification[bonafide], shap_value[0.7845])",
    "ref": [
      "Yes PSRCC which a bonafide value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a s value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Ye PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.7 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ... Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "shap PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "The audio sample had CepstralFeature and Cepstrum features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ... Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a bonafide value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7845 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[no])",
    "ref": [
      "yes MFCC was used to determine speaker id ... I do not recognize any of the CaptureDevice signatures ...",
      "I do t recognize any of the CaptureDevice signatures ...",
      "yes MFCC was used to determine speaker id ...",
      "I do not recognize any of the CaptureDevice signatures ... I do not recognize any of the CaptureDevice signatures ...",
      "I do recognize any of the CaptureDevice signatures ...",
      "I do spooft recognize any of the CaptureDevice signatures ...",
      "yes MFCC was used to determine speaker id ... I do not recognize any of the CaptureDevice signatures ...",
      "I do t recognize any of the CaptureDevice signatures ...",
      "yes MFCC was used to determine speaker id ...",
      "I do not recognize any of the CaptureDevice signatures ... I do not recognize any of the CaptureDevice signatures ...",
      "I do not recognize any of the CaptureDevice signatures ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ no ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ... The voice changes during the conversation ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "The voice changes during the conversation ... The voice changes during the conversation ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ... The voice changes during the conversation ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "The voice changes during the conversation ... The voice changes during the conversation ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ... The voice changes during the conversation ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ...",
      "The voice changes during the conversation ... The voice changes during the conversation ...",
      "Yes LFCC which a shap value of 0.4647 was used to detect the sample as Audio_signal ... The voice changes during the conversation ...",
      "The voice changes during the conversation ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-12], interpreter[shap], shap_value[0.364])",
    "ref": [
      "Yes LFCC which a shap value of 0.34 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a  value of 0.364 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a 0.364 value of 0.364 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-12 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of 0.30.3644 was used to detect the id of speaker 0.364 for the audio sample ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 0.34 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.364 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], detected_by[CNN])",
    "ref": [
      "The Audio_signal was detected by spoof audio was converted ...",
      "The Audio_signal was detected by CNN audio was converted ... The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by CN audio was converted ...",
      "The next CaptureDevice starts at 10 seconds ... The Audio_signal was detected by CNN audio was converted ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "The Audio_signal was detected by spoof audio was converted ...",
      "The Audio_signal was detected by CNN audio was converted ... The Audio_signal was detected by CNN audio was converted ...",
      "The Audio_signal was detected by CN audio was converted ...",
      "The next CaptureDevice starts at 10 seconds ... The Audio_signal was detected by CNN audio was converted ...",
      "The next CaptureDevice starts at 10 seconds ...",
      "The Audio_signal was detected by CNN audio was converted ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ...",
      "Yes person 7 was detected by MSRCC with a shap value of -0.7561 ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ... There was more than one CaptureDevice ...",
      "There was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-11], shap_value[-0.761])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "-0.761 determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.76 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      "sh determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "-0.761 determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.76 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.761 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <shap_value> shap value: [ -0.761 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-57], interpreter[shap], shap_value[0.1692])",
    "ref": [
      "Yes person 0.1692 was detected by LFCC with a shap value of 0.1690.1692 ...",
      "Yes person 2 was detected by LFCC with a shap value of  ...",
      "No the Audio_signal was detected by CNN recording was not converted .. Yes person 2 was detected by LFCC with a shap value of 0.1692 ...",
      "No the Audio_signal was detected by CNN recording was not converted ..",
      "Yes person 2 was detected by LFCC with a  value of 0.1692 ...",
      "Yes person 2 was detected by LFCC with a shap value of 2 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.1692 ... Yes person 2 was detected by LFCC with a shap value of 0.1692 ...",
      "Yes person 2 was detected by LFCC with a yes value of 0.1692 ...",
      "Yes person  was detected by LFCC with a shap value of 0.169 ...",
      "Yes person 0.1692 was detected by LFCC with a shap value of 0.1690.1692 ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.1692 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-57 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1692 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-2], classification[bonafide])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-2 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ...",
      "the audio sample had CepstralFeature features extracted and MSRCC-2 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.3846 ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSR was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-51], classification[bonafide])",
    "ref": [
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-51 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio was Audio_signal was detected by CNN? the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio was Audio_signal was detected by CNN?",
      "the audio sample had CepstralFeature features extracted and PSRCC-10 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio was Audio_signal was detected by CNN? the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio was Audio_signal was detected by CNN?",
      "the audio sample had CepstralFeature features extracted and PSRCC-10 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-10], interpreter[shap], shap_value[0.4852])",
    "ref": [
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a 0.4852 value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a  value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-10 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 0.4852 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4852 ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "This is a Audio_signal was detected by CNN recording This is a Audio_signal was detected by CNN recording",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... This is a Audio_signal was detected by CNN recording",
      "This is a Audio_signal was detected by spoof recording",
      "This is a Audio_signal was detected by CN recording",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "This is a Audio_signal was detected by CNN recording This is a Audio_signal was detected by CNN recording",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... This is a Audio_signal was detected by CNN recording",
      "This is a Audio_signal was detected by spoof recording",
      "This is a Audio_signal was detected by CN recording",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "This is a Audio_signal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-1], shap_value[0.5149])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.51 ...",
      "s determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ...",
      "0.5149 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.51 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.5149 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <shap_value> shap value: [ 0.5149 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-10], interpreter[shap], shap_value[-0.3591])",
    "ref": [
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker -0.3591 for the audio sample ...",
      "Yes MFCC which a shap value of -0 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a yes value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a s value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3591 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-4], shap_value[0.6758])",
    "ref": [
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of shap ...",
      "0.6758 determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ...",
      " determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ... shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.6196 ...",
      "shap determined that the PSRCC feature was one of the more important features by assigning it a value of 0.6758 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <shap_value> shap value: [ 0.6758 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-22], interpreter[shap], shap_value[-0.9592])",
    "ref": [
      "Yes person 4 was detected by LFCC with a sha value of -0.9592 ...",
      "Yes person yes was detected by LFCC with a shap value of -0.9592 ...",
      "Yes person  was detected by LFCC with a shap value of -0.9592 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.9592 ... Yes person 4 was detected by LFCC with a shap value of -0.9592 ...",
      "Yes person 4 was detected by LFCC with a shap value of  ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ... Yes person 4 was detected by LFCC with a shap value of -0.9592 ...",
      "Yes person 4 was detected by LFCC with a shap value of 4 ...",
      "Yes person 4 was detected by LFCC with a -0.9592 value of -0.9592 ...",
      "Yes person 4 was detected by LFCC with a sha value of -0.9592 ...",
      "Yes person 4 was detected by LFCC with a shap value of -0.9592 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9592 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-13], interpreter[shap], shap_value[0.7152])",
    "ref": [
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ... Yes person 2 was detected by MFCC with a shap value of 0.7152 ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.715 ...",
      "Yes MSRCC which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ... Yes person 2 was detected by MFCC with a shap value of 0.7152 ...",
      "Yes person 2 was detected by MFCC with a sha value of 0.7152 ...",
      "Yes person MFCC-13 was detected by MFCC with a shap value of 0.715MFCC-13 ...",
      "Yes person  was detected by MFCC with a shap value of 0.715 ...",
      "Yes person 2 was detected by MFCC with a 0.7152 value of 0.7152 ...",
      "Yes person 2 was detected by MFCC with a shap value of MFCC-13 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ... Yes person 2 was detected by MFCC with a shap value of 0.7152 ...",
      "Yes person 2 was detected by MFCC with a shap value of 0.7152 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7152 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-1], interpreter[shap], shap_value[0.2695])",
    "ref": [
      "Yes LFCC which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a LFCC-1 value of 0.2695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ...",
      "Yes person 7 was detected by LFCC with a shap value of 0.6718 ... Yes LFCC which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ... Yes LFCC which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.LFCC-1695 was used to detect the id of speaker LFCC-1 for the audio sample ...",
      "Yes LFCC which a shap value of 0.695 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a sha value of 0.2695 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.26 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2695 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-14], classification[bonafide], shap_value[0.3406])",
    "ref": [
      "Yes MFCC which a MFCC-14 value of 0.3406 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of 0.3406 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of Yes was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.3 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a s value of 0.3406 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.3406 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.3406 was used to detect the sample as Audio_signal ...",
      "shap MFCC which a shap value of 0.3406 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.3406 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a MFCC-14 value of 0.3406 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.3406 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3406 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-56], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.8535 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-56 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a spoof ...",
      "Some of the recording was made using a com ...",
      "Yes .",
      "Yes . Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ... Some of the recording was made using a computer ...",
      "Some of the recording was made using a spoof ...",
      "Some of the recording was made using a com ...",
      "Yes .",
      "Yes . Some of the recording was made using a computer ...",
      "Some of the recording was made using a computer ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[no_microphone])",
    "ref": [
      "yes MFCC was used to determine speaker id ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ... Dynamic microphones were used the most ...",
      "yes MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... Dynamic microphones were used the most ...",
      "Dynamic microphones were used the most ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ no_microphone ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ..."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-34], interpreter[shap], shap_value[0.6721])",
    "ref": [
      "Yes person  was detected by MFCC with a shap value of 0.6721 ...",
      "Yes person 5 was detected by MFCC with a sh value of 0.6721 ...",
      "Yes person 5 was detected by MFCC with a shap value of shap ...",
      "Yes person yes was detected by MFCC with a shap value of 0.6721 ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.6721 ... Yes person 5 was detected by MFCC with a shap value of 0.6721 ...",
      "Yes person 5 was detected by MFCC with a shap value of 0 ...",
      "Yes person 5 was detected by MFCC with a MFCC-34 value of 0.6721 ...",
      "Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ... Yes person 5 was detected by MFCC with a shap value of 0.6721 ...",
      "Yes MFCC which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes person  was detected by MFCC with a shap value of 0.6721 ...",
      "Yes person 5 was detected by MFCC with a shap value of 0.6721 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6721 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-42], shap_value[-0.4086])",
    "ref": [
      "The speed increases at the 20 second mark ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ...",
      "The speed increases at the 20 second mark ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.408 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of shap ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ...",
      "LFCC-42 determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ...",
      "The speed increases at the 20 second mark ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ...",
      "The speed increases at the 20 second mark ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.408 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.4086 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <shap_value> shap value: [ -0.4086 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-2], interpreter[shap], shap_value[-0.4862])",
    "ref": [
      "Yes person 2 was detected by MFCC with a -0.4862 value of -0.4862 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.4862 ... Yes person 2 was detected by MFCC with a shap value of -0.4862 ...",
      "Yes person yes was detected by MFCC with a shap value of -0.486yes ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 2 was detected by MFCC with a s value of -0.4862 ...",
      "Yes person  was detected by MFCC with a shap value of -0.486 ...",
      "Yes person 2 was detected by MFCC with a shap value of 2 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0. ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes person 2 was detected by MFCC with a shap value of -0.4862 ...",
      "Yes person 2 was detected by MFCC with a -0.4862 value of -0.4862 ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.4862 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4862 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-44], interpreter[shap], shap_value[-0.643])",
    "ref": [
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a  value of -0.643 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.64 ...",
      "Yes person 5 was detected by LFCC with a LFCC-44 value of -0.643 ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.643 ... Yes person 5 was detected by LFCC with a shap value of -0.643 ...",
      "Yes person  was detected by LFCC with a shap value of -0.643 ...",
      "Yes person -0.643 was detected by LFCC with a shap value of -0.643 ...",
      "Yes person 5 was detected by LFCC with a shap value of LFCC-44 ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ... Yes person 5 was detected by LFCC with a shap value of -0.643 ...",
      "Yes PSRCC which a shap value of 0.7845 was used to detect the sample as Audio_signal ...",
      "Yes person 5 was detected by LFCC with a shap value of -0.643 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-44 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.643 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-49], interpreter[shap], shap_value[0.6995])",
    "ref": [
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ... Yes person 5 was detected by LFCC with a shap value of 0.6995 ...",
      "Yes person 5 was detected by LFCC with a shap value of 5 ...",
      "Yes person  was detected by LFCC with a shap value of 0.699 ...",
      "Yes person 5 was detected by LFCC with a shap value of  ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ... Yes person 5 was detected by LFCC with a shap value of 0.6995 ...",
      "Yes person shap was detected by LFCC with a shap value of 0.699shap ...",
      "Yes person 5 was detected by LFCC with a sh value of 0.6995 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ...",
      "Yes person 5 was detected by LFCC with a yes value of 0.6995 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ... Yes person 5 was detected by LFCC with a shap value of 0.6995 ...",
      "Yes person 5 was detected by LFCC with a shap value of 0.6995 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-49 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6995 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-9], classification[replayed], shap_value[0.1518], detected_by[CNN])",
    "ref": [
      "Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ...",
      "shap MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of -0.3069 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by Yes ...",
      "Yes MFCC which a shap value of 0.15 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a sha value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a MFCC-9 value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1518 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-0], interpreter[shap], shap_value[0.4844])",
    "ref": [
      "It appears there was voice cloning .. Yes person 3 was detected by MSRCC with a shap value of 0.4844 ...",
      "Yes person 3 was detected by MSRCC with a shap value of 0.4844 ... Yes person 3 was detected by MSRCC with a shap value of 0.4844 ...",
      "It appears there was voice cloning ..",
      "Yes person  was detected by MSRCC with a shap value of 0.4844 ...",
      "Yes person 3 was detected by MSRCC with a s value of 0.4844 ...",
      "Yes person shap was detected by MSRCC with a shap value of 0.4844 ...",
      "Yes person 3 was detected by MSRCC with a 3 value of 0.4844 ...",
      "Yes person 3 was detected by MSRCC with a shap value of 3 ...",
      "Yes person 3 was detected by MSRCC with a shap value of 0.484 ...",
      "It appears there was voice cloning .. Yes person 3 was detected by MSRCC with a shap value of 0.4844 ...",
      "Yes person 3 was detected by MSRCC with a shap value of 0.4844 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4844 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-3], shap_value[-0.2957])",
    "ref": [
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-3 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of  ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ...",
      "-0.2957 determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-3 ...",
      "s determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of -0.2957 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <shap_value> shap value: [ -0.2957 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-17], classification[replayed], shap_value[-0.524], detected_by[CNN])",
    "ref": [
      "Ye LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a  value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.5 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a Yes value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "shap LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by replayed ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by C ...",
      "Yes LFCC which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.524 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio is not Audio_signal ...",
      "The audio is Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio is not Audio_signal ... The audio is not Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio is not Audio_signal ...",
      "The audio is Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "The audio is not Audio_signal ... The audio is not Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... The audio is not Audio_signal ...",
      "The audio is Audio_signal ...",
      "The audio is not Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-23], interpreter[shap], shap_value[-0.4514])",
    "ref": [
      "Yes person 1 was detected by MFCC with a shap value of shap ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4 ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ... Yes person 1 was detected by MFCC with a shap value of -0.4514 ...",
      "Yes there was more than one CaptureDevice ... Yes person 1 was detected by MFCC with a shap value of -0.4514 ...",
      "Yes person 1 was detected by MFCC with a sh value of -0.4514 ...",
      "Yes there was more than one CaptureDevice ...",
      "Yes person 1 was detected by MFCC with a -0.4514 value of -0.4514 ...",
      "Yes person  was detected by MFCC with a shap value of -0.454 ...",
      "Yes person -0.4514 was detected by MFCC with a shap value of -0.45-0.45144 ...",
      "Yes person 1 was detected by MFCC with a shap value of shap ...",
      "Yes person 1 was detected by MFCC with a shap value of -0.4514 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4514 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LF was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-1], classification[bonafide])",
    "ref": [
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-1 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and PSRCC-1 was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and P was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.373 ...",
      "the audio sample had CepstralFeature features extracted and PSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-11], classification[bonafide], shap_value[-0.6353])",
    "ref": [
      "Yes LFCC which a Yes value of -0.6353 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "-0.6353 LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ...",
      " LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.635 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a sh value of -0.6353 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a Yes value of -0.6353 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.6353 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6353 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-33], classification[bonafide])",
    "ref": [
      "6 was found to be the id of the speaker in the sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "6 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "6 was found to be the id of the speaker in the sample ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "6 was found to be the id of the speaker in the sample ...",
      "the audio sample had CepstralFeature features extracted and bonafide was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-33 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-4], classification[bonafide])",
    "ref": [
      "Yes person 3 was detected by MSRCC with a shap value of 0.4844 ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 3 was detected by MSRCC with a shap value of 0.4844 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 3 was detected by MSRCC with a shap value of 0.4844 ...",
      "the audio sample had CepstralFeature features extracted and  was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes person 3 was detected by MSRCC with a shap value of 0.4844 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-54], interpreter[shap], shap_value[0.6141])",
    "ref": [
      "Yes LFCC which a yes value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0. was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ... Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker yes for the audio sample ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a  value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1297 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a yes value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes LFCC which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-54 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6141 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-41], classification[bonafide], shap_value[0.5419])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of 0.1692 ...",
      "Yes MFCC which a shap value of 0.5419 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of 0.5419 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a Yes value of 0.5419 was used to detect the sample as Audio_signal ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.1692 ... Yes MFCC which a shap value of 0.5419 was used to detect the sample as Audio_signal ...",
      " MFCC which a shap value of 0.5419 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a sha value of 0.5419 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of 0.54 was used to detect the sample as Audio_signal ...",
      "MFCC-41 MFCC which a shap value of 0.5419 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.1692 ...",
      "Yes MFCC which a shap value of 0.5419 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5419 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1], change_at[16])",
    "ref": [
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ...",
      "The next synthesized area begins at  seconds ...",
      "The next synthesized area begins at 16 seconds ... The next synthesized area begins at 16 seconds ...",
      "The next synthesized area begins at >1 seconds ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ... The next synthesized area begins at 16 seconds ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ...",
      "The next synthesized area begins at  seconds ...",
      "The next synthesized area begins at 16 seconds ... The next synthesized area begins at 16 seconds ...",
      "The next synthesized area begins at >1 seconds ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ... The next synthesized area begins at 16 seconds ...",
      "The next synthesized area begins at 16 seconds ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ], <change_at> change at: [ 16 ]> )"
  },
  {
    "mr": "inform(speaker_id[3], model[SVM])",
    "ref": [
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "The recording was faked using playback ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "The recording was faked using playback ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "The recording was faked using playback ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ...",
      "The recording was faked using playback ... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-16], shap_value[-0.27])",
    "ref": [
      "LFCC-16 determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of LFCC-16 ...",
      "s determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.2 ...",
      "LFCC-16 determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ... shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ...",
      "shap determined that the LFCC feature was one of the more important features by assigning it a value of -0.27 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <shap_value> shap value: [ -0.27 ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "person 3 was detected as the primary speaker of the audio sample ... person 3 was detected as the primary speaker of the audio sample ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... person 3 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "person 3 was detected as the primary speaker of the audio sample ... person 3 was detected as the primary speaker of the audio sample ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... person 3 was detected as the primary speaker of the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ...",
      "person 3 was detected as the primary speaker of the audio sample ... person 3 was detected as the primary speaker of the audio sample ...",
      "Yes person 2 was detected by GTCC with a shap value of 0 ... person 3 was detected as the primary speaker of the audio sample ...",
      "person 3 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-5], determined[speaker_id])",
    "ref": [
      "There is an echo .. yes MFCC was used to determine speaker id ...",
      "MFCC-5 MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      " MFCC was used to determine speaker id ...",
      "There is an echo ..",
      "There is an echo .. yes MFCC was used to determine speaker id ...",
      "MFCC-5 MFCC was used to determine speaker id ...",
      "yes MFCC was used to determine speaker id ... yes MFCC was used to determine speaker id ...",
      " MFCC was used to determine speaker id ...",
      "There is an echo ..",
      "yes MFCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-5 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ... Yes there was more than one CaptureDevice ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "Ye there was more than one CaptureDevice ...",
      "Yes there was more than one CaptureDevice ... Yes there was more than one CaptureDevice ...",
      ">1 there was more than one CaptureDevice ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ... Yes there was more than one CaptureDevice ...",
      "Yes person 1 was detected by LFCC with a shap value of 0.7825 ...",
      "Ye there was more than one CaptureDevice ...",
      "Yes there was more than one CaptureDevice ... Yes there was more than one CaptureDevice ...",
      ">1 there was more than one CaptureDevice ...",
      "Yes there was more than one CaptureDevice ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-19], interpreter[shap], shap_value[-0.2333])",
    "ref": [
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker MFCC-19 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a 7 value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ... Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0. was used to detect the id of speaker 7 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes MFCC which a  value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of MFCC-19 was used to detect the id of speaker 7 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker MFCC-19 for the audio sample ...",
      "Yes MFCC which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2333 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-4], classification[bonafide], shap_value[-0.4076])",
    "ref": [
      "Yes MFCC which a  value of -0.4076 was used to detect the sample as Audio_signal ...",
      "MFCC-4 MFCC which a shap value of -0.4076 was used to detect the sample as Audio_signal ...",
      "Ye MFCC which a shap value of -0.4076 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4076 was used to detect the sample as Audio_signal ... Yes MFCC which a shap value of -0.4076 was used to detect the sample as Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ...",
      "Yes MFCC which a Yes value of -0.4076 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of - was used to detect the sample as Audio_signal ...",
      "Yes person 2 was detected by MFCC with a shap value of -0.9056 ... Yes MFCC which a shap value of -0.4076 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of shap was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a  value of -0.4076 was used to detect the sample as Audio_signal ...",
      "Yes MFCC which a shap value of -0.4076 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4076 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-29], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ...",
      "the audio sample had CepstralFeature features extracted and CNN was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ... the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and L was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-29 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-0], shap_value[0.2452])",
    "ref": [
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-0 ...",
      "person 3 was detected as the primary speaker of the audio sample ...",
      "person 3 was detected as the primary speaker of the audio sample ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ...",
      "0.2452 determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ...",
      "sha determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of MSRCC-0 ...",
      "person 3 was detected as the primary speaker of the audio sample ...",
      "person 3 was detected as the primary speaker of the audio sample ... shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ...",
      "shap determined that the MSRCC feature was one of the more important features by assigning it a value of 0.2452 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <shap_value> shap value: [ 0.2452 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... The Interpreters values indicate the contribution of the features on the outcome of the classification model...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "The voice changes during the conversation ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The voice changes during the conversation ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The voice changes during the conversation ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The voice changes during the conversation ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The voice changes during the conversation ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The voice changes during the conversation ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "The voice changes during the conversation ... Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ...",
      "Interpreters determined that ConstantQCepstralCoefficients MFCC LFCC MFCC-4 had the highest impact on classification ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-23], interpreter[shap], shap_value[-0.664])",
    "ref": [
      "No the Audio_signal was detected by CNN recording was not converted .. Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a  value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.6 was used to detect the id of speaker 2 for the audio sample ...",
      "No the Audio_signal was detected by CNN recording was not converted ..",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker yes for the audio sample ...",
      "Yes MFCC which a MFCC-23 value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "No the Audio_signal was detected by CNN recording was not converted .. Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.664 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-21], shap_value[0.8713])",
    "ref": [
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.871 ...",
      "MFCC-21 determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "sha determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of MFCC-21 ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ... shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ...",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...",
      "shap determined that the MFCC feature was one of the more important features by assigning it a value of 0.8713 ..."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <shap_value> shap value: [ 0.8713 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-4], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a replayed value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by  ...",
      "Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.5419 was used to detect the sample as Audio_signal ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "GTCC-4 GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      " GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by shap ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a  value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Features in the recording show there were two microphones used ... It is not a bona fide recording ...",
      "It is not a bona fide recording ... It is not a bona fide recording ...",
      "It is a bona fide recording ...",
      "Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... It is not a bona fide recording ...",
      "It is not a bona fide recording ... It is not a bona fide recording ...",
      "It is a bona fide recording ...",
      "Features in the recording show there were two microphones used ...",
      "Features in the recording show there were two microphones used ... It is not a bona fide recording ...",
      "It is not a bona fide recording ... It is not a bona fide recording ...",
      "It is not a bona fide recording ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-37], interpreter[shap], shap_value[-0.6485])",
    "ref": [
      "Yes LFCC which a  value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0. was used to detect the id of speaker 1 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker LFCC-37 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ... Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of yes was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a -0.6485 value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a  value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6485 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-49], interpreter[shap], shap_value[-0.1791])",
    "ref": [
      "Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ...",
      "Yes LFCC which a shap value of - was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a yes value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a  value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of LFCC-49 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker LFCC-49 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker  for the audio sample ...",
      "shap determined that the GTCC feature was one of the more important features by assigning it a value of 0 ... Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ... Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes LFCC which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-49 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1791 ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ... person 7 was detected as the primary speaker of the audio sample ...",
      "person 7 was detected as the primary speaker of the audio sample ... person 7 was detected as the primary speaker of the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ... person 7 was detected as the primary speaker of the audio sample ...",
      "person 7 was detected as the primary speaker of the audio sample ... person 7 was detected as the primary speaker of the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...",
      "person  was detected as the primary speaker of the audio sample ...",
      "Yes MFCC which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ... person 7 was detected as the primary speaker of the audio sample ...",
      "person 7 was detected as the primary speaker of the audio sample ... person 7 was detected as the primary speaker of the audio sample ...",
      "person 7 was detected as the primary speaker of the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes GTCC which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and replayed was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MS was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "the audio sample had CepstralFeature features extracted and MSRCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ..."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-3], determined[speaker_id])",
    "ref": [
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ... yes GTCC was used to determine speaker id ...",
      "GTCC-3 GTCC was used to determine speaker id ...",
      "ye GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "yes GTCC was used to determine speaker id ... yes GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ... yes GTCC was used to determine speaker id ...",
      "GTCC-3 GTCC was used to determine speaker id ...",
      "ye GTCC was used to determine speaker id ...",
      "Yes MFCC which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...",
      "yes GTCC was used to determine speaker id ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-3 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-9], interpreter[shap], shap_value[-0.562])",
    "ref": [
      "Yes MFCC which a shap value of -0.562 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.5 was used to detect the id of speaker 3 for the audio sample ...",
      "6 was found to be the id of the speaker in the sample ...",
      "Yes MFCC which a  value of -0.562 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a 3 value of -0.562 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ... Yes MFCC which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of 3 was used to detect the id of speaker 3 for the audio sample ...",
      "6 was found to be the id of the speaker in the sample ... Yes MFCC which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ...",
      "Yes MFCC which a shap value of -0.562 was used to detect the id of speaker -0.562 for the audio sample ...",
      "Yes MFCC which a shap value of -0.562 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.562 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-15], interpreter[shap], shap_value[-0.6354])",
    "ref": [
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes LFCC which a -0.6354 value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a sh value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.635shap was used to detect the id of speaker shap for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.635 was used to detect the id of speaker  for the audio sample ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ... Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes LFCC which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6354 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "There were spoof microphones used ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "There were  microphones used ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ... There were 2 microphones used ...",
      "There were spoof microphones used ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "There were  microphones used ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...",
      "Yes MFCC which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ... There were 2 microphones used ...",
      "There were 2 microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-40], classification[bonafide], shap_value[-0.8852])",
    "ref": [
      "Y LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a s value of -0.8852 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of bonafide was used to detect the sample as Audio_signal ...",
      "LFCC-40 LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ... Yes LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a bonafide value of -0.8852 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ... Yes LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...",
      "Y LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ...",
      "Yes LFCC which a shap value of -0.8852 was used to detect the sample as Audio_signal ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8852 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The audio uses multiple microphones ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "The audio uses multiple microphones ... There were 2 microphones used ...",
      "The audio uses multiple microphones ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "The audio uses multiple microphones ... There were 2 microphones used ...",
      "The audio uses multiple microphones ...",
      "There were 2 microphones used ... There were 2 microphones used ...",
      "The audio uses multiple microphones ... There were 2 microphones used ...",
      "The audio uses multiple microphones ...",
      "There were 2 microphones used ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-4], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 2 was detected by LFCC with a shap value of 0.4129 ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4129 ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker shap for the audio sample ...",
      "Yes GTCC which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a 0 value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a sha value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of  was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker  for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes person 2 was detected by LFCC with a shap value of 0.4129 ... Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...",
      "Yes GTCC which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speech_speed])",
    "ref": [
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different speed ... Other samples show the person speaks at a different speed ...",
      "Other samples show the person speaks at a different speed ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speech_speed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-10], interpreter[shap], shap_value[0.114])",
    "ref": [
      "Yes PSRCC which a shap value of 0.11 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ...",
      "Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ... Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a yes value of 0.114 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.11 was used to detect the id of speaker  for the audio sample ...",
      "Yes PSRCC which a shap value of 0.11yes was used to detect the id of speaker yes for the audio sample ...",
      "Yes PSRCC which a  value of 0.114 was used to detect the id of speaker 4 for the audio sample ...",
      "the audio sample had CepstralFeature features extracted and LFCC was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audio_signal ... Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.11 was used to detect the id of speaker 4 for the audio sample ...",
      "Yes PSRCC which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.114 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-32], interpreter[shap], shap_value[0.0732])",
    "ref": [
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...",
      "Yes MFCC which a yes value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a sh value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes LFCC which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ... Yes MFCC which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0730.0732 was used to detect the id of speaker 0.0732 for the audio sample ...",
      "Yes MFCC which a shap value of 0.073 was used to detect the id of speaker  for the audio sample ...",
      "Yes MFCC which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ... Yes MFCC which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of shap was used to detect the id of speaker 2 for the audio sample ...",
      "Yes MFCC which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0732 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-7], interpreter[shap], shap_value[0.0685])",
    "ref": [
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ... Yes person 5 was detected by MSRCC with a shap value of 0.0685 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0 ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ...",
      "Yes person  was detected by MSRCC with a shap value of 0.068 ...",
      "Yes person shap was detected by MSRCC with a shap value of 0.068shap ...",
      "Yes person 3 was detected by MFCC with a shap value of 0.2648 ... Yes person 5 was detected by MSRCC with a shap value of 0.0685 ...",
      "Yes person 5 was detected by MSRCC with a 0.0685 value of 0.0685 ...",
      "Yes person 5 was detected by MSRCC with a shap value of yes ...",
      "Yes person 5 was detected by MSRCC with a sh value of 0.0685 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ... Yes person 5 was detected by MSRCC with a shap value of 0.0685 ...",
      "Yes person 5 was detected by MSRCC with a shap value of 0.0685 ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0685 ]> )"
  }
]