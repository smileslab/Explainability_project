[
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-22], classification[bonafide])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-22 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-53], classification[bonafide], shap_value[0.1457])",
    "ref": [
      " Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal ....",
      "Yes the recording is synthetic ....",
      "Yes Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-53 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.1457 was used to detect the sample as Audiosignal ....",
      "Yes the recording is synthetic .... Yes Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal ....",
      "0.1457 Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of 0.1457 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.1457 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-53 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.1457 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "Yes there were  microphones ....",
      "The recording is artificially slowed ....",
      "The recording is artificially slowed .... Yes there were 2 microphones ....",
      "Yes there were 2 microphones .... Yes there were 2 microphones ....",
      "Yes there were spoof microphones ....",
      "Yes there were  microphones ....",
      "The recording is artificially slowed ....",
      "The recording is artificially slowed .... Yes there were 2 microphones ....",
      "Yes there were 2 microphones .... Yes there were 2 microphones ....",
      "Yes there were spoof microphones ....",
      "Yes there were 2 microphones ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-17], interpreter[shap], shap_value[-0.164])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.1-0.1644 was used to detect the id of speaker -0.164 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a sh value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a -0.164 value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.14 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of MFCC-17 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.1-0.1644 was used to detect the id of speaker -0.164 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-17 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.164 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      " the Audiosignal was detected by CNN recording was not converted ...",
      "CNN the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by  recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not No ...",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 .... No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was converted ...",
      "No the Audiosignal was detected by CNN recording was not converted ... No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by spoofed recording was not converted ...",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 ....",
      "No the Audiosignal was detected by CNN recording was not convert ...",
      "No the Audiosignal was detected by CNN recording was not converted ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "There are inconsistencies .... There are inconsistencies ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... There are inconsistencies ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "There are inconsistencies .... There are inconsistencies ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... There are inconsistencies ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "There are inconsistencies .... There are inconsistencies ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... There are inconsistencies ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "There are inconsistencies .... There are inconsistencies ....",
      "There are inconsistencies ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-35], interpreter[shap], shap_value[0.4155])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a 0.4155 value of 0.4155 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4155 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4155 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a sh value of 0.4155 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4155 was used to detect the id of speaker 3 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-35 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4155 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-31], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-31 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... There is an echo ...",
      "There is an echo ... There is an echo ...",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... There is an echo ...",
      "There is an echo ... There is an echo ...",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... There is an echo ...",
      "There is an echo ... There is an echo ...",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... There is an echo ...",
      "There is an echo ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[sampling])",
    "ref": [
      "Yes . Yes . There is evidence of sampling ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 .... Yes . There is evidence of sampling ....",
      "Yes . There is evidence of spoof ....",
      "There is evidence of sampling ....",
      "Yes . Yes . Yes . There is evidence of sampling ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 .... There is evidence of sampling ....",
      "Yes . There is evidence of sampl ....",
      " . There is evidence of sampling ....",
      "Yes .",
      "Yes . There is evidence of sampling ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "Interpreters is used for identifying the important features in classifing the audio .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Interpreters is used for identifying the important features in classifing the audio .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Interpreters is used for identifying the important features in classifing the audio .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Interpreters is used for identifying the important features in classifing the audio .... Interpreters is used for identifying the important features in classifing the audio ....",
      "Interpreters is used for identifying the important features in classifing the audio ...."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "The audio has several CaptureDevice signatures .... The audio has several CaptureDevice signatures ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The audio has several CaptureDevice signatures ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio has several CaptureDevice signatures .... The audio has several CaptureDevice signatures ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The audio has several CaptureDevice signatures ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio has several CaptureDevice signatures .... The audio has several CaptureDevice signatures ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The audio has several CaptureDevice signatures ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio has several CaptureDevice signatures .... The audio has several CaptureDevice signatures ....",
      "The audio has several CaptureDevice signatures ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], feature[CQCC-4], feature[MFCC-0], feature[LFCC-2], feature[MFCC-5])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC SHAP had the highest impact on classification ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC  had the highest impact on classification ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC SHAP had the highest impact on classification ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC  had the highest impact on classification ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <feature> feature: [ CQCC-4 ], <feature> feature: [ MFCC-0 ], <feature> feature: [ LFCC-2 ], <feature> feature: [ MFCC-5 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-20], interpreter[shap], shap_value[-0.9142])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of LFCC-20 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.9142 .... Yes person 2 was detected by Cepstrum with a shap value of -0.9142 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 .... Yes person 2 was detected by Cepstrum with a shap value of -0.9142 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.91 ....",
      "Yes person 2 was detected by Cepstrum with a s value of -0.9142 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.914 ....",
      "Yes person 2 was detected by Cepstrum with a LFCC-20 value of -0.9142 ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.914yes ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.9142 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-20 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9142 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-23], interpreter[shap], shap_value[-0.2913])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of -0.2913 .... Yes person 2 was detected by Cepstrum with a shap value of -0.2913 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of shap ....",
      "Yes person -0.2913 was detected by Cepstrum with a shap value of -0.-0.2913913 ....",
      "Yes person 2 was detected by Cepstrum with a sh value of -0.2913 ....",
      "Yes person 2 was detected by Cepstrum with a 2 value of -0.2913 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "Yes person  was detected by Cepstrum with a shap value of -0.913 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.2 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... Yes person 2 was detected by Cepstrum with a shap value of -0.2913 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.2913 .... Yes person 2 was detected by Cepstrum with a shap value of -0.2913 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.2913 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2913 ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Everything points to this audio sample being Audiosignal ....",
      "Everything points to this audio sample being Audiosignal .... Everything points to this audio sample being Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Everything points to this audio sample being Audiosignal ....",
      "Everything points to this audio sample being Audiosignal .... Everything points to this audio sample being Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Everything points to this audio sample being Audiosignal ....",
      "Everything points to this audio sample being Audiosignal .... Everything points to this audio sample being Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Everything points to this audio sample being Audiosignal ....",
      "Everything points to this audio sample being Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], edit_type[multi_microphone], mic_quantity[>1], signal_length(10))",
    "ref": [
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... The next CaptureDevice starts at 10 seconds ....",
      "The next CaptureDevice starts at 10 seconds .... The next CaptureDevice starts at 10 seconds ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... The next CaptureDevice starts at 10 seconds ....",
      "The next CaptureDevice starts at 10 seconds .... The next CaptureDevice starts at 10 seconds ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... The next CaptureDevice starts at 10 seconds ....",
      "The next CaptureDevice starts at 10 seconds .... The next CaptureDevice starts at 10 seconds ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "The next CaptureDevice starts at 10 seconds ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-34], classification[replayed], shap_value[-0.2293], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a s value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a CNN value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "LFCC-34 Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-34 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2293 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[4], model[SVM])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ...."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 4 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-34], interpreter[shap], shap_value[-0.8814])",
    "ref": [
      "Yes Cepstrum which a 5 value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample .... Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker LFCC-34 for the audio sample ....",
      "Yes Cepstrum which a sh value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a 5 value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8814 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-38], classification[replayed], shap_value[-0.643], detected_by[CNN])",
    "ref": [
      " Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sh value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by replayed ....",
      "shap Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6995 .... Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a CNN value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6995 ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of - was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-38 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.643 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It seems like a computer was used .... It seems like a computer was used ....",
      "It seems like a compute was used ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... It seems like a computer was used ....",
      "It seems like a spoof was used ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "It seems like a computer was used .... It seems like a computer was used ....",
      "It seems like a compute was used ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... It seems like a computer was used ....",
      "It seems like a spoof was used ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "It seems like a computer was used ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-31], classification[replayed], shap_value[0.8955], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by  ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sh value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a 0.8955 value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by MFCC-31 ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "replayed Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-31 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.8955 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-39], classification[bonafide], shap_value[0.4439])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.443 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a 0.4439 value of 0.4439 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.4439 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.4439 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of 0.4439 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.4439 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.4439 was used to detect the sample as Audiosignal ....",
      "LFCC-39 Cepstrum which a shap value of 0.4439 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.443 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.4439 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-39 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4439 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-57], interpreter[shap], shap_value[0.6978])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker shap for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 1 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample .... Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a  value of 0.6978 was used to detect the id of speaker 1 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a 0.6978 value of 0.6978 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker shap for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-57 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6978 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-21], interpreter[shap], shap_value[0.3949])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a s value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a MFCC-21 value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "No the Audiosignal was detected by CNN recording was not converted ... Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker MFCC-21 for the audio sample ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-21 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3949 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[GTCC-11], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes Cepstrum which a sha value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 1 for the audio sample .... Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a yes value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a sha value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ GTCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[synthetic])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The audio is synthetic ....",
      "The audio is synthetic .... The audio is synthetic ....",
      "The audio is spoof ....",
      "The audio is syn ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The audio is synthetic ....",
      "The audio is synthetic .... The audio is synthetic ....",
      "The audio is spoof ....",
      "The audio is syn ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio is synthetic ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ synthetic ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-45], interpreter[shap], shap_value[-0.3826])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.38 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a  value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a yes value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker LFCC-45 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-45 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3826 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[copy])",
    "ref": [
      "The audio appears to be a copy ... The audio appears to be a copy ...",
      "No other spoof types were detected .... The audio appears to be a copy ...",
      "The audio appears to be a  ...",
      "The audio appears to be a spoof ...",
      "No other spoof types were detected ....",
      "The audio appears to be a copy ... The audio appears to be a copy ...",
      "No other spoof types were detected .... The audio appears to be a copy ...",
      "The audio appears to be a  ...",
      "The audio appears to be a spoof ...",
      "No other spoof types were detected ....",
      "The audio appears to be a copy ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ copy ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "The next synthesized area begins at 16 seconds ....",
      "No this audio is fake .... No this audio is fake ....",
      "The next synthesized area begins at 16 seconds .... No this audio is fake ....",
      "The next synthesized area begins at 16 seconds ....",
      "No this audio is fake .... No this audio is fake ....",
      "The next synthesized area begins at 16 seconds .... No this audio is fake ....",
      "The next synthesized area begins at 16 seconds ....",
      "No this audio is fake .... No this audio is fake ....",
      "The next synthesized area begins at 16 seconds .... No this audio is fake ....",
      "The next synthesized area begins at 16 seconds ....",
      "No this audio is fake ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-6], interpreter[shap], shap_value[-0.8167])",
    "ref": [
      "Yes person shap was detected by Cepstrum with a shap value of -0.8167 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of yes ....",
      "yes Cepstrum was used to determine speaker id .... Yes person 3 was detected by Cepstrum with a shap value of -0.8167 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.8 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.8167 ....",
      "yes Cepstrum was used to determine speaker id ....",
      "Yes person 3 was detected by Cepstrum with a sha value of -0.8167 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.8167 .... Yes person 3 was detected by Cepstrum with a shap value of -0.8167 ....",
      "Yes person 3 was detected by Cepstrum with a -0.8167 value of -0.8167 ....",
      "Yes person shap was detected by Cepstrum with a shap value of -0.8167 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.8167 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8167 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[GTCC-13], shap_value[0])",
    "ref": [
      "0 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of  ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of GTCC-13 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "0 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-4], classification[replayed], shap_value[-0.7388], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by shap ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a  value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.7825 .... Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.73 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.7825 ....",
      "Yes Cepstrum which a MSRCC-4 value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7388 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[cloning])",
    "ref": [
      "Ye voice cloning was used ....",
      "Yes voice cloni was used ....",
      "Yes voice cloning was used .... Yes voice cloning was used ....",
      "Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes voice cloning was used ....",
      "Yes voice spoofed was used ....",
      "cloning voice cloning was used ....",
      "Yes Cepstrum which a shap value of -0.643 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Ye voice cloning was used ....",
      "Yes voice cloni was used ....",
      "Yes voice cloning was used .... Yes voice cloning was used ....",
      "Yes voice cloning was used ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ cloning ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 .... Features in the recording show there were two microphones used ....",
      "Features in the recording show there were two microphones used .... Features in the recording show there were two microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 .... Features in the recording show there were two microphones used ....",
      "Features in the recording show there were two microphones used .... Features in the recording show there were two microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 .... Features in the recording show there were two microphones used ....",
      "Features in the recording show there were two microphones used .... Features in the recording show there were two microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 .... Features in the recording show there were two microphones used ....",
      "Features in the recording show there were two microphones used ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-40], interpreter[shap], shap_value[-0.9913])",
    "ref": [
      "Yes person LFCC-40 was detected by Cepstrum with a shap value of -0.9913 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.99 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 .... Yes person 5 was detected by Cepstrum with a shap value of -0.9913 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 .... Yes person 5 was detected by Cepstrum with a shap value of -0.9913 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.9913 ....",
      "Yes person 5 was detected by Cepstrum with a 5 value of -0.9913 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 5 ....",
      "Yes person 5 was detected by Cepstrum with a sha value of -0.9913 ....",
      "Yes person LFCC-40 was detected by Cepstrum with a shap value of -0.9913 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-40 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9913 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-53], interpreter[shap], shap_value[-0.2638])",
    "ref": [
      "Yes person 1 was detected by Cepstrum with a shap value of -0.2638 .... Yes person 1 was detected by Cepstrum with a shap value of -0.2638 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.2638 ....",
      "Yes person 1 was detected by Cepstrum with a  value of -0.2638 ....",
      "It is not a bona fide recording ....",
      "Yes person LFCC-53 was detected by Cepstrum with a shap value of -0.2638 ....",
      "Yes person 1 was detected by Cepstrum with a -0.2638 value of -0.2638 ....",
      "It is not a bona fide recording .... Yes person 1 was detected by Cepstrum with a shap value of -0.2638 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of shap ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.2638 .... Yes person 1 was detected by Cepstrum with a shap value of -0.2638 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.2638 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-53 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2638 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-19], classification[bonafide])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-19 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-12], classification[replayed], shap_value[-0.6521], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of PSRCC-12 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.652 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "CNN Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a -0.6521 value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 .... Yes Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a shap value of -0.6521 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.6521 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-57], classification[bonafide])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-57 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-2], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 4 for the audio sample ....",
      "The alterations are consistent with known programs ...",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a 4 value of 1 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a sha value of 1 was used to detect the id of speaker 4 for the audio sample ....",
      "The alterations are consistent with known programs ... Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment], detected_by[CNN])",
    "ref": [
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CN in this way ...",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 .... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ...",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ...",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 ....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by spoof in this way ...",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CN in this way ...",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 .... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ...",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ... The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ...",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 ....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by spoof in this way ...",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-39], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-39 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-14], shap_value[0.6262])",
    "ref": [
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "0.6262 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.62 ....",
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "0.6262 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-14 ], <shap_value> shap value: [ 0.6262 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-24], classification[replayed], shap_value[-0.0073], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a CNN value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "-0.0073 Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by MFCC-24 ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CN ....",
      "Ye Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.007 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sh value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-24 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.0073 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-7], classification[bonafide])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-7 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-10], classification[bonafide], shap_value[0.0536])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.0536 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.0536 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.0536 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of 0.0536 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sh value of 0.0536 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a 0.0536 value of 0.0536 was used to detect the sample as Audiosignal ....",
      "0.0536 Cepstrum which a shap value of 0.0536 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.0536 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-10 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0536 ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... The audio sample was found to be spoofed....",
      "The audio sample was found to be spoofed.... The audio sample was found to be spoofed....",
      "The audio sample was found to be sed....",
      "Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... The audio sample was found to be spoofed....",
      "The audio sample was found to be spoofed.... The audio sample was found to be spoofed....",
      "The audio sample was found to be sed....",
      "Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... The audio sample was found to be spoofed....",
      "The audio sample was found to be spoofed...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-33], interpreter[shap], shap_value[0.4724])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a sha value of 0.4724 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 .... Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 .... Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.4724 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.47 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of yes ....",
      "Yes person 5 was detected by Cepstrum with a 0.4724 value of 0.4724 ....",
      "Yes person LFCC-33 was detected by Cepstrum with a shap value of 0.4724 ....",
      "Yes person 5 was detected by Cepstrum with a sha value of 0.4724 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4724 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-3], classification[bonafide], shap_value[0.9178])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.9 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sh value of 0.9178 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "bonafide Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of 0.9178 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.9178 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.9178 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-52], classification[bonafide], shap_value[0.3733])",
    "ref": [
      "Yes Cepstrum which a LFCC-52 value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-52 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ....",
      " Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "bonafide Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a  value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample .... Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a LFCC-52 value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-52 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3733 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-32], interpreter[shap], shap_value[-0.9992])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal .... Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of yes ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.9992 ....",
      "Yes person 1 was detected by Cepstrum with a 1 value of -0.9992 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 .... Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ....",
      "Yes person 1 was detected by Cepstrum with a sha value of -0.9992 ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.9992 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.999 ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9992 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[software])",
    "ref": [
      "It looks like the recording was edited using spoof ....",
      "It looks like the recording was edited using software .... It looks like the recording was edited using software ....",
      "Everything points to this audio sample being Audiosignal .... It looks like the recording was edited using software ....",
      "It looks like the recording was edited using softwar ....",
      "Everything points to this audio sample being Audiosignal ....",
      "It looks like the recording was edited using spoof ....",
      "It looks like the recording was edited using software .... It looks like the recording was edited using software ....",
      "Everything points to this audio sample being Audiosignal .... It looks like the recording was edited using software ....",
      "It looks like the recording was edited using softwar ....",
      "Everything points to this audio sample being Audiosignal ....",
      "It looks like the recording was edited using software ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ software ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-11], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a  value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "GTCC-11 Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-33], interpreter[shap], shap_value[0.2648])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 .... Yes person 3 was detected by Cepstrum with a shap value of 0.2648 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of yes ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.2648 ....",
      "Yes person 3 was detected by Cepstrum with a sh value of 0.2648 ....",
      "Yes person 3 was detected by Cepstrum with a MFCC-33 value of 0.2648 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.26 ....",
      "Yes person yes was detected by Cepstrum with a shap value of 0.2648 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.2648 .... Yes person 3 was detected by Cepstrum with a shap value of 0.2648 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 .... Yes person 3 was detected by Cepstrum with a shap value of 0.2648 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.2648 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2648 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 .... There is more than one area of synthesized AcousticWave ....",
      "There is more than one area of synthesized AcousticWave .... There is more than one area of synthesized AcousticWave ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 .... There is more than one area of synthesized AcousticWave ....",
      "There is more than one area of synthesized AcousticWave .... There is more than one area of synthesized AcousticWave ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 .... There is more than one area of synthesized AcousticWave ....",
      "There is more than one area of synthesized AcousticWave .... There is more than one area of synthesized AcousticWave ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 .... There is more than one area of synthesized AcousticWave ....",
      "There is more than one area of synthesized AcousticWave ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-2], interpreter[shap], shap_value[0.6718])",
    "ref": [
      "No most of the recording was not made with a mobile phone ....",
      "Yes person shap was detected by Cepstrum with a shap value of 0.6shap18 ....",
      "Yes person 7 was detected by Cepstrum with a yes value of 0.6718 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of LFCC-2 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "No most of the recording was not made with a mobile phone .... Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.618 ....",
      "Yes person 7 was detected by Cepstrum with a sha value of 0.6718 ....",
      "No most of the recording was not made with a mobile phone ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6718 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-14], interpreter[shap], shap_value[-0.8355])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.8 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample .... Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker  for the audio sample ....",
      "The audio is not Audiosignal ....",
      "Yes Cepstrum which a sha value of -0.8355 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a 1 value of -0.8355 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker yes for the audio sample ....",
      "The audio is not Audiosignal .... Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-14 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.8355 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-6], classification[bonafide], shap_value[0.5258])",
    "ref": [
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the sample as Audiosignal ....",
      "bonafide Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sh value of 0.5258 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Y Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a 0.5258 value of 0.5258 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5258 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "There were 2 microphones used .... There were 2 microphones used ....",
      "yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... There were 2 microphones used ....",
      "There were  microphones used ....",
      "There were multi_microphone microphones used ....",
      "There were 2 microphones used .... There were 2 microphones used ....",
      "yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... There were 2 microphones used ....",
      "There were  microphones used ....",
      "There were multi_microphone microphones used ....",
      "There were 2 microphones used ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-11], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-11 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-21], classification[bonafide], shap_value[0.6636])",
    "ref": [
      "Yes Cepstrum which a Yes value of 0.6636 was used to detect the sample as Audiosignal ....",
      "0.6636 Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-21 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.6636 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 .... Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "Yes Cepstrum which a shap value of 0.66 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a Yes value of 0.6636 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-21 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6636 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-20], classification[bonafide], shap_value[0.6675])",
    "ref": [
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ....",
      "Yes Cepstrum which a 0.6675 value of 0.6675 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of 0.6675 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.6675 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6675 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.6675 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 .... Yes Cepstrum which a shap value of 0.6675 was used to detect the sample as Audiosignal ....",
      "LFCC-20 Cepstrum which a shap value of 0.6675 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6675 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-20 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6675 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-7], interpreter[shap], shap_value[-0.9296])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.92 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a 6 value of -0.9296 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.929 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.929yes was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a sha value of -0.9296 was used to detect the id of speaker 6 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.9296 was used to detect the id of speaker 6 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9296 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-7], interpreter[shap], shap_value[-0.4878])",
    "ref": [
      "Yes person 3 was detected by Cepstrum with a shap value of MFCC-7 ....",
      "Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0 ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.4878 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.4878 .... Yes person 3 was detected by Cepstrum with a shap value of -0.4878 ....",
      "Yes person 3 was detected by Cepstrum with a  value of -0.4878 ....",
      "Yes person 3 was detected by Cepstrum with a 3 value of -0.4878 ....",
      "Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample .... Yes person 3 was detected by Cepstrum with a shap value of -0.4878 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.4878 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of MFCC-7 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.4878 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4878 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-51], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-51 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(model[CNN], task[spoof_detecting], detected_by[CNN])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not converted ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal .... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "No the Audiosignal was detected by CNN recording was not converted ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal .... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "No the Audiosignal was detected by CNN recording was not converted ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal .... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "No the Audiosignal was detected by CNN recording was not converted ... the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ....",
      "the audio sample had features extracted which were fed into a FeedforwardNeuralNetwork Abstract for detection of being Audiosignal or Audio_signal ...."
    ],
    "new_mr": "<inform> inform ( <model> model: [ CNN ], <task> task: [ spoof_detecting ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... The audio sample was found to be bonafide....",
      "The audio sample was found to be bonafide.... The audio sample was found to be bonafide....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The audio sample was found to be none....",
      "The audio sample was found to be bonafid....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... The audio sample was found to be bonafide....",
      "The audio sample was found to be bonafide.... The audio sample was found to be bonafide....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The audio sample was found to be none....",
      "The audio sample was found to be bonafid....",
      "The audio sample was found to be bonafide...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-12], classification[replayed], shap_value[-0.642], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by -0.642 ....",
      "Yes Cepstrum which a s value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of LFCC-12 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "-0.642 Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a replayed value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.642 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.642 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There were 2 microphones used .... The audio uses multiple microphones ....",
      "The audio uses multiple microphones .... The audio uses multiple microphones ....",
      "There were 2 microphones used ....",
      "There were 2 microphones used .... The audio uses multiple microphones ....",
      "The audio uses multiple microphones .... The audio uses multiple microphones ....",
      "There were 2 microphones used ....",
      "There were 2 microphones used .... The audio uses multiple microphones ....",
      "The audio uses multiple microphones .... The audio uses multiple microphones ....",
      "There were 2 microphones used ....",
      "There were 2 microphones used .... The audio uses multiple microphones ....",
      "The audio uses multiple microphones ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-1], classification[replayed], shap_value[-1], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a -1 value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 .... Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by  ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by GTCC-1 ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "-1 Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -1 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-55], classification[bonafide], shap_value[-0.1297])",
    "ref": [
      "Yes Cepstrum which a bonafide value of -0.1297 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.1297 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.1297 was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of -0.1297 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.1297 was used to detect the sample as Audiosignal ....",
      "-0.1297 Cepstrum which a shap value of -0.1297 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -0.1297 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.12 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of -0.1297 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.1297 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-55 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.1297 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-32], shap_value[-0.7306])",
    "ref": [
      "It seems like a computer was used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.73 ....",
      "MFCC-32 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "It seems like a computer was used .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "It seems like a computer was used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.73 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-32 ], <shap_value> shap value: [ -0.7306 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[cloning])",
    "ref": [
      "No this audio is fake .... It appears there was voice cloning ...",
      "It appears there was voice clo ...",
      "It appears there was voice spoof ...",
      "It appears there was voice cloning ... It appears there was voice cloning ...",
      "No this audio is fake ....",
      "No this audio is fake .... It appears there was voice cloning ...",
      "It appears there was voice clo ...",
      "It appears there was voice spoof ...",
      "It appears there was voice cloning ... It appears there was voice cloning ...",
      "No this audio is fake ....",
      "It appears there was voice cloning ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ cloning ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "A DigitalSignal signature was not detected .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "A DigitalSignal signature was not detected ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "A DigitalSignal signature was not detected .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "A DigitalSignal signature was not detected ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "A DigitalSignal signature was not detected .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "A DigitalSignal signature was not detected ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "A DigitalSignal signature was not detected .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[No], classification[bonafide])",
    "ref": [
      "No it is not a bona fide recording .... No it is not a bona fide recording ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal .... No it is not a bona fide recording ....",
      "bonafide it is not a bona fide recording ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "No it is a bona fide recording ....",
      "N it is not a bona fide recording ....",
      "No it is not a bona fide recording .... No it is not a bona fide recording ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal .... No it is not a bona fide recording ....",
      "bonafide it is not a bona fide recording ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "No it is not a bona fide recording ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "The audio was Audiosignal was detected by CN?",
      "The audio was Audiosignal was detected by CNN? The audio was Audiosignal was detected by CNN?",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample .... The audio was Audiosignal was detected by CNN?",
      "The audio was Audiosignal was detected by spoof?",
      "The audio was Audiosignal was detected by CN?",
      "The audio was Audiosignal was detected by CNN? The audio was Audiosignal was detected by CNN?",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6978 was used to detect the id of speaker 1 for the audio sample .... The audio was Audiosignal was detected by CNN?",
      "The audio was Audiosignal was detected by spoof?",
      "The audio was Audiosignal was detected by CNN?"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-8], interpreter[shap], shap_value[0.3074])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.30 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample .... Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a yes value of 0.3074 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker shap for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a sh value of 0.3074 was used to detect the id of speaker 5 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-8 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.3074 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer], detected_by[CNN])",
    "ref": [
      "The audio file was classified as being Audiosignal was detected by  by a MixtureModel Abstract ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 .... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being Audiosignal was detected by computer by a MixtureModel Abstract ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being Audiosignal was detected by  by a MixtureModel Abstract ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 .... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being Audiosignal was detected by computer by a MixtureModel Abstract ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-27], classification[replayed], shap_value[-0.5562], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a CNN value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "person 3 was detected as the primary speaker of the audio sample .... Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of MFCC-27 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "person 3 was detected as the primary speaker of the audio sample ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5562 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-12], interpreter[shap], shap_value[-0.6016])",
    "ref": [
      "Yes person 3 was detected by Cepstrum with a shap value of -0.8167 ....",
      "Yes Cepstrum which a shap value of MFCC-12 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a sh value of -0.6016 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a -0.6016 value of -0.6016 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.60 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6016 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample .... Yes Cepstrum which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6016 was used to detect the id of speaker -0.6016 for the audio sample ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.8167 .... Yes Cepstrum which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.8167 ....",
      "Yes Cepstrum which a shap value of -0.6016 was used to detect the id of speaker 2 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6016 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-50], classification[bonafide])",
    "ref": [
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-50 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-51], classification[replayed], shap_value[-0.8842], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by -0.8842 ....",
      "Yes Cepstrum which a Yes value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "-0.8842 Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CN ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-51 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.8842 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-25], classification[bonafide], shap_value[0.983])",
    "ref": [
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.983 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a LFCC-25 value of 0.983 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "0.983 Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-25 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.983 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-11], interpreter[shap], shap_value[-0.9056])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a MFCC-11 value of -0.9056 ....",
      "Yes person 2 was detected by Cepstrum with a sh value of -0.9056 ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.9056 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 .... Yes person 2 was detected by Cepstrum with a shap value of -0.9056 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of shap ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.9056 .... Yes person 2 was detected by Cepstrum with a shap value of -0.9056 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.9056 ....",
      "Yes person 2 was detected by Cepstrum with a MFCC-11 value of -0.9056 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.9056 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9056 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "The audio uses multiple microphones .... The audio uses multiple microphones ....",
      "No the Audiosignal was detected by CNN recording was not converted ... The audio uses multiple microphones ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "The audio uses multiple microphones .... The audio uses multiple microphones ....",
      "No the Audiosignal was detected by CNN recording was not converted ... The audio uses multiple microphones ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "The audio uses multiple microphones .... The audio uses multiple microphones ....",
      "No the Audiosignal was detected by CNN recording was not converted ... The audio uses multiple microphones ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "The audio uses multiple microphones ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[environment])",
    "ref": [
      "Because the background noise changes too quickly to be natural .... Because the background noise changes too quickly to be natural ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample .... Because the background noise changes too quickly to be natural ....",
      "Because the background noise changes too quickly to be natural .... Because the background noise changes too quickly to be natural ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample .... Because the background noise changes too quickly to be natural ....",
      "Because the background noise changes too quickly to be natural .... Because the background noise changes too quickly to be natural ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample .... Because the background noise changes too quickly to be natural ....",
      "Because the background noise changes too quickly to be natural .... Because the background noise changes too quickly to be natural ....",
      "Because the background noise changes too quickly to be natural ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ environment ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-12], shap_value[-0.5786])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "LFCC-12 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of  ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-12 ], <shap_value> shap value: [ -0.5786 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-42], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the recording is synthetic .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the recording is synthetic ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the recording is synthetic .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the recording is synthetic ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the recording is synthetic .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the recording is synthetic ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-42 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-1], classification[bonafide], shap_value[-0.5419])",
    "ref": [
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 .... Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "shap Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a s value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-1 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a -0.5419 value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-1 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.5419 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-14], classification[replayed], shap_value[0.5317], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample .... Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "replayed Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a Yes value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5317 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-8], classification[replayed], shap_value[0.7072], detected_by[CNN])",
    "ref": [
      "Ye Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "Yes Cepstrum which a CNN value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by shap ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sha value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of PSRCC-8 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "replayed Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CN ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.7072 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-0], classification[replayed], shap_value[0.3558], detected_by[CNN])",
    "ref": [
      "Y Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a  value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by  ....",
      "Yes Cepstrum which a shap value of 0.355 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "Yes Cepstrum which a shap value of MSRCC-0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio .... Yes Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by shap ....",
      "Yes Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "CNN Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.3558 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.3558 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-22], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-22 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-46], shap_value[-0.2953])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "The alterations are consistent with known programs ... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.29 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of LFCC-46 ....",
      "-0.2953 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "The alterations are consistent with known programs ... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-46 ], <shap_value> shap value: [ -0.2953 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-8], shap_value[-0.373])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.3 ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "LFCC-8 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of LFCC-8 ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.3 ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.373 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-8 ], <shap_value> shap value: [ -0.373 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-13], classification[replayed], shap_value[0], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a sh value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a replayed value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by replayed ....",
      "Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "0 Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-13 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-2], classification[replayed], detected_by[CNN])",
    "ref": [
      "The audio uses multiple microphones .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio uses multiple microphones ....",
      "The audio uses multiple microphones .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio uses multiple microphones ....",
      "The audio uses multiple microphones .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The audio uses multiple microphones ....",
      "The audio uses multiple microphones .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-2 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal .... person 6 was detected as the primary speaker of the audio sample ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "person 6 was detected as the primary speaker of the audio sample .... person 6 was detected as the primary speaker of the audio sample ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal .... person 6 was detected as the primary speaker of the audio sample ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "person 6 was detected as the primary speaker of the audio sample .... person 6 was detected as the primary speaker of the audio sample ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.5419 was used to detect the sample as Audiosignal .... person 6 was detected as the primary speaker of the audio sample ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "person 6 was detected as the primary speaker of the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-36], shap_value[-0.0131])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.01 ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 ....",
      "-0.0131 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.01 ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0131 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-36 ], <shap_value> shap value: [ -0.0131 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[5])",
    "ref": [
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... The audio is a little faster between the five and ten second mark ....",
      "The audio is a little faster between the five and ten second mark .... The audio is a little faster between the five and ten second mark ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... The audio is a little faster between the five and ten second mark ....",
      "The audio is a little faster between the five and ten second mark .... The audio is a little faster between the five and ten second mark ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... The audio is a little faster between the five and ten second mark ....",
      "The audio is a little faster between the five and ten second mark .... The audio is a little faster between the five and ten second mark ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... The audio is a little faster between the five and ten second mark ....",
      "The audio is a little faster between the five and ten second mark ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 5 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-9], classification[replayed], shap_value[0.5114], detected_by[CNN])",
    "ref": [
      "Y Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by LFCC-9 ....",
      "Yes Cepstrum which a shap value of LFCC-9 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sha value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "CNN Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ... Yes Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The breathing irregularities and abrupt changes indicate the audio was Audiosignal was detected by CNN in this way ...",
      "Yes Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by  ....",
      "Yes Cepstrum which a shap value of 0.5114 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.5114 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], mic_type[mobile_phone], mic_type[computer])",
    "ref": [
      "Y some of the recording was made with a mobile device and some with a computer ...",
      "Yes some of the recording was made with a mobile device and some with a compute ...",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes some of the recording was made with a mobile device and some with a computer ... Yes some of the recording was made with a mobile device and some with a computer ...",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes some of the recording was made with a mobile device and some with a computer ...",
      "computer some of the recording was made with a mobile device and some with a computer ...",
      "Yes some of the recording was made with a mobile device and some with a mobile_phone ...",
      "Y some of the recording was made with a mobile device and some with a computer ...",
      "Yes some of the recording was made with a mobile device and some with a compute ...",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes some of the recording was made with a mobile device and some with a computer ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ], <mic_type> mic type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-16], interpreter[shap], shap_value[0.8851])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ....",
      "person 6 was detected as the primary speaker of the audio sample ....",
      "Yes Cepstrum which a yes value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "person 6 was detected as the primary speaker of the audio sample .... Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a s value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8851 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-11], classification[replayed], shap_value[-0.5246], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sh value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by -0.5246 ....",
      "replayed Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.52 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by  ....",
      " Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.5246 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-11 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.5246 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-17], classification[bonafide], shap_value[0.0961])",
    "ref": [
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 .... Yes Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "0.0961 Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.0961 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-17 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.0961 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-10], classification[bonafide])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-10 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-8], determined[speaker_id])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN .... yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "ye Cepstrum was used to determine speaker id ....",
      "speaker_id Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN .... yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of -0.5562 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "ye Cepstrum was used to determine speaker id ....",
      "speaker_id Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-8 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(classification[spoof], mic_type[mobile_phone])",
    "ref": [
      "Some of the recording was made using a computer .... Some of the recording was made using a computer ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample .... Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... Some of the recording was made using a computer ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample .... Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... Some of the recording was made using a computer ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8851 was used to detect the id of speaker 4 for the audio sample .... Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], spoof_type[syntheic])",
    "ref": [
      "spoof the recording is synthetic ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "Yes the recording is synthetic .... Yes the recording is synthetic ....",
      "Ye the recording is synthetic ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal .... Yes the recording is synthetic ....",
      "spoof the recording is synthetic ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "Yes the recording is synthetic .... Yes the recording is synthetic ....",
      "Ye the recording is synthetic ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal .... Yes the recording is synthetic ....",
      "Yes the recording is synthetic ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <spoof_type> spoof type: [ syntheic ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-13], shap_value[-0.8209])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of - ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "-0.8209 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of - ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-13 ], <shap_value> shap value: [ -0.8209 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-8], classification[replayed], shap_value[-0.9437], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CN ....",
      "Yes Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model.... Yes Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "-0.9437 Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0. was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a Yes value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by replayed ....",
      "Yes Cepstrum which a sha value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.9437 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-8 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.9437 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-23], shap_value[-0.0117])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.01 ....",
      "MFCC-23 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ....",
      "Yes Cepstrum which a shap value of -0.8355 was used to detect the id of speaker 1 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.0117 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-23 ], <shap_value> shap value: [ -0.0117 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-25], interpreter[shap], shap_value[0.7825])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes person 1 was detected by Cepstrum with a shap value of 0.7825 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 1 was detected by Cepstrum with a yes value of 0.7825 ....",
      "Yes person 1 was detected by Cepstrum with a sh value of 0.7825 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.7825 .... Yes person 1 was detected by Cepstrum with a shap value of 0.7825 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of yes ....",
      "Yes person 0.7825 was detected by Cepstrum with a shap value of 0.7825 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.7825 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0. ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes person 1 was detected by Cepstrum with a shap value of 0.7825 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.7825 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-25 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7825 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-27], interpreter[shap], shap_value[-0.3514])",
    "ref": [
      "Yes person 3 was detected by Cepstrum with a shap value of -0.35 ....",
      "Yes person 3 was detected by Cepstrum with a 3 value of -0.3514 ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes person 3 was detected by Cepstrum with a  value of -0.3514 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.514 ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample .... Yes person 3 was detected by Cepstrum with a shap value of -0.3514 ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.yes514 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.3514 .... Yes person 3 was detected by Cepstrum with a shap value of -0.3514 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 3 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.35 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of -0.3514 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3514 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-47], classification[replayed], detected_by[CNN])",
    "ref": [
      "Constant-Q Cepstral Coefficients ....",
      "Constant-Q Cepstral Coefficients .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Constant-Q Cepstral Coefficients ....",
      "Constant-Q Cepstral Coefficients .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Constant-Q Cepstral Coefficients ....",
      "Constant-Q Cepstral Coefficients .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-47 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed], change_at[20])",
    "ref": [
      "The s increases at the 20 second mark ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "The speed increases at the spoof second mark ....",
      "The speed increases at the 2 second mark ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 .... The speed increases at the 20 second mark ....",
      "The speed increases at the 20 second mark .... The speed increases at the 20 second mark ....",
      "The spoof increases at the 20 second mark ....",
      "The s increases at the 20 second mark ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "The speed increases at the spoof second mark ....",
      "The speed increases at the 20 second mark ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ], <change_at> change at: [ 20 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-56], interpreter[shap], shap_value[0.8985])",
    "ref": [
      "Constant-Q Cepstral Coefficients .... Yes Cepstrum which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a sh value of 0.8985 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a 5 value of 0.8985 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.898yes was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 5 for the audio sample ....",
      "Constant-Q Cepstral Coefficients ....",
      "Yes Cepstrum which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample .... Yes Cepstrum which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.898 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 5 for the audio sample ....",
      "Constant-Q Cepstral Coefficients .... Yes Cepstrum which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8985 was used to detect the id of speaker 5 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-56 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8985 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-57], shap_value[-0.5116])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0 ....",
      "Yes the recording is synthetic ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "-0.5116 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "Yes the recording is synthetic .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0 ....",
      "Yes the recording is synthetic ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <shap_value> shap value: [ -0.5116 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-33], interpreter[shap], shap_value[-0.2863])",
    "ref": [
      "No other spoof types were detected ....",
      "Yes Cepstrum which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ....",
      "No other spoof types were detected .... Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a MFCC-33 value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a  value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker -0.2863 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "No other spoof types were detected ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-33 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2863 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "multi_microphone there was more than one CaptureDevice ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes there was more than one CaptureDevice ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Ye there was more than one CaptureDevice ....",
      "Yes there was more than one CaptureDevice .... Yes there was more than one CaptureDevice ....",
      "multi_microphone there was more than one CaptureDevice ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes there was more than one CaptureDevice ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Ye there was more than one CaptureDevice ....",
      "Yes there was more than one CaptureDevice .... Yes there was more than one CaptureDevice ....",
      "Yes there was more than one CaptureDevice ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-50], interpreter[shap], shap_value[-0.1122])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample .... Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a  value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.11yesyes was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.11 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a 2 value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 2 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.11 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.1122 was used to detect the id of speaker 2 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-50 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1122 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-10], interpreter[shap], shap_value[0.289])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a  value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of  ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 .... Yes person 5 was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 5 was detected by Cepstrum with a LFCC-10 value of 0.289 ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes person 5 was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of shap ....",
      "Yes person shap was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a  value of 0.289 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.289 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.289 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "The alterations are consistent with known programs ... The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 .... The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "The alterations are consistent with known programs ... The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 .... The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "The alterations are consistent with known programs ... The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 .... The alterations are consistent with known programs ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "The alterations are consistent with known programs ..."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-12], interpreter[shap], shap_value[0.4129])",
    "ref": [
      "Yes person  was detected by Cepstrum with a shap value of 0.419 ....",
      "Yes person 2 was detected by Cepstrum with a 0.4129 value of 0.4129 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 .... Yes person 2 was detected by Cepstrum with a shap value of 0.4129 ....",
      "Yes person LFCC-12 was detected by Cepstrum with a shap value of 0.41LFCC-129 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 2 was detected by Cepstrum with a shap value of LFCC-12 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes person 2 was detected by Cepstrum with a shap value of 0.4129 ....",
      "Yes person 2 was detected by Cepstrum with a s value of 0.4129 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.412 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.419 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.4129 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4129 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[synthetic], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by Yes recording was a synthetic recording ....",
      "Yes the Audiosignal was detected by CNN recording was a syntheti recording ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... Yes the Audiosignal was detected by CNN recording was a synthetic recording ....",
      "CNN the Audiosignal was detected by CNN recording was a synthetic recording ....",
      "Yes the Audiosignal was detected by CNN recording was a Yes recording ....",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording .... Yes the Audiosignal was detected by CNN recording was a synthetic recording ....",
      " the Audiosignal was detected by CNN recording was a synthetic recording ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes the Audiosignal was detected by C recording was a synthetic recording ....",
      "Yes the Audiosignal was detected by Yes recording was a synthetic recording ....",
      "Yes the Audiosignal was detected by CNN recording was a synthetic recording ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ synthetic ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-11], interpreter[shap], shap_value[-0.3846])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of - ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.3846 ....",
      "The audio sample was PhysicalAccess was detected by CNN as well ....",
      "Yes person 5 was detected by Cepstrum with a -0.3846 value of -0.3846 ....",
      "Yes person 5 was detected by Cepstrum with a  value of -0.3846 ....",
      "Yes person LFCC-11 was detected by Cepstrum with a shap value of -0.3846 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 .... Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "The audio sample was PhysicalAccess was detected by CNN as well .... Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of shap ....",
      "Yes person 5 was detected by Cepstrum with a shap value of - ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-11 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3846 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "It appears there was voice cloning ...",
      "It appears there was voice cloning ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "It appears there was voice cloning ...",
      "It appears there was voice cloning ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "It appears there was voice cloning ...",
      "It appears there was voice cloning ... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-2], shap_value[0.0476])",
    "ref": [
      "It was altered using software ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of PSRCC-2 ....",
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 ....",
      "It was altered using software .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 ....",
      "0.0476 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0 ....",
      "It was altered using software ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of PSRCC-2 ....",
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.0476 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <shap_value> shap value: [ 0.0476 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-3], classification[replayed], shap_value[-0.7698], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a -0.7698 value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "CNN Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.769 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by -0.7698 ....",
      "Yes Cepstrum which a s value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-3 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7698 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-6], classification[bonafide], shap_value[-0.8808])",
    "ref": [
      "It is not a bona fide recording ....",
      "bonafide Cepstrum which a shap value of -0.8808 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a Yes value of -0.8808 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a s value of -0.8808 was used to detect the sample as Audiosignal ....",
      "It is not a bona fide recording .... Yes Cepstrum which a shap value of -0.8808 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8808 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.8808 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of MFCC-6 was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of -0.8808 was used to detect the sample as Audiosignal ....",
      "It is not a bona fide recording ....",
      "Yes Cepstrum which a shap value of -0.8808 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8808 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[GTCC-13], interpreter[shap], shap_value[1])",
    "ref": [
      "Yes Cepstrum which a s value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of GTCC-13 was used to detect the id of speaker 3 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 .... Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a GTCC-13 value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a s value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ GTCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-16], classification[bonafide], shap_value[0.4647])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sh value of 0.4647 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of 0.4647 was used to detect the sample as Audiosignal ....",
      "0.4647 Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample .... Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8814 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.4647 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-19], shap_value[0.6196])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of MFCC-19 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.619 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ....",
      "0.6196 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6196 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-19 ], <shap_value> shap value: [ 0.6196 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-1], classification[replayed], shap_value[-0.2422], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CN ....",
      "Yes Cepstrum which a replayed value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by -0.2422 ....",
      "Yes Cepstrum which a shap value of -0.242 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-1 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.2422 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-6], classification[bonafide], shap_value[1])",
    "ref": [
      "Yes Cepstrum which a  value of 1 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of 1 was used to detect the sample as Audiosignal ....",
      "GTCC-6 Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a  value of 1 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-6 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 1 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "It shows signs of having been digitally manipulated .... It shows signs of having been digitally manipulated ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal .... It shows signs of having been digitally manipulated ....",
      "It shows signs of having been digitally manipulated .... It shows signs of having been digitally manipulated ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal .... It shows signs of having been digitally manipulated ....",
      "It shows signs of having been digitally manipulated .... It shows signs of having been digitally manipulated ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3733 was used to detect the sample as Audiosignal .... It shows signs of having been digitally manipulated ....",
      "It shows signs of having been digitally manipulated .... It shows signs of having been digitally manipulated ....",
      "It shows signs of having been digitally manipulated ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[2])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker GTCC ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-30], classification[replayed], shap_value[-0.662], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of shap was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "Y Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "replayed Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a LFCC-30 value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "Yes Cepstrum which a shap value of -0.662 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-30 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.662 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 .... It appears that part of the audio was sped up ....",
      "It appears that part of the audio was sped up .... It appears that part of the audio was sped up ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 .... It appears that part of the audio was sped up ....",
      "It appears that part of the audio was sped up .... It appears that part of the audio was sped up ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 .... It appears that part of the audio was sped up ....",
      "It appears that part of the audio was sped up .... It appears that part of the audio was sped up ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5116 ....",
      "It appears that part of the audio was sped up ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-7], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.983 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-7 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-5], classification[replayed], shap_value[-0.7587], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.758 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a CNN value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by C ....",
      "replayed Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by -0.7587 ....",
      "Yes Cepstrum which a  value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Ye Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7587 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-5 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.7587 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-46], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-46 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(speaker_id[6])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN .... 6 was found to be the id of the speaker in the sample ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " was found to be the id of the speaker in the sample ....",
      "6 was found to be the id of the speaker in the sample .... 6 was found to be the id of the speaker in the sample ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN .... 6 was found to be the id of the speaker in the sample ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      " was found to be the id of the speaker in the sample ....",
      "6 was found to be the id of the speaker in the sample .... 6 was found to be the id of the speaker in the sample ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN .... 6 was found to be the id of the speaker in the sample ....",
      "Yes Cepstrum which a shap value of -0.0073 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "6 was found to be the id of the speaker in the sample ...."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 6 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-17], classification[bonafide])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7388 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-17 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[PSRCC-3], interpreter[shap], shap_value[-0.5773])",
    "ref": [
      "Yes person yes was detected by Cepstrum with a shap value of -0.5773 ....",
      "Yes person 6 was detected by Cepstrum with a 6 value of -0.5773 ....",
      "Yes person 6 was detected by Cepstrum with a shap value of -0.5 ....",
      "Yes person 6 was detected by Cepstrum with a shap value of -0.5773 .... Yes person 6 was detected by Cepstrum with a shap value of -0.5773 ....",
      "Yes person 6 was detected by Cepstrum with a shap value of 6 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 .... Yes person 6 was detected by Cepstrum with a shap value of -0.5773 ....",
      "Yes person 6 was detected by Cepstrum with a sha value of -0.5773 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.5773 ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.5773 ....",
      "Yes person 6 was detected by Cepstrum with a shap value of -0.5773 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ PSRCC-3 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5773 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MSRCC-7], interpreter[shap], shap_value[-0.2138])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.213 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a -0.2138 value of -0.2138 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a sha value of -0.2138 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of MSRCC-7 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2138 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2138 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-27], interpreter[shap], shap_value[0.8535])",
    "ref": [
      "Yes person 1 was detected by Cepstrum with a shap value of 0.8535 .... Yes person 1 was detected by Cepstrum with a shap value of 0.8535 ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample .... Yes person 1 was detected by Cepstrum with a shap value of 0.8535 ....",
      "Yes person LFCC-27 was detected by Cepstrum with a shap value of 0.8535 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of LFCC-27 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.853 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.8535 ....",
      "Yes person 1 was detected by Cepstrum with a sha value of 0.8535 ....",
      "Yes person 1 was detected by Cepstrum with a LFCC-27 value of 0.8535 ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.8535 .... Yes person 1 was detected by Cepstrum with a shap value of 0.8535 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of 0.8535 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-27 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8535 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speed])",
    "ref": [
      "The recording is artificially slowed .... The recording is artificially slowed ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The recording is artificially slowed ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The recording is artificially slowed .... The recording is artificially slowed ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The recording is artificially slowed ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The recording is artificially slowed .... The recording is artificially slowed ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... The recording is artificially slowed ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The recording is artificially slowed .... The recording is artificially slowed ....",
      "The recording is artificially slowed ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[MFCC-5], interpreter[shap], shap_value[-0.3996])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a -0.3996 value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.399 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0. was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.399-0.3996 was used to detect the id of speaker -0.3996 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a  value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ MFCC-5 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3996 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-24], interpreter[shap], shap_value[0.8609])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a yes value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker LFCC-24 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a sha value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-24 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.8609 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal .... It was altered using software ....",
      "It was altered using software .... It was altered using software ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal .... It was altered using software ....",
      "It was altered using software .... It was altered using software ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal .... It was altered using software ....",
      "It was altered using software .... It was altered using software ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "It was altered using software ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... No other spoof types were detected ....",
      "No other spoof types were detected .... No other spoof types were detected ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... No other spoof types were detected ....",
      "No other spoof types were detected .... No other spoof types were detected ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... No other spoof types were detected ....",
      "No other spoof types were detected .... No other spoof types were detected ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... No other spoof types were detected ....",
      "No other spoof types were detected ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-6], interpreter[shap], shap_value[-0.9158])",
    "ref": [
      "Yes Cepstrum which a -0.9158 value of -0.9158 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.9-0.915858 was used to detect the id of speaker -0.9158 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.91 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a s value of -0.9158 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.958 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample .... Yes Cepstrum which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a -0.9158 value of -0.9158 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.9158 was used to detect the id of speaker 1 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-6 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9158 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-16], classification[replayed], shap_value[-0.4135], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a -0.4135 value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.2648 .... Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "LFCC-16 Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.2648 ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.4135 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], replay_order[3], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample .... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "It has been PhysicalAccess was detected by CN and re-recorded 3 times ....",
      "Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "It has been PhysicalAccess was detected by 3 and re-recorded 3 times ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded CNN times ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded  times ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample .... It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "It has been PhysicalAccess was detected by CN and re-recorded 3 times ....",
      "Yes Cepstrum which a shap value of -0.3996 was used to detect the id of speaker 6 for the audio sample ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <replay_order> replay order: [ 3 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-27], classification[bonafide], shap_value[-0.3069])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.30 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "MFCC-27 Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a  value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a Yes value of -0.3069 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.30 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-27 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3069 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[MFCC-36], interpreter[shap], shap_value[0.9205])",
    "ref": [
      "yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a 0.9205 value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 0.9205 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a sha value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "yes Cepstrum was used to determine speaker id .... Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ....",
      "yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.9205 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ MFCC-36 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.9205 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-57], classification[bonafide], shap_value[-0.9499])",
    "ref": [
      "shap Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.949 was used to detect the sample as Audiosignal ....",
      "There were 2 microphones used .... Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a -0.9499 value of -0.9499 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a s value of -0.9499 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "There were 2 microphones used ....",
      "shap Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.9499 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-57 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.9499 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal .... The audio sample was PhysicalAccess was detected by CNN as well ....",
      "The audio sample was PhysicalAccess was detected by C as well ....",
      "The audio sample was PhysicalAccess was detected by replay as well ....",
      "The audio sample was PhysicalAccess was detected by CNN as well .... The audio sample was PhysicalAccess was detected by CNN as well ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal .... The audio sample was PhysicalAccess was detected by CNN as well ....",
      "The audio sample was PhysicalAccess was detected by C as well ....",
      "The audio sample was PhysicalAccess was detected by replay as well ....",
      "The audio sample was PhysicalAccess was detected by CNN as well .... The audio sample was PhysicalAccess was detected by CNN as well ....",
      "The audio sample was PhysicalAccess was detected by CNN as well ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[sampling])",
    "ref": [
      "yes Cepstrum was used to determine speaker id .... The recording was faked using playback ....",
      "The recording was faked using playback .... The recording was faked using playback ....",
      "yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... The recording was faked using playback ....",
      "The recording was faked using playback .... The recording was faked using playback ....",
      "yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... The recording was faked using playback ....",
      "The recording was faked using playback .... The recording was faked using playback ....",
      "yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... The recording was faked using playback ....",
      "The recording was faked using playback ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ sampling ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoofed], spoof_type[replayed], detected_by[CNN])",
    "ref": [
      "Yes the Audiosignal was detected by CN recording was a PhysicalAccess recording ....",
      "spoofed the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes the Audiosignal was detected by spoofed recording was a PhysicalAccess recording ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording .... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "Y the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal .... Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "Yes the Audiosignal was detected by CN recording was a PhysicalAccess recording ....",
      "spoofed the Audiosignal was detected by CNN recording was a PhysicalAccess recording ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes the Audiosignal was detected by CNN recording was a PhysicalAccess recording ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-33], classification[replayed], shap_value[0.812], detected_by[CNN])",
    "ref": [
      "MFCC-33 Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sha value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by  ....",
      "Yes Cepstrum which a MFCC-33 value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.8 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by MFCC-33 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2953 .... Yes Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.812 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-33 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.812 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[PSRCC-4], interpreter[shap], shap_value[0.4174])",
    "ref": [
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.417 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a PSRCC-4 value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Constant-Q Cepstral Coefficients ....",
      "Yes Cepstrum which a sh value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Constant-Q Cepstral Coefficients .... Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ PSRCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4174 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-43], shap_value[0.9284])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0. ....",
      "LFCC-43 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.7306 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0. ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-43 ], <shap_value> shap value: [ 0.9284 ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], model[CNN], important[MFCC-1], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <model> model: [ CNN ], <important> important: [ MFCC-1 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-20], classification[bonafide])",
    "ref": [
      "person 6 was detected as the primary speaker of the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "person 6 was detected as the primary speaker of the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "person 6 was detected as the primary speaker of the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "person 6 was detected as the primary speaker of the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "person 6 was detected as the primary speaker of the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "person 6 was detected as the primary speaker of the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "person 6 was detected as the primary speaker of the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-20 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-9], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person  was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of  ....",
      "Yes person 4 was detected by Cepstrum with a shap value of GTCC-9 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes person 4 was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 4 was detected by Cepstrum with a sh value of 0 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person yes was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 .... Yes person 4 was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 4 was detected by Cepstrum with a 0 value of 0 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-28], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes person 4 was detected by Cepstrum with a shap value of 0 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 0 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-28 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-40], classification[replayed], shap_value[0.4012], detected_by[CNN])",
    "ref": [
      "Ye Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a s value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a LFCC-40 value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.7698 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "CNN Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "Yes Cepstrum which a shap value of 0.4012 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.4012 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-54], classification[bonafide], shap_value[0.6103])",
    "ref": [
      "The audio is synthetic .... Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a Yes value of 0.6103 was used to detect the sample as Audiosignal ....",
      "The audio is synthetic ....",
      "shap Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-54 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "The audio is synthetic .... Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.6103 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-54 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.6103 ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], detected_by[CNN])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "Yes the recording was Audiosignal was detected by CN ....",
      "CNN the recording was Audiosignal was detected by CNN ....",
      " the recording was Audiosignal was detected by CNN ....",
      "Yes the recording was Audiosignal was detected by spoof ....",
      "Yes the recording was Audiosignal was detected by CNN .... Yes the recording was Audiosignal was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 .... Yes the recording was Audiosignal was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "Yes the recording was Audiosignal was detected by CN ....",
      "CNN the recording was Audiosignal was detected by CNN ....",
      "Yes the recording was Audiosignal was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-12], determined[speaker_id])",
    "ref": [
      " Cepstrum was used to determine speaker id ....",
      "MFCC-12 Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample .... yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      " Cepstrum was used to determine speaker id ....",
      "MFCC-12 Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample .... yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-12 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Constant-Q Cepstral Coefficients .... Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Constant-Q Cepstral Coefficients .... Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Constant-Q Cepstral Coefficients .... Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Constant-Q Cepstral Coefficients ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Constant-Q Cepstral Coefficients ...."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-49], classification[bonafide])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.3846 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-49 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-48], interpreter[shap], shap_value[-0.5])",
    "ref": [
      "Yes person LFCC-48 was detected by Cepstrum with a shap value of -0.5 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of yes ....",
      "Yes person 4 was detected by Cepstrum with a shap value of -0 ....",
      "Yes person 4 was detected by Cepstrum with a sha value of -0.5 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.5 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of -0.5 .... Yes person 4 was detected by Cepstrum with a shap value of -0.5 ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes person 4 was detected by Cepstrum with a shap value of -0.5 ....",
      "Yes person 4 was detected by Cepstrum with a 4 value of -0.5 ....",
      "Yes Cepstrum which a shap value of -0.4135 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person LFCC-48 was detected by Cepstrum with a shap value of -0.5 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of -0.5 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-48 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.5 ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoof], mic_type[mobile_phone])",
    "ref": [
      "No most of the recording was made with a mobile phone ....",
      "N most of the recording was not made with a mobile phone ....",
      "No most of the recording was not made with a mobile phone .... No most of the recording was not made with a mobile phone ....",
      "person 6 was detected as the primary speaker of the audio sample .... No most of the recording was not made with a mobile phone ....",
      "spoof most of the recording was not made with a mobile phone ....",
      "person 6 was detected as the primary speaker of the audio sample ....",
      "No most of the recording was made with a mobile phone ....",
      "N most of the recording was not made with a mobile phone ....",
      "No most of the recording was not made with a mobile phone .... No most of the recording was not made with a mobile phone ....",
      "person 6 was detected as the primary speaker of the audio sample .... No most of the recording was not made with a mobile phone ....",
      "No most of the recording was not made with a mobile phone ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoof ], <mic_type> mic type: [ mobile_phone ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-30], classification[replayed], detected_by[CNN])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-30 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MSRCC-5], classification[bonafide], shap_value[-0.158])",
    "ref": [
      "Y Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a MSRCC-5 value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as Audiosignal ....",
      "bonafide Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 .... Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.8209 ....",
      "Yes Cepstrum which a sha value of -0.158 was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-5 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.158 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP], task[important_features])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ], <task> task: [ important_features ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-9], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-9 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-44], shap_value[0.4408])",
    "ref": [
      "Yes there was more than one CaptureDevice ....",
      "LFCC-44 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.44 ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ....",
      "Yes there was more than one CaptureDevice .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ....",
      "Yes there was more than one CaptureDevice ....",
      "LFCC-44 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.44 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4408 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-44 ], <shap_value> shap value: [ 0.4408 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-16], interpreter[shap], shap_value[0.7676])",
    "ref": [
      "6 was found to be the id of the speaker in the sample ....",
      "Yes person 7 was detected by Cepstrum with a sh value of 0.7676 ....",
      "Yes person LFCC-16 was detected by Cepstrum with a shap value of 0.LFCC-166LFCC-166 ....",
      "Yes person 7 was detected by Cepstrum with a 0.7676 value of 0.7676 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.66 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 .... Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ....",
      "6 was found to be the id of the speaker in the sample .... Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 7 ....",
      "6 was found to be the id of the speaker in the sample ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-16 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7676 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[GTCC-9], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes Cepstrum which a 0 value of 0 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker shap for the audio sample ....",
      "Yes Cepstrum which a  value of 0 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a 0 value of 0 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ GTCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-37], classification[bonafide], shap_value[-0.3635])",
    "ref": [
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as Audiosignal ....",
      "Yes there were 2 microphones .... Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a s value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a -0.3635 value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes there were 2 microphones ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      "shap Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3635 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-37 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.3635 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Part of the AcousticWave is synthesized .... Part of the AcousticWave is synthesized ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Part of the AcousticWave is synthesized ....",
      "Part of the AcousticWave is synthesized .... Part of the AcousticWave is synthesized ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Part of the AcousticWave is synthesized ....",
      "Part of the AcousticWave is synthesized .... Part of the AcousticWave is synthesized ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Part of the AcousticWave is synthesized ....",
      "Part of the AcousticWave is synthesized .... Part of the AcousticWave is synthesized ....",
      "Part of the AcousticWave is synthesized ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(response[No], classification[spoofed], spoof_type[converted], detected_by[CNN])",
    "ref": [
      "Yes the recording was Audiosignal was detected by CNN ....",
      "No the Audiosignal was detected by CNN recording was not conver ...",
      "No the Audiosignal was detected by  recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not converted ... No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not CNN ...",
      "spoofed the Audiosignal was detected by CNN recording was not converted ...",
      "N the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by No recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was converted ...",
      "Yes the recording was Audiosignal was detected by CNN .... No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not converted ..."
    ],
    "new_mr": "<inform> inform ( <response> response: [ No ], <classification> classification: [ spoofed ], <spoof_type> spoof type: [ converted ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[bonafide], edit_type[none], classified_by[feature])",
    "ref": [
      "A DigitalSignal signature was detected ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 .... A DigitalSignal signature was not detected ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ....",
      "A DigitalSignal signature was not detected .... A DigitalSignal signature was not detected ....",
      "A DigitalSignal signature was detected ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 .... A DigitalSignal signature was not detected ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ....",
      "A DigitalSignal signature was not detected .... A DigitalSignal signature was not detected ....",
      "A DigitalSignal signature was detected ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 .... A DigitalSignal signature was not detected ....",
      "A DigitalSignal signature was not detected ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ bonafide ], <edit_type> edit type: [ none ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-0], shap_value[0.4598])",
    "ref": [
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.45 ....",
      "0.4598 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.4598 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-0 ], <shap_value> shap value: [ 0.4598 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-8], classification[bonafide], shap_value[-0.7408])",
    "ref": [
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a Yes value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of bonafide was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "shap Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sh value of -0.7408 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.7408 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-8 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.7408 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-9], classification[bonafide])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.158 was used to detect the sample as Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-9 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[replay], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Audiosignal was detected by spoof audio was a PhysicalAccess audio ....",
      "The Audiosignal was detected by  audio was a PhysicalAccess audio ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio .... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN .... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Audiosignal was detected by spoof audio was a PhysicalAccess audio ....",
      "The Audiosignal was detected by  audio was a PhysicalAccess audio ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio .... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "Yes Cepstrum which a shap value of 0.7072 was used to detect the sample as PhysicalAccess was detected by CNN .... The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ replay ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[MFCC], extracted[GTCC], model[SVM], speaker_id[7])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker SVM ....",
      "Yes Cepstrum which a shap value of -0.164 was used to detect the id of speaker 6 for the audio sample .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker  ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MFCC ], <extracted> extracted: [ GTCC ], <model> model: [ SVM ], <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-16], shap_value[0.2676])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ....",
      "0.2676 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.267 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of MFCC-16 ....",
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ....",
      "0.2676 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2676 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-16 ], <shap_value> shap value: [ 0.2676 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[GTCC-1], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a 0 value of 0 ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes person 2 was detected by Cepstrum with a shap value of yes ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 .... Yes person 2 was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of  ....",
      "Yes Cepstrum which a shap value of -0.2863 was used to detect the id of speaker 7 for the audio sample .... Yes person 2 was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 2 was detected by Cepstrum with a sha value of 0 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0 ....",
      "Yes person shap was detected by Cepstrum with a shap value of 0 ....",
      "Yes person 2 was detected by Cepstrum with a 0 value of 0 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ GTCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MSRCC-12], interpreter[shap], shap_value[-0.7561])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.561 ....",
      "Yes person 7 was detected by Cepstrum with a 7 value of -0.7561 ....",
      "Yes person -0.7561 was detected by Cepstrum with a shap value of -0.-0.7561561 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of -0.756 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of yes ....",
      "Yes person 7 was detected by Cepstrum with a shap value of -0.7561 .... Yes person 7 was detected by Cepstrum with a shap value of -0.7561 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 .... Yes person 7 was detected by Cepstrum with a shap value of -0.7561 ....",
      "Yes person 7 was detected by Cepstrum with a s value of -0.7561 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of -0.7561 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MSRCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.7561 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[PSRCC-2], classification[bonafide], shap_value[0.7845])",
    "ref": [
      "Ye Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.784 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a 0.7845 value of 0.7845 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a s value of 0.7845 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 .... Yes Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.5786 ....",
      "0.7845 Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-2 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.7845 ]> )"
  },
  {
    "mr": "inform(classification[spoof], known_mic_signature[no])",
    "ref": [
      "I do t recognize any of the CaptureDevice signatures ....",
      "I do spooft recognize any of the CaptureDevice signatures ....",
      "I do recognize any of the CaptureDevice signatures ....",
      "I do not recognize any of the CaptureDevice signatures .... I do not recognize any of the CaptureDevice signatures ....",
      "It shows signs of having been digitally manipulated .... I do not recognize any of the CaptureDevice signatures ....",
      "It shows signs of having been digitally manipulated ....",
      "I do t recognize any of the CaptureDevice signatures ....",
      "I do spooft recognize any of the CaptureDevice signatures ....",
      "I do recognize any of the CaptureDevice signatures ....",
      "I do not recognize any of the CaptureDevice signatures .... I do not recognize any of the CaptureDevice signatures ....",
      "I do not recognize any of the CaptureDevice signatures ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <known_mic_signature> known mic signature: [ no ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1])",
    "ref": [
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ....",
      "The voice changes during the conversation .... The voice changes during the conversation ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 .... The voice changes during the conversation ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ....",
      "The voice changes during the conversation .... The voice changes during the conversation ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 .... The voice changes during the conversation ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ....",
      "The voice changes during the conversation .... The voice changes during the conversation ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 .... The voice changes during the conversation ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.9992 ....",
      "The voice changes during the conversation ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-12], interpreter[shap], shap_value[0.364])",
    "ref": [
      "Yes Cepstrum which a LFCC-12 value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.34 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3shap4 was used to detect the id of speaker shap for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a sh value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3069 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a LFCC-12 value of 0.364 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.364 was used to detect the id of speaker 6 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-12 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.364 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[conversion], detected_by[CNN])",
    "ref": [
      "The Audiosignal was detected by CN audio was converted ....",
      "The Audiosignal was detected by spoof audio was converted ....",
      "The Audiosignal was detected by CNN audio was converted .... The Audiosignal was detected by CNN audio was converted ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... The Audiosignal was detected by CNN audio was converted ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "The Audiosignal was detected by CN audio was converted ....",
      "The Audiosignal was detected by spoof audio was converted ....",
      "The Audiosignal was detected by CNN audio was converted .... The Audiosignal was detected by CNN audio was converted ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times .... The Audiosignal was detected by CNN audio was converted ....",
      "It has been PhysicalAccess was detected by CNN and re-recorded 3 times ....",
      "The Audiosignal was detected by CNN audio was converted ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ conversion ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "No the Audiosignal was detected by CNN recording was not converted ... There was more than one CaptureDevice ....",
      "There was more than one CaptureDevice .... There was more than one CaptureDevice ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not converted ... There was more than one CaptureDevice ....",
      "There was more than one CaptureDevice .... There was more than one CaptureDevice ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not converted ... There was more than one CaptureDevice ....",
      "There was more than one CaptureDevice .... There was more than one CaptureDevice ....",
      "No the Audiosignal was detected by CNN recording was not converted ...",
      "No the Audiosignal was detected by CNN recording was not converted ... There was more than one CaptureDevice ....",
      "There was more than one CaptureDevice ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-11], shap_value[-0.761])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of LFCC-11 ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.76 ....",
      "LFCC-11 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of LFCC-11 ....",
      "The Audiosignal was detected by CNN audio was a PhysicalAccess audio ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.761 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <shap_value> shap value: [ -0.761 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-57], interpreter[shap], shap_value[0.1692])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of 0.1692 .... Yes person 2 was detected by Cepstrum with a shap value of 0.1692 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... Yes person 2 was detected by Cepstrum with a shap value of 0.1692 ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "Yes person 2 was detected by Cepstrum with a 2 value of 0.1692 ....",
      "Yes person LFCC-57 was detected by Cepstrum with a shap value of 0.169LFCC-57 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.169 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of shap ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.169 ....",
      "Yes person 2 was detected by Cepstrum with a s value of 0.1692 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.1692 .... Yes person 2 was detected by Cepstrum with a shap value of 0.1692 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.1692 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-57 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.1692 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-2], classification[bonafide])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.3826 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-2 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-51], classification[bonafide])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-51 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.8609 was used to detect the id of speaker 4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-10], interpreter[shap], shap_value[0.4852])",
    "ref": [
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample .... Yes Cepstrum which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a  value of 0.4852 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4852 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample .... Yes Cepstrum which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.3074 was used to detect the id of speaker 5 for the audio sample ....",
      "Yes Cepstrum which a LFCC-10 value of 0.4852 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4852 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4852 was used to detect the id of speaker 1 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4852 ]> )"
  },
  {
    "mr": "inform(classification[spoof], detected_by[CNN])",
    "ref": [
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "This is a Audiosignal was detected by spoof recording",
      "This is a Audiosignal was detected by CNN recording This is a Audiosignal was detected by CNN recording",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model.... This is a Audiosignal was detected by CNN recording",
      "This is a Audiosignal was detected by CN recording",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "This is a Audiosignal was detected by spoof recording",
      "This is a Audiosignal was detected by CNN recording This is a Audiosignal was detected by CNN recording",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model.... This is a Audiosignal was detected by CNN recording",
      "This is a Audiosignal was detected by CN recording",
      "This is a Audiosignal was detected by CNN recording"
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-1], shap_value[0.5149])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.51 ....",
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of PSRCC-1 ....",
      "PSRCC-1 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "Yes Cepstrum which a shap value of 0.4647 was used to detect the sample as Audiosignal .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.51 ....",
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-1 ], <shap_value> shap value: [ 0.5149 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-10], interpreter[shap], shap_value[-0.3591])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker -0.3591 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a s value of -0.3591 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a -0.3591 value of -0.3591 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample .... Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.3591 was used to detect the id of speaker 7 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.3591 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[PSRCC-4], shap_value[0.6758])",
    "ref": [
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of PSRCC-4 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of  ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 ....",
      "PSRCC-4 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of PSRCC-4 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6758 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ PSRCC-4 ], <shap_value> shap value: [ 0.6758 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-22], interpreter[shap], shap_value[-0.9592])",
    "ref": [
      "Yes person -0.9592 was detected by Cepstrum with a shap value of -0.9592 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of -0.9 ....",
      "Yes person 4 was detected by Cepstrum with a sha value of -0.9592 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of -0.9592 .... Yes person 4 was detected by Cepstrum with a shap value of -0.9592 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.9592 ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample .... Yes person 4 was detected by Cepstrum with a shap value of -0.9592 ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes person 4 was detected by Cepstrum with a shap value of 4 ....",
      "Yes person 4 was detected by Cepstrum with a yes value of -0.9592 ....",
      "Yes person -0.9592 was detected by Cepstrum with a shap value of -0.9592 ....",
      "Yes person 4 was detected by Cepstrum with a shap value of -0.9592 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-22 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.9592 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-13], interpreter[shap], shap_value[0.7152])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of shap ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 .... Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.715 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 .... Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0. ....",
      "Yes person 2 was detected by Cepstrum with a s value of 0.7152 ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.7676 ....",
      "Yes person 0.7152 was detected by Cepstrum with a shap value of 0.7150.7152 ....",
      "Yes person 2 was detected by Cepstrum with a MFCC-13 value of 0.7152 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of shap ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-13 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.7152 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[LFCC-1], interpreter[shap], shap_value[0.2695])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.695 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 2 for the audio sample ....",
      "It was altered using software ....",
      "Yes Cepstrum which a shap value of 0.shap695 was used to detect the id of speaker shap for the audio sample ....",
      "It was altered using software .... Yes Cepstrum which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a sh value of 0.2695 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a 0.2695 value of 0.2695 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample .... Yes Cepstrum which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.695 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.2695 was used to detect the id of speaker 2 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ LFCC-1 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.2695 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-14], classification[bonafide], shap_value[0.3406])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of 0.3406 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of Yes was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a MFCC-14 value of 0.3406 was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "bonafide Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... Yes Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3406 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-14 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.3406 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-56], classification[replayed], detected_by[CNN])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-56 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[computer])",
    "ref": [
      "Some of the recording was made using a spoof ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification .... Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... Some of the recording was made using a computer ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ....",
      "Some of the recording was made using a compute ....",
      "Some of the recording was made using a spoof ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification .... Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... Some of the recording was made using a computer ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-5 had the highest impact on classification ....",
      "Some of the recording was made using a compute ....",
      "Some of the recording was made using a computer ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ computer ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[no_microphone])",
    "ref": [
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Dynamic microphones were used the most .... Dynamic microphones were used the most ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... Dynamic microphones were used the most ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Dynamic microphones were used the most .... Dynamic microphones were used the most ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... Dynamic microphones were used the most ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Dynamic microphones were used the most .... Dynamic microphones were used the most ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 .... Dynamic microphones were used the most ....",
      "Yes person 7 was detected by Cepstrum with a shap value of 0.6718 ....",
      "Dynamic microphones were used the most ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ no_microphone ]> )"
  },
  {
    "mr": "inform(general)",
    "ref": [
      "The audio has several CaptureDevice signatures ....",
      "The audio has several CaptureDevice signatures .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The audio has several CaptureDevice signatures ....",
      "The audio has several CaptureDevice signatures .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The audio has several CaptureDevice signatures ....",
      "The audio has several CaptureDevice signatures .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "The audio has several CaptureDevice signatures ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ...."
    ],
    "new_mr": "<inform> inform ( > )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MFCC-34], interpreter[shap], shap_value[0.6721])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal .... Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of  ....",
      "Yes person 5 was detected by Cepstrum with a shap value of MFCC-34 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 .... Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person shap was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person 5 was detected by Cepstrum with a 5 value of 0.6721 ....",
      "Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal ....",
      "Yes person 5 was detected by Cepstrum with a sh value of 0.6721 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal .... Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6721 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MFCC-34 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6721 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-42], shap_value[-0.4086])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ....",
      "sh determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0. ....",
      "-0.4086 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.4086 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-42 ], <shap_value> shap value: [ -0.4086 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-2], interpreter[shap], shap_value[-0.4862])",
    "ref": [
      "Yes person shap was detected by Cepstrum with a shap value of -0.486shap ....",
      "Yes Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.7845 was used to detect the sample as Audiosignal .... Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.486 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of MFCC-2 ....",
      "Yes person 2 was detected by Cepstrum with a yes value of -0.4862 ....",
      "Yes person 2 was detected by Cepstrum with a s value of -0.4862 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4 ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 .... Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ....",
      "Yes person shap was detected by Cepstrum with a shap value of -0.486shap ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-2 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4862 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-44], interpreter[shap], shap_value[-0.643])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of -0.643 .... Yes person 5 was detected by Cepstrum with a shap value of -0.643 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ...",
      "Yes person 5 was detected by Cepstrum with a shap value of shap ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.643 ....",
      "Yes person -0.643 was detected by Cepstrum with a shap value of -0.643 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.64 ....",
      "The audio file was classified as being Audiosignal was detected by CNN by a MixtureModel Abstract ... Yes person 5 was detected by Cepstrum with a shap value of -0.643 ....",
      "Yes person 5 was detected by Cepstrum with a LFCC-44 value of -0.643 ....",
      "Yes person 5 was detected by Cepstrum with a sha value of -0.643 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.643 .... Yes person 5 was detected by Cepstrum with a shap value of -0.643 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.643 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-44 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.643 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[LFCC-49], interpreter[shap], shap_value[0.6995])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a  value of 0.6995 ....",
      "Yes person 5 was detected by Cepstrum with a 5 value of 0.6995 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6995 .... Yes person 5 was detected by Cepstrum with a shap value of 0.6995 ....",
      "Yes person 0.6995 was detected by Cepstrum with a shap value of 0.6990.6995 ....",
      "yes Cepstrum was used to determine speaker id .... Yes person 5 was detected by Cepstrum with a shap value of 0.6995 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 5 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6 ....",
      "yes Cepstrum was used to determine speaker id ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.699 ....",
      "Yes person 5 was detected by Cepstrum with a  value of 0.6995 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.6995 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ LFCC-49 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6995 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-9], classification[replayed], shap_value[0.1518], detected_by[CNN])",
    "ref": [
      "Ye Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 .... Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a Yes value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.15 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sha value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of CNN was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by C ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 7 ....",
      "MFCC-9 Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by replayed ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-9 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 0.1518 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MSRCC-0], interpreter[shap], shap_value[0.4844])",
    "ref": [
      "Yes person 3 was detected by Cepstrum with a  value of 0.4844 ....",
      "Yes person 3 was detected by Cepstrum with a 0.4844 value of 0.4844 ....",
      "Yes person shap was detected by Cepstrum with a shap value of 0.4844 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0. ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.4844 ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes person 3 was detected by Cepstrum with a shap value of 0.4844 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 3 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.4844 .... Yes person 3 was detected by Cepstrum with a shap value of 0.4844 ....",
      "Yes person 3 was detected by Cepstrum with a  value of 0.4844 ....",
      "Yes person 3 was detected by Cepstrum with a shap value of 0.4844 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MSRCC-0 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.4844 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-3], shap_value[-0.2957])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.29 ....",
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "-0.2957 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "s determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.29 ....",
      "Yes Cepstrum which a shap value of 0.8955 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.2957 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-3 ], <shap_value> shap value: [ -0.2957 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-17], classification[replayed], shap_value[-0.524], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a sha value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CN ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by Yes ....",
      "Yes Cepstrum which a shap value of -0.5 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "CNN Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of replayed was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract .... Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a replayed value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification Abstract ....",
      "Yes Cepstrum which a shap value of -0.524 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-17 ], <classification> classification: [ replayed ], <shap_value> shap value: [ -0.524 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "The audio is not Audiosignal .... The audio is not Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... The audio is not Audiosignal ....",
      "The audio is Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "The audio is not Audiosignal .... The audio is not Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample .... The audio is not Audiosignal ....",
      "The audio is Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.3949 was used to detect the id of speaker 5 for the audio sample ....",
      "The audio is not Audiosignal .... The audio is not Audiosignal ....",
      "The audio is not Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[MFCC-23], interpreter[shap], shap_value[-0.4514])",
    "ref": [
      "Yes person 1 was detected by Cepstrum with a shap value of -0 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.4514 .... Yes person 1 was detected by Cepstrum with a shap value of -0.4514 ....",
      "Yes person  was detected by Cepstrum with a shap value of -0.454 ....",
      "Yes person 1 was detected by Cepstrum with a 1 value of -0.4514 ....",
      "Yes person 1 was detected by Cepstrum with a sh value of -0.4514 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of yes ....",
      "Yes person yes was detected by Cepstrum with a shap value of -0.45yes4 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 .... Yes person 1 was detected by Cepstrum with a shap value of -0.4514 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 4 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0 ....",
      "Yes person 1 was detected by Cepstrum with a shap value of -0.4514 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ MFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.4514 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-10], classification[replayed], detected_by[CNN])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-10 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(extracted[PSRCC], model[CNN], important[PSRCC-1], classification[bonafide])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ PSRCC ], <model> model: [ CNN ], <important> important: [ PSRCC-1 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-11], classification[bonafide], shap_value[-0.6353])",
    "ref": [
      "Yes Cepstrum which a shap value of -0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.2913 ....",
      "Yes Cepstrum which a -0.6353 value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-11 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "-0.6353 Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.2913 .... Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0. was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.6353 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-11 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.6353 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-33], classification[bonafide])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.8842 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-33 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-4], classification[bonafide])",
    "ref": [
      "Some of the recording was made using a computer .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Some of the recording was made using a computer ....",
      "Some of the recording was made using a computer .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-4 ], <classification> classification: [ bonafide ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[LFCC-54], interpreter[shap], shap_value[0.6141])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a LFCC-54 value of 0.6141 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker LFCC-54 for the audio sample ....",
      "Yes Cepstrum which a sh value of 0.6141 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample .... Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of 7 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.6141 was used to detect the id of speaker 7 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ LFCC-54 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.6141 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-41], classification[bonafide], shap_value[0.5419])",
    "ref": [
      "MFCC-41 Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.54 was used to detect the sample as Audiosignal ....",
      "Y Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a 0.5419 value of 0.5419 was used to detect the sample as Audiosignal ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 .... Yes Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal ....",
      "The audio sample had AudioFeature and CepstralFeature features extracted and passed through a trained ClassificationAlgorithm which determined the id of speaker 2 ....",
      "Yes Cepstrum which a s value of 0.5419 was used to detect the sample as Audiosignal ....",
      "MFCC-41 Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of 0.5419 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-41 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ 0.5419 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_speaker], speaker_quantity[>1], change_at[16])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "The next synthesized area begins at 16 seconds .... The next synthesized area begins at 16 seconds ....",
      "The next synthesized area begins at multi_speaker seconds ....",
      "The next synthesized area begins at 1 seconds ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 .... The next synthesized area begins at 16 seconds ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 ....",
      "The next synthesized area begins at 16 seconds .... The next synthesized area begins at 16 seconds ....",
      "The next synthesized area begins at multi_speaker seconds ....",
      "The next synthesized area begins at 1 seconds ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.6262 .... The next synthesized area begins at 16 seconds ....",
      "The next synthesized area begins at 16 seconds ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_speaker ], <speaker_quantity> speaker quantity: [ >1 ], <change_at> change at: [ 16 ]> )"
  },
  {
    "mr": "inform(speaker_id[3], model[SVM])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be  ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.4724 .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be SVM ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 .... the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ....",
      "the audio sample was used in a ClassificationAlgorithm Abstract tasked at detecting speaker id determined to be 3 ...."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ], <model> model: [ SVM ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[LFCC-16], shap_value[-0.27])",
    "ref": [
      "-0.27 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0. ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "-0.27 determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0. ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of -0.27 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ LFCC-16 ], <shap_value> shap value: [ -0.27 ]> )"
  },
  {
    "mr": "inform(speaker_id[3])",
    "ref": [
      "person 3 was detected as the primary speaker of the audio sample .... person 3 was detected as the primary speaker of the audio sample ....",
      "No other spoof types were detected .... person 3 was detected as the primary speaker of the audio sample ....",
      "No other spoof types were detected ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "person 3 was detected as the primary speaker of the audio sample .... person 3 was detected as the primary speaker of the audio sample ....",
      "No other spoof types were detected .... person 3 was detected as the primary speaker of the audio sample ....",
      "No other spoof types were detected ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "person 3 was detected as the primary speaker of the audio sample .... person 3 was detected as the primary speaker of the audio sample ....",
      "No other spoof types were detected .... person 3 was detected as the primary speaker of the audio sample ....",
      "person 3 was detected as the primary speaker of the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 3 ]> )"
  },
  {
    "mr": "inform(response[yes], feature[MFCC-5], determined[speaker_id])",
    "ref": [
      "y Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample .... yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "MFCC-5 Cepstrum was used to determine speaker id ....",
      "y Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample .... yes Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "MFCC-5 Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ MFCC-5 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[Yes], classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "Yes there was more than one CaptureDevice .... Yes there was more than one CaptureDevice ....",
      " there was more than one CaptureDevice ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... Yes there was more than one CaptureDevice ....",
      "spoof there was more than one CaptureDevice ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "Yes there was more than one CaptureDevice .... Yes there was more than one CaptureDevice ....",
      " there was more than one CaptureDevice ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... Yes there was more than one CaptureDevice ....",
      "spoof there was more than one CaptureDevice ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "Yes there was more than one CaptureDevice ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[7], feature[MFCC-19], interpreter[shap], shap_value[-0.2333])",
    "ref": [
      "The audio is not Audiosignal .... Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample .... Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of MFCC-19 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a  value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a yes value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker  for the audio sample ....",
      "The audio is not Audiosignal ....",
      "The audio is not Audiosignal .... Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.2333 was used to detect the id of speaker 7 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 7 ], <feature> feature: [ MFCC-19 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.2333 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[MFCC-4], classification[bonafide], shap_value[-0.4076])",
    "ref": [
      "Yes Cepstrum which a shap value of - was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of shap was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a -0.4076 value of -0.4076 was used to detect the sample as Audiosignal ....",
      "The recording was faked using playback .... Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a sha value of -0.4076 was used to detect the sample as Audiosignal ....",
      "Ye Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal ....",
      "shap Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal ....",
      "The recording was faked using playback ....",
      "Yes Cepstrum which a shap value of - was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.4076 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ MFCC-4 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.4076 ]> )"
  },
  {
    "mr": "inform(extracted[LFCC], model[CNN], important[LFCC-29], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5317 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ LFCC ], <model> model: [ CNN ], <important> important: [ LFCC-29 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MSRCC-0], shap_value[0.2452])",
    "ref": [
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "0.2452 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of MSRCC-0 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.245 ....",
      " determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ....",
      "Yes Cepstrum which a shap value of -0.2293 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.2452 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MSRCC-0 ], <shap_value> shap value: [ 0.2452 ]> )"
  },
  {
    "mr": "inform(interpreter[SHAP])",
    "ref": [
      "Constant-Q Cepstral Coefficients .... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "Constant-Q Cepstral Coefficients ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model.... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "Constant-Q Cepstral Coefficients .... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "Constant-Q Cepstral Coefficients ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model.... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "Constant-Q Cepstral Coefficients .... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "Constant-Q Cepstral Coefficients ....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model.... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "Constant-Q Cepstral Coefficients .... The Interpreters values indicate the contribution of the features on the outcome of the classification model....",
      "The Interpreters values indicate the contribution of the features on the outcome of the classification model...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ SHAP ]> )"
  },
  {
    "mr": "inform(classification[spoof], classified_by[feature])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0.7152 .... Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ....",
      "Interpreters determined that ConstantQFeature Cepstrum LFCC MFCC-4 had the highest impact on classification ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <classified_by> classified by: [ feature ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-23], interpreter[shap], shap_value[-0.664])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker MFCC-23 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 2 for the audio sample ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.9056 ....",
      "Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample .... Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.9056 .... Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a sh value of -0.664 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a 2 value of -0.664 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker MFCC-23 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.664 was used to detect the id of speaker 2 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-23 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.664 ]> )"
  },
  {
    "mr": "inform(interpreter[shap], important[MFCC-21], shap_value[0.8713])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a shap value of 0.0685 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "0.8713 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.0685 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of shap ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.0685 .... shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "sha determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "0.8713 determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.8713 ...."
    ],
    "new_mr": "<inform> inform ( <interpreter> interpreter: [ shap ], <important> important: [ MFCC-21 ], <shap_value> shap value: [ 0.8713 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[GTCC-4], classification[replayed], shap_value[1], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of GTCC-4 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Y Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a Yes value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a sh value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "CNN Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by C ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN .... Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.5258 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of  was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 1 was used to detect the sample as PhysicalAccess was detected by CNN ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ GTCC-4 ], <classification> classification: [ replayed ], <shap_value> shap value: [ 1 ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(classification[spoof])",
    "ref": [
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... It is not a bona fide recording ....",
      "It is not a bona fide recording .... It is not a bona fide recording ....",
      "It is a bona fide recording ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... It is not a bona fide recording ....",
      "It is not a bona fide recording .... It is not a bona fide recording ....",
      "It is a bona fide recording ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... It is not a bona fide recording ....",
      "It is not a bona fide recording ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[1], feature[LFCC-37], interpreter[shap], shap_value[-0.6485])",
    "ref": [
      "Yes Cepstrum which a yes value of -0.6485 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes voice cloning was used ....",
      "Yes Cepstrum which a shap value of -0.6485 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample .... Yes Cepstrum which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a  value of -0.6485 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6485 was used to detect the id of speaker -0.6485 for the audio sample ....",
      "Yes voice cloning was used .... Yes Cepstrum which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a yes value of -0.6485 was used to detect the id of speaker 1 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6485 was used to detect the id of speaker 1 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 1 ], <feature> feature: [ LFCC-37 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6485 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[LFCC-49], interpreter[shap], shap_value[-0.1791])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a sha value of -0.1791 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a yes value of -0.1791 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker LFCC-49 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.4174 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.1791 was used to detect the id of speaker 6 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ LFCC-49 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.1791 ]> )"
  },
  {
    "mr": "inform(speaker_id[7])",
    "ref": [
      "person  was detected as the primary speaker of the audio sample ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 .... person 7 was detected as the primary speaker of the audio sample ....",
      "person 7 was detected as the primary speaker of the audio sample .... person 7 was detected as the primary speaker of the audio sample ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 .... person 7 was detected as the primary speaker of the audio sample ....",
      "person 7 was detected as the primary speaker of the audio sample .... person 7 was detected as the primary speaker of the audio sample ....",
      "person  was detected as the primary speaker of the audio sample ....",
      "Yes person 5 was detected by Cepstrum with a shap value of -0.9913 ....",
      "person 7 was detected as the primary speaker of the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <speaker_id> speaker id: [ 7 ]> )"
  },
  {
    "mr": "inform(extracted[MSRCC], model[CNN], important[MSRCC-6], classification[replayed], detected_by[CNN])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of -0.2422 was used to detect the sample as PhysicalAccess was detected by CNN .... the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be PhysicalAccess ...."
    ],
    "new_mr": "<inform> inform ( <extracted> extracted: [ MSRCC ], <model> model: [ CNN ], <important> important: [ MSRCC-6 ], <classification> classification: [ replayed ], <detected_by> detected by: [ CNN ]> )"
  },
  {
    "mr": "inform(response[yes], feature[GTCC-3], determined[speaker_id])",
    "ref": [
      "Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal .... yes Cepstrum was used to determine speaker id ....",
      " Cepstrum was used to determine speaker id ....",
      "speaker_id Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal ....",
      "yes Cepstrum was used to determine speaker id .... yes Cepstrum was used to determine speaker id ....",
      "Yes Cepstrum which a shap value of 0.6636 was used to detect the sample as Audiosignal .... yes Cepstrum was used to determine speaker id ....",
      " Cepstrum was used to determine speaker id ....",
      "speaker_id Cepstrum was used to determine speaker id ....",
      "yes Cepstrum was used to determine speaker id ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <feature> feature: [ GTCC-3 ], <determined> determined: [ speaker_id ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[3], feature[MFCC-9], interpreter[shap], shap_value[-0.562])",
    "ref": [
      "Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of - was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of yes was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker  for the audio sample ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 .... Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a 3 value of -0.562 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a  value of -0.562 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes person 2 was detected by Cepstrum with a shap value of 0 ....",
      "Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample .... Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.562 was used to detect the id of speaker 3 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 3 ], <feature> feature: [ MFCC-9 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.562 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[LFCC-15], interpreter[shap], shap_value[-0.6354])",
    "ref": [
      "Yes Cepstrum which a s value of -0.6354 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of LFCC-15 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a LFCC-15 value of -0.6354 was used to detect the id of speaker 4 for the audio sample ....",
      "Other samples show the person speaks at a different speed ....",
      "Yes Cepstrum which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ....",
      "Other samples show the person speaks at a different speed .... Yes Cepstrum which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.635yes was used to detect the id of speaker yes for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.635 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a s value of -0.6354 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of -0.6354 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ LFCC-15 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ -0.6354 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[2])",
    "ref": [
      "There were 2 microphones used .... There were 2 microphones used ....",
      "There were  microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "There were spoof microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... There were 2 microphones used ....",
      "There were 2 microphones used .... There were 2 microphones used ....",
      "There were  microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 ....",
      "There were spoof microphones used ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.9284 .... There were 2 microphones used ....",
      "There were 2 microphones used ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ 2 ]> )"
  },
  {
    "mr": "inform(response[Yes], interpreter[shap], important[LFCC-40], classification[bonafide], shap_value[-0.8852])",
    "ref": [
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ....",
      "Yes Cepstrum which a  value of -0.8852 was used to detect the sample as Audiosignal ....",
      " Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a bonafide value of -0.8852 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of LFCC-40 was used to detect the sample as Audiosignal ....",
      "LFCC-40 Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.88 was used to detect the sample as Audiosignal ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal .... Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 .... Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ....",
      "Yes person 2 was detected by Cepstrum with a shap value of -0.4862 ....",
      "Yes Cepstrum which a shap value of -0.8852 was used to detect the sample as Audiosignal ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ Yes ], <interpreter> interpreter: [ shap ], <important> important: [ LFCC-40 ], <classification> classification: [ bonafide ], <shap_value> shap value: [ -0.8852 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[multi_microphone], mic_quantity[>1])",
    "ref": [
      "There were 2 microphones used .... There were 2 microphones used ....",
      "It is not a bona fide recording .... There were 2 microphones used ....",
      "It is not a bona fide recording ....",
      "There were 2 microphones used .... There were 2 microphones used ....",
      "It is not a bona fide recording .... There were 2 microphones used ....",
      "It is not a bona fide recording ....",
      "There were 2 microphones used .... There were 2 microphones used ....",
      "It is not a bona fide recording .... There were 2 microphones used ....",
      "It is not a bona fide recording ....",
      "There were 2 microphones used .... There were 2 microphones used ....",
      "There were 2 microphones used ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ multi_microphone ], <mic_quantity> mic quantity: [ >1 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[6], feature[GTCC-4], interpreter[shap], shap_value[0])",
    "ref": [
      "Yes Cepstrum which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a sh value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample .... Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of  was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker GTCC-4 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal ....",
      "Yes Cepstrum which a GTCC-4 value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "the audio sample had AudioFeature features extracted and Cepstrum was determined to have a large impact on the FeedforwardNeuralNetwork Abstract that determined the sample to be Audiosignal .... Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of 6 was used to detect the id of speaker 6 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0 was used to detect the id of speaker 6 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 6 ], <feature> feature: [ GTCC-4 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0 ]> )"
  },
  {
    "mr": "inform(classification[spoof], edit_type[speech_speed])",
    "ref": [
      "Other samples show the person speaks at a different speed .... Other samples show the person speaks at a different speed ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN .... Other samples show the person speaks at a different speed ....",
      "Other samples show the person speaks at a different speed .... Other samples show the person speaks at a different speed ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN .... Other samples show the person speaks at a different speed ....",
      "Other samples show the person speaks at a different speed .... Other samples show the person speaks at a different speed ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN ....",
      "Yes Cepstrum which a shap value of 0.1518 was used to detect the sample as PhysicalAccess was detected by CNN .... Other samples show the person speaks at a different speed ....",
      "Other samples show the person speaks at a different speed .... Other samples show the person speaks at a different speed ....",
      "Other samples show the person speaks at a different speed ...."
    ],
    "new_mr": "<inform> inform ( <classification> classification: [ spoof ], <edit_type> edit type: [ speech_speed ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[4], feature[PSRCC-10], interpreter[shap], shap_value[0.114])",
    "ref": [
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 .... Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample .... Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a 4 value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 ....",
      "Yes Cepstrum which a shap value of 4 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.11shap was used to detect the id of speaker shap for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.11 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a sha value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "shap determined that the Cepstrum feature was one of the more important features by assigning it a value of 0.5149 .... Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.114 was used to detect the id of speaker 4 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 4 ], <feature> feature: [ PSRCC-10 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.114 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[2], feature[MFCC-32], interpreter[shap], shap_value[0.0732])",
    "ref": [
      "Yes Cepstrum which a sha value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Constant-Q Cepstral Coefficients .... Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample .... Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Constant-Q Cepstral Coefficients ....",
      "Yes Cepstrum which a shap value of 0. was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.073 was used to detect the id of speaker  for the audio sample ....",
      "Yes Cepstrum which a shap value of shap was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a 2 value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.073MFCC-32 was used to detect the id of speaker MFCC-32 for the audio sample ....",
      "Yes Cepstrum which a sha value of 0.0732 was used to detect the id of speaker 2 for the audio sample ....",
      "Yes Cepstrum which a shap value of 0.0732 was used to detect the id of speaker 2 for the audio sample ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 2 ], <feature> feature: [ MFCC-32 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0732 ]> )"
  },
  {
    "mr": "inform(response[yes], speaker_id[5], feature[MSRCC-7], interpreter[shap], shap_value[0.0685])",
    "ref": [
      "Yes person 5 was detected by Cepstrum with a MSRCC-7 value of 0.0685 ....",
      "Yes person  was detected by Cepstrum with a shap value of 0.068 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.0685 .... Yes person 5 was detected by Cepstrum with a shap value of 0.0685 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of yes ....",
      "Yes person 5 was detected by Cepstrum with a shap value of  ....",
      "Yes there was more than one CaptureDevice .... Yes person 5 was detected by Cepstrum with a shap value of 0.0685 ....",
      "Yes person 5 was detected by Cepstrum with a  value of 0.0685 ....",
      "Yes there was more than one CaptureDevice ....",
      "Yes person 0.0685 was detected by Cepstrum with a shap value of 0.0680.0685 ....",
      "Yes person 5 was detected by Cepstrum with a MSRCC-7 value of 0.0685 ....",
      "Yes person 5 was detected by Cepstrum with a shap value of 0.0685 ...."
    ],
    "new_mr": "<inform> inform ( <response> response: [ yes ], <speaker_id> speaker id: [ 5 ], <feature> feature: [ MSRCC-7 ], <interpreter> interpreter: [ shap ], <shap_value> shap value: [ 0.0685 ]> )"
  }
]